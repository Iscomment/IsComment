{"aId": 1, "code": "BinaryOperatorNode getSwappedEquivalent() throws StandardException {\n        BinaryOperatorNode newNode = (BinaryOperatorNode) getNodeFactory().getNode(getNodeTypeForSwap(),\n                rightOperand, leftOperand,\n                getContextManager());\n        newNode.setType(getTypeServices());\n        return newNode;\n    }", "comment": " Return an equivalent node with the operands swapped, and possibly with the operator type changed in order to preserve the meaning of the expression.", "issueId": "DERBY-2282", "issueStringList": ["Incorrect \"transitive closure\" logic leads to inconsistent behavior for binary comparison predicates.", "The logic that handles \"transive closure\" for search predicates is in the \"searchClauseTransitiveClosure()\" method of impl/sql/compile/PredicateList.java.", "That method contains the following logic:", "else if (operator instanceof BinaryComparisonOperatorNode)", "{", "BinaryComparisonOperatorNode bcon = (BinaryComparisonOperatorNode) operator;", "ValueNode left = bcon.getLeftOperand();", "ValueNode right = bcon.getRightOperand();", "RESOLVE: Consider using variant type of the expression, instead of", "ConstantNode or ParameterNode in the future.", "if (left instanceof ColumnReference &&", "(right instanceof ConstantNode || right instanceof ParameterNode))", "{", "searchClauses.addElement(predicate);", "}", "else if (right instanceof ConstantNode && left instanceof ColumnReference)", "{", "put the ColumnReference on the left to simplify things", "bcon.swapOperands();", "searchClauses.addElement(predicate);", "}", "continue;", "}", "Notice that the inner \"else-if\" condition is wrong.", "It's supposed to be checking to see if the right node is a ColumnReference and the left node is a Constant, but that's not what it does--instead, it does a check that is really a sub-condition of the \"if\" condition--i.e.", "whenever the \"else if\" condition is true the \"if\" condition will be true and thus we won't ever execute the \"else if\" branch.", "I confirmed this by looking at the code coverage results for 10.2:", "http://people.apache.org/~fuzzylogic/codecoverage/428586/_files/2f4.html#2d", "The lines in question are never executed.", "What this means is that a query which specifies constants on the *left* side of a comparison predicate will behave differently than a query which specifies constants on the *right* side of the same comparison.", "As an example:", "create table t1 (i int);", "create table t2 (j int);", "insert into t1 values 1, 5, 7, 11, 13, 17, 19;", "insert into t2 values 23, 29, 31, 37, 43, 47, 53;", "insert into t1 select 23 * i from t1 where i < 19;", "insert into t2 select 23 * j from t2 where j < 55;", "Following will show two qualifiers for T2 and three for T1", "because transitive closure adds two new qualifiers, \"t2.j >= 23\"", "and \"t1.i <= 30\" to the list.", "select * from t1, t2 where t1.i = t2.j and t1.i >= 23 and t2.j <= 30;", "But if we put the constants on the left-hand side, we don't", "detect the transitive closure and thus we have a single qualifier", "for T2 and only two qualifiers for T1.", "select * from t1, t2 where t1.i = t2.j and 23 <= t1.i and 30 >= t2.j;", "The above two queries should in theory show the same query plan--but if we execute the above statements while logging query plans, we'll see a difference (as explained in the sql comments above).", "I did a quick scan of the various branches and found that this incorrect logic appears in every branch back to 10.0 (hence the massive \"Affects Versions\" list).", "That said, the result of this bug isn't an error nor is it wrong results, so I'm just marking it \"Minor\".", "The fix looks to be pretty straightforward....", "Triaged for 10.5.2: assigned normal urgency, noted that a repro is attached, flagged as wrong query result.", "Removed wrong query result flag since the bug doesn't cause wrong results, it only produces a suboptimal plan.", "Also flagged \"known fix\" since the bug description explains how to fix the broken logic.", "I'm assuming that the straightforward fix mentioned in the bug description is to swap left and right in the broken else if branch.", "But if we do that the second query starts returning an empty result (it's supposed to return one row).", "I believe this is because BinaryOperatorNode.swapOperands() only swaps the operands and doesn't actually turn the operator around.", "This means 23 <= t1.i is rewritten to t1.i <= 23, which is not an equivalent expression.", "The attachement test.diff contains a JUnit test that I used to test it.", "Right now, it fails because the second query's plan doesn't have the expected operators.", "If left and right are swapped in the broken if clause, it fails because the query returns wrong results.", "Here's a patch that addresses the issue by changing the else-if condition as suggested, and by swapping the operands and changing the operator type if necessary.", "The method BinaryOperatorNode.swapOperands(), which only works if the operator is symmetric, is no longer used, and it is therefore removed.", "Instead, a new method called getSwappedEquivalent() (in the lack of a better name, other suggestions are welcome) was added to BinaryComparisonOperatorNode.", "This method is modelled after getNegation() and creates a new node with the left and right operands swapped, and it changes the operator type to preserve the meaning of the expression (< is changed to >, = is kept as it is, >= is changed to <=, etc).", "All the regression tests ran cleanly.", "The check for constants on the right side of the operator check for both ConstantNode and ParameterNode, whereas the check for constants on the left side check for ConstantNode only.", "Should the else-if condition also check for ParameterNode for completeness?", "(< is changed to >, = is kept as it is, >= is changed to <=, etc)", "getInverseNode()?", "getReverseNode()?", "getEquivalentNodeWithSwappedOperands() seems far too long :)", "I think that getSwappedEquivalent is a pretty good name, actually.", "Thanks for the suggestions, Bryan.", "getReverseNode() sounds like a good alternative.", "I'm not sure about getInverseNode(), since \"invert\" is an overloaded term (it is sometimes even used as a synonym for \"negate\", which is the opposite of what we're doing here).", "I think I'll stick to getSwappedEquivalent() for now, since it highlights both that we swap the operands and that the returned node should be equivalent to the node on which it is being called.", "But I'm sure there must be a technical term for this transformation...", "Is this a duplicate of DERBY-813?", "Yes, I believe it is.", "Since DERBY-813 is a sub-task of a closed issue, it's probably best to close the sub-task and continue the work on this top-level issue.", "I committed the 1a patch to trunk with revision 887156.", "Regarding my previous comment about checking for ParameterNode as well, I see that it's also mentioned by Satheesh in DERBY-813.", "I will prepare a follow-up patch which handles ParameterNode and adds a test for that case.", "+1, would be nice to handle the ParameterNode case as well :) Patch looks good."], "SplitGT": [" Return an equivalent node with the operands swapped, and possibly with the operator type changed in order to preserve the meaning of the expression."], "issueString": "Incorrect \"transitive closure\" logic leads to inconsistent behavior for binary comparison predicates.\nThe logic that handles \"transive closure\" for search predicates is in the \"searchClauseTransitiveClosure()\" method of impl/sql/compile/PredicateList.java.  That method contains the following logic:\n\n            else if (operator instanceof BinaryComparisonOperatorNode)\n            {\n                BinaryComparisonOperatorNode bcon = (BinaryComparisonOperatorNode) operator;\n                ValueNode left = bcon.getLeftOperand();\n                ValueNode right = bcon.getRightOperand();\n\n                // RESOLVE: Consider using variant type of the expression, instead of\n                // ConstantNode or ParameterNode in the future.\n                if (left instanceof ColumnReference && \n                      (right instanceof ConstantNode || right instanceof ParameterNode))\n                {\n                    searchClauses.addElement(predicate);\n                }\n                else if (right instanceof ConstantNode && left instanceof ColumnReference)\n                {\n                    // put the ColumnReference on the left to simplify things\n                    bcon.swapOperands();\n                    searchClauses.addElement(predicate);\n                }\n                continue;\n            }\n\nNotice that the inner \"else-if\" condition is wrong.  It's supposed to be checking to see if the right node is a ColumnReference and the left node is a Constant, but that's not what it does--instead, it does a check that is really a sub-condition of the \"if\" condition--i.e. whenever the \"else if\" condition is true the \"if\" condition will be true and thus we won't ever execute the \"else if\" branch.\n\nI confirmed this by looking at the code coverage results for 10.2:\n\n  http://people.apache.org/~fuzzylogic/codecoverage/428586/_files/2f4.html#2d\n\nThe lines in question are never executed.\n\nWhat this means is that a query which specifies constants on the *left* side of a comparison predicate will behave differently than a query which specifies constants on the *right* side of the same comparison.  As an example:\n\ncreate table t1 (i int);\ncreate table t2 (j int);\n\ninsert into t1 values 1, 5, 7, 11, 13, 17, 19;\ninsert into t2 values 23, 29, 31, 37, 43, 47, 53;\ninsert into t1 select 23 * i from t1 where i < 19;\ninsert into t2 select 23 * j from t2 where j < 55;\n\n-- Following will show two qualifiers for T2 and three for T1\n-- because transitive closure adds two new qualifiers, \"t2.j >= 23\"\n-- and \"t1.i <= 30\" to the list.\nselect * from t1, t2 where t1.i = t2.j and t1.i >= 23 and t2.j <= 30;\n\n-- But if we put the constants on the left-hand side, we don't\n-- detect the transitive closure and thus we have a single qualifier\n-- for T2 and only two qualifiers for T1.\nselect * from t1, t2 where t1.i = t2.j and 23 <= t1.i and 30 >= t2.j;\n\nThe above two queries should in theory show the same query plan--but if we execute the above statements while logging query plans, we'll see a difference (as explained in the sql comments above).\n\nI did a quick scan of the various branches and found that this incorrect logic appears in every branch back to 10.0 (hence the massive \"Affects Versions\" list).  That said, the result of this bug isn't an error nor is it wrong results, so I'm just marking it \"Minor\".\n\nThe fix looks to be pretty straightforward....\nTriaged for 10.5.2: assigned normal urgency, noted that a repro is attached, flagged as wrong query result.\nRemoved wrong query result flag since the bug doesn't cause wrong results, it only produces a suboptimal plan. Also flagged \"known fix\" since the bug description explains how to fix the broken logic.\nI'm assuming that the straightforward fix mentioned in the bug description is to swap left and right in the broken else if branch. But if we do that the second query starts returning an empty result (it's supposed to return one row). I believe this is because BinaryOperatorNode.swapOperands() only swaps the operands and doesn't actually turn the operator around. This means 23 <= t1.i is rewritten to t1.i <= 23, which is not an equivalent expression.\nThe attachement test.diff contains a JUnit test that I used to test it. Right now, it fails because the second query's plan doesn't have the expected operators. If left and right are swapped in the broken if clause, it fails because the query returns wrong results.\nHere's a patch that addresses the issue by changing the else-if condition as suggested, and by swapping the operands and changing the operator type if necessary.\n\nThe method BinaryOperatorNode.swapOperands(), which only works if the operator is symmetric, is no longer used, and it is therefore removed. Instead, a new method called getSwappedEquivalent() (in the lack of a better name, other suggestions are welcome) was added to BinaryComparisonOperatorNode. This method is modelled after getNegation() and creates a new node with the left and right operands swapped, and it changes the operator type to preserve the meaning of the expression (< is changed to >, = is kept as it is, >= is changed to <=, etc).\n\nAll the regression tests ran cleanly.\nThe check for constants on the right side of the operator check for both ConstantNode and ParameterNode, whereas the check for constants on the left side check for ConstantNode only. Should the else-if condition also check for ParameterNode for completeness?\n   (< is changed to >, = is kept as it is, >= is changed to <=, etc)\n\ngetInverseNode()?      getReverseNode()?  \n\ngetEquivalentNodeWithSwappedOperands() seems far too long :)\n\nI think that getSwappedEquivalent is a pretty good name, actually.\nThanks for the suggestions, Bryan. getReverseNode() sounds like a good alternative. I'm not sure about getInverseNode(), since \"invert\" is an overloaded term (it is sometimes even used as a synonym for \"negate\", which is the opposite of what we're doing here). I think I'll stick to getSwappedEquivalent() for now, since it highlights both that we swap the operands and that the returned node should be equivalent to the node on which it is being called. But I'm sure there must be a technical term for this transformation...\nIs this a duplicate of DERBY-813?\nYes, I believe it is. Since DERBY-813 is a sub-task of a closed issue, it's probably best to close the sub-task and continue the work on this top-level issue.\nI committed the 1a patch to trunk with revision 887156.\n\nRegarding my previous comment about checking for ParameterNode as well, I see that it's also mentioned by Satheesh in DERBY-813. I will prepare a follow-up patch which handles ParameterNode and adds a test for that case.\n+1, would be nice to handle the ParameterNode case as well :) Patch looks good.\n", "issueSearchSentences": ["But if we do that the second query starts returning an empty result (it's supposed to return one row).", "Here's a patch that addresses the issue by changing the else-if condition as suggested, and by swapping the operands and changing the operator type if necessary.", "getEquivalentNodeWithSwappedOperands() seems far too long :)", "I'm assuming that the straightforward fix mentioned in the bug description is to swap left and right in the broken else if branch.", "The method BinaryOperatorNode.swapOperands(), which only works if the operator is symmetric, is no longer used, and it is therefore removed."], "issueSearchIndexes": [54, 60, 70, 53, 61]}
{"aId": 8, "code": "public  String  statementText() { return _statementText; }", "comment": " Return the text of the statement which invoked the table function", "issueId": "DERBY-6117", "issueStringList": ["Extend the Table Functions java interface to pass more query context information from Derby", "General requirement is to extend the Table Functions java interface (through RestrictedVTI or another interface) and pass more context information from Derby to Table Functions - esp in query execution phase.", "Greater urgency is required for the first 2 items below, especially the ability to access the original SQL which was available with VTIs.", "This is critical to the GaianDB project - we extract HINTs from the query (where we pass meta data like user credentials), and also extract full original complex predicate expressions (involving functions etc - which cannot be expressed with a Restriction) - to push on in our query prorogation...", "In order of importance + simplicity:", "1 - Original SQL (this used to be available with VTIs through VTIEnvironment for both compilation and execution phases)", "2 - Name of function that was called", "3 - User Info (ID, etc) - (this can currently be passed in the SQL hint)", "4 - Richer predicate expressions (incl functions, etc)", "5 - Context within Join query (e.g.", "inner or outer table, join type)", "6 - Other Query Plan information", "7 - Anything else...?", "Original forum discussion:", "http://apache-database.10148.n7.nabble.com/Limitations-of-Table-Functions-vs-old-VTIs-td127988.html#a127995", "i agree with all above, especially the name of the function called.", "adding information from", "https://issues.apache.org/jira/browse/DERBY-6115", "1) derby should support passing IN to initScan", "2) derby should transform IN to an OR clause as a work around to not passing down IN scan", "3) function should have access to information about the function's return type, i.e.", "the if the result type is a table definition, function should have access to that definition.", "this is necessary when a function is declared with multiple names and return types.", "for example, with foreign table loads, we want to pre-transform data from remote result set in 1 thread, then hand to derby thread.", "we need to know what the main derby thread reading resultset wants in sqltype for each column.", "4) derby should introspect resultset to see which column names are searchable, and thus, fast for querying,  perhaps isSearchable on ResultSetMetaData is the right / wrong thing to do.", "maybe can do this with VTIConsting ?", "5) derby should do multi-probe on vti function if vti function indicates on a metaData that isSearchable is true, or that it implements perfectly the initscan restriction.", "6) vti function should be able to tell derby that it correctly implements the vti restriction, either for a given one, or for any, and derby should not request the column in initscan columnNames, and derby  should not check again the restriction.", "( for example, assume foreign table with username and picture as BLOB) , a query for select username where picture is not null, currently, derby will pass select username and picture as columnnames, and function will have to pull all the username and blob data and hand to derby, just to allow derby to check again is not null, even though function already did this .", "This is a HUGE performance issue we are experiencing.", "i'm sure i'll have more issues to add :)", "Note that part of item (3) can be obtained by calling DriverManager.getConnection( \"jdbc:default:connection\" ) in order to get the connection and then executing a \"values current_user\" statement.", "\ufeff\ufeffAttaching derby-6117-01-aa-AwareVTI.diff.", "This patch introduces the AwareVTI interface.", "This is a first step toward giving table functions more context about their execution environments.", "I am running tests now.", "Introduces two new classes/interfaces:", "o VTIContext - This is a simple class which contains the following information:", "The name of the schema holding the table function.", "The non-schema-qualified name of the table function.", "The text of the statement invoking the table function.", "o AwareVTI - Table functions which implement this interface are handed the VTIContext describing their execution environment.", "VTITemplate now implements AwareVTI so most table functions will get this functionality for free.", "VTIContext exposes the following methods:", "{noformat}", "public  String  vtiSchema() { return _vtiSchema; }", "public  String  vtiTable()  { return _vtiTable; }", "public  String  statementText() { return _statementText; }", "{noformat}", "AwareVTI contains these method:", "{noformat}", "public  VTIContext  getContext();", "public  void    setContext( VTIContext context );", "{noformat}", "Touches the following files:", "A       java/engine/org/apache/derby/vti/VTIContext.java", "A       java/engine/org/apache/derby/vti/AwareVTI.java", "M       java/engine/org/apache/derby/vti/VTITemplate.java", "Introduces the new classes and wires them into most existing table functions.", "M       java/engine/org/apache/derby/iapi/sql/execute/ResultSetFactory.java", "M       java/engine/org/apache/derby/impl/sql/compile/MethodCallNode.java", "M       java/engine/org/apache/derby/impl/sql/compile/FromVTI.java", "M       java/engine/org/apache/derby/impl/sql/compile/StaticMethodCallNode.java", "M       java/engine/org/apache/derby/impl/sql/execute/GenericResultSetFactory.java", "M       java/engine/org/apache/derby/impl/sql/execute/VTIResultSet.java", "Compile-time and execution-time machinery to support VTIContext.", "A       java/testing/org/apache/derbyTesting/functionTests/tests/lang/AwareVTITest.java", "A       java/testing/org/apache/derbyTesting/functionTests/tests/lang/DummyAwareVTI.java", "M       java/testing/org/apache/derbyTesting/functionTests/tests/lang/_Suite.java", "Basic tests for this new feature.", "M       tools/javadoc/publishedapi.ant", "Adds AwareVTI and VTIContext to the public api.", "Attaching derby-6117-01-ab-AwareVTI.diff.", "This fixes an NPE during compilation of old-style VTIs, introduced by the previous rev of the patch.", "Re-starting the tests.", "Touches the same files as the previous rev.", "Tests passed cleanly for me on derby-6117-01-ab-AwareVTI.diff except for the query plan instability recently introduced into org.apache.derbyTesting.functionTests.tests.lang.SelectivityTest by other work."], "SplitGT": [" Return the text of the statement which invoked the table function"], "issueString": "Extend the Table Functions java interface to pass more query context information from Derby\nGeneral requirement is to extend the Table Functions java interface (through RestrictedVTI or another interface) and pass more context information from Derby to Table Functions - esp in query execution phase.\n\nGreater urgency is required for the first 2 items below, especially the ability to access the original SQL which was available with VTIs. This is critical to the GaianDB project - we extract HINTs from the query (where we pass meta data like user credentials), and also extract full original complex predicate expressions (involving functions etc - which cannot be expressed with a Restriction) - to push on in our query prorogation...\n\nIn order of importance + simplicity:\n--------------------------------------------------\n1 - Original SQL (this used to be available with VTIs through VTIEnvironment for both compilation and execution phases)\n2 - Name of function that was called\n\n3 - User Info (ID, etc) - (this can currently be passed in the SQL hint)\n4 - Richer predicate expressions (incl functions, etc)\n5 - Context within Join query (e.g. inner or outer table, join type)\n6 - Other Query Plan information\n7 - Anything else...?\n\nOriginal forum discussion:\nhttp://apache-database.10148.n7.nabble.com/Limitations-of-Table-Functions-vs-old-VTIs-td127988.html#a127995\ni agree with all above, especially the name of the function called.\n\nadding information from\n\nhttps://issues.apache.org/jira/browse/DERBY-6115\n\n1) derby should support passing IN to initScan\n2) derby should transform IN to an OR clause as a work around to not passing down IN scan\n3) function should have access to information about the function's return type, i.e. the if the result type is a table definition, function should have access to that definition.  this is necessary when a function is declared with multiple names and return types.  for example, with foreign table loads, we want to pre-transform data from remote result set in 1 thread, then hand to derby thread.  we need to know what the main derby thread reading resultset wants in sqltype for each column. \n4) derby should introspect resultset to see which column names are searchable, and thus, fast for querying,  perhaps isSearchable on ResultSetMetaData is the right / wrong thing to do.  maybe can do this with VTIConsting ?\n5) derby should do multi-probe on vti function if vti function indicates on a metaData that isSearchable is true, or that it implements perfectly the initscan restriction.\n6) vti function should be able to tell derby that it correctly implements the vti restriction, either for a given one, or for any, and derby should not request the column in initscan columnNames, and derby  should not check again the restriction. ( for example, assume foreign table with username and picture as BLOB) , a query for select username where picture is not null, currently, derby will pass select username and picture as columnnames, and function will have to pull all the username and blob data and hand to derby, just to allow derby to check again is not null, even though function already did this .  This is a HUGE performance issue we are experiencing.  \n\ni'm sure i'll have more issues to add :)\nNote that part of item (3) can be obtained by calling DriverManager.getConnection( \"jdbc:default:connection\" ) in order to get the connection and then executing a \"values current_user\" statement.\n\ufeff\ufeffAttaching derby-6117-01-aa-AwareVTI.diff. This patch introduces the AwareVTI interface. This is a first step toward giving table functions more context about their execution environments. I am running tests now.\n\nIntroduces two new classes/interfaces:\n\no VTIContext - This is a simple class which contains the following information:\n\n  - The name of the schema holding the table function.\n  - The non-schema-qualified name of the table function.\n  - The text of the statement invoking the table function.\n\no AwareVTI - Table functions which implement this interface are handed the VTIContext describing their execution environment.\n\nVTITemplate now implements AwareVTI so most table functions will get this functionality for free.\n\nVTIContext exposes the following methods:\n\n{noformat}\n    /** Return the name of the schema holding the table function */\n    public  String  vtiSchema() { return _vtiSchema; }\n\n    /** Return the unqualified table function name */\n    public  String  vtiTable()  { return _vtiTable; }\n\n    /** Return the text of the statement which invoked the table function */\n    public  String  statementText() { return _statementText; }\n{noformat}\n\nAwareVTI contains these method:\n\n{noformat}\n    /** Get the table function context */\n    public  VTIContext  getContext();\n\n    /** Set the table function context */\n    public  void    setContext( VTIContext context );\n{noformat}\n\n\n\nTouches the following files:\n\n----------------\n\nA       java/engine/org/apache/derby/vti/VTIContext.java\nA       java/engine/org/apache/derby/vti/AwareVTI.java\nM       java/engine/org/apache/derby/vti/VTITemplate.java\n\nIntroduces the new classes and wires them into most existing table functions.\n\n----------------\n\nM       java/engine/org/apache/derby/iapi/sql/execute/ResultSetFactory.java\nM       java/engine/org/apache/derby/impl/sql/compile/MethodCallNode.java\nM       java/engine/org/apache/derby/impl/sql/compile/FromVTI.java\nM       java/engine/org/apache/derby/impl/sql/compile/StaticMethodCallNode.java\nM       java/engine/org/apache/derby/impl/sql/execute/GenericResultSetFactory.java\nM       java/engine/org/apache/derby/impl/sql/execute/VTIResultSet.java\n\nCompile-time and execution-time machinery to support VTIContext.\n\n----------------\n\nA       java/testing/org/apache/derbyTesting/functionTests/tests/lang/AwareVTITest.java\nA       java/testing/org/apache/derbyTesting/functionTests/tests/lang/DummyAwareVTI.java\nM       java/testing/org/apache/derbyTesting/functionTests/tests/lang/_Suite.java\n\nBasic tests for this new feature.\n\n----------------\n\nM       tools/javadoc/publishedapi.ant\n\nAdds AwareVTI and VTIContext to the public api.\n\nAttaching derby-6117-01-ab-AwareVTI.diff. This fixes an NPE during compilation of old-style VTIs, introduced by the previous rev of the patch. Re-starting the tests.\n\nTouches the same files as the previous rev.\n\nTests passed cleanly for me on derby-6117-01-ab-AwareVTI.diff except for the query plan instability recently introduced into org.apache.derbyTesting.functionTests.tests.lang.SelectivityTest by other work.\n", "issueSearchSentences": ["public  String  vtiTable()  { return _vtiTable; }", "{noformat}", "public  String  vtiSchema() { return _vtiSchema; }", "{noformat}", "public  VTIContext  getContext();"], "issueSearchIndexes": [48, 46, 47, 52, 53]}
{"aId": 11, "code": "private static String buildJvmVersion () {\n        return (String)AccessController.doPrivileged( new PrivilegedAction()\n        {\n           public Object run()\n           {      \n             String jvmversion = \"\";\n             try {\n                 String currentProp  = PropertyUtil.getSystemProperty(\"java.vendor\");\n                 if ( currentProp != null)\n                     jvmversion = \"java.vendor=\" + currentProp;\n                 if ((currentProp = PropertyUtil.getSystemProperty(\"java.runtime.version\")) != null)\n                     jvmversion += \"\\njava.runtime.version=\" + currentProp;\n                 if ((currentProp = PropertyUtil.getSystemProperty(\"java.fullversion\")) != null)\n                     jvmversion += \"\\njava.fullversion=\" + currentProp ;         \n              }\n              catch (SecurityException se) {\n                   return se.getMessage();\n              }\n              return jvmversion;\n            }\n        });\n    }", "comment": " Return values of system properties that identify the JVM.", "issueId": "DERBY-4715", "issueStringList": ["Write jvm information and path of derby.jar to derby.log", "The bug is part of DERBY-1272.", "In production environment, derby.jar can be located different than the derbyclient.jar It can be easier if we have jvm version information and path of derby.jar are in the derby.log", "Write java vendor, java runtime version and java fullversion, the path of derby.jar to derby.log.", "Please review regarding:", "1.", "Does the output looks okay?", "2.", "Whether this will create too long of output for derby.log in general.", "Here is a sample of how derby.log looks now:", "2010-07-01 21:38:01.173 GMT:", "Booting Derby version The Apache Software Foundation - Apache Derby - 10.7.0.0 al", "pha - (959745M): instance a816c00e-0129-8ff1-e2bd-000000132a78", "on database directory sun.misc.Launcher$AppClassLoader@69ba69ba  with class loader", "C:\\derby\\trunk\\testtmp\\test", "Loaded from C:\\derby\\trunk\\jars\\sane\\derby.jar", "java.vendor=IBM Corporation java.runtime.version=pwi32dev-20090707 (SR10 ) J2RE 1.", "5.0 IBM J9 2.3 Windows Vista x86-32 j9vmwi3223-20090707 (JIT enabled)", "J9VM - 20090706_38445_lHdSMr", "JIT  - 20090623_1334_r8", "GC   - 200906_09java.fullversion=J2RE 1.5.0 IBM J9 2.3 Windows Vista x86-32 j9vmwi", "3223-20090707 (JIT enabled)", "J9VM - 20090706_38445_lHdSMr", "JIT  - 20090623_1334_r8", "GC   - 200906_09", "^M", "Database Class Loader started - derby.database.classpath=''^M", "The tests passed on derbyall and Suites.allpackages", "Hi Lily,", "Could you make sure something reasonable happens if there is no permission in the policy file for reading the system properties, getting the source location etc.", "We should still boot and communicate that there is not sufficient permission to report the information  but not in an alarming way.", "Thanks to Kathey.", "DERBY-4715-2.diff patch will boot and communicate there is not sufficient permission to derby.log for derby.jar.", "If there is no permission for print out java.runtime.version or java.fullversion, there will only print java vendor information to derby.log", "Suites.all test is passed.", "It is running derbyall test suite.", "Please review the patch", "derbyall test passed with the patch too.", "Thanks to Kathey for point out BaseDataFileFactory.buildJvmVersion should use AccessController.doPrivileged to handle derby under a security manager.", "I check the derby.log to make sure boot and communicate that there is not sufficient permission to report the information for derby.jar and java version.", "Suites.all test suite passed.", "I am running derbyall now.", "derbyall suites run clean too.", "Granting permissions to Derby need some write up for runtime permission on getProtectionDomain and maybe for PropertyPermission on java.runtime.version and java.fullversion.", "I will issue another JIRA to address the documentation issue relate to this JIRA.", "Thanks Bryan for catching that.", "Do you see any potential issue with the patch?", "I think the patch looks good; the format of the message is OK by me.", "The new utility methods in BaseDataFileFactory seem very useful,", "but it doesn't seem quite right to place them in BaseDataFileFactory.", "It seems like maybe they should go into a package like", "org.apache.derby.iapi.util.", "Perhaps we need a UriUtil class there?", "A couple comments in addition to what Bryan said:", "The methods jarClassPath() and buildJvmVersion() have different indentation than the other methods.", "If formatURL() gets an IOException, it returns the string \"IOException\".", "Perhaps it should also return the exception's message text?", "I don't follow all the logic in formatURL().", "Could you add some comments that explain the various transformations?", "In my environment, just printing what URL.toString() returns gives clear enough information:", "file:/code/derby/trunk0/classes/ or", "file:/code/derby/trunk0/jars/sane/derby.jar", "For readability, I think it would be better to separate the properties with a newline character instead of a space.", "The comments in the policy files say \"Add for DERBY-4715\".", "I think it would be better if they said why the permission was needed since we include them as templates in the distribution and refer to them from the documentation[1], so they are expected to be read by users.", "Perhaps something like \"getProtectionDomain is an optional permission needed for printing classpath information to derby.log.\"", "In server.policy and template.policy, the new permission is added in the section that is labeled \"These permissions are needed for everyday, embedded Derby usage.\"", "My understanding of the patch is that the new permission is optional, and embedded Derby will work fine without it, it just won't print the classpath to derby.log.", "If it's so, I'd suggest moving it to a less prominent section of the policy files.", "Similarly, in AssertFailureTest.policy, the permission is added under the label \"These are the ones that matter\", but AssertFailureTest runs fine without it.", "[1] http://db.apache.org/derby/docs/dev/adminguide/tadminnetservcustom.html", "I have not looked at the updated patch yet, but I know that sometimes it is tempting to put methods requiring permissions in public methods of utility classes, but it is generally not a good idea to do so as it allows external users to access those permissions granted to Derby.", "Regarding the public methods in utility classes, I think it is fine to create (and use them) if they add value, but the utility method should not include the call to doPrivileged.", "Instead, the calling code (which is hopefully not easily accessible and controllable for external users) should call the utility method inside a doPrivileged-block.", "The above approach isn't as compact, but Kathey is right that adding public (static) utility methods with doPrivileged-blocks is dangerous.", "Thanks Knut, Kathey and Kristian for all the commets.", "I made the following changes and attach DERBY-4715-4.diff patch for review.", "Comments:", "The methods jarClassPath() and buildJvmVersion() have different indentation than the other methods.", "Changes according to the current file indentation.", "Right now, the method starts at space 5 while the context starts at space 9.", "If formatURL() gets an IOException, it returns the string \"IOException\".", "Perhaps it should also return the exception's message text?", "It will be return message text for IOException now.", "I don't follow all the logic in formatURL().", "Could you add some comments that explain the various transformations?", "In my environment, just printing what URL.toString() returns gives clear enough information:", "file:/code/derby/trunk0/classes/ or", "file:/code/derby/trunk0/jars/sane/derby.jar", "Great point.", "I always believe coding less is better.", "Use URL.toString() in the code.", "For readability, I think it would be better to separate the properties with a newline character instead of a space.", "The property is separated by a newline instead of a space.", "The comments in the policy files say \"Add for DERBY-4715\".", "I think it would be better if they said why the permission was needed since we include them as templates in the distribution and refer to them from the documentation[1], so they are expected to be read by users.", "Perhaps something like \"getProtectionDomain is an optional permission needed for printing classpath information to derby.log.\"", "All the comment relate to java.lang.RuntimePermission is using this comment.", "In server.policy and template.policy, the new permission is added in the section that is labeled \"These permissions are needed for everyday, embedded Derby usage.\"", "My understanding of the patch is that the new permission is optional, and embedded Derby will work fine without it, it just won't print the classpath to derby.log.", "If it's so, I'd suggest moving it to a less prominent section of the policy files.", "Put the java.lang.RuntimePermission \"getProtectionDomain\" and the comment in its own section", "Similarly, in AssertFailureTest.policy, the permission is added under the label \"These are the ones that matter\", but AssertFailureTest runs fine without it.", "Make similar change as above and place in less prominent section.", "Regarding the public methods in utility classes, there are two new methods - jarClassPatha and buildJvmVersion after removing formatUrl() in BaseDataFileFactory.java.", "They are not so generic to be used or provide a lot of value in the utility classes.", "I am running tests against this patch now.", "Thanks for making these improvements, Lily.", "A couple more comments to the latest patch:", "The javadoc for jarClassPath() is a little unclear.", "I don't understand what's meant by \"the path of string\" or by \"the string of jar file\".", "The javadoc for buildJvmVersion() should make it clear that it returns values of system properties that identify the JVM.", "buildJvmVersion() has a @param tag, but the method has no parameters.", "Now that we add a newline character between each property, there's no need to append \" \" (one space) to each property value.", "If jarClassPath() had taken a Class argument instead of a String argument, and we called it like \"jarCPath = jarClassPath(getClass());\", there would be no need to call Class.forName(), and we could remove the catch block for ClassNotFoundException.", "Thanks Knut for reviewing the patch.", "I make the following changes in DERBY-4715-5.diff", "The javadoc for jarClassPath() is a little unclear.", "I don't understand what's meant by \"the path of string\" or by \"the string of jar file\".", "javadoc is changed.", "I am using similar comment from Main.java.", "Hope it is clearer now.", "The javadoc for buildJvmVersion() should make it clear that it returns values of system properties that identify the JVM.", "Add this to the javadoc on buildJvmVersion()", "buildJvmVersion() has a @param tag, but the method has no parameters.", "It is not there any more.", "Now that we add a newline character between each property, there's no need to append \" \" (one space) to each property value.", "Great catch.", "Change to not append \" \".", "If jarClassPath() had taken a Class argument instead of a String argument, and we called it like \"jarCPath = jarClassPath(getClass());\", there would be no need to call Class.forName(), and we could remove the catch block for ClassNotFoundException.", "After using getClass() to get the class instance for the BaseDataFileFactory class which is also in derby.jar, no need to call Class.forName() and catch block for ClassNotFoundException.", "Please review the change.", "I am running tests now.", "Thanks, Lily.", "The latest patch looks fine to me.", "Thank you, Knut.", "Yeah!", "Suites.all and derbyall seem to run fine except:", "1) ttestSetPortPriority(org.apache.derbyTesting.functionTests.tests.derbynet.Serve", "rPropertiesTest)junit.framework.AssertionFailedError: Port 1537 exceeeds expected", "maximum.", "You may need to update TestConfiguration.MAX_PORTS_USED and the Wiki page", "at http://wiki.apache.org/db-derby/DerbyJUnitTesting if test runs now require mor", "e available ports", "at org.apache.derbyTesting.junit.TestConfiguration.getNextAvailablePort(Te", "stConfiguration.java:1413)", "at org.apache.derbyTesting.functionTests.tests.derbynet.ServerPropertiesTe", "st.ttestSetPortPriority(ServerPropertiesTest.java:445)", "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)", "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.ja", "va:48)", "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccesso", "rImpl.java:37)", "at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:10", "9)", "at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)", "This failure is a known issue by the group.", "DERBY-4715-5.diff is ready to submit.", "Thanks Lily, I will commit first thing Monday if your account does not come through by then."], "SplitGT": [" Return values of system properties that identify the JVM."], "issueString": "Write jvm information and path of derby.jar to derby.log\nThe bug is part of DERBY-1272. In production environment, derby.jar can be located different than the derbyclient.jar It can be easier if we have jvm version information and path of derby.jar are in the derby.log\nWrite java vendor, java runtime version and java fullversion, the path of derby.jar to derby.log. Please review regarding:\n1. Does the output looks okay?\n2. Whether this will create too long of output for derby.log in general.\n\nHere is a sample of how derby.log looks now:\n2010-07-01 21:38:01.173 GMT:\n Booting Derby version The Apache Software Foundation - Apache Derby - 10.7.0.0 al\npha - (959745M): instance a816c00e-0129-8ff1-e2bd-000000132a78\non database directory sun.misc.Launcher$AppClassLoader@69ba69ba  with class loader\n C:\\derby\\trunk\\testtmp\\test\nLoaded from C:\\derby\\trunk\\jars\\sane\\derby.jar\njava.vendor=IBM Corporation java.runtime.version=pwi32dev-20090707 (SR10 ) J2RE 1.\n5.0 IBM J9 2.3 Windows Vista x86-32 j9vmwi3223-20090707 (JIT enabled)\nJ9VM - 20090706_38445_lHdSMr\nJIT  - 20090623_1334_r8\nGC   - 200906_09java.fullversion=J2RE 1.5.0 IBM J9 2.3 Windows Vista x86-32 j9vmwi\n3223-20090707 (JIT enabled)\nJ9VM - 20090706_38445_lHdSMr\nJIT  - 20090623_1334_r8\nGC   - 200906_09\n^M\nDatabase Class Loader started - derby.database.classpath=''^M\nThe tests passed on derbyall and Suites.allpackages\nHi Lily,\n\nCould you make sure something reasonable happens if there is no permission in the policy file for reading the system properties, getting the source location etc.   We should still boot and communicate that there is not sufficient permission to report the information  but not in an alarming way.\n \nThanks to Kathey. DERBY-4715-2.diff patch will boot and communicate there is not sufficient permission to derby.log for derby.jar. If there is no permission for print out java.runtime.version or java.fullversion, there will only print java vendor information to derby.log \n\nSuites.all test is passed. It is running derbyall test suite. Please review the patch\nderbyall test passed with the patch too.\nThanks to Kathey for point out BaseDataFileFactory.buildJvmVersion should use AccessController.doPrivileged to handle derby under a security manager.\nI check the derby.log to make sure boot and communicate that there is not sufficient permission to report the information for derby.jar and java version. \n\nSuites.all test suite passed. I am running derbyall now.\nderbyall suites run clean too. Granting permissions to Derby need some write up for runtime permission on getProtectionDomain and maybe for PropertyPermission on java.runtime.version and java.fullversion. I will issue another JIRA to address the documentation issue relate to this JIRA. \nThanks Bryan for catching that. Do you see any potential issue with the patch?\nI think the patch looks good; the format of the message is OK by me.\n\nThe new utility methods in BaseDataFileFactory seem very useful,\nbut it doesn't seem quite right to place them in BaseDataFileFactory.\nIt seems like maybe they should go into a package like\norg.apache.derby.iapi.util. Perhaps we need a UriUtil class there?\nA couple comments in addition to what Bryan said:\n\n- The methods jarClassPath() and buildJvmVersion() have different indentation than the other methods.\n\n- If formatURL() gets an IOException, it returns the string \"IOException\". Perhaps it should also return the exception's message text?\n\n- I don't follow all the logic in formatURL(). Could you add some comments that explain the various transformations? In my environment, just printing what URL.toString() returns gives clear enough information:\n\nfile:/code/derby/trunk0/classes/ or\nfile:/code/derby/trunk0/jars/sane/derby.jar\n\n- For readability, I think it would be better to separate the properties with a newline character instead of a space.\n\n- The comments in the policy files say \"Add for DERBY-4715\". I think it would be better if they said why the permission was needed since we include them as templates in the distribution and refer to them from the documentation[1], so they are expected to be read by users. Perhaps something like \"getProtectionDomain is an optional permission needed for printing classpath information to derby.log.\"\n\n- In server.policy and template.policy, the new permission is added in the section that is labeled \"These permissions are needed for everyday, embedded Derby usage.\" My understanding of the patch is that the new permission is optional, and embedded Derby will work fine without it, it just won't print the classpath to derby.log. If it's so, I'd suggest moving it to a less prominent section of the policy files.\n\n- Similarly, in AssertFailureTest.policy, the permission is added under the label \"These are the ones that matter\", but AssertFailureTest runs fine without it.\n\n[1] http://db.apache.org/derby/docs/dev/adminguide/tadminnetservcustom.html\nI have not looked at the updated patch yet, but I know that sometimes it is tempting to put methods requiring permissions in public methods of utility classes, but it is generally not a good idea to do so as it allows external users to access those permissions granted to Derby.\n\n\nRegarding the public methods in utility classes, I think it is fine to create (and use them) if they add value, but the utility method should not include the call to doPrivileged. Instead, the calling code (which is hopefully not easily accessible and controllable for external users) should call the utility method inside a doPrivileged-block.\nThe above approach isn't as compact, but Kathey is right that adding public (static) utility methods with doPrivileged-blocks is dangerous.\nThanks Knut, Kathey and Kristian for all the commets.\nI made the following changes and attach DERBY-4715-4.diff patch for review.\n\nComments:\n- The methods jarClassPath() and buildJvmVersion() have different indentation than the other methods. \nChanges according to the current file indentation. Right now, the method starts at space 5 while the context starts at space 9. \n\n- If formatURL() gets an IOException, it returns the string \"IOException\". Perhaps it should also return the exception's message text? \nIt will be return message text for IOException now.\n\n- I don't follow all the logic in formatURL(). Could you add some comments that explain the various transformations? In my environment, just printing what URL.toString() returns gives clear enough information: \n\nfile:/code/derby/trunk0/classes/ or \nfile:/code/derby/trunk0/jars/sane/derby.jar \nGreat point. I always believe coding less is better. Use URL.toString() in the code.\n\n- For readability, I think it would be better to separate the properties with a newline character instead of a space. \nThe property is separated by a newline instead of a space.\n\n- The comments in the policy files say \"Add for DERBY-4715\". I think it would be better if they said why the permission was needed since we include them as templates in the distribution and refer to them from the documentation[1], so they are expected to be read by users. Perhaps something like \"getProtectionDomain is an optional permission needed for printing classpath information to derby.log.\" \nAll the comment relate to java.lang.RuntimePermission is using this comment.\n\n- In server.policy and template.policy, the new permission is added in the section that is labeled \"These permissions are needed for everyday, embedded Derby usage.\" My understanding of the patch is that the new permission is optional, and embedded Derby will work fine without it, it just won't print the classpath to derby.log. If it's so, I'd suggest moving it to a less prominent section of the policy files. \nPut the java.lang.RuntimePermission \"getProtectionDomain\" and the comment in its own section\n\n- Similarly, in AssertFailureTest.policy, the permission is added under the label \"These are the ones that matter\", but AssertFailureTest runs fine without it.\nMake similar change as above and place in less prominent section.\n\nRegarding the public methods in utility classes, there are two new methods - jarClassPatha and buildJvmVersion after removing formatUrl() in BaseDataFileFactory.java. They are not so generic to be used or provide a lot of value in the utility classes.\n\nI am running tests against this patch now.\n\nThanks for making these improvements, Lily. A couple more comments to the latest patch:\n\n- The javadoc for jarClassPath() is a little unclear. I don't understand what's meant by \"the path of string\" or by \"the string of jar file\".\n\n- The javadoc for buildJvmVersion() should make it clear that it returns values of system properties that identify the JVM.\n\n- buildJvmVersion() has a @param tag, but the method has no parameters.\n\n- Now that we add a newline character between each property, there's no need to append \" \" (one space) to each property value.\n\n- If jarClassPath() had taken a Class argument instead of a String argument, and we called it like \"jarCPath = jarClassPath(getClass());\", there would be no need to call Class.forName(), and we could remove the catch block for ClassNotFoundException.\nThanks Knut for reviewing the patch. I make the following changes in DERBY-4715-5.diff\n- The javadoc for jarClassPath() is a little unclear. I don't understand what's meant by \"the path of string\" or by \"the string of jar file\".\njavadoc is changed. I am using similar comment from Main.java. Hope it is clearer now. \n\n- The javadoc for buildJvmVersion() should make it clear that it returns values of system properties that identify the JVM.\nAdd this to the javadoc on buildJvmVersion()\n\n- buildJvmVersion() has a @param tag, but the method has no parameters.\nIt is not there any more.\n\n- Now that we add a newline character between each property, there's no need to append \" \" (one space) to each property value.\nGreat catch. Change to not append \" \".\n\n- If jarClassPath() had taken a Class argument instead of a String argument, and we called it like \"jarCPath = jarClassPath(getClass());\", there would be no need to call Class.forName(), and we could remove the catch block for ClassNotFoundException.\nAfter using getClass() to get the class instance for the BaseDataFileFactory class which is also in derby.jar, no need to call Class.forName() and catch block for ClassNotFoundException. Please review the change. \n\nI am running tests now.\n\nThanks, Lily. The latest patch looks fine to me.\nThank you, Knut. Yeah! Suites.all and derbyall seem to run fine except:\n1) ttestSetPortPriority(org.apache.derbyTesting.functionTests.tests.derbynet.Serve\nrPropertiesTest)junit.framework.AssertionFailedError: Port 1537 exceeeds expected\nmaximum. You may need to update TestConfiguration.MAX_PORTS_USED and the Wiki page\n at http://wiki.apache.org/db-derby/DerbyJUnitTesting if test runs now require mor\ne available ports\n        at org.apache.derbyTesting.junit.TestConfiguration.getNextAvailablePort(Te\nstConfiguration.java:1413)\n        at org.apache.derbyTesting.functionTests.tests.derbynet.ServerPropertiesTe\nst.ttestSetPortPriority(ServerPropertiesTest.java:445)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.ja\nva:48)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccesso\nrImpl.java:37)\n        at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:10\n9)\n        at junit.extensions.TestDecorator.basicRun(TestDecorator.java:22)\n\nThis failure is a known issue by the group.\n\nDERBY-4715-5.diff is ready to submit.\nThanks Lily, I will commit first thing Monday if your account does not come through by then.\n\n", "issueSearchSentences": ["In production environment, derby.jar can be located different than the derbyclient.jar It can be easier if we have jvm version information and path of derby.jar are in the derby.log", "DERBY-4715-2.diff patch will boot and communicate there is not sufficient permission to derby.log for derby.jar.", "Loaded from C:\\derby\\trunk\\jars\\sane\\derby.jar", "derbyall suites run clean too.", "The javadoc for jarClassPath() is a little unclear."], "issueSearchIndexes": [3, 33, 16, 43, 110]}
{"aId": 13, "code": "public void ping() throws Exception {\n        //String feedback = \"Server pinged successfully.\";\n        //boolean success = true;\n        try {\n            server.ping();\n        } catch (Exception ex) {\n            Monitor.logThrowable(ex);\n            //feedback = \"Error occured while pinging server.\";\n            //success = false;\n            throw ex;\n        }\n    }", "comment": " Pings the Network Server.", "issueId": "DERBY-3435", "issueStringList": ["Add an MBean for monitoring and managing the Network Server", "Most functionality of and information about a running instance of the Network Server is currently only available from the host running the Network Server, using the NetworkServerControl API.", "With a JMX Management and Monitoring service in place utilizing JMX (DERBY-1387), it is possible to expose some of the Network Server functionality and information through an MBean that is specific to the Network Server, to both local and remote users (JMX clients), subject to security restrictions.", "Access to Derby libraries on the client side is not even a requirement, potentially making a server administrator's job a lot easier.", "The patch d3435_v01.diff defines and implements an MBean for monitoring", "and (future work) management of the Network Server.", "Although the MBean works, it is currently limited to exposing read-only", "attributes only (i.e.", "no management functionality), in addition to the", "ping() operation, so I consider this just to be a start of what could", "eventually become a very useful bean for server administrators.", "Patch contents:", "A      java/engine/org/apache/derby/mbeans/drda", "New package for Network Server mbeans (included in derbynet.jar)", "A      java/engine/org/apache/derby/mbeans/drda/NetworkServerMBean.java", "The defining interface of the MBean.", "The following read-only attributes are", "available:", "([Attribute]            - [associated server property])", "DrdaHost                - derby.drda.host", "DrdaKeepAlive           - derby.drda.keepAlive", "DrdaMaxThreads          - derby.drda.maxThreads", "DrdaPortNumber          - derby.drda.portNumber", "DrdaSecurityMechanism   - derby.drda.securityMechanism", "DrdaSslMode             - derby.drda.sslMode", "DrdaStreamOutBufferSize - derby.drda.streamOutBufferSize", "DrdaTimeSlice           - derby.drda.timeSlice", "DrdaTraceAll            - derby.drda.traceAll", "DrdaTraceDirectory      - derby.drda.traceDirectory", "The ping() operation requires the permission", "permission java.net.SocketPermission \"*\", \"connect,resolve\";", "(\"*\" may be replaced, depending on the -h option of the server)", "granted to derbynet.jar in order to work, due to the way the network", "server is currently implemented.", "A      java/drda/org/apache/derby/impl/drda/NetworkServerMBeanImpl.java", "The implementation of NetworkServerMBean.", "Instruments NetworkServerControlImpl.", "M      java/drda/org/apache/derby/impl/drda/NetworkServerControlImpl.java", "removes some unused imports", "registers the MBean at server startup", "unregisters the MBean at server shutdown", "relaxes the modifier of the method getPropertyValues() from private", "to package-private in order to allow access to server settings from the", "MBean impl.", "without having to use a network connection.", "M      tools/javadoc/publishedapi.ant", "Adds org.apache.derby.mbeans.drda to the publishedAPI javadocs.", "The patch includes some commented code copied from patch 9 of DERBY-1387,", "as a temporary reminder of the functionality initially proposed as part of", "that Jira issue.", "This code should eventually be removed and/or replaced by", "real code once the community agrees on and implements a security model for", "Derby's JMX functionality.", "Some suggestions for follow-up work:", "add attributes for monitoring:", "number of active sessions", "total number of connections since server started (connNum)", "replication status", "size of queue of sessions waiting for a free thread (runQueue)", "number of DRDAConnThreads waiting for something to do (freeThreads)", "(etc.)", "add the rest of the NetworkServerControl functionality as operations and attribute setters (once we have adequate security mechanisms in place)", "I'll commit the patch in a few minutes with a minor change:", "changed the implementation of the bean to be package private.", "Minor comments.", "The ping command didn't work for me, maybe a permission issue.", "I also think the javadoc for the ping operation should clearly indicate it's a ping from the same machine as the network server.", "Exception handling for ping and the set methods (when added) may need changing.", "If the exception chain includes a class that is not present on the client.", "I hit this yesterday with a EmbedSQLException from a test MBean.", "I think the o.a.d.mbeans.drda package should be under java/drda, not java/engine.", "Any reason it was added to java/engine?", "Thanks for looking at the patch!", "Package placement: No reason, I just didn't think of placing it in java/drda, so feel free to move it.", "The Exception handling issue is known from DERBY-1387 - I did not provide a solution as part of this patch.", "Yes, the ping command requires a SocketPermission (as stated above).", "Even with the permission I'm not sure it will always work, since the NetworkServerControlImpl instance is not designed to ping itself.", "For example, if \"-h 0.0.0.0\" is specified, it pings the host 0.0.0.0 instead of localhost (which works, but there may be other values of -h that won't, I guess).", "I agree with the javadoc suggestion and that the implementation class should be package private.", "Commited slightly modified version of v01 patch with revisions Revision: 629536 & 629537.", "Make the MBean implemetation package private", "Put o.a.d.mbeans.drda under java/drda", "Thanks John.", "Some potential javadoc improvements for NetworkServerMBean", "add a package.html", "Have the class javadoc define what type and other key properties are used (see the other MBeans)", "Remove this vacuous sentence:", "This interface consists of getter and setter methods for attributes that may be read and/or modified, and methods representing operations that can be invoked.", "(it's adds no value, it's the definition of what an MBean is, it's like adding a comment to other classes \"this interface consists of methods that can be called and fields that can be referenced\").", "Correct the comment for getDrdaHost related to 0.0.0.0, it indicates it affects which clients can connect, I think it means that the server listens on all network interfaces", "For each attribute getXXX method add a summary of what the property does, just saying it gets derby.drda.XXX doesn't really help much.", "Make the first javadoc sentence of the getXXX methods be the (English) summary of what the attribute represents and not just that it maps to derby.drda.XXX.", "This means the class summary in javadoc becomes more useful, e.g.", "Gets the host name for the network server", "instead of the current", "Gets the value of the derby.drda.host network server setting.", "To complete the last thought, I think the javadoc should continue to contain the reference to the derby.drda.XXX setting, just not as the primary sentence.", "Thanks for the commit.", "Seems like you forgot to actually move the MBean interface to java/drda (?)", "- now I see the org.apache.derby.mbeans.drda package in java/engine as well as in java/drda.", "The suggested javadoc comments seem valid to me.", "The host property is a bit tricky as always (probably because it should be called derby.drda.connectionInterface or some such instead).", "The suggested \"0.0.0.0\" description change is fine, although the first sentence of the javadoc should be something like", "\"Gets the name of the network interface on which the network server is listening\"", "instead of", "\"Gets the host name for the network server\"", ";-)", "Darn, I'll fix the up location of the mbeans.drda package, I think my ide got confused (or maybe I did)."], "SplitGT": [" Pings the Network Server."], "issueString": "Add an MBean for monitoring and managing the Network Server\nMost functionality of and information about a running instance of the Network Server is currently only available from the host running the Network Server, using the NetworkServerControl API.\n\nWith a JMX Management and Monitoring service in place utilizing JMX (DERBY-1387), it is possible to expose some of the Network Server functionality and information through an MBean that is specific to the Network Server, to both local and remote users (JMX clients), subject to security restrictions. Access to Derby libraries on the client side is not even a requirement, potentially making a server administrator's job a lot easier.\n\n\nThe patch d3435_v01.diff defines and implements an MBean for monitoring\nand (future work) management of the Network Server. \n\nAlthough the MBean works, it is currently limited to exposing read-only \nattributes only (i.e. no management functionality), in addition to the\nping() operation, so I consider this just to be a start of what could \neventually become a very useful bean for server administrators. \n\nPatch contents:\n\nA      java/engine/org/apache/derby/mbeans/drda\n\n  New package for Network Server mbeans (included in derbynet.jar)\n\n\nA      java/engine/org/apache/derby/mbeans/drda/NetworkServerMBean.java\n\n  The defining interface of the MBean. The following read-only attributes are\n  available:\n\n    ([Attribute]            - [associated server property])\n    DrdaHost                - derby.drda.host\n    DrdaKeepAlive           - derby.drda.keepAlive\n    DrdaMaxThreads          - derby.drda.maxThreads\n    DrdaPortNumber          - derby.drda.portNumber\n    DrdaSecurityMechanism   - derby.drda.securityMechanism\n    DrdaSslMode             - derby.drda.sslMode\n    DrdaStreamOutBufferSize - derby.drda.streamOutBufferSize\n    DrdaTimeSlice           - derby.drda.timeSlice\n    DrdaTraceAll            - derby.drda.traceAll\n    DrdaTraceDirectory      - derby.drda.traceDirectory\n\n  The ping() operation requires the permission\n\n    permission java.net.SocketPermission \"*\", \"connect,resolve\";\n\n  (\"*\" may be replaced, depending on the -h option of the server) \n  granted to derbynet.jar in order to work, due to the way the network\n  server is currently implemented.\n\nA      java/drda/org/apache/derby/impl/drda/NetworkServerMBeanImpl.java\n\n  The implementation of NetworkServerMBean. Instruments NetworkServerControlImpl.\n\n\nM      java/drda/org/apache/derby/impl/drda/NetworkServerControlImpl.java\n\n  - removes some unused imports\n  - registers the MBean at server startup\n  - unregisters the MBean at server shutdown\n  - relaxes the modifier of the method getPropertyValues() from private\n    to package-private in order to allow access to server settings from the\n    MBean impl. without having to use a network connection.\n\n\nM      tools/javadoc/publishedapi.ant\n\n  Adds org.apache.derby.mbeans.drda to the publishedAPI javadocs.\n\n\nThe patch includes some commented code copied from patch 9 of DERBY-1387,\nas a temporary reminder of the functionality initially proposed as part of\nthat Jira issue. This code should eventually be removed and/or replaced by \nreal code once the community agrees on and implements a security model for \nDerby's JMX functionality.\n\nSome suggestions for follow-up work:\n\n - add attributes for monitoring:\n     - number of active sessions\n     - total number of connections since server started (connNum)\n     - replication status\n     - size of queue of sessions waiting for a free thread (runQueue)\n     - number of DRDAConnThreads waiting for something to do (freeThreads)\n     (etc.)\n\n - add the rest of the NetworkServerControl functionality as operations and attribute setters (once we have adequate security mechanisms in place)\nI'll commit the patch in a few minutes with a minor change:\n\n  changed the implementation of the bean to be package private.\n\nMinor comments.\n\nThe ping command didn't work for me, maybe a permission issue.\n\nI also think the javadoc for the ping operation should clearly indicate it's a ping from the same machine as the network server.\n\nException handling for ping and the set methods (when added) may need changing. If the exception chain includes a class that is not present on the client. I hit this yesterday with a EmbedSQLException from a test MBean.\nI think the o.a.d.mbeans.drda package should be under java/drda, not java/engine. Any reason it was added to java/engine?\nThanks for looking at the patch!\n\nPackage placement: No reason, I just didn't think of placing it in java/drda, so feel free to move it.\n\nThe Exception handling issue is known from DERBY-1387 - I did not provide a solution as part of this patch.\n\nYes, the ping command requires a SocketPermission (as stated above). Even with the permission I'm not sure it will always work, since the NetworkServerControlImpl instance is not designed to ping itself. For example, if \"-h 0.0.0.0\" is specified, it pings the host 0.0.0.0 instead of localhost (which works, but there may be other values of -h that won't, I guess).\n\nI agree with the javadoc suggestion and that the implementation class should be package private.\n\nCommited slightly modified version of v01 patch with revisions Revision: 629536 & 629537.\n  Make the MBean implemetation package private\n  Put o.a.d.mbeans.drda under java/drda\n\nThanks John.\nSome potential javadoc improvements for NetworkServerMBean\n  - add a package.html\n  - Have the class javadoc define what type and other key properties are used (see the other MBeans)\n  - Remove this vacuous sentence:\n       This interface consists of getter and setter methods for attributes that may be read and/or modified, and methods representing operations that can be invoked.\n      (it's adds no value, it's the definition of what an MBean is, it's like adding a comment to other classes \"this interface consists of methods that can be called and fields that can be referenced\").\n\n  - Correct the comment for getDrdaHost related to 0.0.0.0, it indicates it affects which clients can connect, I think it means that the server listens on all network interfaces\n\n  - For each attribute getXXX method add a summary of what the property does, just saying it gets derby.drda.XXX doesn't really help much.\n\n  - Make the first javadoc sentence of the getXXX methods be the (English) summary of what the attribute represents and not just that it maps to derby.drda.XXX. This means the class summary in javadoc becomes more useful, e.g.\n \n           Gets the host name for the network server\n\n       instead of the current\n\n            Gets the value of the derby.drda.host network server setting.\n     \nTo complete the last thought, I think the javadoc should continue to contain the reference to the derby.drda.XXX setting, just not as the primary sentence.\nThanks for the commit. Seems like you forgot to actually move the MBean interface to java/drda (?) - now I see the org.apache.derby.mbeans.drda package in java/engine as well as in java/drda.\n\nThe suggested javadoc comments seem valid to me.\nThe host property is a bit tricky as always (probably because it should be called derby.drda.connectionInterface or some such instead). The suggested \"0.0.0.0\" description change is fine, although the first sentence of the javadoc should be something like\n\n         \"Gets the name of the network interface on which the network server is listening\"\n\n    instead of \n\n         \"Gets the host name for the network server\"\n    ;-)\nDarn, I'll fix the up location of the mbeans.drda package, I think my ide got confused (or maybe I did).\n", "issueSearchSentences": ["I also think the javadoc for the ping operation should clearly indicate it's a ping from the same machine as the network server.", "The ping command didn't work for me, maybe a permission issue.", "DrdaTraceDirectory      - derby.drda.traceDirectory", "granted to derbynet.jar in order to work, due to the way the network", "available:"], "issueSearchIndexes": [67, 66, 29, 33, 18]}
{"aId": 14, "code": "public void start(PrintWriter consoleWriter)\n\t\tthrows Exception\n\t{\n\t\tDRDAServerStarter starter = new DRDAServerStarter();\n\t\tstarter.setStartInfo(hostAddress,portNumber,consoleWriter);\n        this.setLogWriter(consoleWriter);\n\t\tstartNetworkServer();\n\t\tstarter.boot(false,null);\n\t}", "comment": " Start a network server. Launches a separate thread with DRDAServerStarter.", "issueId": "DERBY-1465", "issueStringList": ["NetworkServerControl.start() should throw an exception and not just  print  exceptions  if the server fails to start", "NetworkServerControl.start()  will not throw an exception  if another server is already running on the same port.", "I am not sure but think perhaps this was changed at  one point to accomodate the derby.drda.startNetworkServer property  so that the embedded server could continue to boot even if the network server failed to start, but  I think this is wrong for normal usage.", "http://www.nabble.com/Questions-about-Network-Server-API-Behavior-p5055814.html", "The relationship between the Network Server API and the derby.drda.startNetworkServer property (and its related functionality) is indeed puzzling.", "See my comment to DERBY-1326 (June 16th), particularly observation b), for another example:", "http://issues.apache.org/jira/browse/DERBY-1326#action_12416494", "Attached is a patch for this issue.", "I ran derbynetclientmats, derbynetmats and suites.All.", "I am a little unsure about this patch.", "I wait only 5 seconds for any error to occur on startup.", "It will catch the most common error that there is already another server on the same port, but still the server can't be verified as up until ping is successful.", "I'll submit another patch for DERBY-1467 which allows a timeout to be specified.", "That seems the preferred way to go.", "The patch attached has a conflict with DERBY-2671, so needs to be redone.", "Ignore the patch DERBY-1465_diff.txt", "Patch for this issue.", "start() will now wait until the server has been started.", "It will wait until just before the server started message prints to return and will throw an exception if one occurred.", "One possible problem with the existing.", "One possible problem with the existing code is that it prints \"server started\" before launching the client thread.", "If that needs to be moved, I will log it as a separate issue.", "derbynetmats, derbynetclientmats and suites.All passed.", "I'll commit this late today if I hear no comments, but I would appreciate if someone would take a look.", "Thanks", "Kathey", "Committed revision 540779", "Should the thread you create via this start method be a daemon thread?", "I couldn't really tell either way from the diff.", "Is it possible to add some comments to the code you added while it's fresh in your mind?", "At least on the", "serverStartComplete variable and its wait/notify.", "Give future readers some clue as to what is going on.", ":-)", "Thanks Dan for looking.", "I don't think it should be a daemon thread if I understand the concept of a daemon thread correctly.", "I don't want the jvm to exit while this thread is running.", "I'll add comments for serverStartComplete.", "Could you also explain the lifetime of this new thread then?", "Does this change mean that starting the network server now has an extra Thread for the lifetime of the network server?", "Does it mean a change in behaviour where previously the JVM could exit but now it cannot until the network server is shutdown?", "Dan asked:", ">Could you also explain the lifetime of this new thread then?", ">Does this change mean that starting the network server now has an extra Thread for the lifetime of the network server?", "No.", "We used to start with DRDAServerStarter which made a thread to start network server.", "Now NetworkServerControl", "old:", "NetworkServerControl.start() called DRDAServerStarter which started a thread calling blockingStart.", "blockingStart would log any exceptions.", "new:", "NetworkServerControl.start() creates its own thread calling blockingStart and throws any exceptions that occur during the startup phase.", "To determine the end of the startup phase it waits on serverStartComplete.", "If start is  successful ...", "When blockingStart gets to the point that it would print the server is up, it notifies serverStartComplete so the start method can return or throw any exception that occurred and waits to be shutdown.", "If start fais....", "blockingStart will throw an exception, notify serverStartComplete  and the thread will end.", "The old thread was started as a daemon thread, in derby's daemon thread group, but this new thread isn't (for either).", "I think Bryan was trying to clean up the code to start the network server, I wonder if that has progressed to be useable, because this is adding another mechanism to start the server in already confused code.", "There are a couple of timing bugs in the wait code:", "There is a chance the server can fail to start but the start method will not throw any exceptions.", "This is because the waiter is notified before 'runtimeException' is set, thus the waiter may see runtimeException as null and not throw an exception.", "There is a chance the start() method will hang, if the spawned thread reaches the notifyAll() before the start() call reaches the wait().", "The standard way to avoid this is to include boolean state information, so that the sync calls are like:", "synchronized (serverStartComplete) {", "completedBoot = true;", "serverStartComplete.notifyAll();", "}", "synchronized(serverStartComplete){", "while (!completedBoot )", "serverStartComplete.wait();", "}", "I wonder if the code could be modifed slightly to use the old thread, rather than creating a new thread ...", "There are some issues with the change noted in Dan's comments.", "Backing out the change and reopen until those can be resolved."], "SplitGT": [" Start a network server.", "Launches a separate thread with DRDAServerStarter."], "issueString": "NetworkServerControl.start() should throw an exception and not just  print  exceptions  if the server fails to start\nNetworkServerControl.start()  will not throw an exception  if another server is already running on the same port.    I am not sure but think perhaps this was changed at  one point to accomodate the derby.drda.startNetworkServer property  so that the embedded server could continue to boot even if the network server failed to start, but  I think this is wrong for normal usage.\n\nhttp://www.nabble.com/Questions-about-Network-Server-API-Behavior-p5055814.html\n\nThe relationship between the Network Server API and the derby.drda.startNetworkServer property (and its related functionality) is indeed puzzling. See my comment to DERBY-1326 (June 16th), particularly observation b), for another example:\n\nhttp://issues.apache.org/jira/browse/DERBY-1326#action_12416494\n\nAttached is a patch for this issue.  I ran derbynetclientmats, derbynetmats and suites.All.\nI am a little unsure about this patch.  I wait only 5 seconds for any error to occur on startup.  It will catch the most common error that there is already another server on the same port, but still the server can't be verified as up until ping is successful.   I'll submit another patch for DERBY-1467 which allows a timeout to be specified.  That seems the preferred way to go.\n\n\n\nThe patch attached has a conflict with DERBY-2671, so needs to be redone.  Ignore the patch DERBY-1465_diff.txt\n\n\nPatch for this issue.  start() will now wait until the server has been started.  It will wait until just before the server started message prints to return and will throw an exception if one occurred. One possible problem with the existing.  One possible problem with the existing code is that it prints \"server started\" before launching the client thread.  If that needs to be moved, I will log it as a separate issue.\n\nderbynetmats, derbynetclientmats and suites.All passed.\nI'll commit this late today if I hear no comments, but I would appreciate if someone would take a look.\n\nThanks\n\nKathey\nCommitted revision 540779\nShould the thread you create via this start method be a daemon thread? I couldn't really tell either way from the diff.\n\nIs it possible to add some comments to the code you added while it's fresh in your mind? At least on the\nserverStartComplete variable and its wait/notify. Give future readers some clue as to what is going on. :-)\nThanks Dan for looking.\n\nI don't think it should be a daemon thread if I understand the concept of a daemon thread correctly.  I don't want the jvm to exit while this thread is running.   I'll add comments for serverStartComplete.\n\n\nCould you also explain the lifetime of this new thread then?\n\nDoes this change mean that starting the network server now has an extra Thread for the lifetime of the network server?\n\nDoes it mean a change in behaviour where previously the JVM could exit but now it cannot until the network server is shutdown?\n\nDan asked:\n>Could you also explain the lifetime of this new thread then?\n>Does this change mean that starting the network server now has an extra Thread for the lifetime of the network server? \n\nNo.  We used to start with DRDAServerStarter which made a thread to start network server. Now NetworkServerControl\n\nold:\nNetworkServerControl.start() called DRDAServerStarter which started a thread calling blockingStart.  blockingStart would log any exceptions.\n\nnew:\nNetworkServerControl.start() creates its own thread calling blockingStart and throws any exceptions that occur during the startup phase.  To determine the end of the startup phase it waits on serverStartComplete. \nIf start is  successful ...\n When blockingStart gets to the point that it would print the server is up, it notifies serverStartComplete so the start method can return or throw any exception that occurred and waits to be shutdown.\n\nIf start fais....\nblockingStart will throw an exception, notify serverStartComplete  and the thread will end.\n\n\nThe old thread was started as a daemon thread, in derby's daemon thread group, but this new thread isn't (for either).\n\nI think Bryan was trying to clean up the code to start the network server, I wonder if that has progressed to be useable, because this is adding another mechanism to start the server in already confused code.\n\nThere are a couple of timing bugs in the wait code:\n\n - There is a chance the server can fail to start but the start method will not throw any exceptions.\nThis is because the waiter is notified before 'runtimeException' is set, thus the waiter may see runtimeException as null and not throw an exception.\n\n- There is a chance the start() method will hang, if the spawned thread reaches the notifyAll() before the start() call reaches the wait().\n   The standard way to avoid this is to include boolean state information, so that the sync calls are like:\n            \n\t\t\tsynchronized (serverStartComplete) {\n                                completedBoot = true;\n\t\t\t\tserverStartComplete.notifyAll();\n\t\t\t}\n\n\n\n      \t\t     synchronized(serverStartComplete){\n                        while (!completedBoot )\n\t\t    \t      serverStartComplete.wait();\n\t\t    }\n\nI wonder if the code could be modifed slightly to use the old thread, rather than creating a new thread ...\nThere are some issues with the change noted in Dan's comments.  Backing out the change and reopen until those can be resolved.\n", "issueSearchSentences": ["old:", "blockingStart would log any exceptions.", "No.", "NetworkServerControl.start()  will not throw an exception  if another server is already running on the same port.", "public void start(PrintWriter consoleWriter)\n\t\tthrows Exception\n\t{\n\t\tDRDAServerStarter starter = new DRDAServerStarter();\n\t\tstarter.setStartInfo(hostAddress,portNumber,consoleWriter);\n        this.setLogWriter(consoleWriter);\n\t\tstartNetworkServer();\n\t\tstarter.boot(false,null);\n\t}"], "issueSearchIndexes": [48, 50, 45, 2, 0]}
{"aId": 15, "code": "public  void    copyFrom( FormatableBitSet that )\n    {\n        System.arraycopy( that.getByteArray(), 0, value, 0, that.getLengthInBytes());\n    }", "comment": " Assumes that this bit set is at least as large as the argument's bit set.", "issueId": "DERBY-6188", "issueStringList": ["Cleanup suspect coding practices in org.apache.derby.iapi.services.io package", "Similar to DERBY-6177.", "Attaching derby-6188-01-ab-formatables.diff.", "This patch cleans up some array-related encapsulation problems in the Formatable machinery.", "I am running tests now.", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/services/io/ArrayUtil.java", "Added a new copy() overload to handle byte arrays.", "M       java/engine/org/apache/derby/iapi/services/io/RegisteredFormatIds.java", "M       java/engine/org/apache/derby/iapi/types/DataValueFactoryImpl.java", "M       java/engine/org/apache/derby/impl/services/monitor/BaseMonitor.java", "Made the array of formatable classes private and added some accessors.", "M       java/engine/org/apache/derby/iapi/services/io/FormatableBitSet.java", "M       java/engine/org/apache/derby/impl/sql/depend/BasicDependencyManager.java", "M       java/testing/org/apache/derbyTesting/unitTests/junit/FormatableBitSetTest.java", "M       java/testing/org/apache/derbyTesting/junit/BaseTestCase.java", "Copy bit arrays in FormatableBitSet's constructor and accessors.", "+1.", "Looks like a good improvement to me.", "It might be worth mentioning in the javadoc comment for FormatableBitSet.copyFrom() that it requires the bit set on which it is called to be at least as large as the bit set in the argument.", "Thanks for the quick review, Knut.", "Attaching derby-6188-01-ac-formatables.diff, which expands the javadoc as you suggested.", "Tests passed cleanly for me on the previous rev.", "Committed at subversion revision 1469948.", "Attaching derby-6188-02-aa-FormatableArrayHolder.diff.", "This patch tightens up the encapsulation of the array wrapped by FormatableArrayHolder.", "I am running tests now.", "Touches the following file:", "M       java/engine/org/apache/derby/iapi/services/io/FormatableArrayHolder.java", "Tests passed cleanly for me on derby-6188-02-aa-FormatableArrayHolder.diff.", "Committed at subversion revision 1469992."], "SplitGT": [" Assumes that this bit set is at least as large as the argument's bit set."], "issueString": "Cleanup suspect coding practices in org.apache.derby.iapi.services.io package\nSimilar to DERBY-6177.\nAttaching derby-6188-01-ab-formatables.diff. This patch cleans up some array-related encapsulation problems in the Formatable machinery. I am running tests now.\n\n\nTouches the following files:\n\n------------------\n\nM       java/engine/org/apache/derby/iapi/services/io/ArrayUtil.java\n\nAdded a new copy() overload to handle byte arrays.\n\n------------------\n\nM       java/engine/org/apache/derby/iapi/services/io/RegisteredFormatIds.java\nM       java/engine/org/apache/derby/iapi/types/DataValueFactoryImpl.java\nM       java/engine/org/apache/derby/impl/services/monitor/BaseMonitor.java\n\nMade the array of formatable classes private and added some accessors.\n\n------------------\n\nM       java/engine/org/apache/derby/iapi/services/io/FormatableBitSet.java\nM       java/engine/org/apache/derby/impl/sql/depend/BasicDependencyManager.java\nM       java/testing/org/apache/derbyTesting/unitTests/junit/FormatableBitSetTest.java\nM       java/testing/org/apache/derbyTesting/junit/BaseTestCase.java\n\nCopy bit arrays in FormatableBitSet's constructor and accessors.\n\n+1. Looks like a good improvement to me.\n\nIt might be worth mentioning in the javadoc comment for FormatableBitSet.copyFrom() that it requires the bit set on which it is called to be at least as large as the bit set in the argument.\nThanks for the quick review, Knut. Attaching derby-6188-01-ac-formatables.diff, which expands the javadoc as you suggested. Tests passed cleanly for me on the previous rev. Committed at subversion revision 1469948.\n\nAttaching derby-6188-02-aa-FormatableArrayHolder.diff. This patch tightens up the encapsulation of the array wrapped by FormatableArrayHolder. I am running tests now.\n\nTouches the following file:\n\nM       java/engine/org/apache/derby/iapi/services/io/FormatableArrayHolder.java\n\nTests passed cleanly for me on derby-6188-02-aa-FormatableArrayHolder.diff. Committed at subversion revision 1469992.\n", "issueSearchSentences": ["Looks like a good improvement to me.", "Made the array of formatable classes private and added some accessors.", "M       java/testing/org/apache/derbyTesting/junit/BaseTestCase.java", "public  void    copyFrom( FormatableBitSet that )\n    {\n        System.arraycopy( that.getByteArray(), 0, value, 0, that.getLengthInBytes());\n    }", "Cleanup suspect coding practices in org.apache.derby.iapi.services.io package"], "issueSearchIndexes": [19, 12, 16, 0, 1]}
{"aId": 16, "code": "void resetForReuse()\n            throws SqlException {\n        resetParameters();\n        super.resetForReuse();\n    }", "comment": " Resets the prepared statement for reuse in a statement pool.", "issueId": "DERBY-3441", "issueStringList": ["Determine and implement a proper procedure for resetting a prepared statement for reuse in a statement pool", "Initial investigations indicate there are no existing suitable methods to properly reset a prepared (or callable) statement for reuse with a statement pool.", "A full reset is too heavy weight and defeats the purpose of statement pooling, but a proper procedure should be achievable by reusing existing pieces of code.", "Correctness is of course the most important thing.", "What is needed for a reset beyond clearParameters, clearBatch and clearWarnings?", "Just wondering why these are too heavy weight?", "The ones you mention are not too heavy weight.", "What about result sets?", "When running some of the tests, I observed lock timeouts.", "The failing tests were all SUR tests, and I think the locking behavior might be a bit special there.", "I tried a very experimental patch, where I closed the result sets on logical statement close and when running suites.All I was down to around 20+ errors/failures (as opposed to around 180).", "Most of these I could link to an existing bug.", "So even though I can't provide a proper answer now, I do believe there is more to be handled than what you mentioned above.", "I'll come back with more info as soon I as have any.", "All of this is a bit in the blue currently, so feedback is very much appreciated.", "I hope to get the basic machinery into place, and then work on issues one by one from there.", "'derby-3441-1a-statement_reset.diff' is the first draft of a reset procedure for a statement to be reused in a statement pool.", "There might be some room for refactoring in am.Statement, since the new method copies code from various other places.", "Please review / comment.", "I am not confident this is the best / correct way of doing it, but I can't see any errors caused by it either.", "Suggestions for how to test this is also welcome (or tests :) )!", "I think a list of what is being reset in resetForReuse()'s javadoc (for the method) would be very useful.", "Otherwise one has to \"slug\" through the", "code figuring out what is being reset.", "A comment to explain this code would be really good:", "+        } catch (SqlException sqle) {", "+            throw sqle.getSQLException();", "+        }", "Ie.", "why is the top-level exception not being thrown.", "Minor improvement in resetParameters()", "+            for (int i = 0; i < parameterMetaData_.columns_; i++) {", "+                parameters_[i] = null;", "+                parameterSet_[i] = false;", "+                parameterRegistered_[i] = false;", "+            }", "would be to use Arrays.fill().", "Thanks for the comment Dan.", "I'll address your other comments later.", "'derby-3441-2a-minor_am_refactoring.diff' addresses Dans comment about the improvement in resetParameters.", "I changed this (and other existing code) to use Arrays.fill, and also removed some unnecessary throws clauses from the existing code.", "I figured out 'batch_' was never set to null, so I made it final and removed a null check.", "In the future it might be better to only create the ArrayList if you actually do batching, and maybe add a clearBatchX method that will be called where batch_.clear is called currently.", "Committed patch 2a to trunk with revision 631515.", "Have run a subset of the regression tests, am running the full suite for verification.", "I have run suties.All and derbyall without failures with patch 2a, Sun JDK 1.6.0 on Solaris 10.", "'derby-3441-1b-statement_reset.diff' is another try at a proper reset procedure.", "The following has been changed:", "a) Added JavaDoc to Statement.resetForReuse", "b) Extracted \"user controllable attributes\" from the init method, and put them into a separate method.", "These attributes must be reset when the statement is put into the cache.", "Examples are query timeout, fetch direction hint and max rows to fetch.", "c) The allowAutoCommit argument for willTickleServer(), is now set to connection_.autoCommit", "Does anyone have any useful info on the willTickleServer method?", "d) Calling batch_.clear() (ArrayList) instead of clearBatch(), to avoid catching/throwing SQLException.", "See related comment for patch 2a above.", "e) Removed the outer try-catch clause, and the method now throws SqlException.", "Dan, I hope your comments are addressed.", "Having slugged through the code, did anything come across as strange?", "I.e.", "why is X reset, but not Y?", "Patch ready for review.", "I hope to commit later today, even if I don't have full confidence in the patch.", "It is a lot better than the current solution anyway, and I'll work on improving it.", "When the patch for this issue is committed, I will enable the statement pooling code by committing DERBY-3329.", "The other know new defect is DERBY-3457, which has a patch awaiting review as well.", "'derby-3441-3a-extract_setTransactionIsolationX.diff' creates an internal setTransactionIsolationX method from the java.sql.Connection.setTransactionIsolation.", "I need to set the transaction isolation level on connection reset, and extracted the internal method to avoid checking for a closed connection multiple times.", "The extraction follows a typical pattern used in the client driver.", "The logic remains unchanged.", "Committed to trunk with revision 632279.", "Forgot to say, I ran derbynet._Suite and jdbcapi._Suite without failures, and I'm running the full set of regression tests to verify.", "'derby-3441-1c-statement_reset.diff' implements a working reset procedure for statement pooling.", "Besides the new functionality, I also had to modify some existing code that broke statement pooling.", "The way things were in the existing code does not seem correct to me, but I need more time to determine what to do about it.", "Also, we should probably discuss whether the required changes should go into 10.4 or be included only in the next release.", "For now I've tried to disturb as little as possible.", "Some cleanup will be required later.", "Since I'm going away for one week, it will have to wait until I'm back.", "And I'm sorry for committing this patch so quickly, but all tests run cleanly and it is required for testing the statement pooling feature.", "Committed patch 1c to trunk with revision 632334."], "SplitGT": [" Resets the prepared statement for reuse in a statement pool."], "issueString": "Determine and implement a proper procedure for resetting a prepared statement for reuse in a statement pool\nInitial investigations indicate there are no existing suitable methods to properly reset a prepared (or callable) statement for reuse with a statement pool.\nA full reset is too heavy weight and defeats the purpose of statement pooling, but a proper procedure should be achievable by reusing existing pieces of code.\n\nCorrectness is of course the most important thing.\nWhat is needed for a reset beyond clearParameters, clearBatch and clearWarnings? Just wondering why these are too heavy weight?\nThe ones you mention are not too heavy weight.\nWhat about result sets?\n\nWhen running some of the tests, I observed lock timeouts. The failing tests were all SUR tests, and I think the locking behavior might be a bit special there.\nI tried a very experimental patch, where I closed the result sets on logical statement close and when running suites.All I was down to around 20+ errors/failures (as opposed to around 180).\nMost of these I could link to an existing bug.\nSo even though I can't provide a proper answer now, I do believe there is more to be handled than what you mentioned above. I'll come back with more info as soon I as have any.\n\n\nAll of this is a bit in the blue currently, so feedback is very much appreciated.\nI hope to get the basic machinery into place, and then work on issues one by one from there.\n'derby-3441-1a-statement_reset.diff' is the first draft of a reset procedure for a statement to be reused in a statement pool. There might be some room for refactoring in am.Statement, since the new method copies code from various other places.\n\nPlease review / comment.\nI am not confident this is the best / correct way of doing it, but I can't see any errors caused by it either. Suggestions for how to test this is also welcome (or tests :) )!\nI think a list of what is being reset in resetForReuse()'s javadoc (for the method) would be very useful. Otherwise one has to \"slug\" through the\ncode figuring out what is being reset.\n\nA comment to explain this code would be really good:\n\n+        } catch (SqlException sqle) {\n+            throw sqle.getSQLException();\n+        }\n\nIe. why is the top-level exception not being thrown.\n\nMinor improvement in resetParameters()\n\n+            for (int i = 0; i < parameterMetaData_.columns_; i++) {\n+                parameters_[i] = null;\n+                parameterSet_[i] = false;\n+                parameterRegistered_[i] = false;\n+            }\n\nwould be to use Arrays.fill().\nThanks for the comment Dan. I'll address your other comments later.\n\n'derby-3441-2a-minor_am_refactoring.diff' addresses Dans comment about the improvement in resetParameters. I changed this (and other existing code) to use Arrays.fill, and also removed some unnecessary throws clauses from the existing code. I figured out 'batch_' was never set to null, so I made it final and removed a null check.\n\nIn the future it might be better to only create the ArrayList if you actually do batching, and maybe add a clearBatchX method that will be called where batch_.clear is called currently.\n\nCommitted patch 2a to trunk with revision 631515.\nHave run a subset of the regression tests, am running the full suite for verification.\nI have run suties.All and derbyall without failures with patch 2a, Sun JDK 1.6.0 on Solaris 10.\n'derby-3441-1b-statement_reset.diff' is another try at a proper reset procedure.\nThe following has been changed:\n a) Added JavaDoc to Statement.resetForReuse\n b) Extracted \"user controllable attributes\" from the init method, and put them into a separate method.\n    These attributes must be reset when the statement is put into the cache.\n    Examples are query timeout, fetch direction hint and max rows to fetch.\n c) The allowAutoCommit argument for willTickleServer(), is now set to connection_.autoCommit\n    Does anyone have any useful info on the willTickleServer method?\n d) Calling batch_.clear() (ArrayList) instead of clearBatch(), to avoid catching/throwing SQLException.\n    See related comment for patch 2a above.\n e) Removed the outer try-catch clause, and the method now throws SqlException.\n\nDan, I hope your comments are addressed.\nHaving slugged through the code, did anything come across as strange?\nI.e. why is X reset, but not Y?\n\nPatch ready for review.\nI hope to commit later today, even if I don't have full confidence in the patch. It is a lot better than the current solution anyway, and I'll work on improving it. When the patch for this issue is committed, I will enable the statement pooling code by committing DERBY-3329. \nThe other know new defect is DERBY-3457, which has a patch awaiting review as well.\n'derby-3441-3a-extract_setTransactionIsolationX.diff' creates an internal setTransactionIsolationX method from the java.sql.Connection.setTransactionIsolation. I need to set the transaction isolation level on connection reset, and extracted the internal method to avoid checking for a closed connection multiple times. The extraction follows a typical pattern used in the client driver.\nThe logic remains unchanged.\n\nCommitted to trunk with revision 632279.\nForgot to say, I ran derbynet._Suite and jdbcapi._Suite without failures, and I'm running the full set of regression tests to verify.\n'derby-3441-1c-statement_reset.diff' implements a working reset procedure for statement pooling.\nBesides the new functionality, I also had to modify some existing code that broke statement pooling. The way things were in the existing code does not seem correct to me, but I need more time to determine what to do about it.\nAlso, we should probably discuss whether the required changes should go into 10.4 or be included only in the next release.\n\nFor now I've tried to disturb as little as possible. Some cleanup will be required later.\nSince I'm going away for one week, it will have to wait until I'm back.\n\nAnd I'm sorry for committing this patch so quickly, but all tests run cleanly and it is required for testing the statement pooling feature.\n\nCommitted patch 1c to trunk with revision 632334.\n", "issueSearchSentences": ["The following has been changed:", "See related comment for patch 2a above.", "Suggestions for how to test this is also welcome (or tests :) )!", "A comment to explain this code would be really good:", "why is the top-level exception not being thrown."], "issueSearchIndexes": [48, 56, 21, 25, 30]}
{"aId": 17, "code": "private void printErrorStack(Throwable t)\n\t{\n\t\tErrorStringBuilder esb = \n            new ErrorStringBuilder(Monitor.getStream().getHeader());\n\t\tesb.stackTrace(t);\n        Monitor.logMessage(esb.get().toString());\n        esb.reset();\n    }", "comment": " print stack trace from the Throwable including its nested exceptions", "issueId": "DERBY-237", "issueStringList": ["Boot errors from store must not lose error messages/stack traces in between.", "Boot errors from store do not show the entire stack traces of the nested exceptions", "We need to print the entire stack trace without losing exceptions in between.", "This will save time to debug errors."], "SplitGT": [" print stack trace from the Throwable including its nested exceptions"], "issueString": "Boot errors from store must not lose error messages/stack traces in between.\nBoot errors from store do not show the entire stack traces of the nested exceptions\nWe need to print the entire stack trace without losing exceptions in between. This will save time to debug errors. \n", "issueSearchSentences": ["private void printErrorStack(Throwable t)\n\t{\n\t\tErrorStringBuilder esb = \n            new ErrorStringBuilder(Monitor.getStream().getHeader());\n\t\tesb.stackTrace(t);\n        Monitor.logMessage(esb.get().toString());\n        esb.reset();\n    }", "Boot errors from store must not lose error messages/stack traces in between.", "Boot errors from store do not show the entire stack traces of the nested exceptions", "We need to print the entire stack trace without losing exceptions in between."], "issueSearchIndexes": [0, 1, 2, 3]}
{"aId": 19, "code": "private void wireIntoBuild()\n        throws Exception\n    {\n        String contents = readFileIntoString( _cliXconfFile );\n        int insertPoint = contents.indexOf( \"   </uris>\" );\n        String insertion = \"     <uri type=\\\"append\\\" src=\\\"releases/release-\" + _releaseID + \".html\\\"/>\\n\";\n        String result = contents.substring( 0, insertPoint ) + insertion + contents.substring( insertPoint );\n\n        writeStringIntoFile( result, _cliXconfFile );\n    }", "comment": " Wire the download page into the build instructions.", "issueId": "DERBY-4855", "issueStringList": ["Automate release publication steps", "Right now, producing a Derby release involves 3 major chunks of work:", "1) Producing the release notes (happens the week before the first release candidate is produced)", "2) Producing release candidates (and submitting them to community vote)", "3) Publishing the release distributions (after the community approves a candidate)", "This JIRA organizes work needed to automate the tasks which are part of step (3).", "Those steps are described here: http://wiki.apache.org/db-derby/ReleasePublication", "Attaching derby-4855-01-aa-docszip.diff.", "This patch adds a new target, repackagedocs, which automates the steps needed to create the zip file of re-arranged docs which we publish for a newly created release.", "Committed at subversion revision 1027230.", "Touches the following file:", "M      build.xml", "Attaching derby-4855-02-ab-releaseNotesTransformer.diff.", "This adds a new ant task and target for turning the release notes into a download page after the vote passes.", "Committed at subversion revision 1033940.", "Currently, the release manager constructs the download page by hand.", "This involves merging material from two source html documents and removing material which the Forrest tool can't handle.", "The new ant task and target simplify this process and make it less brittle.", "To use this new target, do the following.", "You will be prompted to supply a little information:", "o cd to the root of your code client", "o then type \"ant transformreleasenotes\"", "Touches the following files:", "A      java/build/org/apache/derbyBuild/ReleaseNotesTransformer.java", "New ant task.", "M      build.xml", "New ant target.", "Attaching derby-4855-03-aa-cgiTemplate.diff.", "This patch introduces a template cgi script for creating download pages.", "Committed at", "subversion revision 1034474.", "Currently, the release instructions say that you should create a cgi script for the new release by copying the cgi script from an old release.", "This patch formalizes the notion of a template script, making it possible to automate the creation of the new script.", "Touches the following files:", "A      src/documentation/content/xdocs/releases/release-template.cgi", "The new template script.", "M      build/site/releases/release-10.6.2.1.cgi", "This is the built version of the 10.6.2.1 cgi script.", "It turns up checked-out in my website client.", "I think this is just a line-ending issue.", "The original script was probably produced on a Windows box.", "Attaching derby-4855-04-aa-copyCgiScript.diff.", "This makes the transformrelnotes target also create the cgi script for the download page for the new release.", "Committed at subversion revision 1034483.", "Touches the following file:", "M      build.xml", "Attaching derby-4855-05-aa-cliXconf.diff.", "This patch makes the transformrelnotes target wire the new download page into the website-building instructions so that it will be picked up when you build the Derby website.", "Committed at subversion revision 1035700.", "Touches the following files:", "M      java/build/org/apache/derbyBuild/ReleaseNotesTransformer.java", "Logic to update src/documentation/conf/cli.xconf.", "M      build.xml", "Added an extra argument to the transformation ant task.", "Ported 1035700 from trunk to 10.7 branch at subversion revision 1035702."], "SplitGT": [" Wire the download page into the build instructions."], "issueString": "Automate release publication steps\nRight now, producing a Derby release involves 3 major chunks of work:\n\n1) Producing the release notes (happens the week before the first release candidate is produced)\n\n2) Producing release candidates (and submitting them to community vote)\n\n3) Publishing the release distributions (after the community approves a candidate)\n\nThis JIRA organizes work needed to automate the tasks which are part of step (3). Those steps are described here: http://wiki.apache.org/db-derby/ReleasePublication\nAttaching derby-4855-01-aa-docszip.diff. This patch adds a new target, repackagedocs, which automates the steps needed to create the zip file of re-arranged docs which we publish for a newly created release. Committed at subversion revision 1027230.\n\n\nTouches the following file:\n\nM      build.xml\n\nAttaching derby-4855-02-ab-releaseNotesTransformer.diff. This adds a new ant task and target for turning the release notes into a download page after the vote passes. Committed at subversion revision 1033940.\n\nCurrently, the release manager constructs the download page by hand. This involves merging material from two source html documents and removing material which the Forrest tool can't handle. The new ant task and target simplify this process and make it less brittle. To use this new target, do the following. You will be prompted to supply a little information:\n\no cd to the root of your code client\n\no then type \"ant transformreleasenotes\"\n\nTouches the following files:\n\n--------------\n\nA      java/build/org/apache/derbyBuild/ReleaseNotesTransformer.java\n\nNew ant task.\n\n--------------\n\nM      build.xml\n\nNew ant target.\n\nAttaching derby-4855-03-aa-cgiTemplate.diff. This patch introduces a template cgi script for creating download pages. Committed at\nsubversion revision 1034474.\n\nCurrently, the release instructions say that you should create a cgi script for the new release by copying the cgi script from an old release. This patch formalizes the notion of a template script, making it possible to automate the creation of the new script.\n\nTouches the following files:\n\n----------\n\nA      src/documentation/content/xdocs/releases/release-template.cgi\n\nThe new template script.\n\n----------\n\nM      build/site/releases/release-10.6.2.1.cgi\n\nThis is the built version of the 10.6.2.1 cgi script. It turns up checked-out in my website client. I think this is just a line-ending issue. The original script was probably produced on a Windows box.\n\nAttaching derby-4855-04-aa-copyCgiScript.diff. This makes the transformrelnotes target also create the cgi script for the download page for the new release. Committed at subversion revision 1034483.\n\n\nTouches the following file:\n\nM      build.xml\n\nAttaching derby-4855-05-aa-cliXconf.diff. This patch makes the transformrelnotes target wire the new download page into the website-building instructions so that it will be picked up when you build the Derby website. Committed at subversion revision 1035700.\n\nTouches the following files:\n\n----------\n\nM      java/build/org/apache/derbyBuild/ReleaseNotesTransformer.java\n\nLogic to update src/documentation/conf/cli.xconf.\n\n----------\n\nM      build.xml\n\nAdded an extra argument to the transformation ant task.\n\nPorted 1035700 from trunk to 10.7 branch at subversion revision 1035702.\n", "issueSearchSentences": ["Touches the following files:", "The new template script.", "o cd to the root of your code client", "M      java/build/org/apache/derbyBuild/ReleaseNotesTransformer.java", "subversion revision 1034474."], "issueSearchIndexes": [34, 36, 21, 51, 31]}
{"aId": 20, "code": "private void startLogReceiverThread() {\n        logReceiverThread = new SlaveLogReceiverThread();\n        logReceiverThread.start();\n    }", "comment": " Starts the LogReceiverThread that will listen for chunks of log records from the master and apply the log records to the local log file.", "issueId": "DERBY-3021", "issueStringList": ["Replication: Add a ReplicationSlave controller that will manage replication on the slave side", "The replication slave role includes many tasks:", "set up a network connection with the master", "receive chunks of log from the master, and parse these into individual log records", "append log records to the local log file", "make sure that the recovery process is not allowed to access the logfile we are currently writing to", "etc", "This issue is for adding a controller that will start/stop/initiate all services needed for the replication slave role.", "When Derby takes the replication slave role for a database, it has to start with an unmodified database image received from the master.", "Only log (i.e.", "operations) generated at the master can be appended to the slave database as long as it has this role.", "Normally, when a database is booted, Derby goes through recovery (in the LogFactory service).", "Recovery performs work that cannot be done when a database is in the slave mode.", "As an example, recovery will undo operations from transactions that are not logged as committed.", "Since first booting the database and then initiate replication will not work for the slave mode, slave functionality must be added to the work performed at database boot time.", "As in DERBY-2977, the slave controller service will be implemented incrementally in multiple steps:", "1) Add basic code to Derby so that the slave controller can be booted as a service when a \"startslave\" command is issued to NetworkServerControl", "2-n) Incrementally add controller logic as replication patches are added to Derby.", "The current plan for step 1 is:", "Add a slave replication property that is checked for when RawStore is booted", "If RawStore finds the property during boot, it will boot the SlaveController service and then start booting the LogFactory service in such a way that LogFactory#recovery does not disrupt replication.", "I want to refuse connections to a database that is in the slave mode.", "To do so, I intend to add a check in BasicDatabase.java#setupConnection that throws a StandardException stating \"Cannot connect to a database in replication slave mode\" or similar.", "In SQLStates.java there is now a subset of error codes for repliation: XRExx.", "Initially, I intended to use code XRE02.C for this error.", "However, this exception is thrown on connection, which has error class 08 in the SQL specification.", "Any thoughts on whether the most appropriate error code for this would be:", "XRE02.C since it is a replication error message with session severity, or", "0800x (e.g., 08006 - connection failure) since this is a connection error?", "Patch v1 adds a service that is booted at database boot time if SlaveFactory.SLAVE_MODE is specified in the boot Properties.", "Currently, this code is not reachable in Derby.", "M      java/engine/org/apache/derby/modules.properties", "A      java/engine/org/apache/derby/iapi/services/replication/slave", "A      java/engine/org/apache/derby/iapi/services/replication/slave/SlaveFactory.java", "A      java/engine/org/apache/derby/impl/services/replication/slave/SlaveController.java", "The new service, booted by RawStore if SlaveFactory.SLAVE_MODE is", "specified in the boot Properties", "M      java/engine/org/apache/derby/impl/store/raw/log/LogToFile.java", "Sets a variable inSlaveMode = true if SlaveFactory.SLAVE_MODE is found", "in the boot properties.", "This variable is not currently in use, but", "will be used soon", "M      java/engine/org/apache/derby/impl/store/raw/RawStore.java", "Boots SlaveFactory if SlaveFactory.SLAVE_MODE is specified in the boot Properties", "M      java/engine/org/apache/derby/impl/db/BasicDatabase.java", "Throws an exception if the database is in slave mode and a client", "tries to connect to it.", "M      java/engine/org/apache/derby/loc/messages.xml", "M      java/shared/org/apache/derby/shared/common/reference/SQLState.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/lang/ErrorCodeTest.java", "The new 08004 SQL state and message used when a connection attempt is", "performed on a database already booted in slave mode", "All tests pass for this patch combined with patch 1 for DERBY-3060.", "Code looks good.", "I have just a few minor comments, all on wording,", "but I think at least the javadoc errors need to be fixed before I can", "commit this patch:", "1.", "SlaveController#boot:", "I assume you mean 'new NetworkReceive()'", "2.", "SlaveController#failover, javadoc:", "a) \"operations from transactions where the commit log record has", "not been received from the master will be removed\" sounds a bit", "strange to me.", "I suggest either \"... will be undone\" or", "\"... will not be reflected\".", "b) References to MasterFactory and MasterController will not be", "resolved since they are not it the same package.", "3.", "BasicDatabase#boot, comment:", "\"Make sure it is not connected to by other clients\".", "I think it", "would be clearer if you said: \"Make sure other clients are not able", "to connect\"", "4.", "SlaveFactory#failover, javadoc:", "See 2 b)", "5. messages.xml:", "I suggest:  \"Connection refused to database ...\"", "\u00d8ystein,", "Thanks for reviewing the patch.", "I attached a new patch, v1b, incorporating your suggestions.", "I have not rerun the tests since there are no code changes.", "Committed patch derby-3021-1b.diff with revision 575670.", "This patch/commit caused a failure in the tinderbox test:", "1) test_errorcode(org.apache.derbyTesting.functionTests.tests.lang.ErrorCodeTest)junit.framework.AssertionFailedError: Missing rows in ResultSet", "at org.apache.derbyTesting.junit.JDBC.assertUnorderedResultSet(JDBC.java:1044)", "at org.apache.derbyTesting.junit.JDBC.assertUnorderedResultSet(JDBC.java:980)", "at org.apache.derbyTesting.functionTests.tests.lang.ErrorCodeTest.test_errorcode(ErrorCodeTest.java:243)", "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)", "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)", "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)", "at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:95)", "Is a new bug needed or is this already being worked on?", "\"I have not rerun the tests since there are no code changes.\"", "- Silly assumption; sorry about that one :-/", "I have found the error and am now *running tests* on it before submitting.", "I have already committed a fix as version 576288.", "For me, ErrorCodeTest now runs without errors.", "The attached patch, 2a, extends the functionality of the SlaveController to make use of the modifications to store.raw.log made in derby-3071.", "It touches the following files:", "M      java/engine/org/apache/derby/impl/services/replication/net/ReplicationMessageReceive.java", "Constructor now throws StandardException", "initConnection now times out if connection is not established", "M      java/engine/org/apache/derby/impl/services/replication/slave/SlaveController.java", "Localhost is now used to set up the network socket", "Added thread that applies log chunks received from the master", "Functionality to start replication slave mode", "M      java/engine/org/apache/derby/impl/store/raw/log/LogToFile.java", "Adds public methods for switchLogFile and applyLogRecord.", "These check that replication slave mode is active to avoid misuse.", "rename initializeSlaveReplication() to initializeReplicationSlaveMode() for consistency", "M      java/engine/org/apache/derby/iapi/services/replication/slave/SlaveFactory.java", "Added property keys: DB_NAME and SLAVE_HOST", "M      java/engine/org/apache/derby/impl/store/raw/log/ReadOnly.java", "M      java/engine/org/apache/derby/iapi/store/raw/log/LogFactory.java", "Added method initializeReplicationSlaveRole()", "M      java/engine/org/apache/derby/loc/messages.xml", "M      java/shared/org/apache/derby/shared/common/reference/SQLState.java", "M      java/shared/org/apache/derby/shared/common/reference/MessageId.java", "Added messages and exceptions", "Patch v2 passed all tests.", "Thanks for the patch, J\u00f8rgen.", "It looks good, but I have a few comments/questions?", "1.", "SlaveController:", "a) I think it is a bit confusing that part of the code assumes that", "logFactory is of type LogToFile, while other code does not.", "I", "think it is better to make that assumption up-front in", "startSlave().", "That would also mean that you would not have to", "create initializeReplicationSlaveRole() functions in LogFactory", "and ReadOnly.", "It can be specific to LogToFile.", "b) I think you should more explicitly state in comments that the", "main idea is that the slave does not time out while waiting for", "a connection from the master.", "It will continue doing so until a", "connection is achieved or it is told to shut down.", "c) It is a bit unclear to me how the properties for host name and", "port is to be used.", "Is the idea that these properties will be", "set right before trying to boot the slave?", "If I am not", "mistaken, these properties will be shared for the entire JVM.", "It seems like that could create problems if two different slave", "databases are booted in parallel?", "d) I think it would be cleaner if setUpConnection() returned a", "boolean that told whether a connection was achieved or not, and", "that this was used to determined whether to continue or not.", "Splitting the logic of testing for inReplicationSlaveMode over", "two functions seems a bit brittle to me.", "e) Will not accesses to inReplicationSlaveMode mode need to be", "synchronized (or the field made volatile)?", "Otherwise, I do not", "think there will be any guarantees as to when it will be detected", "that a stop has been requested.", "f) It would be good if the master and the slave could share the", "code to log errors.", "I do not see anything slave specific about", "logError().", "g) Typo in SlaveLogReceiverThread#run: \"Exceptions not _cause_ by\"", "2.", "LogToFile:", "a) I do not understand the comment for logFileNumber: \"current log", "file number other than during boot and recovery time, and by", "initializeReplicationSlaveRole if in slave replication mode,\".", "It seems to me that the last sentence \"and by ... \" does not fit", "in here.", "b) I am not sure I like the steps to prevent others from calling", "your publicized methods when not running as a slave.", "If someone", "wants to switch log files for other purposes, should he then", "make another function switchLogFileForOtherPurposes()?", "Either", "switchLogFile is part of the public interface, or it is not.", "At", "least, I do not feel generating run-time errors is the right", "approach.", "I think it is better to just document that you do not", "recommend it for other purposes.", "If you really want to hide", "this from the public interface, I guess you can implement a", "subclass of LogToFile in the replication package and let the", "existing methods be protected.", "c) I do not quite understand this comment:", "Before recovery is allowed to start, log scans will be", "allowed unrestricted access to the log files through this", "method.", "This is needed because boot() and", "initializeReplicationSlaveRole() use this method to find", "the log end.", "As opposed to after recovery is allowed to start, when the", "access is more restricted?", "3. messages.xml", "a) For XRE05, don't you have to indicate where the arguments should", "go?", "Thanks for reviewing the patch, \u00d8ystein.", "I uploaded a new patch,", "v2b, which is modified as follows:", "Fixed:", "1a,1b,1f,1g,2c: I agree.", "Fixed.", "1c: startSlave, where these property values are used, will be", "called immediately after booting the module.", "The properties", "belong to a specific connection, i.e., they have been specified", "by the caller of the startSlave command and are not shared", "between connections.", "If two slaves are started with the same slave port, either", "specified explicitly or because both use the default port,", "startSlave will throw a StandardException with type", "REPLICATION_CONNECTION_EXCEPTION, wrapping a", "'java.net.BindException: Address already in use' to the client", "calling startSlave last.", "1d: ok", "1e: inReplicationSlaveMode is volatile already.", "Does it still", "need to be synchronized?", "The only change that can be made to that", "boolean is setting it to false in stopSlave.", "It is never set to true except", "during object creation.", "2a: Should have been two sentences.", "\"current log file number.", "Other", "than...\" - changed", "2b: I thought asserts in sane mode should be used to check that", "the method usage was as planned?", "If another usage of the method", "later appeared, the person implementing that usage would be free", "to change this method... Not a big deal, though.", "I made", "switchLogFile and appendLogRecord public as suggested.", "3: Do you refer to the order of the arguments in", "SlaveController#handleLogChunk?", "If so - fixed.", "Patch v2b passed all tests.", "Thank you for adressing my comments J\u00f8rgen.", "The changes looks good, but it seems you have forgotten to add ReplicationLogger to the patch.", "(I am bit surprised that you have used inheritance here, but I guess that is a matter of personal taste.)", "My comments to 1c, 1e,  and 3, are misunderstandings on my side.", "For some reason I thought you were dealing with system properties, I did not see that it was already volatile, and part of the error message did not show up when I printed your patch.", "My bad.", "Hi \u00d8ystein,", "Reattaching the patch with ReplicationLogger added.", "Sorry 'bout that :)", "Committed patch  derby-3021-2c.diff  with revision 595900"], "SplitGT": [" Starts the LogReceiverThread that will listen for chunks of log records from the master and apply the log records to the local log file."], "issueString": "Replication: Add a ReplicationSlave controller that will manage replication on the slave side\nThe replication slave role includes many tasks:\n\n* set up a network connection with the master\n* receive chunks of log from the master, and parse these into individual log records\n* append log records to the local log file\n* make sure that the recovery process is not allowed to access the logfile we are currently writing to\n* etc\n\nThis issue is for adding a controller that will start/stop/initiate all services needed for the replication slave role.\nWhen Derby takes the replication slave role for a database, it has to start with an unmodified database image received from the master. Only log (i.e. operations) generated at the master can be appended to the slave database as long as it has this role.\n\nNormally, when a database is booted, Derby goes through recovery (in the LogFactory service). Recovery performs work that cannot be done when a database is in the slave mode. As an example, recovery will undo operations from transactions that are not logged as committed. Since first booting the database and then initiate replication will not work for the slave mode, slave functionality must be added to the work performed at database boot time. \n\nAs in DERBY-2977, the slave controller service will be implemented incrementally in multiple steps:\n1) Add basic code to Derby so that the slave controller can be booted as a service when a \"startslave\" command is issued to NetworkServerControl \n2-n) Incrementally add controller logic as replication patches are added to Derby. \n\nThe current plan for step 1 is:\n* Add a slave replication property that is checked for when RawStore is booted\n* If RawStore finds the property during boot, it will boot the SlaveController service and then start booting the LogFactory service in such a way that LogFactory#recovery does not disrupt replication.\nI want to refuse connections to a database that is in the slave mode. To do so, I intend to add a check in BasicDatabase.java#setupConnection that throws a StandardException stating \"Cannot connect to a database in replication slave mode\" or similar.\n\nIn SQLStates.java there is now a subset of error codes for repliation: XRExx. Initially, I intended to use code XRE02.C for this error. However, this exception is thrown on connection, which has error class 08 in the SQL specification. \n\nAny thoughts on whether the most appropriate error code for this would be:\n\n* XRE02.C since it is a replication error message with session severity, or\n* 0800x (e.g., 08006 - connection failure) since this is a connection error? \nPatch v1 adds a service that is booted at database boot time if SlaveFactory.SLAVE_MODE is specified in the boot Properties. Currently, this code is not reachable in Derby.\n\nM      java/engine/org/apache/derby/modules.properties\nA      java/engine/org/apache/derby/iapi/services/replication/slave\nA      java/engine/org/apache/derby/iapi/services/replication/slave/SlaveFactory.java\nA      java/engine/org/apache/derby/impl/services/replication/slave/SlaveController.java\n\nThe new service, booted by RawStore if SlaveFactory.SLAVE_MODE is\nspecified in the boot Properties\n\nM      java/engine/org/apache/derby/impl/store/raw/log/LogToFile.java\n\nSets a variable inSlaveMode = true if SlaveFactory.SLAVE_MODE is found\nin the boot properties. This variable is not currently in use, but\nwill be used soon\n\nM      java/engine/org/apache/derby/impl/store/raw/RawStore.java\n\nBoots SlaveFactory if SlaveFactory.SLAVE_MODE is specified in the boot Properties\n\nM      java/engine/org/apache/derby/impl/db/BasicDatabase.java\n\nThrows an exception if the database is in slave mode and a client\ntries to connect to it.\n\nM      java/engine/org/apache/derby/loc/messages.xml\nM      java/shared/org/apache/derby/shared/common/reference/SQLState.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/lang/ErrorCodeTest.java\n\nThe new 08004 SQL state and message used when a connection attempt is\nperformed on a database already booted in slave mode\n\nAll tests pass for this patch combined with patch 1 for DERBY-3060.\nCode looks good.  I have just a few minor comments, all on wording,\nbut I think at least the javadoc errors need to be fixed before I can\ncommit this patch:\n\n1. SlaveController#boot:  \n\n   I assume you mean 'new NetworkReceive()'\n\n\n2. SlaveController#failover, javadoc:\n\n   a) \"operations from transactions where the commit log record has\n      not been received from the master will be removed\" sounds a bit\n      strange to me.  I suggest either \"... will be undone\" or\n      \"... will not be reflected\".\n\n   b) References to MasterFactory and MasterController will not be\n      resolved since they are not it the same package.\n\n\n3. BasicDatabase#boot, comment:\n\n   \"Make sure it is not connected to by other clients\".  I think it\n   would be clearer if you said: \"Make sure other clients are not able\n   to connect\"\n\n\n4. SlaveFactory#failover, javadoc:\n\n   See 2 b)\n\n\n5. messages.xml:\n\n   I suggest:  \"Connection refused to database ...\"\n \n   \n\n\u00d8ystein, \n\nThanks for reviewing the patch. \n\nI attached a new patch, v1b, incorporating your suggestions. I have not rerun the tests since there are no code changes.\nCommitted patch derby-3021-1b.diff with revision 575670.\nThis patch/commit caused a failure in the tinderbox test:\n\n1) test_errorcode(org.apache.derbyTesting.functionTests.tests.lang.ErrorCodeTest)junit.framework.AssertionFailedError: Missing rows in ResultSet\n\tat org.apache.derbyTesting.junit.JDBC.assertUnorderedResultSet(JDBC.java:1044)\n\tat org.apache.derbyTesting.junit.JDBC.assertUnorderedResultSet(JDBC.java:980)\n\tat org.apache.derbyTesting.functionTests.tests.lang.ErrorCodeTest.test_errorcode(ErrorCodeTest.java:243)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:95)\n\nIs a new bug needed or is this already being worked on?\n\"I have not rerun the tests since there are no code changes.\" - Silly assumption; sorry about that one :-/\n\nI have found the error and am now *running tests* on it before submitting.\nI have already committed a fix as version 576288.  For me, ErrorCodeTest now runs without errors.\nThe attached patch, 2a, extends the functionality of the SlaveController to make use of the modifications to store.raw.log made in derby-3071. \n\nIt touches the following files:\n\nM      java/engine/org/apache/derby/impl/services/replication/net/ReplicationMessageReceive.java\n\nConstructor now throws StandardException\ninitConnection now times out if connection is not established\n\nM      java/engine/org/apache/derby/impl/services/replication/slave/SlaveController.java\n\nLocalhost is now used to set up the network socket\nAdded thread that applies log chunks received from the master\nFunctionality to start replication slave mode\n\n\nM      java/engine/org/apache/derby/impl/store/raw/log/LogToFile.java\n\nAdds public methods for switchLogFile and applyLogRecord. These check that replication slave mode is active to avoid misuse.\nrename initializeSlaveReplication() to initializeReplicationSlaveMode() for consistency\n\nM      java/engine/org/apache/derby/iapi/services/replication/slave/SlaveFactory.java\n\nAdded property keys: DB_NAME and SLAVE_HOST\n\nM      java/engine/org/apache/derby/impl/store/raw/log/ReadOnly.java\nM      java/engine/org/apache/derby/iapi/store/raw/log/LogFactory.java\n\nAdded method initializeReplicationSlaveRole()\n\nM      java/engine/org/apache/derby/loc/messages.xml\nM      java/shared/org/apache/derby/shared/common/reference/SQLState.java\nM      java/shared/org/apache/derby/shared/common/reference/MessageId.java\n\nAdded messages and exceptions\nPatch v2 passed all tests.\nThanks for the patch, J\u00f8rgen.  It looks good, but I have a few comments/questions?\n\n1. SlaveController:\n\n   a) I think it is a bit confusing that part of the code assumes that\n      logFactory is of type LogToFile, while other code does not.  I\n      think it is better to make that assumption up-front in\n      startSlave().  That would also mean that you would not have to\n      create initializeReplicationSlaveRole() functions in LogFactory\n      and ReadOnly.  It can be specific to LogToFile.\n\n   b) I think you should more explicitly state in comments that the\n      main idea is that the slave does not time out while waiting for\n      a connection from the master.  It will continue doing so until a\n      connection is achieved or it is told to shut down.\n\n   c) It is a bit unclear to me how the properties for host name and\n      port is to be used.  Is the idea that these properties will be\n      set right before trying to boot the slave?  If I am not\n      mistaken, these properties will be shared for the entire JVM.\n      It seems like that could create problems if two different slave\n      databases are booted in parallel?\n\n   d) I think it would be cleaner if setUpConnection() returned a\n      boolean that told whether a connection was achieved or not, and\n      that this was used to determined whether to continue or not.\n      Splitting the logic of testing for inReplicationSlaveMode over\n      two functions seems a bit brittle to me.\n\n   e) Will not accesses to inReplicationSlaveMode mode need to be\n      synchronized (or the field made volatile)?  Otherwise, I do not\n      think there will be any guarantees as to when it will be detected\n      that a stop has been requested.\n\n   f) It would be good if the master and the slave could share the\n      code to log errors.  I do not see anything slave specific about\n      logError().\n\n   g) Typo in SlaveLogReceiverThread#run: \"Exceptions not _cause_ by\"\n\n\n2. LogToFile:\n\n   a) I do not understand the comment for logFileNumber: \"current log\n      file number other than during boot and recovery time, and by\n      initializeReplicationSlaveRole if in slave replication mode,\".\n      It seems to me that the last sentence \"and by ... \" does not fit\n      in here.\n\n   b) I am not sure I like the steps to prevent others from calling\n      your publicized methods when not running as a slave.  If someone\n      wants to switch log files for other purposes, should he then\n      make another function switchLogFileForOtherPurposes()?  Either\n      switchLogFile is part of the public interface, or it is not.  At\n      least, I do not feel generating run-time errors is the right\n      approach.  I think it is better to just document that you do not\n      recommend it for other purposes.  If you really want to hide\n      this from the public interface, I guess you can implement a\n      subclass of LogToFile in the replication package and let the\n      existing methods be protected.\n\n   c) I do not quite understand this comment: \n        // Before recovery is allowed to start, log scans will be\n        // allowed unrestricted access to the log files through this\n        // method. This is needed because boot() and\n        // initializeReplicationSlaveRole() use this method to find\n        // the log end.\n      As opposed to after recovery is allowed to start, when the\n      access is more restricted?\n\n       \n3. messages.xml\n\n   a) For XRE05, don't you have to indicate where the arguments should\n      go?\n\nThanks for reviewing the patch, \u00d8ystein. I uploaded a new patch,\nv2b, which is modified as follows:\n\nFixed:\n\n1a,1b,1f,1g,2c: I agree. Fixed.\n\n1c: startSlave, where these property values are used, will be\ncalled immediately after booting the module. The properties\nbelong to a specific connection, i.e., they have been specified\nby the caller of the startSlave command and are not shared\nbetween connections.\n\nIf two slaves are started with the same slave port, either\nspecified explicitly or because both use the default port,\nstartSlave will throw a StandardException with type\nREPLICATION_CONNECTION_EXCEPTION, wrapping a\n'java.net.BindException: Address already in use' to the client\ncalling startSlave last.\n\n1d: ok\n\n1e: inReplicationSlaveMode is volatile already. Does it still\nneed to be synchronized? The only change that can be made to that\nboolean is setting it to false in stopSlave. It is never set to true except\nduring object creation.\n\n2a: Should have been two sentences. \"current log file number. Other\nthan...\" - changed\n\n2b: I thought asserts in sane mode should be used to check that\nthe method usage was as planned? If another usage of the method\nlater appeared, the person implementing that usage would be free\nto change this method... Not a big deal, though. I made\nswitchLogFile and appendLogRecord public as suggested.\n\n3: Do you refer to the order of the arguments in\nSlaveController#handleLogChunk? If so - fixed.\n\nPatch v2b passed all tests.\nThank you for adressing my comments J\u00f8rgen.  The changes looks good, but it seems you have forgotten to add ReplicationLogger to the patch.  (I am bit surprised that you have used inheritance here, but I guess that is a matter of personal taste.)\n\nMy comments to 1c, 1e,  and 3, are misunderstandings on my side.    For some reason I thought you were dealing with system properties, I did not see that it was already volatile, and part of the error message did not show up when I printed your patch.  My bad.\nHi \u00d8ystein,\n\nReattaching the patch with ReplicationLogger added. Sorry 'bout that :)\nCommitted patch  derby-3021-2c.diff  with revision 595900\n", "issueSearchSentences": ["Thanks for reviewing the patch, \u00d8ystein.", "logError().", "Added thread that applies log chunks received from the master", "SlaveController#boot:", "c) I do not quite understand this comment:"], "issueSearchIndexes": [200, 163, 108, 59, 188]}
{"aId": 22, "code": "public void\tupdateSYSCOLPERMSforAddColumnToUserTable(UUID tableID, TransactionController tc)\n\tthrows StandardException\n\t{\n\t\t// In Derby authorization mode, permission catalogs may not be present\n\t\tif (!usesSqlAuthorization)\n\t\t\treturn;\n\n\t\t/* This method has 2 steps to it. First get all the ColPermsDescriptor   \n\t\tfor given tableid. And next step is to go back to SYSCOLPERMS to find\n\t\tunique row corresponding to each of ColPermsDescriptor and update the\n\t\t\"COLUMNS\" column in SYSCOLPERMS. The reason for this 2 step process is\n\t\tthat SYSCOLPERMS has a non-unique row on \"TABLEID\" column and hence   \n\t\twe can't get a unique handle on each of the affected row in SYSCOLPERMS\n\t\tusing just the \"TABLEID\" column */\n\n\t\t// First get all the ColPermsDescriptor for the given tableid from   \n\t\t//SYSCOLPERMS using getDescriptorViaIndex(). \n\t\tList permissionDescriptorsList;//all ColPermsDescriptor for given tableid\n\t\tDataValueDescriptor\t\ttableIDOrderable = getValueAsDVD(tableID);\n\t\tTabInfoImpl\tti = getNonCoreTI(SYSCOLPERMS_CATALOG_NUM);\n\t\tSYSCOLPERMSRowFactory rf = (SYSCOLPERMSRowFactory) ti.getCatalogRowFactory();\n\t\tExecIndexRow keyRow = exFactory.getIndexableRow(1);\n\t\tkeyRow.setColumn(1, tableIDOrderable);\n\t\tpermissionDescriptorsList = newSList();\n\t\tgetDescriptorViaIndex(\n\t\t\tSYSCOLPERMSRowFactory.TABLEID_INDEX_NUM,\n\t\t\tkeyRow,\n\t\t\t(ScanQualifier [][]) null,\n\t\t\tti,\n\t\t\t(TupleDescriptor) null,\n\t\t\tpermissionDescriptorsList,\n\t\t\tfalse);\n\n\t\t/* Next, using each of the ColPermDescriptor's uuid, get the unique row \n\t\tin SYSCOLPERMS and expand the \"COLUMNS\" column in SYSCOLPERMS to \n\t\taccomodate the newly added column to the tableid*/\n\t\tColPermsDescriptor colPermsDescriptor;\n\t\tExecRow curRow;\n\t\tExecIndexRow uuidKey;\n\t\t// Not updating any indexes on SYSCOLPERMS\n\t\tboolean[] bArray = new boolean[SYSCOLPERMSRowFactory.TOTAL_NUM_OF_INDEXES];\n\t\tint[] colsToUpdate = {SYSCOLPERMSRowFactory.COLUMNS_COL_NUM};\n\t\tfor (Iterator iterator = permissionDescriptorsList.iterator(); iterator.hasNext(); )\n\t\t{\n\t\t\tcolPermsDescriptor = (ColPermsDescriptor) iterator.next();\n\t\t\tremovePermEntryInCache(colPermsDescriptor);\n\t\t\tuuidKey = rf.buildIndexKeyRow(rf.COLPERMSID_INDEX_NUM, colPermsDescriptor);\n\t\t\tcurRow=ti.getRow(tc, uuidKey, rf.COLPERMSID_INDEX_NUM);\n\t        FormatableBitSet columns = (FormatableBitSet) curRow.getColumn( \n\t\t\t\t\t  SYSCOLPERMSRowFactory.COLUMNS_COL_NUM).getObject();\n\t        int currentLength = columns.getLength();\n\t        columns.grow(currentLength+1);\n\t        curRow.setColumn(SYSCOLPERMSRowFactory.COLUMNS_COL_NUM,\n\t\t\t\t\t  dvf.getDataValue((Object) columns));\n\t\t\tti.updateRow(keyRow, curRow,\n\t\t\t\t\tSYSCOLPERMSRowFactory.TABLEID_INDEX_NUM,\n\t\t\t\t\t bArray, \n\t\t\t\t\t colsToUpdate,\n\t\t\t\t\t tc);\n\t\t}\n\t}", "comment": " SYSCOLPERMS has a column called \"COLUMNS\" which is a bit map for all the columns in a given user table.", "issueId": "DERBY-1847", "issueStringList": ["SELECT statement asserts with XJ001 when attempted to select a newly added column in SQL authorization mode", "Following script causes the select statement below to assert in sane build.", "ij> connect 'jdbc:derby:wombat;create=true' user 'user1' as user1;", "WARNING 01J14: SQL authorization is being used without first enabling authentication.", "ij> create table t1 (c1 int, c2 int);", "0 rows inserted/updated/deleted", "ij> grant select(c1,c2) on t1 to user2;", "0 rows inserted/updated/deleted", "ij> connect 'jdbc:derby:wombat;create=true' user 'user2' as user2;", "WARNING 01J01: Database 'wombat' not created, connection made to existing database instead.", "WARNING 01J14: SQL authorization is being used without first enabling authentication.", "ij(USER2)> set connection user1;", "ij(USER1)> alter table t1 add c3 int;", "0 rows inserted/updated/deleted", "ij(USER1)> set connection user2;", "ij(USER2)> select c3 from user1.t1;", "ERROR XJ001: Java exception: 'ASSERT FAILED Attempt to get a bit position (2)that exceeds the max length (2): org.apache.derby.shared.common.sanity.AssertFailure'.", "stack trace:", "org.apache.derby.shared.common.sanity.AssertFailure: ASSERT FAILED Attempt to get a bit position (1)that exceeds the max length (1)", "at org.apache.derby.shared.common.sanity.SanityManager.THROWASSERT(SanityManager.java:149)", "at org.apache.derby.iapi.services.io.FormatableBitSet.isSet(FormatableBitSet.java:614)", "at org.apache.derby.iapi.services.io.FormatableBitSet.get(FormatableBitSet.java:643)", "at org.apache.derby.iapi.sql.dictionary.StatementColumnPermission.check(StatementColumnPermission.java:119)", "at org.apache.derby.impl.sql.conn.GenericAuthorizer.authorize(GenericAuthorizer.java:158)", "at org.apache.derby.exe.ac601a400fx010dxaa5bx09e8x00000013b9400.fillResultSet(Unknown Source)", "at org.apache.derby.exe.ac601a400fx010dxaa5bx09e8x00000013b9400.execute(Unknown Source)", "at org.apache.derby.impl.sql.GenericActivationHolder.execute(GenericActivationHolder.java:327)", "at org.apache.derby.impl.sql.GenericPreparedStatement.execute(GenericPreparedStatement.java:356)", "at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(EmbedStatement.java:1182)", "at org.apache.derby.impl.jdbc.EmbedStatement.execute(EmbedStatement.java:585)", "at org.apache.derby.impl.jdbc.EmbedStatement.execute(EmbedStatement.java:517)", "at org.apache.derby.impl.tools.ij.ij.executeImmediate(ij.java:321)", "at org.apache.derby.impl.tools.ij.utilMain.doCatch(utilMain.java:517)", "at org.apache.derby.impl.tools.ij.utilMain.runScriptGuts(utilMain.java:370)", "at org.apache.derby.impl.tools.ij.utilMain.go(utilMain.java:268)", "at org.apache.derby.impl.tools.ij.Main.go(Main.java:204)", "at org.apache.derby.impl.tools.ij.Main.mainCore(Main.java:170)", "at org.apache.derby.impl.tools.ij.Main14.main(Main14.java:56)", "at org.apache.derby.tools.ij.main(ij.java:71)", "sysinfo:", "Java Information ------------------", "Java Version:    1.4.2_12", "Java Vendor:     Sun Microsystems Inc.", "Java home:       C:\\Program Files\\Java\\j2re1.4.2_12", "Java classpath:  classes;.", "OS name:         Windows XP", "OS architecture: x86", "OS version:      5.1", "Java user name:  Yip", "Java user home:  C:\\Documents and Settings\\Yip", "Java user dir:   C:\\work3\\derby\\trunk", "java.specification.name: Java Platform API Specification", "java.specification.version: 1.4", "Derby Information --------", "JRE - JDBC: J2SE 1.4.2 - JDBC 3.0", "[C:\\work3\\derby\\trunk\\classes] 10.3.0.0 alpha - (443080)", "Locale Information -----------------", "Current Locale :  [English/United States [en_US]]", "Found support for locale: [de_DE]", "version: 10.3.0.0 alpha - (443080)", "Found support for locale: [es]", "version: 10.3.0.0 alpha - (443080)", "Found support for locale: [fr]", "version: 10.3.0.0 alpha - (443080)", "Found support for locale: [it]", "version: 10.3.0.0 alpha - (443080)", "Found support for locale: [ja_JP]", "version: 10.3.0.0 alpha - (443080)", "Found support for locale: [ko_KR]", "version: 10.3.0.0 alpha - (443080)", "Found support for locale: [pt_BR]", "version: 10.3.0.0 alpha - (443080)", "Found support for locale: [zh_CN]", "version: 10.3.0.0 alpha - (443080)", "Found support for locale: [zh_TW]", "version: 10.3.0.0 alpha - (443080)", "It looks like at alter table add column/drop column time, we need to go update the column \"COLUMNS\" in SYSCOLPERMS to incorporate the change in the table's column structure.", "Unassigning myself from this jira, just realized that I still have another jira issue open.", "At a very high level, it seems like we need to:", "run through each row in SYSCOLPERMS and call FormatableBitSet.grow(1) on the COLUMNS column", "clear the PermissionsCache so that in-memory descriptors will get re-read", "The clearing of the PermissionsCache seems like it should happen in", "DataDictionaryImpl.clearCaches.", "Thanks for sharing your findings from ALTER TABLE DROP COLUMN, Bryan.", "I will investigate further into this Jira entry to see how", "1)SYSCOLPERMS should be updated and", "2)clear the permission cache so that we don't use stale column permission descriptors.", "It looks like the permission cache is handled differently than the other descriptor caches.", "When DataDictionary's startWriting()  is called, the other caches will be *ALL* cleared out except for the permission cache, where the actual removal of its cached items are done in various DDL contant actions(DROP TABLE/VIEW, etc.)", "and it only removes those associated cached permission descriptor(s) and not *ALL* of them.", "So it seems like the permission cache clearing was left out  intentionally in clearCaches().", "It would be helpful to know if this is indeed the case.", "Just wanted to mention that I was distracted by other work during last few days but have started working on this jira entry again and making progress.", "Hope to have something to propose by early next week.", "I have attached a patch as DERBY1846_V1_diff_AddColumnAndGrantRevoke.txt", "The output of svn stat -q is attached as DERBY1846_V1_stat_AddColumnAndGrantRevoke.txt", "To recap the problem, in SQL Authorization mode, when a new column is added to a table, the rows in SYSCOLPERMS for the table in question were not getting updated to incorporate the new column.", "This caused ASSERT failure when a non-table owner attempted to select the new column.", "Some background information on system table involved: SYSCOLPERMS keeps track of column level privileges on a given table.", "One of the columns in SYSCOLPERMS is \"COLUMNS\" and it has a bit map to show which columns have the given permission granted on them.", "When a new column is added to the user table, the \"COLUMNS\" need to be expanded by one bit and that bit should be initialized to zero since no privileges have been granted on that column at the ALTER TABLE...ADD COLUMN time.", "I have fixed this problem by having AlterTableConstantAction.addNewColumnToTable call the new method in DataDictionary called updateSYSCOLPERMSforAddColumnToUserTable.", "At this point, we know of only the TableDescriptor's uuid which can help us determine all the rows in SYSCOLPERMS for that given table uuid.", "I get ColPermsDescriptor for each one of those rows and then use the ColPermsDescriptor's uuid to update the \"COLUMNS\" column so SYSCOLPERMS is aware of the newly added column in user table.", "This fixes the problem because at the time of SELECT, when we do privilege lookup in SYSCOLPERMS, we have info on the newly added column.", "I have added few tests for this Jira entry in lang/grantRevokeDDL.sql The derbyall suite ran fine on Windows XP with Sun's jdk 1.4", "Any feedback will be greatly appreciated.", "Hi Mamta, I took a look at your patch and it makes sense to me.", "A handful of questions:", "1) I was interested in why you chose to put the new logic into DataDictionaryImpl as", "opposed to, perhaps, TablePrivilegeInfo.", "2) I was wondering whether you thought that updateSYSCOLPERMSforAddColumnToUserTable()", "could also be used, in the future, as part of solving DERBY-1909, and, if so, whether the", "possible future reuse of this routine might run into any complications trying to share the code.", "3) I was confused by this part of your change to DataDictionaryImpl (see below).", "Is this a", "necessary part of the change, or is it some cleanup that you were doing as part of working", "in this class?", "@@ -2528,7 +2606,6 @@", "{", "ExecRow curRow;", "PermissionsDescriptor perm;", "ExecIndexRow newKey;", "TabInfoImpl\tti = getNonCoreTI(SYSTABLEPERMS_CATALOG_NUM);", "SYSTABLEPERMSRowFactory rf = (SYSTABLEPERMSRowFactory) ti.getCatalogRowFactory();", "@@ -2560,7 +2637,6 @@", "{", "ExecRow curRow;", "PermissionsDescriptor perm;", "ExecIndexRow newKey;", "TabInfoImpl\tti = getNonCoreTI(SYSCOLPERMS_CATALOG_NUM);", "SYSCOLPERMSRowFactory rf = (SYSCOLPERMSRowFactory) ti.getCatalogRowFactory();", "@@ -10223,9 +10299,7 @@", "Remove cached permissions data.", "The cache may hold permissions data for this key even if", "the row in the permissions table is new.", "In that case the cache may have an entry indicating no", "permissions", "Cacheable cacheEntry = getPermissionsCache().findCached( perm);", "if( cacheEntry != null)", "getPermissionsCache().remove( cacheEntry);", "+\t\tremovePermEntryInCache(perm);", "If we are dealing with grant, then the caller does not need to send", "any invalidation actions to anyone and hence return false", "Bryan, thanks for taking the time to review the code.", "Let me answer attempt to answer your questions", "1)Main reason behind putting the update system table code in DataDictionary was that for some reason, I thought DataDictionary class was the place to put all the code related to updating the system tables.", "2)I think DERBY-1909 might need the some of the same code as updateSYSCOLPERMSforAddColumnToUserTable(), in particular, getting the affected rows from SYSCOLPERMS using the tableid.", "May be I should go ahead and put some comment in DERBY-1909 for this so whoever works on it will be aware of the code in updateSYSCOLPERMSforAddColumnToUserTable()", "3)I always tend to cleanup code around when I work on a Jira entry although it is not related to actual work that I am doing (wish, I did that at home, my house will look much cleaner).", "So, sorry about the confusion about the cleanup work that went into this patch.", "They were not related to the bug and I should have said something in my patch description about it.", "committed patch to the trunk and marked fixed in 10.3.", "m3_ibm142:148>svn commit", "Sending        java\\engine\\org\\apache\\derby\\iapi\\sql\\dictionary\\DataDictionary.j", "ava", "Sending        java\\engine\\org\\apache\\derby\\impl\\sql\\catalog\\DataDictionaryImpl.", "java", "Sending        java\\engine\\org\\apache\\derby\\impl\\sql\\catalog\\SYSCOLPERMSRowFacto", "ry.java", "Sending        java\\engine\\org\\apache\\derby\\impl\\sql\\execute\\AlterTableConstantA", "ction.java", "Sending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\grantRe", "vokeDDL.out", "Sending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\tests\\lang\\gra", "ntRevokeDDL.sql", "Transmitting file data ......", "Committed revision 453352."], "SplitGT": [" SYSCOLPERMS has a column called \"COLUMNS\" which is a bit map for all the columns in a given user table."], "issueString": "SELECT statement asserts with XJ001 when attempted to select a newly added column in SQL authorization mode\nFollowing script causes the select statement below to assert in sane build. \n\nij> connect 'jdbc:derby:wombat;create=true' user 'user1' as user1;\nWARNING 01J14: SQL authorization is being used without first enabling authentication.\nij> create table t1 (c1 int, c2 int);\n0 rows inserted/updated/deleted\nij> grant select(c1,c2) on t1 to user2;\n0 rows inserted/updated/deleted\nij> connect 'jdbc:derby:wombat;create=true' user 'user2' as user2;\nWARNING 01J01: Database 'wombat' not created, connection made to existing database instead.\nWARNING 01J14: SQL authorization is being used without first enabling authentication.\nij(USER2)> set connection user1;\nij(USER1)> alter table t1 add c3 int;\n0 rows inserted/updated/deleted\nij(USER1)> set connection user2;\nij(USER2)> select c3 from user1.t1;\nERROR XJ001: Java exception: 'ASSERT FAILED Attempt to get a bit position (2)that exceeds the max length (2): org.apache.derby.shared.common.sanity.AssertFailure'.\n\nstack trace:\n\norg.apache.derby.shared.common.sanity.AssertFailure: ASSERT FAILED Attempt to get a bit position (1)that exceeds the max length (1)\n\tat org.apache.derby.shared.common.sanity.SanityManager.THROWASSERT(SanityManager.java:149)\n\tat org.apache.derby.iapi.services.io.FormatableBitSet.isSet(FormatableBitSet.java:614)\n\tat org.apache.derby.iapi.services.io.FormatableBitSet.get(FormatableBitSet.java:643)\n\tat org.apache.derby.iapi.sql.dictionary.StatementColumnPermission.check(StatementColumnPermission.java:119)\n\tat org.apache.derby.impl.sql.conn.GenericAuthorizer.authorize(GenericAuthorizer.java:158)\n\tat org.apache.derby.exe.ac601a400fx010dxaa5bx09e8x00000013b9400.fillResultSet(Unknown Source)\n\tat org.apache.derby.exe.ac601a400fx010dxaa5bx09e8x00000013b9400.execute(Unknown Source)\n\tat org.apache.derby.impl.sql.GenericActivationHolder.execute(GenericActivationHolder.java:327)\n\tat org.apache.derby.impl.sql.GenericPreparedStatement.execute(GenericPreparedStatement.java:356)\n\tat org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(EmbedStatement.java:1182)\n\tat org.apache.derby.impl.jdbc.EmbedStatement.execute(EmbedStatement.java:585)\n\tat org.apache.derby.impl.jdbc.EmbedStatement.execute(EmbedStatement.java:517)\n\tat org.apache.derby.impl.tools.ij.ij.executeImmediate(ij.java:321)\n\tat org.apache.derby.impl.tools.ij.utilMain.doCatch(utilMain.java:517)\n\tat org.apache.derby.impl.tools.ij.utilMain.runScriptGuts(utilMain.java:370)\n\tat org.apache.derby.impl.tools.ij.utilMain.go(utilMain.java:268)\n\tat org.apache.derby.impl.tools.ij.Main.go(Main.java:204)\n\tat org.apache.derby.impl.tools.ij.Main.mainCore(Main.java:170)\n\tat org.apache.derby.impl.tools.ij.Main14.main(Main14.java:56)\n\tat org.apache.derby.tools.ij.main(ij.java:71)\n\nsysinfo:\n\n------------------ Java Information ------------------\nJava Version:    1.4.2_12\nJava Vendor:     Sun Microsystems Inc.\nJava home:       C:\\Program Files\\Java\\j2re1.4.2_12\nJava classpath:  classes;.\nOS name:         Windows XP\nOS architecture: x86\nOS version:      5.1\nJava user name:  Yip\nJava user home:  C:\\Documents and Settings\\Yip\nJava user dir:   C:\\work3\\derby\\trunk\njava.specification.name: Java Platform API Specification\njava.specification.version: 1.4\n--------- Derby Information --------\nJRE - JDBC: J2SE 1.4.2 - JDBC 3.0\n[C:\\work3\\derby\\trunk\\classes] 10.3.0.0 alpha - (443080)\n------------------------------------------------------\n----------------- Locale Information -----------------\nCurrent Locale :  [English/United States [en_US]]\nFound support for locale: [de_DE]\n         version: 10.3.0.0 alpha - (443080)\nFound support for locale: [es]\n         version: 10.3.0.0 alpha - (443080)\nFound support for locale: [fr]\n         version: 10.3.0.0 alpha - (443080)\nFound support for locale: [it]\n         version: 10.3.0.0 alpha - (443080)\nFound support for locale: [ja_JP]\n         version: 10.3.0.0 alpha - (443080)\nFound support for locale: [ko_KR]\n         version: 10.3.0.0 alpha - (443080)\nFound support for locale: [pt_BR]\n         version: 10.3.0.0 alpha - (443080)\nFound support for locale: [zh_CN]\n         version: 10.3.0.0 alpha - (443080)\nFound support for locale: [zh_TW]\n         version: 10.3.0.0 alpha - (443080)\n------------------------------------------------------\nIt looks like at alter table add column/drop column time, we need to go update the column \"COLUMNS\" in SYSCOLPERMS to incorporate the change in the table's column structure.\nUnassigning myself from this jira, just realized that I still have another jira issue open.\nAt a very high level, it seems like we need to:\n - run through each row in SYSCOLPERMS and call FormatableBitSet.grow(1) on the COLUMNS column\n - clear the PermissionsCache so that in-memory descriptors will get re-read\n\nThe clearing of the PermissionsCache seems like it should happen in\nDataDictionaryImpl.clearCaches.\n\nThanks for sharing your findings from ALTER TABLE DROP COLUMN, Bryan. I will investigate further into this Jira entry to see how \n1)SYSCOLPERMS should be updated and \n2)clear the permission cache so that we don't use stale column permission descriptors.\nIt looks like the permission cache is handled differently than the other descriptor caches.  When DataDictionary's startWriting()  is called, the other caches will be *ALL* cleared out except for the permission cache, where the actual removal of its cached items are done in various DDL contant actions(DROP TABLE/VIEW, etc.) and it only removes those associated cached permission descriptor(s) and not *ALL* of them.  So it seems like the permission cache clearing was left out  intentionally in clearCaches().  It would be helpful to know if this is indeed the case.\n\nJust wanted to mention that I was distracted by other work during last few days but have started working on this jira entry again and making progress. Hope to have something to propose by early next week.\nI have attached a patch as DERBY1846_V1_diff_AddColumnAndGrantRevoke.txt\nThe output of svn stat -q is attached as DERBY1846_V1_stat_AddColumnAndGrantRevoke.txt\n\nTo recap the problem, in SQL Authorization mode, when a new column is added to a table, the rows in SYSCOLPERMS for the table in question were not getting updated to incorporate the new column. This caused ASSERT failure when a non-table owner attempted to select the new column.\n\nSome background information on system table involved: SYSCOLPERMS keeps track of column level privileges on a given table. One of the columns in SYSCOLPERMS is \"COLUMNS\" and it has a bit map to show which columns have the given permission granted on them. When a new column is added to the user table, the \"COLUMNS\" need to be expanded by one bit and that bit should be initialized to zero since no privileges have been granted on that column at the ALTER TABLE...ADD COLUMN time.\n\nI have fixed this problem by having AlterTableConstantAction.addNewColumnToTable call the new method in DataDictionary called updateSYSCOLPERMSforAddColumnToUserTable. At this point, we know of only the TableDescriptor's uuid which can help us determine all the rows in SYSCOLPERMS for that given table uuid. I get ColPermsDescriptor for each one of those rows and then use the ColPermsDescriptor's uuid to update the \"COLUMNS\" column so SYSCOLPERMS is aware of the newly added column in user table. This fixes the problem because at the time of SELECT, when we do privilege lookup in SYSCOLPERMS, we have info on the newly added column.\n\nI have added few tests for this Jira entry in lang/grantRevokeDDL.sql The derbyall suite ran fine on Windows XP with Sun's jdk 1.4\n\nAny feedback will be greatly appreciated.\nHi Mamta, I took a look at your patch and it makes sense to me. A handful of questions:\n\n1) I was interested in why you chose to put the new logic into DataDictionaryImpl as\nopposed to, perhaps, TablePrivilegeInfo.\n\n2) I was wondering whether you thought that updateSYSCOLPERMSforAddColumnToUserTable()\ncould also be used, in the future, as part of solving DERBY-1909, and, if so, whether the\npossible future reuse of this routine might run into any complications trying to share the code.\n\n3) I was confused by this part of your change to DataDictionaryImpl (see below). Is this a\nnecessary part of the change, or is it some cleanup that you were doing as part of working\nin this class?\n\n@@ -2528,7 +2606,6 @@\n\n \t{\n \t\tExecRow curRow;\n \t\tPermissionsDescriptor perm;\n-\t\tExecIndexRow newKey;\n \t\tTabInfoImpl\tti = getNonCoreTI(SYSTABLEPERMS_CATALOG_NUM);\n \t\tSYSTABLEPERMSRowFactory rf = (SYSTABLEPERMSRowFactory) ti.getCatalogRowFactory();\n \n@@ -2560,7 +2637,6 @@\n\n \t{\n \t\tExecRow curRow;\n \t\tPermissionsDescriptor perm;\n-\t\tExecIndexRow newKey;\n \t\tTabInfoImpl\tti = getNonCoreTI(SYSCOLPERMS_CATALOG_NUM);\n \t\tSYSCOLPERMSRowFactory rf = (SYSCOLPERMSRowFactory) ti.getCatalogRowFactory();\n \n@@ -10223,9 +10299,7 @@\n\n         // Remove cached permissions data. The cache may hold permissions data for this key even if\n         // the row in the permissions table is new. In that case the cache may have an entry indicating no\n         // permissions\n-        Cacheable cacheEntry = getPermissionsCache().findCached( perm);\n-        if( cacheEntry != null)\n-            getPermissionsCache().remove( cacheEntry);\n+\t\tremovePermEntryInCache(perm);\n \n         //If we are dealing with grant, then the caller does not need to send \n         //any invalidation actions to anyone and hence return false\n\nBryan, thanks for taking the time to review the code.\n\nLet me answer attempt to answer your questions \n1)Main reason behind putting the update system table code in DataDictionary was that for some reason, I thought DataDictionary class was the place to put all the code related to updating the system tables. \n\n2)I think DERBY-1909 might need the some of the same code as updateSYSCOLPERMSforAddColumnToUserTable(), in particular, getting the affected rows from SYSCOLPERMS using the tableid. May be I should go ahead and put some comment in DERBY-1909 for this so whoever works on it will be aware of the code in updateSYSCOLPERMSforAddColumnToUserTable() \n\n3)I always tend to cleanup code around when I work on a Jira entry although it is not related to actual work that I am doing (wish, I did that at home, my house will look much cleaner). So, sorry about the confusion about the cleanup work that went into this patch. They were not related to the bug and I should have said something in my patch description about it.\n\ncommitted patch to the trunk and marked fixed in 10.3.\n\nm3_ibm142:148>svn commit\n\nSending        java\\engine\\org\\apache\\derby\\iapi\\sql\\dictionary\\DataDictionary.j\nava\nSending        java\\engine\\org\\apache\\derby\\impl\\sql\\catalog\\DataDictionaryImpl.\njava\nSending        java\\engine\\org\\apache\\derby\\impl\\sql\\catalog\\SYSCOLPERMSRowFacto\nry.java\nSending        java\\engine\\org\\apache\\derby\\impl\\sql\\execute\\AlterTableConstantA\nction.java\nSending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\grantRe\nvokeDDL.out\nSending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\tests\\lang\\gra\nntRevokeDDL.sql\nTransmitting file data ......\nCommitted revision 453352.\n", "issueSearchSentences": ["At this point, we know of only the TableDescriptor's uuid which can help us determine all the rows in SYSCOLPERMS for that given table uuid.", "TabInfoImpl\tti = getNonCoreTI(SYSCOLPERMS_CATALOG_NUM);", "At a very high level, it seems like we need to:", "Some background information on system table involved: SYSCOLPERMS keeps track of column level privileges on a given table.", "The output of svn stat -q is attached as DERBY1846_V1_stat_AddColumnAndGrantRevoke.txt"], "issueSearchIndexes": [103, 131, 79, 99, 96]}
{"aId": 24, "code": "public static long skipFully(InputStream is) throws IOException {\n        if(is == null)\n            throw new NullPointerException();\n\n        long bytes = 0;\n        long r = 0;\n        while((r = skipPersistent(is, SKIP_BUFFER_SIZE)) > 0){\n            bytes += r;\n        }\n\n        return bytes;\n    }", "comment": " Skips until EOF, returns number of bytes skipped.", "issueId": "DERBY-3770", "issueStringList": ["Create a utility class for skipping data in an InputStream", "The contract of InputStream.skip is somewhat difficult, some would even say broken.", "See http://java.sun.com/javase/6/docs/api/java/io/InputStream.html#skip(long))", "A utility class should be created to ensure that we use the same skip procedure throughout the Derby code base.", "Suggested functionality:", "long skipFully(InputStream) : skips until EOF, returns number of bytes skipped", "void skipFully(InputStream,long) : skips requested number of bytes, throws EOFException if there is too few bytes in the stream", "I know of two different approaches, both skipping in a loop:", "a) Verify EOF with a read call when skip returns zero.", "b) Throw EOFException if skip returns zero before requested number of bytes have been skipped.", "There's related code in iapi.util.UTF8Util.", "Maybe this class, say StreamUtil, could be put in the same package?", "Hi, Kristian.", "Please check the patch, thanks!", "Junjie, I will look at the patch soon but if you get a chance, can you put a brief description of the logic of the patch in this jira entry?", "Junjie, the patch is commented pretty well and the code changes for those comments look good.", "One comment for the engine code change", "1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes).", "Should we put NullPointerException() also in the javadoc?", "Just couple comments for the new junit test", "1)testNullStream has 2 test cases to check for null inputstream.", "For some reason, if no NullPointerException is thrown, then we have following to catch it", "fail(\"Null InputStream is refused!", "\");", "The error message looks misleading.", "Should it be saying something like", "fail(\"Null InputStream is accepted!", "\");", "2)The 2 tests in testNullStream only check for NullPointerException.", "Shouldn't we be catching other exceptions and make the test fail for those exceptions.", "3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre.", "Thanks for working on this jira entry.", "Thanks for your attention, Mamta.", "I have receive your comments just now.", "Sorry to reply late.", "<<Junjie, the patch is commented pretty well and the code changes for those comments look good.", "<<One comment for the engine code change", "<<1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes).", "Should we put NullPointerException() also in the javadoc?", "I have add the declaration for NullException.", "<<Just couple comments for the new junit test", "<<1)testNullStream has 2 test cases to check for null inputstream.", "For some reason, if no NullPointerException is thrown, then we have following to catch it", "<<fail(\"Null InputStream is refused!", "\");", "<<The error message looks misleading.", "Should it be saying something like", "<<fail(\"Null InputStream is accepted!", "\");", "I have correct it.", "<<2)The 2 tests in testNullStream only check for NullPointerException.", "Shouldn't we be catching other exceptions and make the test fail for those exceptions.", "I'm not clear about this.", "What other exceptions should be tested int testNullStream()?", "For EOFException, I have tested it in testSkipFully().", "As to IOException, excluding EOFException, I don't know how to create or simulate it.", "Could you give me more advices?", "<<3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre.", "testSkipUtilEOFWithOddLength() only tests EOF with special length, I think it's better to seperate it from common length.", "Is the name of the method not clear?", "Is testSkipUtilEOFWithSpecialLength() better?", "<<Thanks for working on this jira entry.", "Mamta, please give more suggestion to improve the patch.", "Thanks again!", "Regards", "Junjie", "Junjie, sorry for not getting back to you sooner.", "What I meant bu comment 2) for the tests is something along following line.", "In most of the JDBC junit tests in Derby, if say executing a specific query is only allowed to send a specific exception, then we assert that using following (s below is java.sql.Statement)", "assertStatementError(\"42Y55\", s, \"CALL SYSCS_UTIL.SYSCS_UPDATE_STATISTICS('APP','T1',null)\");", "So, if the query above throws any exception other than \"42Y55\" then that will cause the junit test to fail saying that it expected 42Y55 but it got something else.", "I was wonderinf in the test in question here, if there was anyway of catching exceptions other than NPE", "+        try{", "+            StreamUtil.skipFully(null);", "+            fail(\"Null InputStream is accepted!", "\");", "+        }catch (NullPointerException e) {", "+            assertTrue(true);", "+        }", "I guess, if the test case above did get an exception other than NPE, we will just get out of the test fixture with that exception.", "I was curious if there was some more graceful way of catching unexpected exceptions like we do for jave.sql.Statement with assertStatementError.", "This is not a biggie and feel free to not address this issue if there is no simple way of doing what assertStatementError does.", "Mamta, thanks for your adivice.", "I have contemplated your comment , I think the test is OK in this situation.", "The NPE is checked first when calling the skipFully() method, so no other kind of exception will be thrown.", "What's your opinion?", "As to the \"more graceful way of catching unexpected exceptions\", above all, thanks for your advice, it helps me understand the test framework better.", "However, I haven't found known tools to realize it, so I would leave it as it's now.", "Regards", "Junjie", "The handling of unexpected exceptions looks fine to me.", "Since they are not caught explicitly, they will propagate out to the JUnit framework and be reported correctly there.", "It may be slightly clearer, though, if we replace assertTrue(true) with just a comment like this:", "catch (NullPointerException npe) {", "ignoring expected exception", "}", "The StreamUtil class imports sun.tools.tree.NullExpression, which seems wrong.", "Also, the javadoc comments in that class say \"@throws NullExpression\", whereas they should have said \"@throws NullPointerException\".", "It's probably also a good idea to move the code from UTF8Util.skipPersistent() into the StreamUtil class, since that method doesn't have anything to do with UTF-8 and therefore making it non-private in the UTF8Util class may cause some confusion.", "Hi, Knut.", "Thanks for your advice.", "1.)", "---test framework.", "I agree with your method to add comment \"      // ignoring expected exception \".", "However, as what I used is just like Andrew suggested in his <Pragmatic Unit Testing>, I think it can work well.", "2.)", "---wrong import.", "I have corrected in the new patch.", "3.)", "---move the code from UTF8Util.skipPersistent() into the StreamUtil class.", "It's a good suggestion, I have adopted it.", "Please check the patch!", "Regards", "Junjie", "Thanks, Junjie!", "The patch looks good to me.", "I'll run some tests and commit the patch if there are no problems.", "Committed revision 688049.", "Some questions/comments about    skipFully(InputStream is)", "What is the purpose of this method, when would it be used?", "Skipping until EOF seems a useless operation.", "SKIP_BUFFER_SIZE is a somewhat confusing name since no buffer is ever allocated.", "skipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent().", "Other input stream utility methods are in org.apache.derby.iapi.services.io, any reason to have this new class in a different package?"], "SplitGT": [" Skips until EOF, returns number of bytes skipped."], "issueString": "Create a utility class for skipping data in an InputStream\nThe contract of InputStream.skip is somewhat difficult, some would even say broken.\nSee http://java.sun.com/javase/6/docs/api/java/io/InputStream.html#skip(long))\n\nA utility class should be created to ensure that we use the same skip procedure throughout the Derby code base.\nSuggested functionality:\n - long skipFully(InputStream) : skips until EOF, returns number of bytes skipped\n - void skipFully(InputStream,long) : skips requested number of bytes, throws EOFException if there is too few bytes in the stream\n\nI know of two different approaches, both skipping in a loop:\n a) Verify EOF with a read call when skip returns zero.\n b) Throw EOFException if skip returns zero before requested number of bytes have been skipped.\n\nThere's related code in iapi.util.UTF8Util. Maybe this class, say StreamUtil, could be put in the same package?\nHi, Kristian. Please check the patch, thanks!\nJunjie, I will look at the patch soon but if you get a chance, can you put a brief description of the logic of the patch in this jira entry?\nJunjie, the patch is commented pretty well and the code changes for those comments look good. \nOne comment for the engine code change\n1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes). Should we put NullPointerException() also in the javadoc?\n\nJust couple comments for the new junit test\n1)testNullStream has 2 test cases to check for null inputstream. For some reason, if no NullPointerException is thrown, then we have following to catch it\nfail(\"Null InputStream is refused!\");\nThe error message looks misleading. Should it be saying something like\nfail(\"Null InputStream is accepted!\");\n2)The 2 tests in testNullStream only check for NullPointerException. Shouldn't we be catching other exceptions and make the test fail for those exceptions.\n3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre.\n\nThanks for working on this jira entry.\nThanks for your attention, Mamta. I have receive your comments just now. Sorry to reply late.\n\n<<Junjie, the patch is commented pretty well and the code changes for those comments look good. \n<<One comment for the engine code change \n<<1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes). Should we put NullPointerException() also in the javadoc? \n-----I have add the declaration for NullException.\n\n<<Just couple comments for the new junit test \n<<1)testNullStream has 2 test cases to check for null inputstream. For some reason, if no NullPointerException is thrown, then we have following to catch it \n<<fail(\"Null InputStream is refused!\"); \n<<The error message looks misleading. Should it be saying something like \n<<fail(\"Null InputStream is accepted!\");\n-----I have correct it. \n<<2)The 2 tests in testNullStream only check for NullPointerException. Shouldn't we be catching other exceptions and make the test fail for those exceptions. \n-----I'm not clear about this. What other exceptions should be tested int testNullStream()? For EOFException, I have tested it in testSkipFully(). As to IOException, excluding EOFException, I don't know how to create or simulate it. Could you give me more advices?\n<<3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre. \n-----testSkipUtilEOFWithOddLength() only tests EOF with special length, I think it's better to seperate it from common length. Is the name of the method not clear? Is testSkipUtilEOFWithSpecialLength() better?\n<<Thanks for working on this jira entry. \n\nMamta, please give more suggestion to improve the patch. Thanks again!\n\nRegards\nJunjie\n\nJunjie, sorry for not getting back to you sooner.\n\nWhat I meant bu comment 2) for the tests is something along following line. In most of the JDBC junit tests in Derby, if say executing a specific query is only allowed to send a specific exception, then we assert that using following (s below is java.sql.Statement)\n        assertStatementError(\"42Y55\", s, \"CALL SYSCS_UTIL.SYSCS_UPDATE_STATISTICS('APP','T1',null)\");\nSo, if the query above throws any exception other than \"42Y55\" then that will cause the junit test to fail saying that it expected 42Y55 but it got something else.\n\nI was wonderinf in the test in question here, if there was anyway of catching exceptions other than NPE\n+        try{\n+            StreamUtil.skipFully(null);\n+            fail(\"Null InputStream is accepted!\");\n+        }catch (NullPointerException e) {\n+            assertTrue(true);\n+        }\n\nI guess, if the test case above did get an exception other than NPE, we will just get out of the test fixture with that exception. I was curious if there was some more graceful way of catching unexpected exceptions like we do for jave.sql.Statement with assertStatementError. This is not a biggie and feel free to not address this issue if there is no simple way of doing what assertStatementError does.\nMamta, thanks for your adivice. \n\nI have contemplated your comment , I think the test is OK in this situation. The NPE is checked first when calling the skipFully() method, so no other kind of exception will be thrown. What's your opinion?\n\nAs to the \"more graceful way of catching unexpected exceptions\", above all, thanks for your advice, it helps me understand the test framework better. However, I haven't found known tools to realize it, so I would leave it as it's now.\n\nRegards\nJunjie\nThe handling of unexpected exceptions looks fine to me. Since they are not caught explicitly, they will propagate out to the JUnit framework and be reported correctly there.\n\nIt may be slightly clearer, though, if we replace assertTrue(true) with just a comment like this:\n\n  catch (NullPointerException npe) {\n      // ignoring expected exception\n  }\n\nThe StreamUtil class imports sun.tools.tree.NullExpression, which seems wrong. Also, the javadoc comments in that class say \"@throws NullExpression\", whereas they should have said \"@throws NullPointerException\".\n\nIt's probably also a good idea to move the code from UTF8Util.skipPersistent() into the StreamUtil class, since that method doesn't have anything to do with UTF-8 and therefore making it non-private in the UTF8Util class may cause some confusion.\nHi, Knut. Thanks for your advice.\n\n1.)---test framework. I agree with your method to add comment \"      // ignoring expected exception \". However, as what I used is just like Andrew suggested in his <Pragmatic Unit Testing>, I think it can work well.\n\n2.)---wrong import. I have corrected in the new patch. \n\n3.)---move the code from UTF8Util.skipPersistent() into the StreamUtil class. It's a good suggestion, I have adopted it.\n\nPlease check the patch!\n\nRegards\nJunjie\nThanks, Junjie!\n\nThe patch looks good to me. I'll run some tests and commit the patch if there are no problems.\nCommitted revision 688049.\nSome questions/comments about    skipFully(InputStream is) \n\nWhat is the purpose of this method, when would it be used? Skipping until EOF seems a useless operation.\n\nSKIP_BUFFER_SIZE is a somewhat confusing name since no buffer is ever allocated.\n\nskipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent().\n\nOther input stream utility methods are in org.apache.derby.iapi.services.io, any reason to have this new class in a different package?\n", "issueSearchSentences": ["long skipFully(InputStream) : skips until EOF, returns number of bytes skipped", "One comment for the engine code change", "<<One comment for the engine code change", "Suggested functionality:", "SKIP_BUFFER_SIZE is a somewhat confusing name since no buffer is ever allocated."], "issueSearchIndexes": [6, 17, 37, 5, 122]}
{"aId": 25, "code": "private Properties checkIndexPageSizeProperty(ConstraintDefinitionNode cdn) \n        throws StandardException\n    {\n        Properties result = cdn.getProperties();\n        if (result == null)\n            result = new Properties();\n        if ( result.get(Property.PAGE_SIZE_PARAMETER) != null ||\n             PropertyUtil.getServiceProperty(\n                 getLanguageConnectionContext().getTransactionCompile(),\n                 Property.PAGE_SIZE_PARAMETER) != null)\n        {\n            // do not override the user's choice of page size, whether it\n            // is set for the whole database or just set on this statement.\n            return result;\n        }\n        ResultColumnList rcl = cdn.getColumnList();\n        int approxLength = 0;\n        for (int index = 0; index < rcl.size(); index++)\n        {\n            String colName = ((ResultColumn) rcl.elementAt(index)).getName();\n            DataTypeDescriptor dtd;\n            if (td == null)\n                dtd = getColumnDataTypeDescriptor(colName);\n            else\n                dtd = getColumnDataTypeDescriptor(colName, td);\n            // There may be no DTD if the column does not exist. That syntax\n            // error is not caught til later in processing, so here we just\n            // skip the length checking if the column doesn't exist.\n            if (dtd != null)\n                approxLength+=dtd.getTypeId().getApproximateLengthInBytes(dtd);\n        }\n        if (approxLength > Property.IDX_PAGE_SIZE_BUMP_THRESHOLD)\n        {\n            result.put(\n                    Property.PAGE_SIZE_PARAMETER,\n                    Property.PAGE_SIZE_DEFAULT_LONG);\n        }\n        return result;\n    }", "comment": " Checks if the index should use a larger page size.", "issueId": "DERBY-3947", "issueStringList": ["Cannot insert 994 character long string into indexed column", "Inserting a 994 character string into a varchar(1000) column with an index fails.", "These steps", "1.", "\"create table t (x varchar(1000) primary key)\"", "2.", "\"insert into t values (?)\"", "where ?", "holds a 994 character string", "produce the following error:", "ERROR XSCB6: Limitation: Record of a btree secondary index cannot be updated or inserted due to lack of space on the page.", "Use the parameters derby.storage.pageSize and/or derby.storage.pageReservedSpace to work around this limitation.", "at org.apache.derby.iapi.error.StandardException.newException(StandardException.java:276)", "at org.apache.derby.impl.store.access.btree.BTreeController.doIns(BTreeController.java:845)", "at org.apache.derby.impl.store.access.btree.BTreeController.insert(BTreeController.java:1264)", "at org.apache.derby.impl.store.access.btree.index.B2IController.insert(B2IController.java:210)", "at org.apache.derby.impl.sql.execute.IndexChanger.insertAndCheckDups(IndexChanger.java:439)", "at org.apache.derby.impl.sql.execute.IndexChanger.doInsert(IndexChanger.java:383)", "at org.apache.derby.impl.sql.execute.IndexChanger.insert(IndexChanger.java:589)", "at org.apache.derby.impl.sql.execute.IndexSetChanger.insert(IndexSetChanger.java:268)", "at org.apache.derby.impl.sql.execute.RowChangerImpl.insertRow(RowChangerImpl.java:453)", "at org.apache.derby.impl.sql.execute.InsertResultSet.normalInsertCore(InsertResultSet.java:1011)", "at org.apache.derby.impl.sql.execute.InsertResultSet.open(InsertResultSet.java:487)", "at org.apache.derby.impl.sql.GenericPreparedStatement.execute(GenericPreparedStatement.java:372)", "at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(EmbedStatement.java:1235)", "The page size should be set sufficiently high at index creation time to hold columns with the specified maximum size.", "Attaching test case which reproduces the bug.", "Similar problem reported by Alan Burlison on the user list, see http://www.nabble.com/btree-overflow-during-insert-to20460876.html", "Triaged July 3, 2009: Assigned normal urgency, marked as Repro attached, Workaround attached and as Seen in production (even though 'm not 100% sure if the bug was seen in production or in the pre-deployment phase).", "I fiddled with this problem for a little while, and I think that the", "problem is that the index which is created behind-the-scenes to", "implement the PRIMARY KEY constraint goes through a different", "code path than the normal index which is created by CREATE INDEX.", "In the case of", "create table t (x varchar(1000));", "create index t_ix on t(x);", "we go through CreateIndexNode.makeConstantAction, where there", "is code that looks at the size of the columns in the index and notices", "that we need a larger page size for this index, and chooses the", "larger page size automatically.", "But in the case from the issue description", "create table t (x varchar(1000) primary key)", "we *instead* go through TableElementNode.genIndexAction,", "which doesn't have any logic to notice that a larger page size is needed.", "I think that we could fix this problem by arranging for the colInfos data", "from the CreateTableNode to be passed through to TableElementNode.genIndexAction", "so that it can check the size of the columns and see if it needs to create the", "PRIMARY KEY index with a larger page size.", "Ideally, it would be great if we could somehow share this code between", "CreateIndexNode and TableElementNode, but I think that the data", "structures are unfortunately not very similar so we may end up", "with two bits of code instead.", "At least, I can *start* by writing a second bit of code and demonstrating", "that it fixes the problem, and then we can try to figure out how to share", "the code and only compute the index's needed page size once.", "Attached is my first try at fixing this problem.", "The patch contains a regression", "test case, based on Knut's repro program, and a change to TableElementList", "to check, when creating the index which backs up a constraint, whether the", "index needs to use a large page size rather than the default page size.", "The change makes the repro case passes, but does NOT handle the similar,", "but different, cases of ALTER TABLE ADD CONSTRAINT, so the patch is", "not ready for commit.", "But I think the basic idea is workable, so I'll see if I can extend it to handle", "the special needs of ALTER TABLE.", "Upon more study, I don't think that ALTER TABLE takes a different code path", "when adding a constraint; i think the flow still goes through TableElementList.", "I did, however, add some more tests, including a test of trying to add a constraint", "which mentions a column which doesn't exist, which caught the fact that the", "patch needs to be careful when looking at the column lengths, because if the", "column doesn't exist, we can't access its length.", "I added more tests to the patch proposal, and am running a full set of regression tests.", "Regression testing was uneventful.", "I think that 'moreTests.diff' is worthy", "of consideration as a resolution to this, and would appreciate any input.", "Thanks for investigating this issue, Bryan.", "The fix looks correct to me.", "+1 to commit.", "Thanks for the review, Knut.", "Committed to the trunk as revision 886162."], "SplitGT": [" Checks if the index should use a larger page size."], "issueString": "Cannot insert 994 character long string into indexed column\nInserting a 994 character string into a varchar(1000) column with an index fails.\n\nThese steps\n\n1. \"create table t (x varchar(1000) primary key)\"\n2. \"insert into t values (?)\" where ? holds a 994 character string\n\nproduce the following error:\n\nERROR XSCB6: Limitation: Record of a btree secondary index cannot be updated or inserted due to lack of space on the page.  Use the parameters derby.storage.pageSize and/or derby.storage.pageReservedSpace to work around this limitation.\n        at org.apache.derby.iapi.error.StandardException.newException(StandardException.java:276)\n        at org.apache.derby.impl.store.access.btree.BTreeController.doIns(BTreeController.java:845)\n        at org.apache.derby.impl.store.access.btree.BTreeController.insert(BTreeController.java:1264)\n        at org.apache.derby.impl.store.access.btree.index.B2IController.insert(B2IController.java:210)\n        at org.apache.derby.impl.sql.execute.IndexChanger.insertAndCheckDups(IndexChanger.java:439)\n        at org.apache.derby.impl.sql.execute.IndexChanger.doInsert(IndexChanger.java:383)\n        at org.apache.derby.impl.sql.execute.IndexChanger.insert(IndexChanger.java:589)\n        at org.apache.derby.impl.sql.execute.IndexSetChanger.insert(IndexSetChanger.java:268)\n        at org.apache.derby.impl.sql.execute.RowChangerImpl.insertRow(RowChangerImpl.java:453)\n        at org.apache.derby.impl.sql.execute.InsertResultSet.normalInsertCore(InsertResultSet.java:1011)\n        at org.apache.derby.impl.sql.execute.InsertResultSet.open(InsertResultSet.java:487)\n        at org.apache.derby.impl.sql.GenericPreparedStatement.execute(GenericPreparedStatement.java:372)\n        at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(EmbedStatement.java:1235)\n\nThe page size should be set sufficiently high at index creation time to hold columns with the specified maximum size.\nAttaching test case which reproduces the bug.\nSimilar problem reported by Alan Burlison on the user list, see http://www.nabble.com/btree-overflow-during-insert-to20460876.html\nTriaged July 3, 2009: Assigned normal urgency, marked as Repro attached, Workaround attached and as Seen in production (even though 'm not 100% sure if the bug was seen in production or in the pre-deployment phase).\nI fiddled with this problem for a little while, and I think that the\nproblem is that the index which is created behind-the-scenes to\nimplement the PRIMARY KEY constraint goes through a different\ncode path than the normal index which is created by CREATE INDEX.\n\nIn the case of\n\n  create table t (x varchar(1000));\n  create index t_ix on t(x);\n\nwe go through CreateIndexNode.makeConstantAction, where there\nis code that looks at the size of the columns in the index and notices\nthat we need a larger page size for this index, and chooses the\nlarger page size automatically.\n\nBut in the case from the issue description\n\n   create table t (x varchar(1000) primary key)\n\nwe *instead* go through TableElementNode.genIndexAction,\nwhich doesn't have any logic to notice that a larger page size is needed.\n\nI think that we could fix this problem by arranging for the colInfos data\nfrom the CreateTableNode to be passed through to TableElementNode.genIndexAction\nso that it can check the size of the columns and see if it needs to create the\nPRIMARY KEY index with a larger page size.\n\nIdeally, it would be great if we could somehow share this code between\nCreateIndexNode and TableElementNode, but I think that the data\nstructures are unfortunately not very similar so we may end up\nwith two bits of code instead.\n\nAt least, I can *start* by writing a second bit of code and demonstrating\nthat it fixes the problem, and then we can try to figure out how to share\nthe code and only compute the index's needed page size once.\nAttached is my first try at fixing this problem. The patch contains a regression\ntest case, based on Knut's repro program, and a change to TableElementList\nto check, when creating the index which backs up a constraint, whether the\nindex needs to use a large page size rather than the default page size.\n\nThe change makes the repro case passes, but does NOT handle the similar,\nbut different, cases of ALTER TABLE ADD CONSTRAINT, so the patch is\nnot ready for commit.\n\nBut I think the basic idea is workable, so I'll see if I can extend it to handle \nthe special needs of ALTER TABLE.\nUpon more study, I don't think that ALTER TABLE takes a different code path\nwhen adding a constraint; i think the flow still goes through TableElementList.\n\nI did, however, add some more tests, including a test of trying to add a constraint\nwhich mentions a column which doesn't exist, which caught the fact that the\npatch needs to be careful when looking at the column lengths, because if the\ncolumn doesn't exist, we can't access its length.\n\nI added more tests to the patch proposal, and am running a full set of regression tests.\n\nRegression testing was uneventful. I think that 'moreTests.diff' is worthy\nof consideration as a resolution to this, and would appreciate any input.\nThanks for investigating this issue, Bryan. The fix looks correct to me. +1 to commit.\nThanks for the review, Knut. Committed to the trunk as revision 886162.\n\n", "issueSearchSentences": ["from the CreateTableNode to be passed through to TableElementNode.genIndexAction", "we go through CreateIndexNode.makeConstantAction, where there", "which mentions a column which doesn't exist, which caught the fact that the", "is code that looks at the size of the columns in the index and notices", "not ready for commit."], "issueSearchIndexes": [46, 37, 69, 38, 63]}
{"aId": 30, "code": "void resetForReuse()\n            throws SqlException {\n        this.batch_.clear();\n        clearWarningsX();\n        // Close open resultsets.\n        // Regardless of whether or not this statement is in the prepared state,\n        // we need to close any open cursors for this statement on the server.\n        int numberOfResultSetsToClose = 0;\n        if (resultSetList_ != null) {\n            numberOfResultSetsToClose = resultSetList_.length;\n        }\n        try {\n            if (willTickleServer(\n                    numberOfResultSetsToClose, connection_.autoCommit_)) {\n                flowClose();\n            } else {\n                flowCloseOutsideUOW();\n            }\n        } finally {\n            // If an exception is thrown above, the statement should not be put\n            // back into the statement pool, as the state may not be consistent.\n            markResultSetsClosed();\n            // In case a cursorName was set on the Statement but the Statement\n            // was never used to execute a query, the cursorName will not be\n            // remove when the resultSets are mark closed, so we need to remove\n            // the cursorName from the cache.\n            removeClientCursorNameFromCache();\n            markPreparedStatementForAutoGeneratedKeysClosed();\n\n            if (setSpecialRegisterSection_ != null) {\n                setSpecialRegisterSection_.free();\n                setSpecialRegisterSection_ = null;\n            }\n            resetUserControllableAttributes();\n        }\n    }", "comment": " Resets the statement for reuse in a statement pool.", "issueId": "DERBY-3441", "issueStringList": ["Determine and implement a proper procedure for resetting a prepared statement for reuse in a statement pool", "Initial investigations indicate there are no existing suitable methods to properly reset a prepared (or callable) statement for reuse with a statement pool.", "A full reset is too heavy weight and defeats the purpose of statement pooling, but a proper procedure should be achievable by reusing existing pieces of code.", "Correctness is of course the most important thing.", "What is needed for a reset beyond clearParameters, clearBatch and clearWarnings?", "Just wondering why these are too heavy weight?", "The ones you mention are not too heavy weight.", "What about result sets?", "When running some of the tests, I observed lock timeouts.", "The failing tests were all SUR tests, and I think the locking behavior might be a bit special there.", "I tried a very experimental patch, where I closed the result sets on logical statement close and when running suites.All I was down to around 20+ errors/failures (as opposed to around 180).", "Most of these I could link to an existing bug.", "So even though I can't provide a proper answer now, I do believe there is more to be handled than what you mentioned above.", "I'll come back with more info as soon I as have any.", "All of this is a bit in the blue currently, so feedback is very much appreciated.", "I hope to get the basic machinery into place, and then work on issues one by one from there.", "'derby-3441-1a-statement_reset.diff' is the first draft of a reset procedure for a statement to be reused in a statement pool.", "There might be some room for refactoring in am.Statement, since the new method copies code from various other places.", "Please review / comment.", "I am not confident this is the best / correct way of doing it, but I can't see any errors caused by it either.", "Suggestions for how to test this is also welcome (or tests :) )!", "I think a list of what is being reset in resetForReuse()'s javadoc (for the method) would be very useful.", "Otherwise one has to \"slug\" through the", "code figuring out what is being reset.", "A comment to explain this code would be really good:", "+        } catch (SqlException sqle) {", "+            throw sqle.getSQLException();", "+        }", "Ie.", "why is the top-level exception not being thrown.", "Minor improvement in resetParameters()", "+            for (int i = 0; i < parameterMetaData_.columns_; i++) {", "+                parameters_[i] = null;", "+                parameterSet_[i] = false;", "+                parameterRegistered_[i] = false;", "+            }", "would be to use Arrays.fill().", "Thanks for the comment Dan.", "I'll address your other comments later.", "'derby-3441-2a-minor_am_refactoring.diff' addresses Dans comment about the improvement in resetParameters.", "I changed this (and other existing code) to use Arrays.fill, and also removed some unnecessary throws clauses from the existing code.", "I figured out 'batch_' was never set to null, so I made it final and removed a null check.", "In the future it might be better to only create the ArrayList if you actually do batching, and maybe add a clearBatchX method that will be called where batch_.clear is called currently.", "Committed patch 2a to trunk with revision 631515.", "Have run a subset of the regression tests, am running the full suite for verification.", "I have run suties.All and derbyall without failures with patch 2a, Sun JDK 1.6.0 on Solaris 10.", "'derby-3441-1b-statement_reset.diff' is another try at a proper reset procedure.", "The following has been changed:", "a) Added JavaDoc to Statement.resetForReuse", "b) Extracted \"user controllable attributes\" from the init method, and put them into a separate method.", "These attributes must be reset when the statement is put into the cache.", "Examples are query timeout, fetch direction hint and max rows to fetch.", "c) The allowAutoCommit argument for willTickleServer(), is now set to connection_.autoCommit", "Does anyone have any useful info on the willTickleServer method?", "d) Calling batch_.clear() (ArrayList) instead of clearBatch(), to avoid catching/throwing SQLException.", "See related comment for patch 2a above.", "e) Removed the outer try-catch clause, and the method now throws SqlException.", "Dan, I hope your comments are addressed.", "Having slugged through the code, did anything come across as strange?", "I.e.", "why is X reset, but not Y?", "Patch ready for review.", "I hope to commit later today, even if I don't have full confidence in the patch.", "It is a lot better than the current solution anyway, and I'll work on improving it.", "When the patch for this issue is committed, I will enable the statement pooling code by committing DERBY-3329.", "The other know new defect is DERBY-3457, which has a patch awaiting review as well.", "'derby-3441-3a-extract_setTransactionIsolationX.diff' creates an internal setTransactionIsolationX method from the java.sql.Connection.setTransactionIsolation.", "I need to set the transaction isolation level on connection reset, and extracted the internal method to avoid checking for a closed connection multiple times.", "The extraction follows a typical pattern used in the client driver.", "The logic remains unchanged.", "Committed to trunk with revision 632279.", "Forgot to say, I ran derbynet._Suite and jdbcapi._Suite without failures, and I'm running the full set of regression tests to verify.", "'derby-3441-1c-statement_reset.diff' implements a working reset procedure for statement pooling.", "Besides the new functionality, I also had to modify some existing code that broke statement pooling.", "The way things were in the existing code does not seem correct to me, but I need more time to determine what to do about it.", "Also, we should probably discuss whether the required changes should go into 10.4 or be included only in the next release.", "For now I've tried to disturb as little as possible.", "Some cleanup will be required later.", "Since I'm going away for one week, it will have to wait until I'm back.", "And I'm sorry for committing this patch so quickly, but all tests run cleanly and it is required for testing the statement pooling feature.", "Committed patch 1c to trunk with revision 632334."], "SplitGT": [" Resets the statement for reuse in a statement pool."], "issueString": "Determine and implement a proper procedure for resetting a prepared statement for reuse in a statement pool\nInitial investigations indicate there are no existing suitable methods to properly reset a prepared (or callable) statement for reuse with a statement pool.\nA full reset is too heavy weight and defeats the purpose of statement pooling, but a proper procedure should be achievable by reusing existing pieces of code.\n\nCorrectness is of course the most important thing.\nWhat is needed for a reset beyond clearParameters, clearBatch and clearWarnings? Just wondering why these are too heavy weight?\nThe ones you mention are not too heavy weight.\nWhat about result sets?\n\nWhen running some of the tests, I observed lock timeouts. The failing tests were all SUR tests, and I think the locking behavior might be a bit special there.\nI tried a very experimental patch, where I closed the result sets on logical statement close and when running suites.All I was down to around 20+ errors/failures (as opposed to around 180).\nMost of these I could link to an existing bug.\nSo even though I can't provide a proper answer now, I do believe there is more to be handled than what you mentioned above. I'll come back with more info as soon I as have any.\n\n\nAll of this is a bit in the blue currently, so feedback is very much appreciated.\nI hope to get the basic machinery into place, and then work on issues one by one from there.\n'derby-3441-1a-statement_reset.diff' is the first draft of a reset procedure for a statement to be reused in a statement pool. There might be some room for refactoring in am.Statement, since the new method copies code from various other places.\n\nPlease review / comment.\nI am not confident this is the best / correct way of doing it, but I can't see any errors caused by it either. Suggestions for how to test this is also welcome (or tests :) )!\nI think a list of what is being reset in resetForReuse()'s javadoc (for the method) would be very useful. Otherwise one has to \"slug\" through the\ncode figuring out what is being reset.\n\nA comment to explain this code would be really good:\n\n+        } catch (SqlException sqle) {\n+            throw sqle.getSQLException();\n+        }\n\nIe. why is the top-level exception not being thrown.\n\nMinor improvement in resetParameters()\n\n+            for (int i = 0; i < parameterMetaData_.columns_; i++) {\n+                parameters_[i] = null;\n+                parameterSet_[i] = false;\n+                parameterRegistered_[i] = false;\n+            }\n\nwould be to use Arrays.fill().\nThanks for the comment Dan. I'll address your other comments later.\n\n'derby-3441-2a-minor_am_refactoring.diff' addresses Dans comment about the improvement in resetParameters. I changed this (and other existing code) to use Arrays.fill, and also removed some unnecessary throws clauses from the existing code. I figured out 'batch_' was never set to null, so I made it final and removed a null check.\n\nIn the future it might be better to only create the ArrayList if you actually do batching, and maybe add a clearBatchX method that will be called where batch_.clear is called currently.\n\nCommitted patch 2a to trunk with revision 631515.\nHave run a subset of the regression tests, am running the full suite for verification.\nI have run suties.All and derbyall without failures with patch 2a, Sun JDK 1.6.0 on Solaris 10.\n'derby-3441-1b-statement_reset.diff' is another try at a proper reset procedure.\nThe following has been changed:\n a) Added JavaDoc to Statement.resetForReuse\n b) Extracted \"user controllable attributes\" from the init method, and put them into a separate method.\n    These attributes must be reset when the statement is put into the cache.\n    Examples are query timeout, fetch direction hint and max rows to fetch.\n c) The allowAutoCommit argument for willTickleServer(), is now set to connection_.autoCommit\n    Does anyone have any useful info on the willTickleServer method?\n d) Calling batch_.clear() (ArrayList) instead of clearBatch(), to avoid catching/throwing SQLException.\n    See related comment for patch 2a above.\n e) Removed the outer try-catch clause, and the method now throws SqlException.\n\nDan, I hope your comments are addressed.\nHaving slugged through the code, did anything come across as strange?\nI.e. why is X reset, but not Y?\n\nPatch ready for review.\nI hope to commit later today, even if I don't have full confidence in the patch. It is a lot better than the current solution anyway, and I'll work on improving it. When the patch for this issue is committed, I will enable the statement pooling code by committing DERBY-3329. \nThe other know new defect is DERBY-3457, which has a patch awaiting review as well.\n'derby-3441-3a-extract_setTransactionIsolationX.diff' creates an internal setTransactionIsolationX method from the java.sql.Connection.setTransactionIsolation. I need to set the transaction isolation level on connection reset, and extracted the internal method to avoid checking for a closed connection multiple times. The extraction follows a typical pattern used in the client driver.\nThe logic remains unchanged.\n\nCommitted to trunk with revision 632279.\nForgot to say, I ran derbynet._Suite and jdbcapi._Suite without failures, and I'm running the full set of regression tests to verify.\n'derby-3441-1c-statement_reset.diff' implements a working reset procedure for statement pooling.\nBesides the new functionality, I also had to modify some existing code that broke statement pooling. The way things were in the existing code does not seem correct to me, but I need more time to determine what to do about it.\nAlso, we should probably discuss whether the required changes should go into 10.4 or be included only in the next release.\n\nFor now I've tried to disturb as little as possible. Some cleanup will be required later.\nSince I'm going away for one week, it will have to wait until I'm back.\n\nAnd I'm sorry for committing this patch so quickly, but all tests run cleanly and it is required for testing the statement pooling feature.\n\nCommitted patch 1c to trunk with revision 632334.\n", "issueSearchSentences": ["b) Extracted \"user controllable attributes\" from the init method, and put them into a separate method.", "I hope to get the basic machinery into place, and then work on issues one by one from there.", "It is a lot better than the current solution anyway, and I'll work on improving it.", "I changed this (and other existing code) to use Arrays.fill, and also removed some unnecessary throws clauses from the existing code.", "Ie."], "issueSearchIndexes": [50, 16, 64, 41, 29]}
{"aId": 31, "code": "public  ConstantNode getNullNode(TypeId typeId,\n\t\t\tContextManager cm, int collationType, int collationDerivation)\n\t\tthrows StandardException\n\t{\n\t\tQueryTreeNode constantNode = null;\n\t\tNodeFactory nf = getNodeFactory();\n\n\t\tswitch (typeId.getJDBCTypeId())\n\t\t{\n\t\t  case Types.VARCHAR:\n\t\t\tconstantNode =  nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.VARCHAR_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.CHAR:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.CHAR_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.TINYINT:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.TINYINT_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.SMALLINT:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.SMALLINT_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.INTEGER:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.INT_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.BIGINT:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.LONGINT_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.REAL:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.FLOAT_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.DOUBLE:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.DOUBLE_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.NUMERIC:\n\t\t  case Types.DECIMAL:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.DECIMAL_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.DATE:\n\t\t  case Types.TIME:\n\t\t  case Types.TIMESTAMP:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.USERTYPE_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.BINARY:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.BIT_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.VARBINARY:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.VARBIT_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.LONGVARCHAR:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.LONGVARCHAR_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.CLOB:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.CLOB_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.LONGVARBINARY:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.LONGVARBIT_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case Types.BLOB:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.BLOB_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  case StoredFormatIds.XML_TYPE_ID:\n\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.XML_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\tbreak;\n\n\t\t  default:\n\t\t\tif (typeId.getSQLTypeName().equals(\"BOOLEAN\"))\n\t\t\t{\n\t\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.BOOLEAN_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\t}\n\t\t\telse if (typeId.userType())\n\t\t\t{\n\t\t\t\tconstantNode = nf.getNode(\n\t\t\t\t\t\t\t\t\t\tC_NodeTypes.USERTYPE_CONSTANT_NODE,\n\t\t\t\t\t\t\t\t\t\ttypeId,\n\t\t\t\t\t\t\t\t\t\tcm);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif (SanityManager.DEBUG)\n\t\t\t\tSanityManager.THROWASSERT( \"Unknown type \" + \n\t\t\t\t\t\ttypeId.getSQLTypeName() + \" in getNullNode\");\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t\tConstantNode cn = (ConstantNode) constantNode;\n\t\tcn.getTypeServices().setCollationType(collationType);\n\t\tcn.getTypeServices().setCollationDerivation(collationDerivation);\n\t\treturn cn;\n\t}", "comment": " Then set it's collation type and derivation", "issueId": "DERBY-2599", "issueStringList": ["Set correct collation type and derivation on DataTypeDescriptor(DTD).", "DTD has TypeDescriptorImpl in it which has 2 new fields, namely, collationType and collationDerivation.", "These 2 fields are available for all different types of DTDs but only apply to character types.", "The other datatypes should ignore these 2 fields.", "This Jira is a placeholder for loading the correct values into collationType and collationDerivation.", "The patch (DERBY2599_IntermediatePatch_v1_diff.txt) attached is not for commit.", "I just wanted to put out my approach for changing the DTD constructors to take collation type and derivation.", "There has been some discussion on this approach at http://www.nabble.com/DERBY-1478-Lineitem-DERBY-2599%3A-Associating-correct-collation-type-and-derivation-with-DTD-tf3671106.html Dan recommended using setCollationType rather than changing each and every DTD constructor call.", "I will explore using setCollationType vs DTD constructor changes.", "Committed attached patch DERBY2599_collationType_default_UCS_BASIC_v1_diff.txt using revision 534157.", "This patch will have the collation type default to UCS_BASIC.", "It can later be set to TERRITORY_BASED wherever applicable using DataTypeDescriptor.setCollationType.", "The attached patch DERBY2599_correct_collation_for_cast_v1_diff.txt ensures that when an operand is CASTed to string datatype, the result type will take the collation of the current schema.", "So, if current schema is user schema for a database with territory based collation, then a comparison between a persistent character column from system table and a constant character string will fail because persistent character column from system table will have the collation of UCS_BASIC but the constant character string will pick up it's collation from current schema which is user schema and hence the collation will be territory based.", "Since the 2 collations don't match, we will get a compilation error for the query.", "To get around this, a user can rewrite the query to CAST persistent character column from system table to one of the character types and that resultant character type will pickup it's collation from current schema, so now both the operands will have collation of territory based and the query will execute without collation mismatch failure.", "I will go ahead and commit this patch in next few minutes.", "If any feedback, please feel free to share.", "Committed the patch DERBY2599_correct_collation_for_cast_v1_diff.txt  using revision 539060", "Hi Mamta,", "Just one minor nit that I noticed.", "It's not actually specific to this issue, but it's a collation question that I noticed while doing a quick test.", "As seen in the new test case introduced with the patch for this issue, an attempt to compare a constant with a persistent system column fails with error 42818.", "The fact that it fails is fine; I do wonder, though, if that specific error message is appropriate.", "Take, for the example, the following:", "ij> connect 'nodb;create=true;territory=no;collation=TERRITORY_BASED';", "ij> select * from sys.systables where tablename = 'T1';", "ERROR 42818: Comparisons between 'VARCHAR' and 'CHAR' are not supported.", "The error message is a tad misleading--one can most certainly compare VARCHARs with CHARs in Derby :)  I don't know how hard it would, or if it would be worth it, but I think it'd be great if the error message could actually say something about collation (maybe a new error would be required)?", "Otherwise, this seems like the kind of thing that could really confuse a user.", "At least, it scared me for a second or two before I realized what was going on :)", "Army, I agree with your observation about the error message.", "I will go ahead and make a jira entry for the error message so we don't loose track of it.", "I created a Jira entry DERBY-2668 : At the time of compilation of a comparison operation, if the collation types of the operands do not match, then we should throw a meaningful error message.", "Attaching patch DERBY2599_Set_collation_for_aggregates_v1_diff.txt which does the job of setting the correct collation type and derivation for aggregates.", "As per SQL standard, if the operands of the aggregate methods are string operands and they do not all have the same collation derivaiton and type on them, then the resultant string operand will have collation derivaiton of NONE.", "One thing that is missing is as per SQL spec, in a comparison operator, as far as there is one operand with non-NONE collation derivation, the comparison should work.", "I do not have that part working yet.", "If the two operands of the comparison operator do not have the same collation, the comparison will fail.", "Also, if both the sides of the comparison operator have NONE collation, the current DERBY10.3 code will not catch that.", "Both of these issues can go as a subsequent patch.", "The aggregate methods that are covered by the patch are COALESCE, CONCATENATE, NULLIF, CASE", "Committed attached patch DERBY2599_Set_collation_for_aggregates_v1_diff.txt using revision 540201.", "It takes care of correct collation setting for aggregates.", "Commited attached patch using revision 540237.", "The commit comments are as follows", "Commiting patch DERBY2599_Set_collation_for_aggregates_v1_diff.txt attached to DERBY-2599.", "This patch sets correct collation type for MAX and MIN aggregate functions.", "These 2 aggregate functions can return string datatype and this return datatype should take it's collation from it's operand.", "It appears that these 2 functions can't be used in where clause but even then, I think they should have correct collation set on them.", "Hi Mamta, quick question on the latest patch.", "The aggregate patch includes the following diff in ConcatenationOperatorNode:", "+            if (rightOperand.getTypeId().isStringTypeId())", "+            {//collation of ?", "operand should be same as the other operand", "+                leftOperand.getTypeServices().setCollationDerivation(", "+                    rightOperand.getTypeServices().getCollationDerivation());", "+                leftOperand.getTypeServices().setCollationType(", "+                    rightOperand.getTypeServices().getCollationType());", "+            }", "The collation wiki page says the following under \"Collation Determination\":", "8) JDBC parameters (ie.", "?)", "where the type of the parameter is a character", "type will have the same collation as of the character set of the schema", "where the statement is prepared.", "The collation derivation will be", "implicit.", "Is there a mismatch between the code and the wiki page?", "I tried to write a sample case to demonstrate the difference but it looks like Derby always sets the result of a concatenation operator to LONG VARCHAR if one operand is a char type and the other is a parameter (that's the behavior I saw with my examples, anyways; maybe I'm missing something).", "Since LONG VARCHARs are not comparable, that preempts any collation behavior that I was trying to test.", "But I thought I'd post the question anyways, in case there's something here that should be changed (perhaps just the wiki page?", ").", "Apologies if I'm overlooking something obvious...", "For clarity, previous comment was w.r.t:", "DERBY2599_Set_collation_for_aggregates_v1_diff.txt", "Army, thank you very much for reviewing my patches.", "I am getting to the stage in this project where I need to make sure that I set correct collation wherever we construct a DTD.", "So, I am very greatful for these reviews.", "And I think you have definitely found a bug in the changes I made with DERBY2599_Set_collation_for_aggregates_v1_diff.txt.", "The ?", "param should pickup it's collation from schema.", "I will fix that soon.", "Committing attached patch DERBY2599_getNull_should_set_collation_info_v1_diff.txt using revision 540667.", "This address the correct collation setting for ConstantNode created through QueryTreeNode's  getNullNode method.", "This method currently creates a ConstantNode using the passed typeId.", "We need to set the correct collation type and derivation on this ConstantNode.", "This is accomplished by having the caller of this method pass the correct collation type and derivation.", "The junit tests have run fine with no problems.", "derbyall is almost finished with no new failures.", "In addition to the above change, this patch also fixes some comments in DataTypeDescriptor.java and TypeDescriptorImpl.java"], "SplitGT": [" Then set it's collation type and derivation"], "issueString": "Set correct collation type and derivation on DataTypeDescriptor(DTD).\nDTD has TypeDescriptorImpl in it which has 2 new fields, namely, collationType and collationDerivation. These 2 fields are available for all different types of DTDs but only apply to character types. The other datatypes should ignore these 2 fields.\n\nThis Jira is a placeholder for loading the correct values into collationType and collationDerivation.\nThe patch (DERBY2599_IntermediatePatch_v1_diff.txt) attached is not for commit. I just wanted to put out my approach for changing the DTD constructors to take collation type and derivation. There has been some discussion on this approach at http://www.nabble.com/DERBY-1478-Lineitem-DERBY-2599%3A-Associating-correct-collation-type-and-derivation-with-DTD-tf3671106.html Dan recommended using setCollationType rather than changing each and every DTD constructor call. I will explore using setCollationType vs DTD constructor changes.\nCommitted attached patch DERBY2599_collationType_default_UCS_BASIC_v1_diff.txt using revision 534157. This patch will have the collation type default to UCS_BASIC. It can later be set to TERRITORY_BASED wherever applicable using DataTypeDescriptor.setCollationType.\nThe attached patch DERBY2599_correct_collation_for_cast_v1_diff.txt ensures that when an operand is CASTed to string datatype, the result type will take the collation of the current schema. So, if current schema is user schema for a database with territory based collation, then a comparison between a persistent character column from system table and a constant character string will fail because persistent character column from system table will have the collation of UCS_BASIC but the constant character string will pick up it's collation from current schema which is user schema and hence the collation will be territory based. Since the 2 collations don't match, we will get a compilation error for the query. To get around this, a user can rewrite the query to CAST persistent character column from system table to one of the character types and that resultant character type will pickup it's collation from current schema, so now both the operands will have collation of territory based and the query will execute without collation mismatch failure.\n\nI will go ahead and commit this patch in next few minutes. If any feedback, please feel free to share.\nCommitted the patch DERBY2599_correct_collation_for_cast_v1_diff.txt  using revision 539060\nHi Mamta,\n\nJust one minor nit that I noticed.  It's not actually specific to this issue, but it's a collation question that I noticed while doing a quick test.  As seen in the new test case introduced with the patch for this issue, an attempt to compare a constant with a persistent system column fails with error 42818.  The fact that it fails is fine; I do wonder, though, if that specific error message is appropriate.  Take, for the example, the following:\n\nij> connect 'nodb;create=true;territory=no;collation=TERRITORY_BASED';\nij> select * from sys.systables where tablename = 'T1';\nERROR 42818: Comparisons between 'VARCHAR' and 'CHAR' are not supported.\n\nThe error message is a tad misleading--one can most certainly compare VARCHARs with CHARs in Derby :)  I don't know how hard it would, or if it would be worth it, but I think it'd be great if the error message could actually say something about collation (maybe a new error would be required)?  Otherwise, this seems like the kind of thing that could really confuse a user.  At least, it scared me for a second or two before I realized what was going on :)\nArmy, I agree with your observation about the error message. I will go ahead and make a jira entry for the error message so we don't loose track of it.\nI created a Jira entry DERBY-2668 : At the time of compilation of a comparison operation, if the collation types of the operands do not match, then we should throw a meaningful error message.\nAttaching patch DERBY2599_Set_collation_for_aggregates_v1_diff.txt which does the job of setting the correct collation type and derivation for aggregates. As per SQL standard, if the operands of the aggregate methods are string operands and they do not all have the same collation derivaiton and type on them, then the resultant string operand will have collation derivaiton of NONE. One thing that is missing is as per SQL spec, in a comparison operator, as far as there is one operand with non-NONE collation derivation, the comparison should work. I do not have that part working yet. If the two operands of the comparison operator do not have the same collation, the comparison will fail. Also, if both the sides of the comparison operator have NONE collation, the current DERBY10.3 code will not catch that. Both of these issues can go as a subsequent patch.\n\nThe aggregate methods that are covered by the patch are COALESCE, CONCATENATE, NULLIF, CASE\nCommitted attached patch DERBY2599_Set_collation_for_aggregates_v1_diff.txt using revision 540201. It takes care of correct collation setting for aggregates.\nCommited attached patch using revision 540237. The commit comments are as follows\n\nCommiting patch DERBY2599_Set_collation_for_aggregates_v1_diff.txt attached to DERBY-2599. This patch sets correct collation type for MAX and MIN aggregate functions. These 2 aggregate functions can return string datatype and this return datatype should take it's collation from it's operand. It appears that these 2 functions can't be used in where clause but even then, I think they should have correct collation set on them.\nHi Mamta, quick question on the latest patch.\n\nThe aggregate patch includes the following diff in ConcatenationOperatorNode:\n\n+            if (rightOperand.getTypeId().isStringTypeId())\n+            {//collation of ? operand should be same as the other operand\n+                leftOperand.getTypeServices().setCollationDerivation(\n+                    rightOperand.getTypeServices().getCollationDerivation());\n+                leftOperand.getTypeServices().setCollationType(\n+                    rightOperand.getTypeServices().getCollationType());\n+            }\n\nThe collation wiki page says the following under \"Collation Determination\":\n\n  8) JDBC parameters (ie. ?) where the type of the parameter is a character\n     type will have the same collation as of the character set of the schema\n     where the statement is prepared. The collation derivation will be\n     implicit.\n\nIs there a mismatch between the code and the wiki page?\n\nI tried to write a sample case to demonstrate the difference but it looks like Derby always sets the result of a concatenation operator to LONG VARCHAR if one operand is a char type and the other is a parameter (that's the behavior I saw with my examples, anyways; maybe I'm missing something).  Since LONG VARCHARs are not comparable, that preempts any collation behavior that I was trying to test.  But I thought I'd post the question anyways, in case there's something here that should be changed (perhaps just the wiki page?).\n\nApologies if I'm overlooking something obvious...\nFor clarity, previous comment was w.r.t:\n\n  DERBY2599_Set_collation_for_aggregates_v1_diff.txt\nArmy, thank you very much for reviewing my patches. \n\nI am getting to the stage in this project where I need to make sure that I set correct collation wherever we construct a DTD. So, I am very greatful for these reviews. And I think you have definitely found a bug in the changes I made with DERBY2599_Set_collation_for_aggregates_v1_diff.txt. The ? param should pickup it's collation from schema. I will fix that soon.\n\nCommitting attached patch DERBY2599_getNull_should_set_collation_info_v1_diff.txt using revision 540667. \n\nThis address the correct collation setting for ConstantNode created through QueryTreeNode's  getNullNode method. This method currently creates a ConstantNode using the passed typeId. We need to set the correct collation type and derivation on this ConstantNode. This is accomplished by having the caller of this method pass the correct collation type and derivation. The junit tests have run fine with no problems. derbyall is almost finished with no new failures.\n\nIn addition to the above change, this patch also fixes some comments in DataTypeDescriptor.java and TypeDescriptorImpl.java\n", "issueSearchSentences": ["This address the correct collation setting for ConstantNode created through QueryTreeNode's  getNullNode method.", "DTD has TypeDescriptorImpl in it which has 2 new fields, namely, collationType and collationDerivation.", "This method currently creates a ConstantNode using the passed typeId.", "Committing attached patch DERBY2599_getNull_should_set_collation_info_v1_diff.txt using revision 540667.", "Both of these issues can go as a subsequent patch."], "issueSearchIndexes": [85, 2, 86, 84, 41]}
{"aId": 32, "code": "public EngineParameterMetaData getEmbedParameterSetMetaData()\n    throws SQLException\n    {\n        return ((EnginePreparedStatement)getPreparedStatement()).getEmbedParameterSetMetaData();\n    }", "comment": " Imitate the getParameterMetaData function in JDBC 3.0 Retrieves the number, types and properties of this PreparedStatement object's parameters.", "issueId": "DERBY-1015", "issueStringList": ["Define interface between network server and engine through Java interfaces.", "API between the network server and engine is not well defined, leading to inconsistent & multiple ways of handling the different objects returned, such as reflection, explicit casting etc.", "This in turn has lead to bugs such as DERBY-966 .", "DERBY-1005, and DERBY-1006, and access to underlying objects by the application that should be hidden.", "Define interfaces, such as EngineConnection, that both EmbedConnection and BrokeredConnection implement.", "Thus the network server can rely on the fact that any connection it obtains will implement EngineConnection, and call the required methods through that interface.", "Most likely will need EngineConnection, EnginePreparedStatement and EngineResultSet..", "These interfaces would be internal to derby and not exposed to applications.", "I am proposing the following interface for the EnginePreparedStatement for use in the network server.", "snippet:", "+public interface EnginePreparedStatement extends PreparedStatement {", "+", "+ /**", "+  * Immitate the function in JDBC 3.0", "+  *", "+  * Retrieves the number, types and properties of this PreparedStatement", "+  * object's parameters.", "+  *", "+  * @return a EmbedParameterSetMetaData object that contains information about the", "+  * number, types and properties of this PreparedStatement object's parameters.", "+  * @exception SQLException if a database access error occurs", "+    */", "+    public EmbedParameterSetMetaData getEmbedParameterSetMetaData()", "+    throws SQLException;", "+", "+", "+}", "EmbedPreparedStatement implements EnginePreparedStatement", "BrokeredPreparedStatement implements EnginePreparedStatement", "Thoughts/comments ?", "Thanks.", "I wonder if this new interface should be returning EmbedParameterSetMetaData or should an interface be defined for the parameter meta data?", "Of course once jdk 1.3 stops being supported the returned type could be the regular JDBD class.", "Thanks for the feedbac, Dan.", "Looking at this some more, I think it is better to define a new interface for ParameterMetaData for the following reasons:", "no need to import a impl class in iapi", "this implementation seems clean for use in server.", "So the new interface EnginePreparedStatement will return EngineParameterMetaData instead of EmbedParameterSetMetaData.", "Here are the two interfaces I am proposing:", "NEW INTERFACE: EngineParameterMetaData", "An internal api only, mainly for use in the network server.", "This interface imitates the ParameterMetaData interface from JDBC3.0", "We want to provide the ParameterMetaData functionality to JDKs before JDBC3.0.", "org.apache.derby.iapi.jdbc.EnginePreparedStatement interface returns an object", "of this type on a getEmbedParameterSetMetaData", "Once,JDK1.3 stops being supported, this interface can be removed and", "instead the JDBC 3.0 class ParameterMetaData can be used", "public interface EngineParameterMetaData  {", "public int getParameterCount();", "public int isNullable(int param) throws SQLException;", "public boolean isSigned(int param) throws SQLException;", "public int getPrecision(int param) throws SQLException;", "public int getScale(int param) throws SQLException;", "public int getParameterType(int param) throws SQLException;", "public String getParameterTypeName(int param) throws SQLException;", "public String getParameterClassName(int param) throws SQLException;", "public int getParameterMode(int param) throws SQLException;", "}", "(Note: javadoc comments for the methods will be added in the actual patch)", "EmbedParameterSetMetaData implements EngineParameterMetaData", "NEW INTERFACE: EnginePreparedStatement", "Additional methods the embedded engine exposes on its", "PreparedStatement object implementations.", "An internal api only, mainly", "for the network server.", "Allows consistent interaction between embedded", "PreparedStatement and Brokered PreparedStatements.", "public interface EnginePreparedStatement extends PreparedStatement {", "Immitate the getParameterMetaData() that is in JDBC 3.0", "Once,JDK1.3 stops being supported, instead of returning EngineParameterMetaData", "the JDBC 3.0 Class - ParameterMetaData can be used.", "Retrieves the number, types and properties of this PreparedStatement", "object's parameters.", "@return a EngineParameterMetaData object that contains information about the", "number, types and properties of this PreparedStatement object's parameters.", "@exception SQLException if a database access error occurs", "public EngineParameterMetaData getEmbedParameterSetMetaData()", "throws SQLException;", "}", "EmbedPreparedStatement implements EnginePreparedStatement", "BrokeredPreparedStatement implements EnginePreparedStatement", "Thoughts/comments ?", "Thanks.", "I have been looking at derby1015 in context of fixing derby-1227.", "I am attaching a patch 'derby1015.diff.txt' and corresponding 'derby1015.stat.txt' for feedback.", "This patch is a partial fix for the issues mentioned in derby-1015.", "Partial since, it only defines new interface for the PreparedStatement and ParameterMetaData.", "This patch does the following", "1) Defines two new interfaces for use in network server.", "EnginePreparedStatement - This will be used to get a consistent interaction between the BrokeredPreparedStatement and the EmbedPreparedStatement", "EngineParameterMetaData - This interface is defined for the ParameterMetaData.", "EmbedPreparedStatement implements EnginePreparedStatement", "BrokeredPreparedStatement implements EnginePreparedStatement", "EmbedParameterSetMetaData implements EngineParameterMetaData", "The interface details are as mentioned in the previous comment.", "http://issues.apache.org/jira/browse/DERBY-1015#action_12418344", "2) Code changes to make use of the newly defined interfaces in the network server.", "svn stat:", "M      java\\engine\\org\\apache\\derby\\impl\\jdbc\\EmbedPreparedStatement.java", "M      java\\engine\\org\\apache\\derby\\impl\\jdbc\\EmbedParameterSetMetaData.java", "M      java\\engine\\org\\apache\\derby\\iapi\\jdbc\\BrokeredPreparedStatement.java", "A      java\\engine\\org\\apache\\derby\\iapi\\jdbc\\EngineParameterMetaData.java", "A      java\\engine\\org\\apache\\derby\\iapi\\jdbc\\EnginePreparedStatement.java", "M      java\\drda\\org\\apache\\derby\\impl\\drda\\DRDAStatement.java", "M      java\\drda\\org\\apache\\derby\\impl\\drda\\DRDAConnThread.java", "I ran derbyall on linux/ibm142 and tests ran OK.", "I looked at the code coverage for the code snippet in derby-1227 and I see that our current tests already exercise that codepath.", "Not sure how best to address testing for this patch.", "I'd appreciate suggestions/feedback.", "I tried to run javadoc to verify if all the javadoc comments were ok, but  have not been successful in getting it to work.", "I'll look at my setup again.", "Thanks.", "I am attaching a phase 2 patch ( derby1015.p2.diff.txt, derby1015.p2.stat.txt)  to address adding the new interface for ResultSet.", "This patch derby1015.p2.diff.txt  can be applied independently of the derby1015.diff.txt.", "The changes in this patch include", "add a new interface EngineResultSet  for use in Network Server", "make changes in network server code to make use of this interface instead of EmbedResultSet.", "Ran derbyall on linux/ibm142 OK on linux.", "Can someone please review this patch.", "Thanks.", "Please note, there are two pending patches waiting for review.", "derby1015.diff.txt, derby1015.p2.diff.txt.", "These two patches will cover the case of adding new interfaces for PreparedStatement, ResultSet, ParameterMetaData and make use of these interfaces in the server code.", "Since Dan already added the new interfaces for Statement and Connection., I believe with these two patches(derby1015.diff.txt, derby1015.p2.diff.txt), the cases mentioned in the jira description will be covered.", "As an aside, I did a search for Embed* in drda code and came across cases where the server code uses EmbedSQLException.", "I wonder if the server should be using EmbedSQLException or should a interface be defined for use in the server.", "Comments/Thoughts ?", "Thanks.", "I looked at the patches, and they look quite good, very simple and direct, and creating what I think is a very useful and important abstraction between the network server and the engine.", "I think it would be good to complete the abstraction and not depend directly on any engine classes, including EmbedSQLException, but I would argue that should be a separate JIRA.", "I'll work on getting this committed.", "Since David is further ahead than me here I will defer to him for the commit", "Committed revision 421435.", "Passes derbynetclientmats on JDK 1.5"], "SplitGT": [" Imitate the getParameterMetaData function in JDBC 3.0 Retrieves the number, types and properties of this PreparedStatement object's parameters."], "issueString": "Define interface between network server and engine through Java interfaces.\nAPI between the network server and engine is not well defined, leading to inconsistent & multiple ways of handling the different objects returned, such as reflection, explicit casting etc. This in turn has lead to bugs such as DERBY-966 . DERBY-1005, and DERBY-1006, and access to underlying objects by the application that should be hidden.\n\nDefine interfaces, such as EngineConnection, that both EmbedConnection and BrokeredConnection implement. Thus the network server can rely on the fact that any connection it obtains will implement EngineConnection, and call the required methods through that interface.\n\nMost likely will need EngineConnection, EnginePreparedStatement and EngineResultSet.. These interfaces would be internal to derby and not exposed to applications.\n\nI am proposing the following interface for the EnginePreparedStatement for use in the network server. \n\nsnippet:\n\n+public interface EnginePreparedStatement extends PreparedStatement {\n+ \n+ /**\n+  * Immitate the function in JDBC 3.0\n+  *\n+  * Retrieves the number, types and properties of this PreparedStatement\n+  * object's parameters.\n+  *\n+  * @return a EmbedParameterSetMetaData object that contains information about the\n+  * number, types and properties of this PreparedStatement object's parameters.\n+  * @exception SQLException if a database access error occurs\n+    */\n+    public EmbedParameterSetMetaData getEmbedParameterSetMetaData()\n+    throws SQLException;\n+    \n+    \n+}\n\nEmbedPreparedStatement implements EnginePreparedStatement\nBrokeredPreparedStatement implements EnginePreparedStatement\n\nThoughts/comments ?   Thanks.\nI wonder if this new interface should be returning EmbedParameterSetMetaData or should an interface be defined for the parameter meta data? Of course once jdk 1.3 stops being supported the returned type could be the regular JDBD class.\nThanks for the feedbac, Dan. \n\nLooking at this some more, I think it is better to define a new interface for ParameterMetaData for the following reasons:\n-- no need to import a impl class in iapi \n-- this implementation seems clean for use in server. \n\nSo the new interface EnginePreparedStatement will return EngineParameterMetaData instead of EmbedParameterSetMetaData.\n\nHere are the two interfaces I am proposing:  \n\nNEW INTERFACE: EngineParameterMetaData\n\n/**\n * An internal api only, mainly for use in the network server. \n * \n * This interface imitates the ParameterMetaData interface from JDBC3.0\n * We want to provide the ParameterMetaData functionality to JDKs before JDBC3.0. \n * org.apache.derby.iapi.jdbc.EnginePreparedStatement interface returns an object \n * of this type on a getEmbedParameterSetMetaData\n * Once,JDK1.3 stops being supported, this interface can be removed and \n * instead the JDBC 3.0 class ParameterMetaData can be used\n */\npublic interface EngineParameterMetaData  {\n    public int getParameterCount();\n    public int isNullable(int param) throws SQLException;\n    public boolean isSigned(int param) throws SQLException;\n    public int getPrecision(int param) throws SQLException;        \n    public int getScale(int param) throws SQLException;\n    public int getParameterType(int param) throws SQLException;\n    public String getParameterTypeName(int param) throws SQLException;\n    public String getParameterClassName(int param) throws SQLException;\n    public int getParameterMode(int param) throws SQLException;\n    }\n\n(Note: javadoc comments for the methods will be added in the actual patch)\n\nEmbedParameterSetMetaData implements EngineParameterMetaData\n\n-----------------------------------------------------------------------------------------------------------------------------------------------\nNEW INTERFACE: EnginePreparedStatement\n\n/**\n * Additional methods the embedded engine exposes on its \n * PreparedStatement object implementations. An internal api only, mainly \n * for the network server. Allows consistent interaction between embedded \n * PreparedStatement and Brokered PreparedStatements.\n * \n */\npublic interface EnginePreparedStatement extends PreparedStatement {\n    \n    /**\n     * Immitate the getParameterMetaData() that is in JDBC 3.0\n     * Once,JDK1.3 stops being supported, instead of returning EngineParameterMetaData\n     * the JDBC 3.0 Class - ParameterMetaData can be used.\n     *\n     * Retrieves the number, types and properties of this PreparedStatement\n     * object's parameters.\n     *\n     * @return a EngineParameterMetaData object that contains information about the\n     * number, types and properties of this PreparedStatement object's parameters.\n     * @exception SQLException if a database access error occurs\n     */\n    public EngineParameterMetaData getEmbedParameterSetMetaData()\n        throws SQLException;\n    \n}\n\nEmbedPreparedStatement implements EnginePreparedStatement\nBrokeredPreparedStatement implements EnginePreparedStatement \n--------------------------------------------------------------------------------------------------------------\nThoughts/comments ? Thanks. \nI have been looking at derby1015 in context of fixing derby-1227. I am attaching a patch 'derby1015.diff.txt' and corresponding 'derby1015.stat.txt' for feedback.\n\n-- This patch is a partial fix for the issues mentioned in derby-1015.  Partial since, it only defines new interface for the PreparedStatement and ParameterMetaData. \n\nThis patch does the following\n\n1) Defines two new interfaces for use in network server. \n\nEnginePreparedStatement - This will be used to get a consistent interaction between the BrokeredPreparedStatement and the EmbedPreparedStatement\nEngineParameterMetaData - This interface is defined for the ParameterMetaData.\n\nEmbedPreparedStatement implements EnginePreparedStatement\nBrokeredPreparedStatement implements EnginePreparedStatement\nEmbedParameterSetMetaData implements EngineParameterMetaData\n\nThe interface details are as mentioned in the previous comment. \nhttp://issues.apache.org/jira/browse/DERBY-1015#action_12418344\n\n\n2) Code changes to make use of the newly defined interfaces in the network server.  \n\nsvn stat:\nM      java\\engine\\org\\apache\\derby\\impl\\jdbc\\EmbedPreparedStatement.java\nM      java\\engine\\org\\apache\\derby\\impl\\jdbc\\EmbedParameterSetMetaData.java\nM      java\\engine\\org\\apache\\derby\\iapi\\jdbc\\BrokeredPreparedStatement.java\nA      java\\engine\\org\\apache\\derby\\iapi\\jdbc\\EngineParameterMetaData.java\nA      java\\engine\\org\\apache\\derby\\iapi\\jdbc\\EnginePreparedStatement.java\nM      java\\drda\\org\\apache\\derby\\impl\\drda\\DRDAStatement.java\nM      java\\drda\\org\\apache\\derby\\impl\\drda\\DRDAConnThread.java\n\n\nI ran derbyall on linux/ibm142 and tests ran OK.\n\nI looked at the code coverage for the code snippet in derby-1227 and I see that our current tests already exercise that codepath.  Not sure how best to address testing for this patch.  I'd appreciate suggestions/feedback.\n\nI tried to run javadoc to verify if all the javadoc comments were ok, but  have not been successful in getting it to work.   I'll look at my setup again.\n\nThanks.\n\n\nI am attaching a phase 2 patch ( derby1015.p2.diff.txt, derby1015.p2.stat.txt)  to address adding the new interface for ResultSet.  \n\nThis patch derby1015.p2.diff.txt  can be applied independently of the derby1015.diff.txt.   \n\nThe changes in this patch include\n-- add a new interface EngineResultSet  for use in Network Server\n--  make changes in network server code to make use of this interface instead of EmbedResultSet.\n\nRan derbyall on linux/ibm142 OK on linux. \n\nCan someone please review this patch.  Thanks. \n\nPlease note, there are two pending patches waiting for review. \nderby1015.diff.txt, derby1015.p2.diff.txt.\n\nThese two patches will cover the case of adding new interfaces for PreparedStatement, ResultSet, ParameterMetaData and make use of these interfaces in the server code. \n\nSince Dan already added the new interfaces for Statement and Connection., I believe with these two patches(derby1015.diff.txt, derby1015.p2.diff.txt), the cases mentioned in the jira description will be covered.   \n\nAs an aside, I did a search for Embed* in drda code and came across cases where the server code uses EmbedSQLException. I wonder if the server should be using EmbedSQLException or should a interface be defined for use in the server.  Comments/Thoughts ?\n\nThanks.\nI looked at the patches, and they look quite good, very simple and direct, and creating what I think is a very useful and important abstraction between the network server and the engine.  \n\nI think it would be good to complete the abstraction and not depend directly on any engine classes, including EmbedSQLException, but I would argue that should be a separate JIRA.\n\nI'll work on getting this committed.\nSince David is further ahead than me here I will defer to him for the commit\nCommitted revision 421435.  Passes derbynetclientmats on JDK 1.5\n", "issueSearchSentences": ["@exception SQLException if a database access error occurs", "+    */", "+    public EmbedParameterSetMetaData getEmbedParameterSetMetaData()", "public EngineParameterMetaData getEmbedParameterSetMetaData()", "org.apache.derby.iapi.jdbc.EnginePreparedStatement interface returns an object"], "issueSearchIndexes": [76, 22, 23, 77, 44]}
{"aId": 36, "code": "public StringDataValue getValue(RuleBasedCollator collatorForComparison)\n\t{\n\t\tif (collatorForComparison != null)\n\t\t{\n\t\t\t//non-null collatorForComparison means use this collator sensitive\n\t\t\t//implementation of SQLVarchar\n\t\t    setCollator(collatorForComparison);\n\t\t    return this;\t\t\t\n\t\t} else {\n\t\t\t//null collatorForComparison means use UCS_BASIC for collation.\n\t\t\t//For that, we need to use the base class SQLVarchar\n\t\t\tSQLVarchar s = new SQLVarchar();\n\t\t\ts.copyState(this);\n\t\t\treturn s;\n\t\t}\n\t}", "comment": " We do not anticipate this method on collation sensitive DVD to be ever called in Derby 10.3 In future, when Derby will start supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs.", "issueId": "DERBY-2534", "issueStringList": ["Add new api \"public StringDataValue getValue(RuleBasedCollator)\" on StringDataValue.", "This method will return either the base DVDs for char datatypes or it will return collation sensitive DVD for char datatypes.", "In Derby 10.3, the collation of char datatypes can be different depending on what kind of collation is requested by the user at the database create time through the optional JDBC url attribute COLLATION.", "The collation type associated with the DTD will determine which kind of DVD needs to be generated.", "(Note that, irrespective of what collation is used, the format id of the char datatypes remain same.)", "In order to support this behavior of generating the base DVD or the collation sensitive DVD for character datatypes, we need to add a new api to StringDataValue which will look as follows", "Gets either SQLChar/SQLVarchar/SQLLongvarchar/SQLClob(base classes) or", "CollatorSQLChar/CollatorSQLVarchar/CollatorSQLLongvarch/CollatorSQLClob", "(subclasses).", "Whether this method returns the base class or the subclass", "depends on the value of the RuleBasedCollator.", "If RuleBasedCollator is", "null, then the object returned would be baseclass otherwise it would be", "subcalss.", "public StringDataValue getValue(RuleBasedCollator collatorForComparison);", "I am attaching a patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt to this Jira entry which I plan to commit soon.", "The patch adds a new api to StringDataValue interface and the new api looks as follows", "public StringDataValue getValue(RuleBasedCollator collatorForComparison);", "The new api will be needed in quite a few different places.", "2 distinct uses that I can see at this point are", "1)Store will have a format id and collation type when it is trying to construct a DVD template.", "Using the formatid, we will first always get the base class DVD for char datatypes namely SQLChar, SQLVarchar, SQLLongvarchar or SQLClob.", "Next, if the collation type is not 0  ie it is not UCS_BASIC, then we want to use Collation sensitive DVDs of base char DVDs because we want to use the passed Collator for collation rather than the default UCS_BASIC Collator.", "The collation sensitive DVDs of char datatypes are CollatorSQLChar, CollatorSQLVarchar, CollatorSQLLongvarchar and CollatorSQLClob.", "In order to derive these collation sensitive DVDs of character datatypes, we will use this new api called getValue on base character DVDs.", "The getValue method will have the Collator object as parameter to it.", "If the Collator object is null, then we can continue to use the base DVD.", "But if the Collator object is not null, then we want to construct collation sensitive DVD.", "The new api on StringDataValue will help achieve this behavior.", "2)Another place which I can envision using this new api is in DataTypeDescriptor.getNull() method which returns a DVD.", "Currently, the implementation of this method looks as follows", "public DataValueDescriptor getNull() {", "return typeId.getNull();", "}", "So, if the typeid of DTD is character data type, this method will always return base char DVD, no matter what is the collation type of the DTD.", "But, if the DTD has a territory based collation set for it, then this method should return collation sensitive char DVD.", "This functionality can be achieved by using the new api on StringDataValue.", "I do not anticipate this new method ever getting called on collation sensitive DVDs in Derby 10.3 In future, when Derby will start  supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs but for Derby 10.3, the new api in collation sensitive DVDs is just a place holder.", "Another change to note is I changed all the collation sensitive subclasses to have their method setCollator changed from private to protected.", "This is so that the getValue method from their correspoding base classes can call the setCollator method on subclasses.", "The files changed by this patch are", "svn stat -q", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLLongvarchar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\StringDataValue.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLChar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLClob.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLVarchar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLChar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLClob.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLVarchar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLLongvarchar.java", "The code compiles ok with my changes.", "None of the tests should get impacted because currently, this new api on StringDataValue is  not called by any other code in Derby.", "Just commited the patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt with revision 526668.", "If anyone has any feedback, please share them.", "I will address them in subsequent patches."], "SplitGT": [" We do not anticipate this method on collation sensitive DVD to be ever called in Derby 10.3 In future, when Derby will start supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs."], "issueString": "Add new api \"public StringDataValue getValue(RuleBasedCollator)\" on StringDataValue. This method will return either the base DVDs for char datatypes or it will return collation sensitive DVD for char datatypes.\nIn Derby 10.3, the collation of char datatypes can be different depending on what kind of collation is requested by the user at the database create time through the optional JDBC url attribute COLLATION. The collation type associated with the DTD will determine which kind of DVD needs to be generated. (Note that, irrespective of what collation is used, the format id of the char datatypes remain same.) In order to support this behavior of generating the base DVD or the collation sensitive DVD for character datatypes, we need to add a new api to StringDataValue which will look as follows\n\n\t/**\n\t * Gets either SQLChar/SQLVarchar/SQLLongvarchar/SQLClob(base classes) or \n\t * CollatorSQLChar/CollatorSQLVarchar/CollatorSQLLongvarch/CollatorSQLClob\n\t * (subclasses). Whether this method returns the base class or the subclass \n\t * depends on the value of the RuleBasedCollator. If RuleBasedCollator is \n\t * null, then the object returned would be baseclass otherwise it would be \n\t * subcalss.\n\t */\n\tpublic StringDataValue getValue(RuleBasedCollator collatorForComparison);\n\nI am attaching a patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt to this Jira entry which I plan to commit soon. The patch adds a new api to StringDataValue interface and the new api looks as follows\npublic StringDataValue getValue(RuleBasedCollator collatorForComparison);\n\nThe new api will be needed in quite a few different places. 2 distinct uses that I can see at this point are\n1)Store will have a format id and collation type when it is trying to construct a DVD template. Using the formatid, we will first always get the base class DVD for char datatypes namely SQLChar, SQLVarchar, SQLLongvarchar or SQLClob. Next, if the collation type is not 0  ie it is not UCS_BASIC, then we want to use Collation sensitive DVDs of base char DVDs because we want to use the passed Collator for collation rather than the default UCS_BASIC Collator. The collation sensitive DVDs of char datatypes are CollatorSQLChar, CollatorSQLVarchar, CollatorSQLLongvarchar and CollatorSQLClob. In order to derive these collation sensitive DVDs of character datatypes, we will use this new api called getValue on base character DVDs. The getValue method will have the Collator object as parameter to it. If the Collator object is null, then we can continue to use the base DVD. But if the Collator object is not null, then we want to construct collation sensitive DVD. The new api on StringDataValue will help achieve this behavior.\n2)Another place which I can envision using this new api is in DataTypeDescriptor.getNull() method which returns a DVD. Currently, the implementation of this method looks as follows\n\tpublic DataValueDescriptor getNull() {\n\t\treturn typeId.getNull();\n\t}\nSo, if the typeid of DTD is character data type, this method will always return base char DVD, no matter what is the collation type of the DTD. But, if the DTD has a territory based collation set for it, then this method should return collation sensitive char DVD. This functionality can be achieved by using the new api on StringDataValue.\n\nI do not anticipate this new method ever getting called on collation sensitive DVDs in Derby 10.3 In future, when Derby will start  supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs but for Derby 10.3, the new api in collation sensitive DVDs is just a place holder.\n\nAnother change to note is I changed all the collation sensitive subclasses to have their method setCollator changed from private to protected. This is so that the getValue method from their correspoding base classes can call the setCollator method on subclasses.\n\nThe files changed by this patch are\nsvn stat -q\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLLongvarchar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\StringDataValue.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLChar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLClob.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLVarchar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLChar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLClob.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLVarchar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLLongvarchar.java\n\nThe code compiles ok with my changes. None of the tests should get impacted because currently, this new api on StringDataValue is  not called by any other code in Derby.\n\nJust commited the patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt with revision 526668. If anyone has any feedback, please share them. I will address them in subsequent patches.\n", "issueSearchSentences": ["subcalss.", "The patch adds a new api to StringDataValue interface and the new api looks as follows", "The getValue method will have the Collator object as parameter to it.", "Using the formatid, we will first always get the base class DVD for char datatypes namely SQLChar, SQLVarchar, SQLLongvarchar or SQLClob.", "Add new api \"public StringDataValue getValue(RuleBasedCollator)\" on StringDataValue."], "issueSearchIndexes": [14, 17, 26, 22, 1]}
{"aId": 37, "code": "public static void skipFully(InputStream is, long skippedBytes)\n    throws IOException {\n        if(is == null)\n            throw new NullPointerException();\n\n        if(skippedBytes <= 0)\n            return;\n\n        long bytes = skipPersistent(is, skippedBytes);\n\n        if(bytes < skippedBytes)\n            throw new EOFException();\n    }", "comment": " Skips requested number of bytes, throws EOFException if there is too few bytes in the stream.", "issueId": "DERBY-3770", "issueStringList": ["Create a utility class for skipping data in an InputStream", "The contract of InputStream.skip is somewhat difficult, some would even say broken.", "See http://java.sun.com/javase/6/docs/api/java/io/InputStream.html#skip(long))", "A utility class should be created to ensure that we use the same skip procedure throughout the Derby code base.", "Suggested functionality:", "long skipFully(InputStream) : skips until EOF, returns number of bytes skipped", "void skipFully(InputStream,long) : skips requested number of bytes, throws EOFException if there is too few bytes in the stream", "I know of two different approaches, both skipping in a loop:", "a) Verify EOF with a read call when skip returns zero.", "b) Throw EOFException if skip returns zero before requested number of bytes have been skipped.", "There's related code in iapi.util.UTF8Util.", "Maybe this class, say StreamUtil, could be put in the same package?", "Hi, Kristian.", "Please check the patch, thanks!", "Junjie, I will look at the patch soon but if you get a chance, can you put a brief description of the logic of the patch in this jira entry?", "Junjie, the patch is commented pretty well and the code changes for those comments look good.", "One comment for the engine code change", "1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes).", "Should we put NullPointerException() also in the javadoc?", "Just couple comments for the new junit test", "1)testNullStream has 2 test cases to check for null inputstream.", "For some reason, if no NullPointerException is thrown, then we have following to catch it", "fail(\"Null InputStream is refused!", "\");", "The error message looks misleading.", "Should it be saying something like", "fail(\"Null InputStream is accepted!", "\");", "2)The 2 tests in testNullStream only check for NullPointerException.", "Shouldn't we be catching other exceptions and make the test fail for those exceptions.", "3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre.", "Thanks for working on this jira entry.", "Thanks for your attention, Mamta.", "I have receive your comments just now.", "Sorry to reply late.", "<<Junjie, the patch is commented pretty well and the code changes for those comments look good.", "<<One comment for the engine code change", "<<1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes).", "Should we put NullPointerException() also in the javadoc?", "I have add the declaration for NullException.", "<<Just couple comments for the new junit test", "<<1)testNullStream has 2 test cases to check for null inputstream.", "For some reason, if no NullPointerException is thrown, then we have following to catch it", "<<fail(\"Null InputStream is refused!", "\");", "<<The error message looks misleading.", "Should it be saying something like", "<<fail(\"Null InputStream is accepted!", "\");", "I have correct it.", "<<2)The 2 tests in testNullStream only check for NullPointerException.", "Shouldn't we be catching other exceptions and make the test fail for those exceptions.", "I'm not clear about this.", "What other exceptions should be tested int testNullStream()?", "For EOFException, I have tested it in testSkipFully().", "As to IOException, excluding EOFException, I don't know how to create or simulate it.", "Could you give me more advices?", "<<3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre.", "testSkipUtilEOFWithOddLength() only tests EOF with special length, I think it's better to seperate it from common length.", "Is the name of the method not clear?", "Is testSkipUtilEOFWithSpecialLength() better?", "<<Thanks for working on this jira entry.", "Mamta, please give more suggestion to improve the patch.", "Thanks again!", "Regards", "Junjie", "Junjie, sorry for not getting back to you sooner.", "What I meant bu comment 2) for the tests is something along following line.", "In most of the JDBC junit tests in Derby, if say executing a specific query is only allowed to send a specific exception, then we assert that using following (s below is java.sql.Statement)", "assertStatementError(\"42Y55\", s, \"CALL SYSCS_UTIL.SYSCS_UPDATE_STATISTICS('APP','T1',null)\");", "So, if the query above throws any exception other than \"42Y55\" then that will cause the junit test to fail saying that it expected 42Y55 but it got something else.", "I was wonderinf in the test in question here, if there was anyway of catching exceptions other than NPE", "+        try{", "+            StreamUtil.skipFully(null);", "+            fail(\"Null InputStream is accepted!", "\");", "+        }catch (NullPointerException e) {", "+            assertTrue(true);", "+        }", "I guess, if the test case above did get an exception other than NPE, we will just get out of the test fixture with that exception.", "I was curious if there was some more graceful way of catching unexpected exceptions like we do for jave.sql.Statement with assertStatementError.", "This is not a biggie and feel free to not address this issue if there is no simple way of doing what assertStatementError does.", "Mamta, thanks for your adivice.", "I have contemplated your comment , I think the test is OK in this situation.", "The NPE is checked first when calling the skipFully() method, so no other kind of exception will be thrown.", "What's your opinion?", "As to the \"more graceful way of catching unexpected exceptions\", above all, thanks for your advice, it helps me understand the test framework better.", "However, I haven't found known tools to realize it, so I would leave it as it's now.", "Regards", "Junjie", "The handling of unexpected exceptions looks fine to me.", "Since they are not caught explicitly, they will propagate out to the JUnit framework and be reported correctly there.", "It may be slightly clearer, though, if we replace assertTrue(true) with just a comment like this:", "catch (NullPointerException npe) {", "ignoring expected exception", "}", "The StreamUtil class imports sun.tools.tree.NullExpression, which seems wrong.", "Also, the javadoc comments in that class say \"@throws NullExpression\", whereas they should have said \"@throws NullPointerException\".", "It's probably also a good idea to move the code from UTF8Util.skipPersistent() into the StreamUtil class, since that method doesn't have anything to do with UTF-8 and therefore making it non-private in the UTF8Util class may cause some confusion.", "Hi, Knut.", "Thanks for your advice.", "1.)", "---test framework.", "I agree with your method to add comment \"      // ignoring expected exception \".", "However, as what I used is just like Andrew suggested in his <Pragmatic Unit Testing>, I think it can work well.", "2.)", "---wrong import.", "I have corrected in the new patch.", "3.)", "---move the code from UTF8Util.skipPersistent() into the StreamUtil class.", "It's a good suggestion, I have adopted it.", "Please check the patch!", "Regards", "Junjie", "Thanks, Junjie!", "The patch looks good to me.", "I'll run some tests and commit the patch if there are no problems.", "Committed revision 688049.", "Some questions/comments about    skipFully(InputStream is)", "What is the purpose of this method, when would it be used?", "Skipping until EOF seems a useless operation.", "SKIP_BUFFER_SIZE is a somewhat confusing name since no buffer is ever allocated.", "skipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent().", "Other input stream utility methods are in org.apache.derby.iapi.services.io, any reason to have this new class in a different package?", "Good points, Dan.", "As to the purpose of the method that skips until EOF, that's the approach we use to find the length of a resettable stream: move to EOF, count the bytes on the way, and reset the stream.", "Probably clearer to name the method skipUntilEOF instead of skipFully, though.", "I didn't notice before now, but the class iapi.io.InputStreamUtil contains a method skipBytes(InputStream,long) that looks identical to iapi.util.StreamUtil.skipFully(InputStream,long).", "Probably better to add more methods to that class, I agree.", "Minor point on the skipPersistent method, it has the following code:", "long skippedNow = in.skip(bytesToSkip - skipped);", "if (skippedNow <= 0)", "but skippedNow can never be negative so to be clearer the code should be", "long skippedNow = in.skip(bytesToSkip - skipped);", "if (skippedNow  == 0)", "Hi, Mamta and Daniel.", "Thanks for your advices.", "I have done some improvement.", "1.)", "Delete StreamUtil, move the methods to InputStreamUtil, and move the test class to suitable place.", "2.)", "Rename SKIP_BUFFER_SIZE to SKIP_FRAGMENT_SIZE to keep clear.", "3.)", "Use \"        if (skippedNow == 0)\"  in skipPersistent().", "4.)", "About skipByte(InputStream,long):", "Skip a number of bytes in the stream.", "Note that this version takes and returns", "a long instead of the int used by skipBytes.", "@exception IOException if an I/O error occurs.", "@exception EOFException if the end of the stream is reached", "@see DataInput#skipBytes", "public static long skipBytes(InputStream in, long n) throws IOException {", "while (n > 0) {", "System.out.println(\" skip n = \" + n);", "long delta = in.skip(n);", "System.out.println(\" skipped = \" + delta);", "if (delta < 0)", "throw new EOFException();", "n -= delta;", "}", "return n;", "}", "This method doesn't work well.", "First, for \"long delta = in.skip(n); \", delat won't to be negative, so we can not judge EOFException with \"if (delta < 0)\".", "The method skipPersistent() is fittest to judge EOF has arrived.", "So, I deleted skipBytes(), and replace it with skipFully() where skipBytes() is used.", "5.)", "Daniel said \"skipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent(). \"", "Howeve, skipPersistent() is useful to skipFully(), it can guarante that requested num of bytes will be skipped most probably.", "If we use the common skip() method, we can not judge enough bytes has been skipped fully even having not EOFEception.", "Please check the new patch, thanks!", "Hi, Mamta and Daniel.", "Thanks for your advices.", "I have done some improvement.", "1.)", "Delete StreamUtil, move the methods to InputStreamUtil, and move the test class to suitable place.", "2.)", "Rename SKIP_BUFFER_SIZE to SKIP_FRAGMENT_SIZE to keep clear.", "3.)", "Use \"        if (skippedNow == 0)\"  in skipPersistent().", "4.)", "About skipByte(InputStream,long):", "Skip a number of bytes in the stream.", "Note that this version takes and returns", "a long instead of the int used by skipBytes.", "@exception IOException if an I/O error occurs.", "@exception EOFException if the end of the stream is reached", "@see DataInput#skipBytes", "public static long skipBytes(InputStream in, long n) throws IOException {", "while (n > 0) {", "System.out.println(\" skip n = \" + n);", "long delta = in.skip(n);", "System.out.println(\" skipped = \" + delta);", "if (delta < 0)", "throw new EOFException();", "n -= delta;", "}", "return n;", "}", "This method doesn't work well.", "First, for \"long delta = in.skip(n); \", delat won't to be negative, so we can not judge EOFException with \"if (delta < 0)\".", "The method skipPersistent() is fittest to judge EOF has arrived.", "So, I deleted skipBytes(), and replace it with skipFully() where skipBytes() is used.", "5.)", "Daniel said \"skipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent(). \"", "Howeve, skipPersistent() is useful to skipFully(), it can guarante that requested num of bytes will be skipped most probably.", "If we use the common skip() method, we can not judge enough bytes has been skipped fully even having not EOFEception.", "Please check the new patch, thanks!", "Thanks for the new patch.", "It basically looks good.", "A couple of small issues:", "1) Package and class name in the header of InputStreamUtilTest should be updated.", "2) I think Dan's point with skipFully (now skipUntilEOF) was that you don't necessarily have to call skipPersistent until it returns 0.", "It is OK to stop calling it once it returns less bytes than requested.", "So to reduce the number of times skipPersistent is called, skipUntilEOF could do something like this:", "long bytes = 0;", "while (true) {", "long skipped = skipPersistent(is, SKIP_FRAGMENT_SIZE);", "bytes += skipped;", "if (skipped < SKIP_FRAGMENT_SIZE) {", "return bytes;", "}", "}", "3) I noticed that SKIP_FRAGMENT_SIZE had been lowered from 1024*1024 to 512*1024 in this patch.", "I don't think there's any reason to keep this constant small.", "There shouldn't be any disadvantages with having a higher value, so it might be better to set it to a very high value, for instance Integer.MAX_VALUE.", "HI, Knut.", "I adopted your advice, please check the patch.", "Thanks!", "Thank you!", "The patch looks good to me.", "I have started the regression tests and plan to commit it if there aren't any failures.", "Some small things that we may consider to change after the commit:", "1) Should the test be placed under unitTests/junit instead of functionTests/tests/engine?", "The existing tests under functionTests/tests/engine seems to boot the full Derby engine, whereas the test in the patch only tests a single internal class and probably fits better under unitTests/junit.", "2) In skipUntilEOF, the scope of the local variable r could be narrowed down (it could be declared in the body of the while loop).", "OK, Knut.", "I have adopted your advice.", "Please check it!", "Thanks!", "Committed revision 691253."], "SplitGT": [" Skips requested number of bytes, throws EOFException if there is too few bytes in the stream."], "issueString": "Create a utility class for skipping data in an InputStream\nThe contract of InputStream.skip is somewhat difficult, some would even say broken.\nSee http://java.sun.com/javase/6/docs/api/java/io/InputStream.html#skip(long))\n\nA utility class should be created to ensure that we use the same skip procedure throughout the Derby code base.\nSuggested functionality:\n - long skipFully(InputStream) : skips until EOF, returns number of bytes skipped\n - void skipFully(InputStream,long) : skips requested number of bytes, throws EOFException if there is too few bytes in the stream\n\nI know of two different approaches, both skipping in a loop:\n a) Verify EOF with a read call when skip returns zero.\n b) Throw EOFException if skip returns zero before requested number of bytes have been skipped.\n\nThere's related code in iapi.util.UTF8Util. Maybe this class, say StreamUtil, could be put in the same package?\nHi, Kristian. Please check the patch, thanks!\nJunjie, I will look at the patch soon but if you get a chance, can you put a brief description of the logic of the patch in this jira entry?\nJunjie, the patch is commented pretty well and the code changes for those comments look good. \nOne comment for the engine code change\n1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes). Should we put NullPointerException() also in the javadoc?\n\nJust couple comments for the new junit test\n1)testNullStream has 2 test cases to check for null inputstream. For some reason, if no NullPointerException is thrown, then we have following to catch it\nfail(\"Null InputStream is refused!\");\nThe error message looks misleading. Should it be saying something like\nfail(\"Null InputStream is accepted!\");\n2)The 2 tests in testNullStream only check for NullPointerException. Shouldn't we be catching other exceptions and make the test fail for those exceptions.\n3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre.\n\nThanks for working on this jira entry.\nThanks for your attention, Mamta. I have receive your comments just now. Sorry to reply late.\n\n<<Junjie, the patch is commented pretty well and the code changes for those comments look good. \n<<One comment for the engine code change \n<<1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes). Should we put NullPointerException() also in the javadoc? \n-----I have add the declaration for NullException.\n\n<<Just couple comments for the new junit test \n<<1)testNullStream has 2 test cases to check for null inputstream. For some reason, if no NullPointerException is thrown, then we have following to catch it \n<<fail(\"Null InputStream is refused!\"); \n<<The error message looks misleading. Should it be saying something like \n<<fail(\"Null InputStream is accepted!\");\n-----I have correct it. \n<<2)The 2 tests in testNullStream only check for NullPointerException. Shouldn't we be catching other exceptions and make the test fail for those exceptions. \n-----I'm not clear about this. What other exceptions should be tested int testNullStream()? For EOFException, I have tested it in testSkipFully(). As to IOException, excluding EOFException, I don't know how to create or simulate it. Could you give me more advices?\n<<3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre. \n-----testSkipUtilEOFWithOddLength() only tests EOF with special length, I think it's better to seperate it from common length. Is the name of the method not clear? Is testSkipUtilEOFWithSpecialLength() better?\n<<Thanks for working on this jira entry. \n\nMamta, please give more suggestion to improve the patch. Thanks again!\n\nRegards\nJunjie\n\nJunjie, sorry for not getting back to you sooner.\n\nWhat I meant bu comment 2) for the tests is something along following line. In most of the JDBC junit tests in Derby, if say executing a specific query is only allowed to send a specific exception, then we assert that using following (s below is java.sql.Statement)\n        assertStatementError(\"42Y55\", s, \"CALL SYSCS_UTIL.SYSCS_UPDATE_STATISTICS('APP','T1',null)\");\nSo, if the query above throws any exception other than \"42Y55\" then that will cause the junit test to fail saying that it expected 42Y55 but it got something else.\n\nI was wonderinf in the test in question here, if there was anyway of catching exceptions other than NPE\n+        try{\n+            StreamUtil.skipFully(null);\n+            fail(\"Null InputStream is accepted!\");\n+        }catch (NullPointerException e) {\n+            assertTrue(true);\n+        }\n\nI guess, if the test case above did get an exception other than NPE, we will just get out of the test fixture with that exception. I was curious if there was some more graceful way of catching unexpected exceptions like we do for jave.sql.Statement with assertStatementError. This is not a biggie and feel free to not address this issue if there is no simple way of doing what assertStatementError does.\nMamta, thanks for your adivice. \n\nI have contemplated your comment , I think the test is OK in this situation. The NPE is checked first when calling the skipFully() method, so no other kind of exception will be thrown. What's your opinion?\n\nAs to the \"more graceful way of catching unexpected exceptions\", above all, thanks for your advice, it helps me understand the test framework better. However, I haven't found known tools to realize it, so I would leave it as it's now.\n\nRegards\nJunjie\nThe handling of unexpected exceptions looks fine to me. Since they are not caught explicitly, they will propagate out to the JUnit framework and be reported correctly there.\n\nIt may be slightly clearer, though, if we replace assertTrue(true) with just a comment like this:\n\n  catch (NullPointerException npe) {\n      // ignoring expected exception\n  }\n\nThe StreamUtil class imports sun.tools.tree.NullExpression, which seems wrong. Also, the javadoc comments in that class say \"@throws NullExpression\", whereas they should have said \"@throws NullPointerException\".\n\nIt's probably also a good idea to move the code from UTF8Util.skipPersistent() into the StreamUtil class, since that method doesn't have anything to do with UTF-8 and therefore making it non-private in the UTF8Util class may cause some confusion.\nHi, Knut. Thanks for your advice.\n\n1.)---test framework. I agree with your method to add comment \"      // ignoring expected exception \". However, as what I used is just like Andrew suggested in his <Pragmatic Unit Testing>, I think it can work well.\n\n2.)---wrong import. I have corrected in the new patch. \n\n3.)---move the code from UTF8Util.skipPersistent() into the StreamUtil class. It's a good suggestion, I have adopted it.\n\nPlease check the patch!\n\nRegards\nJunjie\nThanks, Junjie!\n\nThe patch looks good to me. I'll run some tests and commit the patch if there are no problems.\nCommitted revision 688049.\nSome questions/comments about    skipFully(InputStream is) \n\nWhat is the purpose of this method, when would it be used? Skipping until EOF seems a useless operation.\n\nSKIP_BUFFER_SIZE is a somewhat confusing name since no buffer is ever allocated.\n\nskipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent().\n\nOther input stream utility methods are in org.apache.derby.iapi.services.io, any reason to have this new class in a different package?\nGood points, Dan.\n\nAs to the purpose of the method that skips until EOF, that's the approach we use to find the length of a resettable stream: move to EOF, count the bytes on the way, and reset the stream. Probably clearer to name the method skipUntilEOF instead of skipFully, though.\n\nI didn't notice before now, but the class iapi.io.InputStreamUtil contains a method skipBytes(InputStream,long) that looks identical to iapi.util.StreamUtil.skipFully(InputStream,long). Probably better to add more methods to that class, I agree.\nMinor point on the skipPersistent method, it has the following code:\n\n            long skippedNow = in.skip(bytesToSkip - skipped);\n            if (skippedNow <= 0)\n\nbut skippedNow can never be negative so to be clearer the code should be\n\n            long skippedNow = in.skip(bytesToSkip - skipped);\n            if (skippedNow  == 0)\nHi, Mamta and Daniel. Thanks for your advices.  I have done some improvement.\n\n1.) Delete StreamUtil, move the methods to InputStreamUtil, and move the test class to suitable place.\n\n2.) Rename SKIP_BUFFER_SIZE to SKIP_FRAGMENT_SIZE to keep clear.\n\n3.) Use \"        if (skippedNow == 0)\"  in skipPersistent().\n\n4.) About skipByte(InputStream,long):\n\t/**\n\t\tSkip a number of bytes in the stream. Note that this version takes and returns\n\t\ta long instead of the int used by skipBytes.\n\n\t\t@exception IOException if an I/O error occurs.\n\t\t@exception EOFException if the end of the stream is reached\n\n\t\t@see DataInput#skipBytes\n\t*/\n\tpublic static long skipBytes(InputStream in, long n) throws IOException {\n\n\t\twhile (n > 0) {\n\t\t\t//System.out.println(\" skip n = \" + n);\n\t\t\tlong delta = in.skip(n);\n\t\t\t//System.out.println(\" skipped = \" + delta);\n\t\t\tif (delta < 0)\n\t\t\t\tthrow new EOFException();\n\t\t\tn -= delta;\n\t\t}\n\n\t\treturn n;\n\t}    \n        \nThis method doesn't work well. First, for \"long delta = in.skip(n); \", delat won't to be negative, so we can not judge EOFException with \"if (delta < 0)\". The method skipPersistent() is fittest to judge EOF has arrived.\nSo, I deleted skipBytes(), and replace it with skipFully() where skipBytes() is used.\n\n5.) Daniel said \"skipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent(). \" Howeve, skipPersistent() is useful to skipFully(), it can guarante that requested num of bytes will be skipped most probably. If we use the common skip() method, we can not judge enough bytes has been skipped fully even having not EOFEception.\n\nPlease check the new patch, thanks!\n\n\nHi, Mamta and Daniel. Thanks for your advices.  I have done some improvement.\n\n1.) Delete StreamUtil, move the methods to InputStreamUtil, and move the test class to suitable place.\n\n2.) Rename SKIP_BUFFER_SIZE to SKIP_FRAGMENT_SIZE to keep clear.\n\n3.) Use \"        if (skippedNow == 0)\"  in skipPersistent().\n\n4.) About skipByte(InputStream,long):\n\t/**\n\t\tSkip a number of bytes in the stream. Note that this version takes and returns\n\t\ta long instead of the int used by skipBytes.\n\n\t\t@exception IOException if an I/O error occurs.\n\t\t@exception EOFException if the end of the stream is reached\n\n\t\t@see DataInput#skipBytes\n\t*/\n\tpublic static long skipBytes(InputStream in, long n) throws IOException {\n\n\t\twhile (n > 0) {\n\t\t\t//System.out.println(\" skip n = \" + n);\n\t\t\tlong delta = in.skip(n);\n\t\t\t//System.out.println(\" skipped = \" + delta);\n\t\t\tif (delta < 0)\n\t\t\t\tthrow new EOFException();\n\t\t\tn -= delta;\n\t\t}\n\n\t\treturn n;\n\t}    \n        \nThis method doesn't work well. First, for \"long delta = in.skip(n); \", delat won't to be negative, so we can not judge EOFException with \"if (delta < 0)\". The method skipPersistent() is fittest to judge EOF has arrived.\nSo, I deleted skipBytes(), and replace it with skipFully() where skipBytes() is used.\n\n5.) Daniel said \"skipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent(). \" Howeve, skipPersistent() is useful to skipFully(), it can guarante that requested num of bytes will be skipped most probably. If we use the common skip() method, we can not judge enough bytes has been skipped fully even having not EOFEception.\n\nPlease check the new patch, thanks!\n\n\nThanks for the new patch. It basically looks good. A couple of small issues:\n\n1) Package and class name in the header of InputStreamUtilTest should be updated.\n\n2) I think Dan's point with skipFully (now skipUntilEOF) was that you don't necessarily have to call skipPersistent until it returns 0. It is OK to stop calling it once it returns less bytes than requested. So to reduce the number of times skipPersistent is called, skipUntilEOF could do something like this:\n\nlong bytes = 0;\nwhile (true) {\n    long skipped = skipPersistent(is, SKIP_FRAGMENT_SIZE);\n    bytes += skipped;\n    if (skipped < SKIP_FRAGMENT_SIZE) {\n        return bytes;\n    }\n}\n\n3) I noticed that SKIP_FRAGMENT_SIZE had been lowered from 1024*1024 to 512*1024 in this patch. I don't think there's any reason to keep this constant small. There shouldn't be any disadvantages with having a higher value, so it might be better to set it to a very high value, for instance Integer.MAX_VALUE.\nHI, Knut. I adopted your advice, please check the patch. Thanks!\nThank you!\n\nThe patch looks good to me. I have started the regression tests and plan to commit it if there aren't any failures.\n\nSome small things that we may consider to change after the commit:\n\n  1) Should the test be placed under unitTests/junit instead of functionTests/tests/engine? The existing tests under functionTests/tests/engine seems to boot the full Derby engine, whereas the test in the patch only tests a single internal class and probably fits better under unitTests/junit.\n\n  2) In skipUntilEOF, the scope of the local variable r could be narrowed down (it could be declared in the body of the while loop).\nOK, Knut. I have adopted your advice. Please check it!\nThanks!\nCommitted revision 691253.\n", "issueSearchSentences": ["One comment for the engine code change", "<<One comment for the engine code change", "if (delta < 0)", "if (delta < 0)", "@see DataInput#skipBytes"], "issueSearchIndexes": [17, 37, 158, 195, 152]}
{"aId": 38, "code": "public int read() throws IOException {\n\n        // when stream has been read and eof reached, stream is closed\n        // and buffer is set to null ( see close() method)\n        // since stream cannot be re-used, check if stream is closed and \n        // if so throw an EOFException\n        if ( buffer == null)\n            throw new EOFException(MessageService.getTextMessage(SQLState.STREAM_EOF));\n\n        \n\t\t// first read\n\t\tif (blen < 0)\n\t\t\tfillBuffer(2);\n\n\t\twhile (boff == blen)\n\t\t{\n\t\t\t// reached end of buffer, read more?\n\t\t\tif (eof)\n            {\n               // we have reached the end of this stream\n               // cleanup here and return -1 indicating \n               // eof of stream\n               close();\n               return -1;\n            }\n                \n\n\t\t\tfillBuffer(0);\n\t\t}\n\n\t\treturn buffer[boff++] & 0xff;\n\n\t}", "comment": " read from stream; characters converted to utf-8 derby specific encoding.", "issueId": "DERBY-500", "issueStringList": ["Update/Select failure when BLOB/CLOB fields updated in several rows by PreparedStatement using setBinaryStream and setCharacterStream", "I have table contained BLOB and CLOB fields:", "Create table string is:", "private static final String CREATE = \"CREATE TABLE ta (\" +", "\"ta_id INTEGER NOT NULL,\" +", "\"mname VARCHAR( 254 ) NOT NULL,\" +", "\"mvalue INT NOT NULL,\" +", "\"mdate DATE NOT NULL,\" +", "\"bytedata BLOB NOT NULL,\" +", "\"chardata CLOB NOT NULL,\" +", "\"PRIMARY KEY ( ta_id ))\";", "Then I insert 2000 rows in the table.", "Then I update all 2000 rows by command:", "private static final String UPDATE  =  \"UPDATE ta \" +", "\"SET bytedata=?", ",chardata=? \"", "+", "\"WHERE mvalue=?", "\";", "int len1 = 10000;//for blob length data", "int len2 = 15000;//for clob length data", "byte buf [] = new byte[len1];", "for(int i=0;i<len1;i++){", "buf [i] = (byte)45;", "}", "ByteArrayInputStream bais = new ByteArrayInputStream(buf);", "char[] bufc = new char[len2];", "for (int i = 0; i < bufc.length; i++) {", "bufc[i] = (char)'b';", "}", "CharArrayReader car = new CharArrayReader(bufc);", "PreparedStatement pstmt = connection.prepareStatement(UPDATE);", "pstmt.setBinaryStream(1,bais, len1);", "pstmt.setCharacterStream(2,car, len2);", "pstmt.setInt(3,5000);", "int updated =  pstmt.executeUpdate();", "pstmt.close();", "System.out.printlen(\"updated =\"+updated );", "all 2000 rows updated , because I receive output : updated =2000", "But If I run select (SELECT bytedata ,chardata  FROM ta)  after update, select failed with error:", "ERROR XSDA7: Restore of a serializable or SQLData object of class , attempted to", "read more data than was originally stored", "at org.apache.derby.iapi.error.StandardException.newException(StandardEx", "ception.java)", "at org.apache.derby.impl.store.raw.data.StoredPage.readRecordFromArray(S", "toredPage.java)", "at org.apache.derby.impl.store.raw.data.StoredPage.restoreRecordFromSlot", "(StoredPage.java)", "at org.apache.derby.impl.store.raw.data.BasePage.fetchFromSlot(BasePage.", "java)", "at org.apache.derby.impl.store.access.conglomerate.GenericScanController", ".fetchRows(GenericScanController.java)", "at org.apache.derby.impl.store.access.heap.HeapScan.fetchNextGroup(HeapS", "can.java)", "at org.apache.derby.impl.sql.execute.BulkTableScanResultSet.reloadArray(", "BulkTableScanResultSet.java)", "at org.apache.derby.impl.sql.execute.BulkTableScanResultSet.getNextRowCo", "re(BulkTableScanResultSet.java)", "at org.apache.derby.impl.sql.execute.NestedLoopJoinResultSet.getNextRowC", "ore(NestedLoopJoinResultSet.java)", "at org.apache.derby.impl.sql.execute.NestedLoopLeftOuterJoinResultSet.ge", "tNextRowCore(NestedLoopLeftOuterJoinResultSet.java)", "at org.apache.derby.impl.sql.execute.ProjectRestrictResultSet.getNextRow", "Core(ProjectRestrictResultSet.java)", "at org.apache.derby.impl.sql.execute.SortResultSet.getRowFromResultSet(S", "ortResultSet.java)", "at org.apache.derby.impl.sql.execute.SortResultSet.getNextRowFromRS(Sort", "ResultSet.java)", "at org.apache.derby.impl.sql.execute.SortResultSet.loadSorter(SortResult", "Set.java)", "at org.apache.derby.impl.sql.execute.SortResultSet.openCore(SortResultSe", "t.java)", "at org.apache.derby.impl.sql.execute.BasicNoPutResultSetImpl.open(BasicN", "oPutResultSetImpl.java)", "at org.apache.derby.impl.sql.GenericPreparedStatement.execute(GenericPre", "paredStatement.java)", "at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(EmbedState", "ment.java)", "at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeStatement(Em", "bedPreparedStatement.java)", "at org.apache.derby.impl.jdbc.EmbedPreparedStatement.execute(EmbedPrepar", "edStatement.java)", "at com.beep_beep.dbtest.complex.Benchmark.testSelect(Unknown Source)", "at com.beep_beep.dbtest.complex.Benchmark.executeSimplestBigTable(Unknown Sour", "ce)", "at com.beep_beep.dbtest.complex.Benchmark.testBigTable(Unknown Source)", "at com.beep_beep.dbtest.complex.Benchmark.executeDegradationBenchmark(Unknown", "Source)", "at com.beep_beep.dbtest.complex.Benchmark.main(Unknown Source)", "From the stack trace and from console I see that Update passed, but error was raised in Select after Update.", "When I try the same update, but with difference(I changed WHERE clause, causing update only 1 row):", "private static final String UPDATE  =  \"UPDATE ta \" +", "\"SET bytedata=?", ",chardata=? \"", "+", "\"WHERE mname=?", "\";", "PreparedStatement pstmt = connection.prepareStatement(UPDATE);", "pstmt.setBinaryStream(1,bais, len1);", "pstmt.setCharacterStream(2,car, len2);", "pstmt.setInt(3,\"PETER\");", "int updated =  pstmt.executeUpdate();", "pstmt.close();", "System.out.printlen(\"updated =\"+updated );", "Only 1 row updated , because I receive output : updated =1", "In this case I have NO errors in select(the same as previous) .", "My assumption:", "It seems that Update receives ByteArrayInputStream and updates correctly only 1 row, then all rows updated by some", "incorrect value(may be because ByteArrayInputStream reached its end in first update), causing select failure.", "I tested PointBase by the same test and PointBase passed this stage without errors, no matter how many rows was updated.", "So I think it is a bug.", "Thank you.", "In previous description I have one mistake:", "instead pstmt.setInt(3,\"PETER\");", "really in code I have pstmt.setString(3,\"PETER\");", "Could you provide some example how to Update BLOB and CLOB fields correctly ?", "Unassigning myself since I'm not currently looking at this issue and Sunitha is looking into it...", "Background :", "In Derby, when a stream is set as a parameter value, the wrapper stream object used for character data is ReaderToUTF8Stream", "and for binary data it is RawToBinaryFormatStream.Both these stream objects on read() return data in a format that is used to store the respective datatype value.", "E.g in case of char, the characters read from the user stream are converted using utf-8 derby specific encoding and read calls return", "the data as expected by store layer.", "Beginning 2 bytes either have the utflen or has zeroes, or if it is a long string, then the value is ended with the special marker 0xE0 , 0x00, 0x00.", "For binary data, the stream data is prepended with 4 zeroes.", "Problem:", "once,the stream has been read fully and end of file reached, further read() returns a -1.", "If a stream is re-read, it returns a -1 which is incorrect data.", "E.g.in the repro for DERBY-500, the update statement has multiple rows that qualify and since the stream parameter is used; the first row gets updated with the correct value and the stream is drained.", "For the subsequent rows, the read from the stream parameter value returns -1 and thus is updated with incorrect data.When retrieving the row back, the format of the fields is incorrect and thus the exception.", "__________", "This patch", "1. adds changes to RawToBinaryFormatStream and ReaderToUTF8Stream to throw an EOFException if stream is re-read.", "If a stream value has been fully read and end of file reached, any further reads on the stream object  will result in an EOFException.", "This seems reasonable and more correct than using incorrect values.", "Adds a new error message - 'Stream has already been read and end-of-file reached and cannot be re-used.'", "2. changes to RememberBytesInputStream to keep track of the stream state and not call read on the stream objects once eof is reached.", "3.", "Fix a bug in StoredPage.logColumn related to streams.", "In one particular scenario, column was not being set to RememberBytesInputStream object and thus losing the data that would be read from stream into RememberBytesInputStream.", "4. adds testcases to store/streamingColumn.java and lang/forbitdata.java", "Also note", "This fix affects cases when a stream is re-used in which case an exception will be thrown.", "So code that reads the stream once and materializes it will not be affected.", "E.g.", "Currently in case of char,varchar,long varchar, streams are materialized and this will work fine as before.", "Ran tests ok on jdk142/win2k (using classes directory)", "svn stat", "M      java\\engine\\org\\apache\\derby\\impl\\jdbc\\RawToBinaryFormatStream.java", "M      java\\engine\\org\\apache\\derby\\impl\\jdbc\\ReaderToUTF8Stream.java", "M      java\\engine\\org\\apache\\derby\\impl\\store\\raw\\data\\RememberBytesInputStream.java", "M      java\\engine\\org\\apache\\derby\\impl\\store\\raw\\data\\StoredPage.java", "M      java\\engine\\org\\apache\\derby\\iapi\\reference\\SQLState.java", "M      java\\engine\\org\\apache\\derby\\loc\\messages_en.properties", "M      java\\testing\\org\\apache\\derbyTesting\\functionTests\\tests\\lang\\forbitdata.java", "M      java\\testing\\org\\apache\\derbyTesting\\functionTests\\tests\\store\\streamingColumn.java", "M      java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\streamingColumn.out", "M      java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\forbitdata.out", "I'll add clarifications to the paper - JDBCImplementation.html and attach it as another patch to this jira entry.", "Can someone please review it.", "Thanks."], "SplitGT": [" read from stream; characters converted to utf-8 derby specific encoding."], "issueString": "Update/Select failure when BLOB/CLOB fields updated in several rows by PreparedStatement using setBinaryStream and setCharacterStream\nI have table contained BLOB and CLOB fields:\n\nCreate table string is:\n\nprivate static final String CREATE = \"CREATE TABLE ta (\" +\n            \"ta_id INTEGER NOT NULL,\" +\n            \"mname VARCHAR( 254 ) NOT NULL,\" +\n            \"mvalue INT NOT NULL,\" +\n            \"mdate DATE NOT NULL,\" +\n            \"bytedata BLOB NOT NULL,\" +\n            \"chardata CLOB NOT NULL,\" +\n            \"PRIMARY KEY ( ta_id ))\";\n\n\nThen I insert 2000 rows in the table.\n\n\n\nThen I update all 2000 rows by command:\n\nprivate static final String UPDATE  =  \"UPDATE ta \" +\n    \t\t\"SET bytedata=? ,chardata=? \" +\n    \t\t\"WHERE mvalue=?\";\n\n/**create blob and clob arrays**/\n        int len1 = 10000;//for blob length data\n        int len2 = 15000;//for clob length data\n        byte buf [] = new byte[len1];\n        for(int i=0;i<len1;i++){\n        \tbuf [i] = (byte)45;\n        }\n        ByteArrayInputStream bais = new ByteArrayInputStream(buf);\n        \n        char[] bufc = new char[len2];\n        for (int i = 0; i < bufc.length; i++) {\n        \tbufc[i] = (char)'b';\n\t\t}\n        CharArrayReader car = new CharArrayReader(bufc);\n/***/\nPreparedStatement pstmt = connection.prepareStatement(UPDATE);\npstmt.setBinaryStream(1,bais, len1);\npstmt.setCharacterStream(2,car, len2);\npstmt.setInt(3,5000);\nint updated =  pstmt.executeUpdate();\npstmt.close();\nSystem.out.printlen(\"updated =\"+updated );\n\n\nall 2000 rows updated , because I receive output : updated =2000\n\nBut If I run select (SELECT bytedata ,chardata  FROM ta)  after update, select failed with error:\n\nERROR XSDA7: Restore of a serializable or SQLData object of class , attempted to\n read more data than was originally stored\n        at org.apache.derby.iapi.error.StandardException.newException(StandardEx\nception.java)\n        at org.apache.derby.impl.store.raw.data.StoredPage.readRecordFromArray(S\ntoredPage.java)\n        at org.apache.derby.impl.store.raw.data.StoredPage.restoreRecordFromSlot\n(StoredPage.java)\n        at org.apache.derby.impl.store.raw.data.BasePage.fetchFromSlot(BasePage.\njava)\n        at org.apache.derby.impl.store.access.conglomerate.GenericScanController\n.fetchRows(GenericScanController.java)\n        at org.apache.derby.impl.store.access.heap.HeapScan.fetchNextGroup(HeapS\ncan.java)\n        at org.apache.derby.impl.sql.execute.BulkTableScanResultSet.reloadArray(\nBulkTableScanResultSet.java)\n        at org.apache.derby.impl.sql.execute.BulkTableScanResultSet.getNextRowCo\nre(BulkTableScanResultSet.java)\n        at org.apache.derby.impl.sql.execute.NestedLoopJoinResultSet.getNextRowC\nore(NestedLoopJoinResultSet.java)\n        at org.apache.derby.impl.sql.execute.NestedLoopLeftOuterJoinResultSet.ge\ntNextRowCore(NestedLoopLeftOuterJoinResultSet.java)\n        at org.apache.derby.impl.sql.execute.ProjectRestrictResultSet.getNextRow\nCore(ProjectRestrictResultSet.java)\n        at org.apache.derby.impl.sql.execute.SortResultSet.getRowFromResultSet(S\nortResultSet.java)\n        at org.apache.derby.impl.sql.execute.SortResultSet.getNextRowFromRS(Sort\nResultSet.java)\n        at org.apache.derby.impl.sql.execute.SortResultSet.loadSorter(SortResult\nSet.java)\n        at org.apache.derby.impl.sql.execute.SortResultSet.openCore(SortResultSe\nt.java)\n        at org.apache.derby.impl.sql.execute.BasicNoPutResultSetImpl.open(BasicN\noPutResultSetImpl.java)\n        at org.apache.derby.impl.sql.GenericPreparedStatement.execute(GenericPre\nparedStatement.java)\n        at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(EmbedState\nment.java)\n        at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeStatement(Em\nbedPreparedStatement.java)\n        at org.apache.derby.impl.jdbc.EmbedPreparedStatement.execute(EmbedPrepar\nedStatement.java)\n        at com.beep_beep.dbtest.complex.Benchmark.testSelect(Unknown Source)\n        at com.beep_beep.dbtest.complex.Benchmark.executeSimplestBigTable(Unknown Sour\nce)\n        at com.beep_beep.dbtest.complex.Benchmark.testBigTable(Unknown Source)\n        at com.beep_beep.dbtest.complex.Benchmark.executeDegradationBenchmark(Unknown\nSource)\n        at com.beep_beep.dbtest.complex.Benchmark.main(Unknown Source)\n\n\nFrom the stack trace and from console I see that Update passed, but error was raised in Select after Update.\n\n\nWhen I try the same update, but with difference(I changed WHERE clause, causing update only 1 row):\nprivate static final String UPDATE  =  \"UPDATE ta \" +\n    \t\t\"SET bytedata=? ,chardata=? \" +\n    \t\t\"WHERE mname=?\";\n\nPreparedStatement pstmt = connection.prepareStatement(UPDATE);\npstmt.setBinaryStream(1,bais, len1);\npstmt.setCharacterStream(2,car, len2);\npstmt.setInt(3,\"PETER\");\nint updated =  pstmt.executeUpdate();\npstmt.close();\nSystem.out.printlen(\"updated =\"+updated );\n\nOnly 1 row updated , because I receive output : updated =1\n\nIn this case I have NO errors in select(the same as previous) .\n\nMy assumption:\nIt seems that Update receives ByteArrayInputStream and updates correctly only 1 row, then all rows updated by some\nincorrect value(may be because ByteArrayInputStream reached its end in first update), causing select failure.\n\nI tested PointBase by the same test and PointBase passed this stage without errors, no matter how many rows was updated.\nSo I think it is a bug.\n\nThank you.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn previous description I have one mistake:\n\ninstead pstmt.setInt(3,\"PETER\");\nreally in code I have pstmt.setString(3,\"PETER\");\n\n\nCould you provide some example how to Update BLOB and CLOB fields correctly ?\n\nUnassigning myself since I'm not currently looking at this issue and Sunitha is looking into it...\nBackground :\nIn Derby, when a stream is set as a parameter value, the wrapper stream object used for character data is ReaderToUTF8Stream \nand for binary data it is RawToBinaryFormatStream.Both these stream objects on read() return data in a format that is used to store the respective datatype value. E.g in case of char, the characters read from the user stream are converted using utf-8 derby specific encoding and read calls return \nthe data as expected by store layer. Beginning 2 bytes either have the utflen or has zeroes, or if it is a long string, then the value is ended with the special marker 0xE0 , 0x00, 0x00. For binary data, the stream data is prepended with 4 zeroes. \n\nProblem:\nonce,the stream has been read fully and end of file reached, further read() returns a -1.  If a stream is re-read, it returns a -1 which is incorrect data.  E.g.in the repro for DERBY-500, the update statement has multiple rows that qualify and since the stream parameter is used; the first row gets updated with the correct value and the stream is drained. For the subsequent rows, the read from the stream parameter value returns -1 and thus is updated with incorrect data.When retrieving the row back, the format of the fields is incorrect and thus the exception. \n__________\nThis patch\n\n1. adds changes to RawToBinaryFormatStream and ReaderToUTF8Stream to throw an EOFException if stream is re-read.\nIf a stream value has been fully read and end of file reached, any further reads on the stream object  will result in an EOFException. This seems reasonable and more correct than using incorrect values.  \nAdds a new error message - 'Stream has already been read and end-of-file reached and cannot be re-used.'\n\n2. changes to RememberBytesInputStream to keep track of the stream state and not call read on the stream objects once eof is reached.\n\n3. Fix a bug in StoredPage.logColumn related to streams. In one particular scenario, column was not being set to RememberBytesInputStream object and thus losing the data that would be read from stream into RememberBytesInputStream.\n\n4. adds testcases to store/streamingColumn.java and lang/forbitdata.java \n\n\nAlso note\n- This fix affects cases when a stream is re-used in which case an exception will be thrown. \nSo code that reads the stream once and materializes it will not be affected. E.g.  Currently in case of char,varchar,long varchar, streams are materialized and this will work fine as before.\n\n\nRan tests ok on jdk142/win2k (using classes directory)\n\nsvn stat\nM      java\\engine\\org\\apache\\derby\\impl\\jdbc\\RawToBinaryFormatStream.java\nM      java\\engine\\org\\apache\\derby\\impl\\jdbc\\ReaderToUTF8Stream.java\nM      java\\engine\\org\\apache\\derby\\impl\\store\\raw\\data\\RememberBytesInputStream.java\nM      java\\engine\\org\\apache\\derby\\impl\\store\\raw\\data\\StoredPage.java\nM      java\\engine\\org\\apache\\derby\\iapi\\reference\\SQLState.java\nM      java\\engine\\org\\apache\\derby\\loc\\messages_en.properties\nM      java\\testing\\org\\apache\\derbyTesting\\functionTests\\tests\\lang\\forbitdata.java\nM      java\\testing\\org\\apache\\derbyTesting\\functionTests\\tests\\store\\streamingColumn.java\nM      java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\streamingColumn.out\nM      java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\forbitdata.out\n\nI'll add clarifications to the paper - JDBCImplementation.html and attach it as another patch to this jira entry.\n\nCan someone please review it. Thanks.\n\n", "issueSearchSentences": ["1. adds changes to RawToBinaryFormatStream and ReaderToUTF8Stream to throw an EOFException if stream is re-read.", "This patch", "This seems reasonable and more correct than using incorrect values.", "Problem:", "Adds a new error message - 'Stream has already been read and end-of-file reached and cannot be re-used.'"], "issueSearchIndexes": [132, 131, 134, 125, 135]}
{"aId": 42, "code": "public void failover() {\n        // Apply all received log records, thus completing the boot of\n        // this database. The database can be connected to after this.\n\n        // // complete recovery of the database \n        // logFactory.setReplicationMode(false); \n\n        // Added when Network Service has been committed to trunk:\n        // connection.shutdown();\n\n        System.out.println(\"SlaveController failover\");\n    }", "comment": " On the other hand, operations from transactions where the commit log record has not been received from the master will not be reflected.", "issueId": "DERBY-3021", "issueStringList": ["Replication: Add a ReplicationSlave controller that will manage replication on the slave side", "The replication slave role includes many tasks:", "set up a network connection with the master", "receive chunks of log from the master, and parse these into individual log records", "append log records to the local log file", "make sure that the recovery process is not allowed to access the logfile we are currently writing to", "etc", "This issue is for adding a controller that will start/stop/initiate all services needed for the replication slave role.", "When Derby takes the replication slave role for a database, it has to start with an unmodified database image received from the master.", "Only log (i.e.", "operations) generated at the master can be appended to the slave database as long as it has this role.", "Normally, when a database is booted, Derby goes through recovery (in the LogFactory service).", "Recovery performs work that cannot be done when a database is in the slave mode.", "As an example, recovery will undo operations from transactions that are not logged as committed.", "Since first booting the database and then initiate replication will not work for the slave mode, slave functionality must be added to the work performed at database boot time.", "As in DERBY-2977, the slave controller service will be implemented incrementally in multiple steps:", "1) Add basic code to Derby so that the slave controller can be booted as a service when a \"startslave\" command is issued to NetworkServerControl", "2-n) Incrementally add controller logic as replication patches are added to Derby.", "The current plan for step 1 is:", "Add a slave replication property that is checked for when RawStore is booted", "If RawStore finds the property during boot, it will boot the SlaveController service and then start booting the LogFactory service in such a way that LogFactory#recovery does not disrupt replication.", "I want to refuse connections to a database that is in the slave mode.", "To do so, I intend to add a check in BasicDatabase.java#setupConnection that throws a StandardException stating \"Cannot connect to a database in replication slave mode\" or similar.", "In SQLStates.java there is now a subset of error codes for repliation: XRExx.", "Initially, I intended to use code XRE02.C for this error.", "However, this exception is thrown on connection, which has error class 08 in the SQL specification.", "Any thoughts on whether the most appropriate error code for this would be:", "XRE02.C since it is a replication error message with session severity, or", "0800x (e.g., 08006 - connection failure) since this is a connection error?", "Patch v1 adds a service that is booted at database boot time if SlaveFactory.SLAVE_MODE is specified in the boot Properties.", "Currently, this code is not reachable in Derby.", "M      java/engine/org/apache/derby/modules.properties", "A      java/engine/org/apache/derby/iapi/services/replication/slave", "A      java/engine/org/apache/derby/iapi/services/replication/slave/SlaveFactory.java", "A      java/engine/org/apache/derby/impl/services/replication/slave/SlaveController.java", "The new service, booted by RawStore if SlaveFactory.SLAVE_MODE is", "specified in the boot Properties", "M      java/engine/org/apache/derby/impl/store/raw/log/LogToFile.java", "Sets a variable inSlaveMode = true if SlaveFactory.SLAVE_MODE is found", "in the boot properties.", "This variable is not currently in use, but", "will be used soon", "M      java/engine/org/apache/derby/impl/store/raw/RawStore.java", "Boots SlaveFactory if SlaveFactory.SLAVE_MODE is specified in the boot Properties", "M      java/engine/org/apache/derby/impl/db/BasicDatabase.java", "Throws an exception if the database is in slave mode and a client", "tries to connect to it.", "M      java/engine/org/apache/derby/loc/messages.xml", "M      java/shared/org/apache/derby/shared/common/reference/SQLState.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/lang/ErrorCodeTest.java", "The new 08004 SQL state and message used when a connection attempt is", "performed on a database already booted in slave mode", "All tests pass for this patch combined with patch 1 for DERBY-3060.", "Code looks good.", "I have just a few minor comments, all on wording,", "but I think at least the javadoc errors need to be fixed before I can", "commit this patch:", "1.", "SlaveController#boot:", "I assume you mean 'new NetworkReceive()'", "2.", "SlaveController#failover, javadoc:", "a) \"operations from transactions where the commit log record has", "not been received from the master will be removed\" sounds a bit", "strange to me.", "I suggest either \"... will be undone\" or", "\"... will not be reflected\".", "b) References to MasterFactory and MasterController will not be", "resolved since they are not it the same package.", "3.", "BasicDatabase#boot, comment:", "\"Make sure it is not connected to by other clients\".", "I think it", "would be clearer if you said: \"Make sure other clients are not able", "to connect\"", "4.", "SlaveFactory#failover, javadoc:", "See 2 b)", "5. messages.xml:", "I suggest:  \"Connection refused to database ...\"", "\u00d8ystein,", "Thanks for reviewing the patch.", "I attached a new patch, v1b, incorporating your suggestions.", "I have not rerun the tests since there are no code changes.", "Committed patch derby-3021-1b.diff with revision 575670."], "SplitGT": [" On the other hand, operations from transactions where the commit log record has not been received from the master will not be reflected."], "issueString": "Replication: Add a ReplicationSlave controller that will manage replication on the slave side\nThe replication slave role includes many tasks:\n\n* set up a network connection with the master\n* receive chunks of log from the master, and parse these into individual log records\n* append log records to the local log file\n* make sure that the recovery process is not allowed to access the logfile we are currently writing to\n* etc\n\nThis issue is for adding a controller that will start/stop/initiate all services needed for the replication slave role.\nWhen Derby takes the replication slave role for a database, it has to start with an unmodified database image received from the master. Only log (i.e. operations) generated at the master can be appended to the slave database as long as it has this role.\n\nNormally, when a database is booted, Derby goes through recovery (in the LogFactory service). Recovery performs work that cannot be done when a database is in the slave mode. As an example, recovery will undo operations from transactions that are not logged as committed. Since first booting the database and then initiate replication will not work for the slave mode, slave functionality must be added to the work performed at database boot time. \n\nAs in DERBY-2977, the slave controller service will be implemented incrementally in multiple steps:\n1) Add basic code to Derby so that the slave controller can be booted as a service when a \"startslave\" command is issued to NetworkServerControl \n2-n) Incrementally add controller logic as replication patches are added to Derby. \n\nThe current plan for step 1 is:\n* Add a slave replication property that is checked for when RawStore is booted\n* If RawStore finds the property during boot, it will boot the SlaveController service and then start booting the LogFactory service in such a way that LogFactory#recovery does not disrupt replication.\nI want to refuse connections to a database that is in the slave mode. To do so, I intend to add a check in BasicDatabase.java#setupConnection that throws a StandardException stating \"Cannot connect to a database in replication slave mode\" or similar.\n\nIn SQLStates.java there is now a subset of error codes for repliation: XRExx. Initially, I intended to use code XRE02.C for this error. However, this exception is thrown on connection, which has error class 08 in the SQL specification. \n\nAny thoughts on whether the most appropriate error code for this would be:\n\n* XRE02.C since it is a replication error message with session severity, or\n* 0800x (e.g., 08006 - connection failure) since this is a connection error? \nPatch v1 adds a service that is booted at database boot time if SlaveFactory.SLAVE_MODE is specified in the boot Properties. Currently, this code is not reachable in Derby.\n\nM      java/engine/org/apache/derby/modules.properties\nA      java/engine/org/apache/derby/iapi/services/replication/slave\nA      java/engine/org/apache/derby/iapi/services/replication/slave/SlaveFactory.java\nA      java/engine/org/apache/derby/impl/services/replication/slave/SlaveController.java\n\nThe new service, booted by RawStore if SlaveFactory.SLAVE_MODE is\nspecified in the boot Properties\n\nM      java/engine/org/apache/derby/impl/store/raw/log/LogToFile.java\n\nSets a variable inSlaveMode = true if SlaveFactory.SLAVE_MODE is found\nin the boot properties. This variable is not currently in use, but\nwill be used soon\n\nM      java/engine/org/apache/derby/impl/store/raw/RawStore.java\n\nBoots SlaveFactory if SlaveFactory.SLAVE_MODE is specified in the boot Properties\n\nM      java/engine/org/apache/derby/impl/db/BasicDatabase.java\n\nThrows an exception if the database is in slave mode and a client\ntries to connect to it.\n\nM      java/engine/org/apache/derby/loc/messages.xml\nM      java/shared/org/apache/derby/shared/common/reference/SQLState.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/lang/ErrorCodeTest.java\n\nThe new 08004 SQL state and message used when a connection attempt is\nperformed on a database already booted in slave mode\n\nAll tests pass for this patch combined with patch 1 for DERBY-3060.\nCode looks good.  I have just a few minor comments, all on wording,\nbut I think at least the javadoc errors need to be fixed before I can\ncommit this patch:\n\n1. SlaveController#boot:  \n\n   I assume you mean 'new NetworkReceive()'\n\n\n2. SlaveController#failover, javadoc:\n\n   a) \"operations from transactions where the commit log record has\n      not been received from the master will be removed\" sounds a bit\n      strange to me.  I suggest either \"... will be undone\" or\n      \"... will not be reflected\".\n\n   b) References to MasterFactory and MasterController will not be\n      resolved since they are not it the same package.\n\n\n3. BasicDatabase#boot, comment:\n\n   \"Make sure it is not connected to by other clients\".  I think it\n   would be clearer if you said: \"Make sure other clients are not able\n   to connect\"\n\n\n4. SlaveFactory#failover, javadoc:\n\n   See 2 b)\n\n\n5. messages.xml:\n\n   I suggest:  \"Connection refused to database ...\"\n \n   \n\n\u00d8ystein, \n\nThanks for reviewing the patch. \n\nI attached a new patch, v1b, incorporating your suggestions. I have not rerun the tests since there are no code changes.\nCommitted patch derby-3021-1b.diff with revision 575670.\n", "issueSearchSentences": ["This issue is for adding a controller that will start/stop/initiate all services needed for the replication slave role.", "operations) generated at the master can be appended to the slave database as long as it has this role.", "Only log (i.e.", "2.", "As an example, recovery will undo operations from transactions that are not logged as committed."], "issueSearchIndexes": [8, 11, 10, 61, 14]}
{"aId": 44, "code": "public boolean supportsRefCursors() { return false; }", "comment": " Derby does not support the Types.REF_CURSOR type.", "issueId": "DERBY-6000", "issueStringList": ["Implement support for JDBC 4.2", "Open JDK 8 will include maintenance rev 4.2 of JDBC.", "The public discussion of JDBC 4.2 will take place here: http://openjdk.java.net/jeps/170.", "We will want to build Derby support for JDBC 4.2 after a public spec appears.", "At this time, it is unclear what Derby release will carry this support.", "Attaching JDBC_4.2_Changes.html, the first rev of a functional spec for this work.", "The changes are defined by the javadoc specdiffs published by JDBC spec lead Lance Andersen.", "The latest specdiffs can be found here: http://cr.openjdk.java.net/~lancea/8005080/specdiffs.01/", "I have built Open JDK 8 on my mac by following the instructions here:", "https://wikis.oracle.com/display/OpenJDK/Mac+OS+X+Port", "However, the mercurial source indicated on that page does not contain the recent Open JDK checkin of JDBC 4.2.", "To get that more complete source, I issued the following command:", "hg clone http://hg.openjdk.java.net/jdk8/tl", "Probably a similar sequence of steps on the platform of your choice will help you build an Open JDK 8 which contains the JDBC 4.2 changes.", "Attaching derby-6000-01-aa-executeLargeUpdateEmbedded.diff.", "This patch adds the new Statement.executeLargeUpdate() methods introduced by JDBC 4.2.", "I am running tests now.", "This patch adds the following new methods to Derby's embedded JDBC 3.0 implementation of java.sql.Statement:", "public  long executeLargeUpdate( String sql ) throws SQLException;", "public  long executeLargeUpdate( String sql, int autoGeneratedKeys) throws SQLException;", "public  long executeLargeUpdate( String sql, int[] columnIndexes ) throws SQLException;", "public  long executeLargeUpdate( String sql, String[] columnNames ) throws SQLException;", "This involved three changes:", "1) Changing the type of the update counter from int to long.", "2) Adding the new methods.", "3) Forwarding the executeUpdate() overloads to the corresponding newly added executeLargeUpdate() overloads.", "I have put off adding regression tests until I have added parallel methods to the client JDBC implementation.", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/sql/ResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/TemporaryRowHolderResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/BasicNoPutResultSetImpl.java", "M       java/engine/org/apache/derby/impl/sql/execute/RealResultSetStatisticsFactory.java", "M       java/engine/org/apache/derby/impl/sql/execute/DMLWriteResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/DeleteResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/NoRowsResultSetImpl.java", "M       java/engine/org/apache/derby/impl/sql/execute/UpdateResultSet.java", "Step (1).", "M       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedPreparedStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java", "Steps (2) and (3).", "Tests passed cleanly for me on derby-6000-01-aa-executeLargeUpdateEmbedded.diff.", "Committed at subversion revision 1438600.", "Attaching derby-6000-02-ad-executeLargeUpdateClient.diff.", "This adds large update support to Statements in the client JDBC driver.", "I am running tests now.", "This adds the following method to the embedded driver:", "Statement.getLargeUpdateCount()", "...and the following methods to the client driver:", "Statement.executeLargeUpdate( String )", "Statement.executeLargeUpdate( String, int )", "Statement.executeLargeUpdate( String, int[] )", "Statement.executeLargeUpdate( String, String[] )", "Statement.getLargeUpdateCount()", "The following changes are made:", "1) The update count on the client side is expanded from an int to a long.", "2) The update count is passed from the server to the client in the SQLCard descriptor.", "Previously, only an int sized update count was passed.", "Now a long sized update count is passed.", "This is done by leaving the low order 32 bits of the update count in the slot of the SQLCard which was previously used for the update count.", "Then the upper 32 bits are put in a previously unused slot of the SQLCard.", "This should mean that when clients and servers are at different revs, the client will still get the correct update count except in cases when the update count is greater than Integer.MAX_VALUE.", "In those oddball cases, the client used to receive garbage from the server.", "In these mixed rev situations, the client will continue to receive garbage for the update count if the number of updated rows exceeds Integer.MAX_VALUE.", "3) Magic numbers were eliminated when processing the SQLCard.", "Hopefully, this will make this code easier to study and debug.", "4) Factory methods were added for client-side BatchUpdateExceptions.", "These will be expanded when we add support for the new BatchUpdateException constructor added by JDBC 4.2.", "5) The new methods were added.", "6) The engine ResultSet code was tweaked to let tests force the engine to return absurdly large update counts.", "Otherwise, it is practically impossible to test the large update methods since this involves generating more than 2 billion rows for each test case.", "7) Tests were added for large updates for both the embedded and client drivers.", "Touches the following files:", "M       java/drda/org/apache/derby/impl/drda/DRDAConnThread.java", "M       java/client/org/apache/derby/client/am/PreparedStatement.java", "M       java/client/org/apache/derby/client/am/Agent.java", "Changes for (1) and (2).", "M       java/client/org/apache/derby/client/net/NetConnectionReply.java", "M       java/client/org/apache/derby/client/net/NetCursor.java", "M       java/client/org/apache/derby/client/am/Sqlca.java", "Changes for (3).", "M       java/client/org/apache/derby/client/am/Utils.java", "M       java/client/org/apache/derby/client/am/BatchUpdateException.java", "Changes for (4).", "M       java/engine/org/apache/derby/iapi/jdbc/EnginePreparedStatement.java", "M       java/client/org/apache/derby/client/am/Statement.java", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java", "M       java/drda/org/apache/derby/impl/drda/DRDAStatement.java", "M       java/client/org/apache/derby/client/am/LogicalStatementEntity.java", "Changes for (5).", "M       java/engine/org/apache/derby/impl/sql/execute/DMLWriteResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/RowUtil.java", "Changes for (6).", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/XA40Test.java", "Changes for (7).", "Tests passed cleanly for me on derby-6000-02-ad-executeLargeUpdateClient.diff.", "Committed derby-6000-02-ad-executeLargeUpdateClient.diff at subversion revision 1439883.", "Attaching derby-6000-03-aa-executeLargeBatch.diff.", "This patch adds large batch support.", "I am running tests now.", "Adds the following method to the embedded and client drivers:", "Statement.executeLargeBatch()", "Most of the machinery needed for this was added as part of implementing large updates.", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/Util.java", "Embedded changes.", "M       java/client/org/apache/derby/client/am/Statement.java", "M       java/client/org/apache/derby/client/am/LogicalStatementEntity.java", "Client changes.", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java", "M       java/testing/org/apache/derbyTesting/junit/BaseTestCase.java", "New tests.", "Tests passed cleanly for me on derby-6000-03-aa-executeLargeBatch.diff.", "Committed at subversion revision 1440035.", "Attaching derby-6000-04-aa-setLargeMaxRows.diff.", "This patch adds support for setting/getting large limits on returned row counts.", "I will run regression tests.", "This patch adds the following JDBC 4.2 methods to the embedded and client drivers:", "Statement.setLargeMaxRows( long )", "Statement.getLargeMaxRows()", "Mostly this involved changing the datatype of some variables from int to long and then adding the new methods.", "As with the previous patch, some debug entry points were added so that we can test the new methods without actually generating more than 2 billion rows.", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/sql/Activation.java", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java", "M       java/engine/org/apache/derby/impl/sql/execute/ScrollInsensitiveResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/BaseActivation.java", "M       java/engine/org/apache/derby/impl/sql/GenericActivationHolder.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedResultSet.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java", "Embedded changes.", "M       java/client/org/apache/derby/client/am/Statement.java", "M       java/client/org/apache/derby/client/am/Cursor.java", "M       java/client/org/apache/derby/client/am/LogicalStatementEntity.java", "M       java/client/org/apache/derby/client/am/ResultSet.java", "Client changes.", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java", "New tests.", "Tests passed cleanly for me on derby-6000-04-aa-setLargeMaxRows.diff.", "Committed at subversion revision 1440656.", "Attaching derby-6000-05-aa-executeLargeUpdatePS.diff.", "This patch adds JDBC 4.2 large update support to PreparedStatements.", "I am running tests now.", "This patch adds the following method to the embedded and client implementations of PreparedStatement:", "public long executeLargeUpdate()", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredPreparedStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EnginePreparedStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedPreparedStatement.java", "Embedded changes.", "M       java/client/org/apache/derby/client/am/PreparedStatement.java", "M       java/client/org/apache/derby/client/am/LogicalPreparedStatement.java", "Client changes.", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/PreparedStatementTest.java", "New tests.", "Tests passed cleanly for me on derby-6000-05-aa-executeLargeUpdatePS.diff.", "Committed at subversion revision 1441088.", "Attaching derby-6000-06-aa-DatabaseMetaData.diff.", "This patch makes the JDBC 4.2 changes to DatabaseMetaData.", "I will run regression tests.", "This patch makes the following changes to the embedded and client drivers:", "1) Changes the datatype of the CARDINALITY and PAGES columns returned by getIndexInfo().", "The column types are changed from INT to BIGINT.", "2) Adds a getMaxLogicalLOBSize() method.", "This method is supposed to return the maximum size of a LOB in bytes.", "For Derby that is the maximum size of a CLOB.", "A CLOB can have Integer.MAX_VALUE chars, which works out to Integer.MAX_VALUE * 2 bytes.", "3) Adds a supportsRefCursors() method.", "This returns false because Derby does not support the Types.REF_CURSOR type.", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/reference/Limits.java", "M       java/engine/org/apache/derby/impl/jdbc/metadata.properties", "M       java/engine/org/apache/derby/impl/jdbc/EmbedDatabaseMetaData.java", "Embedded changes.", "M       java/client/org/apache/derby/client/am/LogicalDatabaseMetaData40.java", "M       java/client/org/apache/derby/client/am/DatabaseMetaData.java", "Client changes.", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/Wrapper41DBMD.java", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/DatabaseMetaDataTest.java", "A       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/Wrapper42DBMD.java", "Tests.", "Tests passed cleanly for me on derby-6000-06-aa-DatabaseMetaData.diff except for the heisenbug in NetworkServerControlClientCommandTest.", "testPingWithWrongHost.", "Committed derby-6000-06-aa-DatabaseMetaData.diff at subversion revision 1441436."], "SplitGT": [" Derby does not support the Types.REF_CURSOR type."], "issueString": "Implement support for JDBC 4.2\nOpen JDK 8 will include maintenance rev 4.2 of JDBC. The public discussion of JDBC 4.2 will take place here: http://openjdk.java.net/jeps/170. We will want to build Derby support for JDBC 4.2 after a public spec appears. At this time, it is unclear what Derby release will carry this support.\nAttaching JDBC_4.2_Changes.html, the first rev of a functional spec for this work. The changes are defined by the javadoc specdiffs published by JDBC spec lead Lance Andersen. The latest specdiffs can be found here: http://cr.openjdk.java.net/~lancea/8005080/specdiffs.01/\nI have built Open JDK 8 on my mac by following the instructions here:\n\nhttps://wikis.oracle.com/display/OpenJDK/Mac+OS+X+Port\n\nHowever, the mercurial source indicated on that page does not contain the recent Open JDK checkin of JDBC 4.2. To get that more complete source, I issued the following command:\n\nhg clone http://hg.openjdk.java.net/jdk8/tl\n\nProbably a similar sequence of steps on the platform of your choice will help you build an Open JDK 8 which contains the JDBC 4.2 changes.\n\n\nAttaching derby-6000-01-aa-executeLargeUpdateEmbedded.diff. This patch adds the new Statement.executeLargeUpdate() methods introduced by JDBC 4.2. I am running tests now.\n\nThis patch adds the following new methods to Derby's embedded JDBC 3.0 implementation of java.sql.Statement:\n\n    public  long executeLargeUpdate( String sql ) throws SQLException;\n    public  long executeLargeUpdate( String sql, int autoGeneratedKeys) throws SQLException;\n    public  long executeLargeUpdate( String sql, int[] columnIndexes ) throws SQLException;\n    public  long executeLargeUpdate( String sql, String[] columnNames ) throws SQLException;\n\nThis involved three changes:\n\n1) Changing the type of the update counter from int to long.\n\n2) Adding the new methods.\n\n3) Forwarding the executeUpdate() overloads to the corresponding newly added executeLargeUpdate() overloads.\n\nI have put off adding regression tests until I have added parallel methods to the client JDBC implementation.\n\n\nTouches the following files:\n\n-----------------------\n\nM       java/engine/org/apache/derby/iapi/sql/ResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/TemporaryRowHolderResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/BasicNoPutResultSetImpl.java\nM       java/engine/org/apache/derby/impl/sql/execute/RealResultSetStatisticsFactory.java\nM       java/engine/org/apache/derby/impl/sql/execute/DMLWriteResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/DeleteResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/NoRowsResultSetImpl.java\nM       java/engine/org/apache/derby/impl/sql/execute/UpdateResultSet.java\n\nStep (1).\n\n-----------------------\n\nM       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedPreparedStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java\n\nSteps (2) and (3).\n\nTests passed cleanly for me on derby-6000-01-aa-executeLargeUpdateEmbedded.diff. Committed at subversion revision 1438600.\nAttaching derby-6000-02-ad-executeLargeUpdateClient.diff. This adds large update support to Statements in the client JDBC driver. I am running tests now.\n\nThis adds the following method to the embedded driver:\n\n  Statement.getLargeUpdateCount()\n\n...and the following methods to the client driver:\n\n  Statement.executeLargeUpdate( String )\n  Statement.executeLargeUpdate( String, int )\n  Statement.executeLargeUpdate( String, int[] )\n  Statement.executeLargeUpdate( String, String[] )\n  Statement.getLargeUpdateCount()\n\nThe following changes are made:\n\n1) The update count on the client side is expanded from an int to a long.\n\n2) The update count is passed from the server to the client in the SQLCard descriptor. Previously, only an int sized update count was passed. Now a long sized update count is passed. This is done by leaving the low order 32 bits of the update count in the slot of the SQLCard which was previously used for the update count. Then the upper 32 bits are put in a previously unused slot of the SQLCard. This should mean that when clients and servers are at different revs, the client will still get the correct update count except in cases when the update count is greater than Integer.MAX_VALUE. In those oddball cases, the client used to receive garbage from the server. In these mixed rev situations, the client will continue to receive garbage for the update count if the number of updated rows exceeds Integer.MAX_VALUE.\n\n3) Magic numbers were eliminated when processing the SQLCard. Hopefully, this will make this code easier to study and debug.\n\n4) Factory methods were added for client-side BatchUpdateExceptions. These will be expanded when we add support for the new BatchUpdateException constructor added by JDBC 4.2.\n\n5) The new methods were added.\n\n6) The engine ResultSet code was tweaked to let tests force the engine to return absurdly large update counts. Otherwise, it is practically impossible to test the large update methods since this involves generating more than 2 billion rows for each test case.\n\n7) Tests were added for large updates for both the embedded and client drivers.\n\n\nTouches the following files:\n\n-----------------------\n\nM       java/drda/org/apache/derby/impl/drda/DRDAConnThread.java\nM       java/client/org/apache/derby/client/am/PreparedStatement.java\nM       java/client/org/apache/derby/client/am/Agent.java\n\nChanges for (1) and (2).\n\n-----------------------\n\nM       java/client/org/apache/derby/client/net/NetConnectionReply.java\nM       java/client/org/apache/derby/client/net/NetCursor.java\nM       java/client/org/apache/derby/client/am/Sqlca.java\n\nChanges for (3).\n\n-----------------------\n\nM       java/client/org/apache/derby/client/am/Utils.java\nM       java/client/org/apache/derby/client/am/BatchUpdateException.java\n\nChanges for (4).\n\n-----------------------\n\nM       java/engine/org/apache/derby/iapi/jdbc/EnginePreparedStatement.java\nM       java/client/org/apache/derby/client/am/Statement.java\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java\nM       java/drda/org/apache/derby/impl/drda/DRDAStatement.java\nM       java/client/org/apache/derby/client/am/LogicalStatementEntity.java\n\nChanges for (5).\n\n-----------------------\n\nM       java/engine/org/apache/derby/impl/sql/execute/DMLWriteResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/RowUtil.java\n\nChanges for (6).\n\n-----------------------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/XA40Test.java\n\nChanges for (7).\n\nTests passed cleanly for me on derby-6000-02-ad-executeLargeUpdateClient.diff.\nCommitted derby-6000-02-ad-executeLargeUpdateClient.diff at subversion revision 1439883.\nAttaching derby-6000-03-aa-executeLargeBatch.diff. This patch adds large batch support. I am running tests now.\n\nAdds the following method to the embedded and client drivers:\n\n  Statement.executeLargeBatch()\n\nMost of the machinery needed for this was added as part of implementing large updates.\n\n\nTouches the following files:\n\n----------\n\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/Util.java\n\nEmbedded changes.\n\n----------\n\nM       java/client/org/apache/derby/client/am/Statement.java\nM       java/client/org/apache/derby/client/am/LogicalStatementEntity.java\n\nClient changes.\n\n----------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java\nM       java/testing/org/apache/derbyTesting/junit/BaseTestCase.java\n\nNew tests.\n\nTests passed cleanly for me on derby-6000-03-aa-executeLargeBatch.diff. Committed at subversion revision 1440035.\nAttaching derby-6000-04-aa-setLargeMaxRows.diff. This patch adds support for setting/getting large limits on returned row counts. I will run regression tests.\n\nThis patch adds the following JDBC 4.2 methods to the embedded and client drivers:\n\n  Statement.setLargeMaxRows( long )\n  Statement.getLargeMaxRows()\n\nMostly this involved changing the datatype of some variables from int to long and then adding the new methods. As with the previous patch, some debug entry points were added so that we can test the new methods without actually generating more than 2 billion rows.\n\nTouches the following files:\n\n----------\n\nM       java/engine/org/apache/derby/iapi/sql/Activation.java\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java\nM       java/engine/org/apache/derby/impl/sql/execute/ScrollInsensitiveResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/BaseActivation.java\nM       java/engine/org/apache/derby/impl/sql/GenericActivationHolder.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedResultSet.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java\n\nEmbedded changes.\n\n----------\n\nM       java/client/org/apache/derby/client/am/Statement.java\nM       java/client/org/apache/derby/client/am/Cursor.java\nM       java/client/org/apache/derby/client/am/LogicalStatementEntity.java\nM       java/client/org/apache/derby/client/am/ResultSet.java\n\nClient changes.\n\n----------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java\n\nNew tests.\n\nTests passed cleanly for me on derby-6000-04-aa-setLargeMaxRows.diff. Committed at subversion revision 1440656.\nAttaching derby-6000-05-aa-executeLargeUpdatePS.diff. This patch adds JDBC 4.2 large update support to PreparedStatements. I am running tests now.\n\nThis patch adds the following method to the embedded and client implementations of PreparedStatement:\n\n  public long executeLargeUpdate()\n\n\n\nTouches the following files:\n\n--------------\n\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredPreparedStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EnginePreparedStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedPreparedStatement.java\n\nEmbedded changes.\n\n--------------\n\nM       java/client/org/apache/derby/client/am/PreparedStatement.java\nM       java/client/org/apache/derby/client/am/LogicalPreparedStatement.java\n\nClient changes.\n\n--------------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/PreparedStatementTest.java\n\nNew tests.\n\nTests passed cleanly for me on derby-6000-05-aa-executeLargeUpdatePS.diff. Committed at subversion revision 1441088.\nAttaching derby-6000-06-aa-DatabaseMetaData.diff. This patch makes the JDBC 4.2 changes to DatabaseMetaData. I will run regression tests.\n\nThis patch makes the following changes to the embedded and client drivers:\n\n1) Changes the datatype of the CARDINALITY and PAGES columns returned by getIndexInfo(). The column types are changed from INT to BIGINT.\n\n2) Adds a getMaxLogicalLOBSize() method. This method is supposed to return the maximum size of a LOB in bytes. For Derby that is the maximum size of a CLOB. A CLOB can have Integer.MAX_VALUE chars, which works out to Integer.MAX_VALUE * 2 bytes.\n\n3) Adds a supportsRefCursors() method. This returns false because Derby does not support the Types.REF_CURSOR type.\n\n\nTouches the following files:\n\n--------------\n\nM       java/engine/org/apache/derby/iapi/reference/Limits.java\nM       java/engine/org/apache/derby/impl/jdbc/metadata.properties\nM       java/engine/org/apache/derby/impl/jdbc/EmbedDatabaseMetaData.java\n\nEmbedded changes.\n\n--------------\n\nM       java/client/org/apache/derby/client/am/LogicalDatabaseMetaData40.java\nM       java/client/org/apache/derby/client/am/DatabaseMetaData.java\n\nClient changes.\n\n--------------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/Wrapper41DBMD.java\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/DatabaseMetaDataTest.java\nA       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/Wrapper42DBMD.java\n\nTests.\n\nTests passed cleanly for me on derby-6000-06-aa-DatabaseMetaData.diff except for the heisenbug in NetworkServerControlClientCommandTest. testPingWithWrongHost.\nCommitted derby-6000-06-aa-DatabaseMetaData.diff at subversion revision 1441436.\n", "issueSearchSentences": ["A CLOB can have Integer.MAX_VALUE chars, which works out to Integer.MAX_VALUE * 2 bytes.", "This patch adds the following method to the embedded and client implementations of PreparedStatement:", "3) Adds a supportsRefCursors() method.", "This patch adds the following new methods to Derby's embedded JDBC 3.0 implementation of java.sql.Statement:", "2) Adds a getMaxLogicalLOBSize() method."], "issueSearchIndexes": [177, 153, 178, 18, 174]}
{"aId": 46, "code": "private ClassLoader getContextClassLoader() {\n        try {\n            return AccessController.doPrivileged(\n                    new PrivilegedAction<ClassLoader>() {\n                @Override\n                public ClassLoader run() {\n                    ClassLoader cl =\n                        Thread.currentThread().getContextClassLoader();\n                    if (cl == ClassLoader.getSystemClassLoader()) {\n                        // If the context class loader is the same as the\n                        // system class loader, we are not worried that the\n                        // timer thread will lead a class loader. (The\n                        // system class loader will stay in memory for the\n                        // lifetime of the JVM anyway, so it's not a problem\n                        // that the timer thread keeps a reference to it.)\n                        // Return null to signal that the context class loader\n                        // doesn't need to be changed.\n                        return null;\n                    } else {\n                        return cl;\n                    }\n                }\n            });\n        } catch (SecurityException se) {\n            // Ignore security exception. Versions of Derby before\n            // the DERBY-3745 fix did not require getContextClassLoader\n            // privileges. We may leak class loaders if we are not\n            // able to do this, but we can't just fail.\n            report(se, MessageId.CANNOT_GET_CLASSLOADER);\n            return null;\n        }\n    }", "comment": " Get the context class loader if it's different from the system class loader.", "issueId": "DERBY-6619", "issueStringList": ["After silently swallowing SecurityExceptions, Derby can leak class loaders", "As part of the fix for DERBY-3745, Derby silently swallows security exceptions and leaks class loaders.", "This can give rise to denial-of-service attacks.", "At a minimum, Derby should report the swallowed exceptions so that the security policy can be corrected and the application can be hardened against this attack.", "The swallowing occurs at these locations:", "{noformat}", "org.apache.derby.impl.services.timer.SingletonTimerFactory run Catch java.lang.SecurityException 0 line 175", "org.apache.derby.impl.services.timer.SingletonTimerFactory run Catch java.lang.SecurityException 1 line 158", "{noformat}", "To reduce the impact, we could make SingletonTimerFactory use an ExecutorService instead of a Timer, and set up the ExecutorService to time out idle threads from the pool after a while.", "That would at least reduce the chances of threads keeping references to stale class loaders forever.", "We did something similar for DERBY-6107.", "Uploading a patch [^derby-6619.diff] which prints warnings on derby.log.", "For example, with this invocation:", "{code}", "java -jar jars/sane/derbyrun.jar server start", "{code}", "which uses the default security manager, the derby.log looks as in [^derby.log].", "Uploading [^derby-6619b.diff], a slightly polished version.", "Attaching [^derby-6619c.diff]: Suggested commit log:", "{quote}", "Patch derby-6619 which prints warnings on derby.log if permissions are missing to get and set the context class loader in SingletonTimerFactory (which can lead to classloader leak).", "Also adds a test of this by checking derby.log in SecureServerTest.", "{quote}", "Running regressions.", "{color:green}[Update: passed]{color}", "I also changed the code to only dump the stack if we run with sane jars, it is not very useful to end users, and rather unsettling.", "I am not planning to rewrite the mechanism to use ExecutorService as Knut suggested for now.", "I can leave the issue open, or close it and create an improvement issue for that rewrite.", "Opinions?", "The tests are failing on Windows after this change.", "See for example [http://download.java.net/javadesktop/derby/request_5594779/javadb-task-3915844.html].", "I'm guessing that it's the construction of the file name in assertWarningDerby6619() that causes the problem, because it assumes the file separator is /.", "{code}", "final String logFileName =", "getSystemProperty(\"derby.system.home\").replace(\"/system\",\"\") +", "File.separator + \"/derby.log\";", "{code}", "(I also suspect that it fails on non-Windows platforms if one of the parent directories of the test directory has a name that begins with \"system\".)", "Maybe something like {{new File(getSystemProperty(\"derby.system.home\")).getParent()}} would be a more reliable way of getting the directory name.", "Or perhaps just {{getSystemProperty(\"user.dir\")}}.", "Thanks, Knut, fixed it, resolving.", "Now I see this warning in derby.log if I start a network server from the command line with the default security policy.", "The warning is not really relevant when you start the network server from the command line, since the leak could only happen if you start the network server embedded within some other application.", "Since the security warning is printed with the default configuration, I guess many will notice it, and we should expect questions from worried users.", "I think we should try to find an approach that doesn't generate warnings in the default configuration.", "I can see the following options:", "Keep the warning and just document it (Pro: avoid the issue", "being ignored, Con: noisy )", "Don't print the warning if the server is started from the command", "line (Pro: less nois, Con: added complexity and different engine", "behavior depending on start mode is somewhar undesirable in itself)", "Augment the default policy file with the needed permission if the", "server is started from the command line before loading it (Pro: less", "noisy, Con: complexity)", "Add the permission to the default policy (needs to be tightened up", "anyway as per our recommendation in the docs - it is already overly", "liberal) (Pro: simple, no noise, Con: less safe by default)", "If I've understood DERBY-3745 correctly, this code is there in order to protect against the case where the thread that starts Derby, has a context class loader that is different from the system class loader.", "In such cases, if the timer thread inherits the context class loader, the context class loader will stay in memory until the Derby engine is shut down, even if all other references to the class loader are gone.", "If the context class loader is the same as the system class loader, on the other hand, such a \"leak\" would not be a problem, since the system class loader will stay in memory until the JVM is shut down anyway.", "I'm wondering if it would be OK to take advantage of this and only attempt to change the context class loader if it is different from the system class loader.", "See the attached patch [^system-loader.diff].", "With that patch, no warning is printed to derby.log when I start the server from the command line, and there's no warning when I start the server using the API with a security manager installed when the context class loader hasn't been changed from the default.", "However, if the server is started using the API with a non-default context class loader, I do see warnings in derby.log if a security manager is installed.", "This behaviour sounds fine to me, since only the last scenario could potentially suffer from the leak.", "For the record, all regression tests ran cleanly with the patch, except an expected failure in SecureServerTest where we check that the warning is always printed if a security manager is installed.", "Thanks for that analysis, Knut.", "I think this is a good way to go.", "I upload [^derby-6619-2.diff] which uses your proposed patch and add tests (in SecureServerTest: a new fixture and new asserts in the existing fixtures.", "Running regressions.", "Thanks, Dag.", "The patch and the test case look good to me.", "+1 to commit.", "I'm wondering if we may want to make a tiny refinement of the if statement in a follow-up.", "We could change it from", "{code}", "if (cl == ClassLoader.getSystemClassLoader()) {", "{code}", "to", "{code}", "if (cl == getClass().getClassLoader() ||", "cl == Thread.class.getClassLoader()) {", "{code}", "That would be two changes from the original:", "1) Check if the context class loader is the same as the loader of the SingletonTimerFactory class (that is, the class loader from which Derby classes are loaded).", "Even if this isn't the same as the system class loader, it would be safe to skip the workaround for DERBY-3745, since the class loader for the Derby classes would not be eligible for garbage collection until the engine is shut down anyway.", "This would prevent some more false positives from being reported in derby.log.", "I'd assume this is a kind of false positive that could easily occur in an application server environment where the Derby classes are not found on the system class loader.", "2) Check against Thread.class.getClassLoader() instead of ClassLoader.getSystemClassLoader().", "Normally, those two checks would be identical.", "If however the setup is such that they aren't identical, we'd still know that the class loader actually used for system classes such as the Thread class would have to stay in memory for as long as the timer thread is alive, regardless of the context class loader of the thread, so the workaround for DERBY-3745 could be skipped if it's the same as the context class loader.", "The check would be a bit more specific this way.", "Not sure about #2, but at least #1 sounds worthwhile.", "FWIW, the new SecureServerTest passes with the suggested additional changes too.", "Uploading [^derby-6619-2b.diff].", "Added an action in the setUp method of the new decorator ClassLoaderTestSetup to shutdown the engine, so we can be sure the Derby classes are all loaded with the new class loader (the lack thereof revealed by the regression suite).", "Attaching [^derby-6619-2-refinement.diff] which implements your suggested improvements to the test, Knut.", "Both seem good to me.", "Resolving the issue again after the second set of changes, also backported to 10.11."], "SplitGT": [" Get the context class loader if it's different from the system class loader."], "issueString": "After silently swallowing SecurityExceptions, Derby can leak class loaders\nAs part of the fix for DERBY-3745, Derby silently swallows security exceptions and leaks class loaders. This can give rise to denial-of-service attacks. At a minimum, Derby should report the swallowed exceptions so that the security policy can be corrected and the application can be hardened against this attack. The swallowing occurs at these locations:\n\n{noformat}\norg.apache.derby.impl.services.timer.SingletonTimerFactory run Catch java.lang.SecurityException 0 line 175\norg.apache.derby.impl.services.timer.SingletonTimerFactory run Catch java.lang.SecurityException 1 line 158\n{noformat}\n\nTo reduce the impact, we could make SingletonTimerFactory use an ExecutorService instead of a Timer, and set up the ExecutorService to time out idle threads from the pool after a while. That would at least reduce the chances of threads keeping references to stale class loaders forever. We did something similar for DERBY-6107.\nUploading a patch [^derby-6619.diff] which prints warnings on derby.log.\n\nFor example, with this invocation:\n{code}\njava -jar jars/sane/derbyrun.jar server start\n{code}\nwhich uses the default security manager, the derby.log looks as in [^derby.log].\nUploading [^derby-6619b.diff], a slightly polished version.\nAttaching [^derby-6619c.diff]: Suggested commit log:\n{quote}\nPatch derby-6619 which prints warnings on derby.log if permissions are missing to get and set the context class loader in SingletonTimerFactory (which can lead to classloader leak). Also adds a test of this by checking derby.log in SecureServerTest.\n{quote}\nRunning regressions. {color:green}[Update: passed]{color}\nI also changed the code to only dump the stack if we run with sane jars, it is not very useful to end users, and rather unsettling.\n\nI am not planning to rewrite the mechanism to use ExecutorService as Knut suggested for now. I can leave the issue open, or close it and create an improvement issue for that rewrite. Opinions?\nThe tests are failing on Windows after this change. See for example [http://download.java.net/javadesktop/derby/request_5594779/javadb-task-3915844.html].\n\nI'm guessing that it's the construction of the file name in assertWarningDerby6619() that causes the problem, because it assumes the file separator is /.\n\n{code}\n        final String logFileName =\n                getSystemProperty(\"derby.system.home\").replace(\"/system\",\"\") +\n                File.separator + \"/derby.log\";\n{code}\n\n(I also suspect that it fails on non-Windows platforms if one of the parent directories of the test directory has a name that begins with \"system\".)\n\nMaybe something like {{new File(getSystemProperty(\"derby.system.home\")).getParent()}} would be a more reliable way of getting the directory name. Or perhaps just {{getSystemProperty(\"user.dir\")}}.\nThanks, Knut, fixed it, resolving.\n\nNow I see this warning in derby.log if I start a network server from the command line with the default security policy. The warning is not really relevant when you start the network server from the command line, since the leak could only happen if you start the network server embedded within some other application. Since the security warning is printed with the default configuration, I guess many will notice it, and we should expect questions from worried users. I think we should try to find an approach that doesn't generate warnings in the default configuration.\nI can see the following options:\n\n- Keep the warning and just document it (Pro: avoid the issue\n  being ignored, Con: noisy )\n\n- Don't print the warning if the server is started from the command\n  line (Pro: less nois, Con: added complexity and different engine\n  behavior depending on start mode is somewhar undesirable in itself)\n\n- Augment the default policy file with the needed permission if the\n  server is started from the command line before loading it (Pro: less\n  noisy, Con: complexity)\n\n- Add the permission to the default policy (needs to be tightened up\n  anyway as per our recommendation in the docs - it is already overly\n  liberal) (Pro: simple, no noise, Con: less safe by default)\n\n\nIf I've understood DERBY-3745 correctly, this code is there in order to protect against the case where the thread that starts Derby, has a context class loader that is different from the system class loader. In such cases, if the timer thread inherits the context class loader, the context class loader will stay in memory until the Derby engine is shut down, even if all other references to the class loader are gone.\n\nIf the context class loader is the same as the system class loader, on the other hand, such a \"leak\" would not be a problem, since the system class loader will stay in memory until the JVM is shut down anyway.\n\nI'm wondering if it would be OK to take advantage of this and only attempt to change the context class loader if it is different from the system class loader. See the attached patch [^system-loader.diff].\n\nWith that patch, no warning is printed to derby.log when I start the server from the command line, and there's no warning when I start the server using the API with a security manager installed when the context class loader hasn't been changed from the default. However, if the server is started using the API with a non-default context class loader, I do see warnings in derby.log if a security manager is installed. This behaviour sounds fine to me, since only the last scenario could potentially suffer from the leak.\n\nFor the record, all regression tests ran cleanly with the patch, except an expected failure in SecureServerTest where we check that the warning is always printed if a security manager is installed.\nThanks for that analysis, Knut. I think this is a good way to go. I upload [^derby-6619-2.diff] which uses your proposed patch and add tests (in SecureServerTest: a new fixture and new asserts in the existing fixtures. Running regressions.\nThanks, Dag. The patch and the test case look good to me. +1 to commit.\n\nI'm wondering if we may want to make a tiny refinement of the if statement in a follow-up. We could change it from\n\n{code}\n                    if (cl == ClassLoader.getSystemClassLoader()) {\n{code}\n\nto\n\n{code}\n                    if (cl == getClass().getClassLoader() ||\n                            cl == Thread.class.getClassLoader()) {\n{code}\n\nThat would be two changes from the original:\n\n1) Check if the context class loader is the same as the loader of the SingletonTimerFactory class (that is, the class loader from which Derby classes are loaded). Even if this isn't the same as the system class loader, it would be safe to skip the workaround for DERBY-3745, since the class loader for the Derby classes would not be eligible for garbage collection until the engine is shut down anyway. This would prevent some more false positives from being reported in derby.log. I'd assume this is a kind of false positive that could easily occur in an application server environment where the Derby classes are not found on the system class loader.\n\n2) Check against Thread.class.getClassLoader() instead of ClassLoader.getSystemClassLoader(). Normally, those two checks would be identical. If however the setup is such that they aren't identical, we'd still know that the class loader actually used for system classes such as the Thread class would have to stay in memory for as long as the timer thread is alive, regardless of the context class loader of the thread, so the workaround for DERBY-3745 could be skipped if it's the same as the context class loader. The check would be a bit more specific this way.\n\nNot sure about #2, but at least #1 sounds worthwhile. FWIW, the new SecureServerTest passes with the suggested additional changes too.\nUploading [^derby-6619-2b.diff]. Added an action in the setUp method of the new decorator ClassLoaderTestSetup to shutdown the engine, so we can be sure the Derby classes are all loaded with the new class loader (the lack thereof revealed by the regression suite).\nAttaching [^derby-6619-2-refinement.diff] which implements your suggested improvements to the test, Knut. Both seem good to me.\nResolving the issue again after the second set of changes, also backported to 10.11.\n", "issueSearchSentences": ["In such cases, if the timer thread inherits the context class loader, the context class loader will stay in memory until the Derby engine is shut down, even if all other references to the class loader are gone.", "Normally, those two checks would be identical.", "That would be two changes from the original:", "If I've understood DERBY-3745 correctly, this code is there in order to protect against the case where the thread that starts Derby, has a context class loader that is different from the system class loader.", "1) Check if the context class loader is the same as the loader of the SingletonTimerFactory class (that is, the class loader from which Derby classes are loaded)."], "issueSearchIndexes": [60, 91, 85, 59, 86]}
{"aId": 53, "code": "public  String  vtiSchema() { return _vtiSchema; }", "comment": " Return the name of the schema holding the table function", "issueId": "DERBY-6117", "issueStringList": ["Extend the Table Functions java interface to pass more query context information from Derby", "General requirement is to extend the Table Functions java interface (through RestrictedVTI or another interface) and pass more context information from Derby to Table Functions - esp in query execution phase.", "Greater urgency is required for the first 2 items below, especially the ability to access the original SQL which was available with VTIs.", "This is critical to the GaianDB project - we extract HINTs from the query (where we pass meta data like user credentials), and also extract full original complex predicate expressions (involving functions etc - which cannot be expressed with a Restriction) - to push on in our query prorogation...", "In order of importance + simplicity:", "1 - Original SQL (this used to be available with VTIs through VTIEnvironment for both compilation and execution phases)", "2 - Name of function that was called", "3 - User Info (ID, etc) - (this can currently be passed in the SQL hint)", "4 - Richer predicate expressions (incl functions, etc)", "5 - Context within Join query (e.g.", "inner or outer table, join type)", "6 - Other Query Plan information", "7 - Anything else...?", "Original forum discussion:", "http://apache-database.10148.n7.nabble.com/Limitations-of-Table-Functions-vs-old-VTIs-td127988.html#a127995", "i agree with all above, especially the name of the function called.", "adding information from", "https://issues.apache.org/jira/browse/DERBY-6115", "1) derby should support passing IN to initScan", "2) derby should transform IN to an OR clause as a work around to not passing down IN scan", "3) function should have access to information about the function's return type, i.e.", "the if the result type is a table definition, function should have access to that definition.", "this is necessary when a function is declared with multiple names and return types.", "for example, with foreign table loads, we want to pre-transform data from remote result set in 1 thread, then hand to derby thread.", "we need to know what the main derby thread reading resultset wants in sqltype for each column.", "4) derby should introspect resultset to see which column names are searchable, and thus, fast for querying,  perhaps isSearchable on ResultSetMetaData is the right / wrong thing to do.", "maybe can do this with VTIConsting ?", "5) derby should do multi-probe on vti function if vti function indicates on a metaData that isSearchable is true, or that it implements perfectly the initscan restriction.", "6) vti function should be able to tell derby that it correctly implements the vti restriction, either for a given one, or for any, and derby should not request the column in initscan columnNames, and derby  should not check again the restriction.", "( for example, assume foreign table with username and picture as BLOB) , a query for select username where picture is not null, currently, derby will pass select username and picture as columnnames, and function will have to pull all the username and blob data and hand to derby, just to allow derby to check again is not null, even though function already did this .", "This is a HUGE performance issue we are experiencing.", "i'm sure i'll have more issues to add :)", "Note that part of item (3) can be obtained by calling DriverManager.getConnection( \"jdbc:default:connection\" ) in order to get the connection and then executing a \"values current_user\" statement.", "\ufeff\ufeffAttaching derby-6117-01-aa-AwareVTI.diff.", "This patch introduces the AwareVTI interface.", "This is a first step toward giving table functions more context about their execution environments.", "I am running tests now.", "Introduces two new classes/interfaces:", "o VTIContext - This is a simple class which contains the following information:", "The name of the schema holding the table function.", "The non-schema-qualified name of the table function.", "The text of the statement invoking the table function.", "o AwareVTI - Table functions which implement this interface are handed the VTIContext describing their execution environment.", "VTITemplate now implements AwareVTI so most table functions will get this functionality for free.", "VTIContext exposes the following methods:", "{noformat}", "public  String  vtiSchema() { return _vtiSchema; }", "public  String  vtiTable()  { return _vtiTable; }", "public  String  statementText() { return _statementText; }", "{noformat}", "AwareVTI contains these method:", "{noformat}", "public  VTIContext  getContext();", "public  void    setContext( VTIContext context );", "{noformat}", "Touches the following files:", "A       java/engine/org/apache/derby/vti/VTIContext.java", "A       java/engine/org/apache/derby/vti/AwareVTI.java", "M       java/engine/org/apache/derby/vti/VTITemplate.java", "Introduces the new classes and wires them into most existing table functions.", "M       java/engine/org/apache/derby/iapi/sql/execute/ResultSetFactory.java", "M       java/engine/org/apache/derby/impl/sql/compile/MethodCallNode.java", "M       java/engine/org/apache/derby/impl/sql/compile/FromVTI.java", "M       java/engine/org/apache/derby/impl/sql/compile/StaticMethodCallNode.java", "M       java/engine/org/apache/derby/impl/sql/execute/GenericResultSetFactory.java", "M       java/engine/org/apache/derby/impl/sql/execute/VTIResultSet.java", "Compile-time and execution-time machinery to support VTIContext.", "A       java/testing/org/apache/derbyTesting/functionTests/tests/lang/AwareVTITest.java", "A       java/testing/org/apache/derbyTesting/functionTests/tests/lang/DummyAwareVTI.java", "M       java/testing/org/apache/derbyTesting/functionTests/tests/lang/_Suite.java", "Basic tests for this new feature.", "M       tools/javadoc/publishedapi.ant", "Adds AwareVTI and VTIContext to the public api.", "Attaching derby-6117-01-ab-AwareVTI.diff.", "This fixes an NPE during compilation of old-style VTIs, introduced by the previous rev of the patch.", "Re-starting the tests.", "Touches the same files as the previous rev.", "Tests passed cleanly for me on derby-6117-01-ab-AwareVTI.diff except for the query plan instability recently introduced into org.apache.derbyTesting.functionTests.tests.lang.SelectivityTest by other work."], "SplitGT": [" Return the name of the schema holding the table function"], "issueString": "Extend the Table Functions java interface to pass more query context information from Derby\nGeneral requirement is to extend the Table Functions java interface (through RestrictedVTI or another interface) and pass more context information from Derby to Table Functions - esp in query execution phase.\n\nGreater urgency is required for the first 2 items below, especially the ability to access the original SQL which was available with VTIs. This is critical to the GaianDB project - we extract HINTs from the query (where we pass meta data like user credentials), and also extract full original complex predicate expressions (involving functions etc - which cannot be expressed with a Restriction) - to push on in our query prorogation...\n\nIn order of importance + simplicity:\n--------------------------------------------------\n1 - Original SQL (this used to be available with VTIs through VTIEnvironment for both compilation and execution phases)\n2 - Name of function that was called\n\n3 - User Info (ID, etc) - (this can currently be passed in the SQL hint)\n4 - Richer predicate expressions (incl functions, etc)\n5 - Context within Join query (e.g. inner or outer table, join type)\n6 - Other Query Plan information\n7 - Anything else...?\n\nOriginal forum discussion:\nhttp://apache-database.10148.n7.nabble.com/Limitations-of-Table-Functions-vs-old-VTIs-td127988.html#a127995\ni agree with all above, especially the name of the function called.\n\nadding information from\n\nhttps://issues.apache.org/jira/browse/DERBY-6115\n\n1) derby should support passing IN to initScan\n2) derby should transform IN to an OR clause as a work around to not passing down IN scan\n3) function should have access to information about the function's return type, i.e. the if the result type is a table definition, function should have access to that definition.  this is necessary when a function is declared with multiple names and return types.  for example, with foreign table loads, we want to pre-transform data from remote result set in 1 thread, then hand to derby thread.  we need to know what the main derby thread reading resultset wants in sqltype for each column. \n4) derby should introspect resultset to see which column names are searchable, and thus, fast for querying,  perhaps isSearchable on ResultSetMetaData is the right / wrong thing to do.  maybe can do this with VTIConsting ?\n5) derby should do multi-probe on vti function if vti function indicates on a metaData that isSearchable is true, or that it implements perfectly the initscan restriction.\n6) vti function should be able to tell derby that it correctly implements the vti restriction, either for a given one, or for any, and derby should not request the column in initscan columnNames, and derby  should not check again the restriction. ( for example, assume foreign table with username and picture as BLOB) , a query for select username where picture is not null, currently, derby will pass select username and picture as columnnames, and function will have to pull all the username and blob data and hand to derby, just to allow derby to check again is not null, even though function already did this .  This is a HUGE performance issue we are experiencing.  \n\ni'm sure i'll have more issues to add :)\nNote that part of item (3) can be obtained by calling DriverManager.getConnection( \"jdbc:default:connection\" ) in order to get the connection and then executing a \"values current_user\" statement.\n\ufeff\ufeffAttaching derby-6117-01-aa-AwareVTI.diff. This patch introduces the AwareVTI interface. This is a first step toward giving table functions more context about their execution environments. I am running tests now.\n\nIntroduces two new classes/interfaces:\n\no VTIContext - This is a simple class which contains the following information:\n\n  - The name of the schema holding the table function.\n  - The non-schema-qualified name of the table function.\n  - The text of the statement invoking the table function.\n\no AwareVTI - Table functions which implement this interface are handed the VTIContext describing their execution environment.\n\nVTITemplate now implements AwareVTI so most table functions will get this functionality for free.\n\nVTIContext exposes the following methods:\n\n{noformat}\n    /** Return the name of the schema holding the table function */\n    public  String  vtiSchema() { return _vtiSchema; }\n\n    /** Return the unqualified table function name */\n    public  String  vtiTable()  { return _vtiTable; }\n\n    /** Return the text of the statement which invoked the table function */\n    public  String  statementText() { return _statementText; }\n{noformat}\n\nAwareVTI contains these method:\n\n{noformat}\n    /** Get the table function context */\n    public  VTIContext  getContext();\n\n    /** Set the table function context */\n    public  void    setContext( VTIContext context );\n{noformat}\n\n\n\nTouches the following files:\n\n----------------\n\nA       java/engine/org/apache/derby/vti/VTIContext.java\nA       java/engine/org/apache/derby/vti/AwareVTI.java\nM       java/engine/org/apache/derby/vti/VTITemplate.java\n\nIntroduces the new classes and wires them into most existing table functions.\n\n----------------\n\nM       java/engine/org/apache/derby/iapi/sql/execute/ResultSetFactory.java\nM       java/engine/org/apache/derby/impl/sql/compile/MethodCallNode.java\nM       java/engine/org/apache/derby/impl/sql/compile/FromVTI.java\nM       java/engine/org/apache/derby/impl/sql/compile/StaticMethodCallNode.java\nM       java/engine/org/apache/derby/impl/sql/execute/GenericResultSetFactory.java\nM       java/engine/org/apache/derby/impl/sql/execute/VTIResultSet.java\n\nCompile-time and execution-time machinery to support VTIContext.\n\n----------------\n\nA       java/testing/org/apache/derbyTesting/functionTests/tests/lang/AwareVTITest.java\nA       java/testing/org/apache/derbyTesting/functionTests/tests/lang/DummyAwareVTI.java\nM       java/testing/org/apache/derbyTesting/functionTests/tests/lang/_Suite.java\n\nBasic tests for this new feature.\n\n----------------\n\nM       tools/javadoc/publishedapi.ant\n\nAdds AwareVTI and VTIContext to the public api.\n\nAttaching derby-6117-01-ab-AwareVTI.diff. This fixes an NPE during compilation of old-style VTIs, introduced by the previous rev of the patch. Re-starting the tests.\n\nTouches the same files as the previous rev.\n\nTests passed cleanly for me on derby-6117-01-ab-AwareVTI.diff except for the query plan instability recently introduced into org.apache.derbyTesting.functionTests.tests.lang.SelectivityTest by other work.\n", "issueSearchSentences": ["{noformat}", "public  String  vtiSchema() { return _vtiSchema; }", "public  String  vtiTable()  { return _vtiTable; }", "{noformat}", "public  VTIContext  getContext();"], "issueSearchIndexes": [46, 47, 48, 52, 53]}
{"aId": 54, "code": "public StringDataValue getValue(RuleBasedCollator collatorForComparison)\n\t{\n\t\tif (collatorForComparison != null)\n\t\t{\n\t\t\t//non-null collatorForComparison means use this collator sensitive\n\t\t\t//implementation of SQLLongvarchar\n\t\t    setCollator(collatorForComparison);\n\t\t    return this;\t\t\t\n\t\t} else {\n\t\t\t//null collatorForComparison means use UCS_BASIC for collation.\n\t\t\t//For that, we need to use the base class SQLLongvarchar\n\t\t\tSQLLongvarchar s = new SQLLongvarchar();\n\t\t\ts.copyState(this);\n\t\t\treturn s;\n\t\t}\n\t}", "comment": " We do not anticipate this method on collation sensitive DVD to be ever called in Derby 10.3 In future, when Derby will start supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs.", "issueId": "DERBY-2534", "issueStringList": ["Add new api \"public StringDataValue getValue(RuleBasedCollator)\" on StringDataValue.", "This method will return either the base DVDs for char datatypes or it will return collation sensitive DVD for char datatypes.", "In Derby 10.3, the collation of char datatypes can be different depending on what kind of collation is requested by the user at the database create time through the optional JDBC url attribute COLLATION.", "The collation type associated with the DTD will determine which kind of DVD needs to be generated.", "(Note that, irrespective of what collation is used, the format id of the char datatypes remain same.)", "In order to support this behavior of generating the base DVD or the collation sensitive DVD for character datatypes, we need to add a new api to StringDataValue which will look as follows", "Gets either SQLChar/SQLVarchar/SQLLongvarchar/SQLClob(base classes) or", "CollatorSQLChar/CollatorSQLVarchar/CollatorSQLLongvarch/CollatorSQLClob", "(subclasses).", "Whether this method returns the base class or the subclass", "depends on the value of the RuleBasedCollator.", "If RuleBasedCollator is", "null, then the object returned would be baseclass otherwise it would be", "subcalss.", "public StringDataValue getValue(RuleBasedCollator collatorForComparison);", "I am attaching a patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt to this Jira entry which I plan to commit soon.", "The patch adds a new api to StringDataValue interface and the new api looks as follows", "public StringDataValue getValue(RuleBasedCollator collatorForComparison);", "The new api will be needed in quite a few different places.", "2 distinct uses that I can see at this point are", "1)Store will have a format id and collation type when it is trying to construct a DVD template.", "Using the formatid, we will first always get the base class DVD for char datatypes namely SQLChar, SQLVarchar, SQLLongvarchar or SQLClob.", "Next, if the collation type is not 0  ie it is not UCS_BASIC, then we want to use Collation sensitive DVDs of base char DVDs because we want to use the passed Collator for collation rather than the default UCS_BASIC Collator.", "The collation sensitive DVDs of char datatypes are CollatorSQLChar, CollatorSQLVarchar, CollatorSQLLongvarchar and CollatorSQLClob.", "In order to derive these collation sensitive DVDs of character datatypes, we will use this new api called getValue on base character DVDs.", "The getValue method will have the Collator object as parameter to it.", "If the Collator object is null, then we can continue to use the base DVD.", "But if the Collator object is not null, then we want to construct collation sensitive DVD.", "The new api on StringDataValue will help achieve this behavior.", "2)Another place which I can envision using this new api is in DataTypeDescriptor.getNull() method which returns a DVD.", "Currently, the implementation of this method looks as follows", "public DataValueDescriptor getNull() {", "return typeId.getNull();", "}", "So, if the typeid of DTD is character data type, this method will always return base char DVD, no matter what is the collation type of the DTD.", "But, if the DTD has a territory based collation set for it, then this method should return collation sensitive char DVD.", "This functionality can be achieved by using the new api on StringDataValue.", "I do not anticipate this new method ever getting called on collation sensitive DVDs in Derby 10.3 In future, when Derby will start  supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs but for Derby 10.3, the new api in collation sensitive DVDs is just a place holder.", "Another change to note is I changed all the collation sensitive subclasses to have their method setCollator changed from private to protected.", "This is so that the getValue method from their correspoding base classes can call the setCollator method on subclasses.", "The files changed by this patch are", "svn stat -q", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLLongvarchar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\StringDataValue.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLChar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLClob.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLVarchar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLChar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLClob.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLVarchar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLLongvarchar.java", "The code compiles ok with my changes.", "None of the tests should get impacted because currently, this new api on StringDataValue is  not called by any other code in Derby.", "Just commited the patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt with revision 526668.", "If anyone has any feedback, please share them.", "I will address them in subsequent patches."], "SplitGT": [" We do not anticipate this method on collation sensitive DVD to be ever called in Derby 10.3 In future, when Derby will start supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs."], "issueString": "Add new api \"public StringDataValue getValue(RuleBasedCollator)\" on StringDataValue. This method will return either the base DVDs for char datatypes or it will return collation sensitive DVD for char datatypes.\nIn Derby 10.3, the collation of char datatypes can be different depending on what kind of collation is requested by the user at the database create time through the optional JDBC url attribute COLLATION. The collation type associated with the DTD will determine which kind of DVD needs to be generated. (Note that, irrespective of what collation is used, the format id of the char datatypes remain same.) In order to support this behavior of generating the base DVD or the collation sensitive DVD for character datatypes, we need to add a new api to StringDataValue which will look as follows\n\n\t/**\n\t * Gets either SQLChar/SQLVarchar/SQLLongvarchar/SQLClob(base classes) or \n\t * CollatorSQLChar/CollatorSQLVarchar/CollatorSQLLongvarch/CollatorSQLClob\n\t * (subclasses). Whether this method returns the base class or the subclass \n\t * depends on the value of the RuleBasedCollator. If RuleBasedCollator is \n\t * null, then the object returned would be baseclass otherwise it would be \n\t * subcalss.\n\t */\n\tpublic StringDataValue getValue(RuleBasedCollator collatorForComparison);\n\nI am attaching a patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt to this Jira entry which I plan to commit soon. The patch adds a new api to StringDataValue interface and the new api looks as follows\npublic StringDataValue getValue(RuleBasedCollator collatorForComparison);\n\nThe new api will be needed in quite a few different places. 2 distinct uses that I can see at this point are\n1)Store will have a format id and collation type when it is trying to construct a DVD template. Using the formatid, we will first always get the base class DVD for char datatypes namely SQLChar, SQLVarchar, SQLLongvarchar or SQLClob. Next, if the collation type is not 0  ie it is not UCS_BASIC, then we want to use Collation sensitive DVDs of base char DVDs because we want to use the passed Collator for collation rather than the default UCS_BASIC Collator. The collation sensitive DVDs of char datatypes are CollatorSQLChar, CollatorSQLVarchar, CollatorSQLLongvarchar and CollatorSQLClob. In order to derive these collation sensitive DVDs of character datatypes, we will use this new api called getValue on base character DVDs. The getValue method will have the Collator object as parameter to it. If the Collator object is null, then we can continue to use the base DVD. But if the Collator object is not null, then we want to construct collation sensitive DVD. The new api on StringDataValue will help achieve this behavior.\n2)Another place which I can envision using this new api is in DataTypeDescriptor.getNull() method which returns a DVD. Currently, the implementation of this method looks as follows\n\tpublic DataValueDescriptor getNull() {\n\t\treturn typeId.getNull();\n\t}\nSo, if the typeid of DTD is character data type, this method will always return base char DVD, no matter what is the collation type of the DTD. But, if the DTD has a territory based collation set for it, then this method should return collation sensitive char DVD. This functionality can be achieved by using the new api on StringDataValue.\n\nI do not anticipate this new method ever getting called on collation sensitive DVDs in Derby 10.3 In future, when Derby will start  supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs but for Derby 10.3, the new api in collation sensitive DVDs is just a place holder.\n\nAnother change to note is I changed all the collation sensitive subclasses to have their method setCollator changed from private to protected. This is so that the getValue method from their correspoding base classes can call the setCollator method on subclasses.\n\nThe files changed by this patch are\nsvn stat -q\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLLongvarchar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\StringDataValue.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLChar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLClob.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLVarchar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLChar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLClob.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLVarchar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLLongvarchar.java\n\nThe code compiles ok with my changes. None of the tests should get impacted because currently, this new api on StringDataValue is  not called by any other code in Derby.\n\nJust commited the patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt with revision 526668. If anyone has any feedback, please share them. I will address them in subsequent patches.\n", "issueSearchSentences": ["subcalss.", "The patch adds a new api to StringDataValue interface and the new api looks as follows", "The getValue method will have the Collator object as parameter to it.", "Using the formatid, we will first always get the base class DVD for char datatypes namely SQLChar, SQLVarchar, SQLLongvarchar or SQLClob.", "Add new api \"public StringDataValue getValue(RuleBasedCollator)\" on StringDataValue."], "issueSearchIndexes": [14, 17, 26, 22, 1]}
{"aId": 55, "code": "public final boolean isValid(int timeout) throws SQLException{\n        // Check first if the Brokered connection is closed\n        if (isClosed()) {\n            return false;\n        }\n\n        // Forward the isValid call to the physical connection\n        try {\n            return getRealConnection().isValid(timeout);\n        } catch (SQLException sqle) {\n            notifyException(sqle);\n            throw sqle;\n        }\n    }", "comment": " Checks if the connection has not been closed and is still valid. The validity is checked by running a simple query against the database.", "issueId": "DERBY-1090", "issueStringList": ["Implement Connection.isValid as defined by JDBC4", "The Javadoc for JDBC4 says this about Connection.isValid:", "boolean isValid(int timeout) throws SQLException", "Returns true if the connection has not been closed and is still valid.", "The driver shall submit a query on the connection or use some other mechanism that positively verifies the connection is still valid when this method is called.", "The query submitted by the driver to validate the connection shall be executed in the context of the current transaction.", "Parameters: timeout - - The time in seconds to wait for the database operation used to validate the connection to complete.", "If the timeout period expires before the operation completes, this method returns false.", "A value of 0 indicates a timeout is not applied to the database operation.", "Returns: true if the connection is valid, false otherwise", "In case someone else have suggestions or ideas on how to best implement this functionality, here are some high-level initial thoughts on how to implement it:", "to check the validity of the connection, issue a simple query like", "e.g., \"VALUES (1)\"", "to implement the timeout, use the setQueryTimeout() method.", "This will hopefully be sufficient in the embedded version as I expect that for all error situations where the connection no longer is valid, an exception will be thrown when issuing the query.", "For the Derby client we probably need some timeout mechanism in the client code (in addition to setting the query timeout) in order to detect that the server has not responded within before the specified timeout has elapsed.", "I have not studied the network code in details yet to find out if it already has code or hooks for specifying a timeout on the DRDA request to the server.", "Any suggestions on how to best implement this are welcome.", "In embedded would it  be sufficient just to call the isClosed() method?", "Dan, thanks for the suggestion of only using isClosed in the embedded driver.", "I have also wondered if calling isClosed would be sufficient, and actually I have not been able to create a scenario where isClosed returns false followed by simple query that fails.", "The main reasons for including execution of a simple query also in the embedded driver are:", "I do not know the code well enough to be sure that there will not be situations where isClosed returns false and a query returns e.g., a timeout or exception due to some resource constraints, deadlock or other error situations.", "It will make the behavior and implementation more similar between what is done in the embedded and in the client driver.", "I will probably submit a patch for how isValid can be implemented for the Embedded server containing both a check for isClosed and a query.", "If you or other on the list still thinks it is unnecessary to include execution of a query I will remove it.", "The query case actually seems somewhat harder to me, and one needs to understand the code far more, than the isClosed approach.", "Maybe this knowledge needs to exist for the client implementation anyway.", "I think one has to see how many ways the query can fail and", "then see how many map to the connection being not valid.", "I don't believe the query failing, always means the connection is not valid.", "If the query failed due to out of memory error, then the connection is still valid.", "There's no requirement for the embedded and client dirver to have identical implementations, the embedded gains performance", "by having direct access to the engine, something that is clearly not possible with the client.", "This naturally leads to different implementations", "for various methods.", "Thanks for commenting on this, Dan.", "I agree that using a query is more complicated than just checking for isClosed.", "So if checking for isClosed is sufficient to verify that the connection is \"valid\" we should go for that approach in the embedded driver as it is less complex and has better performance.", "Still, I think the purpose of adding the isValid method to the JDBC standard is to positively determine that it is possible to run queries on it.", "I am not convinced that your example of a simple query on the connection failing due to out of memory should still return that the connection is \"valid\"?", "I expect this is a method that will be used together with a connection pool implementation where either the pool or the user will use this for \"ensuring\" the connection is \"valid\" before it is used for something.", "And having a connection that returns out of memory errors on every query is not something that an application would think is a \"useful\" connection to have around (on the other side, creating a new connection does probably not make the situation any better in this case).", "The JavaDoc for isValid (see the test in the Jira issue) strongly indicates that we actually should take the cost of running a query against the database.", "Anyway, I have no strong opinions on whether to just check isClosed or issue a query against the database.", "But since I now happen to have a patch that solves this using a query I will upload this patch tonight.", "Tomorrow moring I will upload a new patch that is only checking for isClosed.", "I do not expect anyone to do a review or commit any of these, but it might trigger some more comments and opinions from other on the list.", "The patch contains one alternative implementation of  Connection.isValid() for the embedded driver by verifying that the connection", "is open (by calling isClosed()) and by running a simple query (\"VALUES (1)\") against the database.", "If the connection is closed or if the query returns any SQL exception, isValid returns false.", "To support the timeout defined as a parameter to isValid, setQueryTimeout is used.", "Testing:", "The patch extends the TestConnectionMethods.java test with test for isValid in the following cases:", "wrong parameter values (negative timeout)", "isValid with no timeout", "isValid with a specified timeout", "isValid on a connection that is closed", "isValid on a \"open connection\" to a database that is shutdown", "I plan to submit an alternative patch that is checking only for isClosed as well as a more complete patch containing an implementation of isValid for the Derby client driver.", "svn status reports:", "M      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnection.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java", "I have run the JDBC4 tests using Java 1.6 and derbyall using 1.5 under Solaris 10 x86.", "Only errors seen in the regression test was reported.", "The patch is complete for the embedded driver and could be reviewed and committed, but I expect that we should wait until we have decided if using only isClosed is a better and sufficient solution.", "Hi, Olav.", "It's not clear to me what a committer needs to do with this patch.", "You have checked the box saying you intend it for inclusion to the project, but you also say other, alternate patches are on  the way.", "Do you want a committer to commit this, or is it just for review?", "Hi, David.", "The main purpose of sending in the patch was to get opinions from more people on what would be the best alternative solution to check if a connection is valid in the embedded driver.", "The current alternatives are:", "a) check if connection is not closed followed by a simple query against the database (this is implemented by the patch I submitted yesterday)", "b) just check that the connection is not closed (I plan to submit an alternative patch for this soon)", "Dan has suggested that checking for isClosed could be sufficient in the embedded version.", "It would be good to hear if other have opinions about this.", "If I do not get other suggestions I will probably propose that the next patch (checking only for isClosed) being reviewed and commited.", "This patch (embedded1090-isclosed.diff)  implementations Connection.isValid() for the embedded driver by verifying that the connection", "is not closed (by calling isClosed()).", "If the connection is closed, isValid returns false, otherwise it returns true.", "The timeout defined as a parameter to isValid is not used.", "Compared to the previous patch I sent a few days ago (embedded1090-query.diff), this patch does not run any query against Derby to validate the", "connection.", "My proposal (also based on suggestions from Dan) is that we only check for isClosed() in the embedded driver.", "I have not experienced any situation where isClosed returned false and the query failed.", "If we later discover situations where the connection is not \"valid\" even if isValid returns true, we can add a query as done in my first patch to isValid.", "Testing:", "The patch extends the TestConnectionMethods.java test with test for isValid in the following cases:", "wrong parameter values (negative timeout)", "isValid with no timeout", "isValid with a specified timeout", "isValid on a connection that is closed", "isValid on a \"open connection\" to a database that is shutdown", "svn status reports:", "M      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java", "I have run the JDBC4 tests using Java 1.6 and derbyall using Java 1.5 under Solaris 10 x86.", "Only errors seen in the regression test was reported (runtimeinfo failed in derbynetmats).", "The patch is complete for the embedded driver and can be reviewed and committed.", "Looks good to me.", "The jdbc4 tests run cleanly.", "Derbyall only has errors which I see in a clean client: wisconsin, sysinfo, sysinfo_withproperties, xaSimplePositive, and a new failure in SURTest caused by:", "> java.lang.NoSuchMethodError: main", "> Exception in thread \"main\"", "Test Failed.", "I have committed embedded1090_isClosed.diff at subversion revision 388771.", "This patch (client1090_patch1.diff) implements the Connection.isValid for the network client.", "The connection is valid if (a) it is not closed (checked isClosed()) and (b) a simple query (\"VALUES (1)\") is executed successfully.", "Any exception thrown by the query execution is treated as if the connection is not valid.", "If a timeout is specified this is handled by setting a query timeout for executing the query (queryTimeout() is used).", "The implementation handles most failure situations, with the exception of a hanging server that is not returning any reply to the client.", "I plan to submit a fix for this in a separte patch.", "The isValid() call is tested for the following scenarios:", "illegal parameter values (negative timeout)", "no timeout value", "with a timeout specified", "on a connection to a database that has been shutdown", "on a connection to a network server that has been stopped", "svn status reports:", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java", "M      java/client/org/apache/derby/client/net/NetConnection40.java", "I have run the JDBC4 tests and derbyall with the patch.", "Only failure was in tools/derbyrunjartest.java.", "The patch can be reviewed and committed.", "I have looked at the patch, and I think it looks good, and can be committed.", "I concur, looks good.", "JDBC4 tests run cleanly.", "Derbyall runs cleanly modulo wisconsin noise.", "Committed at subversion revision 396028.", "Dyre and Rick, thanks for reviewing and committing the patch.", "The first implementation of Connection.isValid() for the client driver handles most failuire situations.", "One situation that is not handled is if the server \"hangs\" and the client does not receive a reply.", "The application will be hanging \"forever\" in the isValid() call due to the blocking read on the socket even if a timeout value has been specified.", "I plan to submit a fix to this problem by setting a timeout on the socket before the read is called on the socket (using java.net.socket.setSoTimeout).", "One potential problem with using socket.setSoTimeout is that its implementation is platform dependent.", "Some operating systems might not support the timeout value and block forever on socket operations even if a timeout is set.", "I would appreciate to hear if anybody has better or alternative solutions on how to handle the problem with blocking socket read and hanging server.", "This patch (client1090_patch2.diff) addresses the problem of Connection.isValid() hanging infinite if the server is either \"hanging\" or not sending a reply.", "The reason for the client to hang in these situations is that blocking read (and write) is used for receiving replies from the Derby network server.", "To avoid the client hanging infinite in the blocking read when the caller has specified a timeout to isValid() we set a maximum timeout value on the socket (by using java.net.socket.setSoTimeout()) before the query is sent to the server.", "Thus, if the server does not respond within the specified timeout period the blocking read will return with an exception.", "If this exception is thrown, isValid will return false for this connection.", "The timeout on the socket is reset to whatever value it had before the call to isValid.", "Thus, this socket timeout should only influence on the query issued by the isValid code.", "The implementation has been tested by setting a very low timeout value and introducing a delay in the network server.", "svn status reports:", "M      java/client/org/apache/derby/client/net/NetAgent.java", "M      java/client/org/apache/derby/client/net/NetConnection40.java", "I have run the JDBC4 tests and derbyall with the patch.", "Only failure was in tools/derbyrunjartest.java.", "The patch can be reviewed and committed.", "Looks solid.", "JDBC4 tests run cleanly.", "So does derbyall modulo the wisconsin noise.", "Committed at subversion revision 397899.", "This patch (brokeredlogical1090.diff) implemets support for Connection.isValid for pooled and XA connections.", "Testing of isValid for pooled and XA connections is implemented in the jdbc4/ConnectionTest.junit.", "This test is currently not part of either the jdbc4 suite or derbyall.", "svn status reports:", "M      java/engine/org/apache/derby/iapi/jdbc/BrokeredConnection40.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/ConnectionTest.java", "M      java/client/org/apache/derby/client/am/LogicalConnection40.java", "I have run the jdbc4/ConnectionTest.junig, the JDBC4 test suite and derbyall with the patch.", "Only failure was in tools/derbyrunjartest.java.", "The patch can be reviewed and committed.", "The brokeredlogical1090.diff patch looks solid.", "JDBC4 tests pass.", "Derbyall passes modulo expected diffs in wisconsin and SuicideOfStreaming.", "Committed at subversion revision 406101."], "SplitGT": [" Checks if the connection has not been closed and is still valid.", "The validity is checked by running a simple query against the database."], "issueString": "Implement Connection.isValid as defined by JDBC4\nThe Javadoc for JDBC4 says this about Connection.isValid:\n\nboolean isValid(int timeout) throws SQLException\n\nReturns true if the connection has not been closed and is still valid. The driver shall submit a query on the connection or use some other mechanism that positively verifies the connection is still valid when this method is called. \n\nThe query submitted by the driver to validate the connection shall be executed in the context of the current transaction. \n\nParameters: timeout - - The time in seconds to wait for the database operation used to validate the connection to complete. If the timeout period expires before the operation completes, this method returns false. A value of 0 indicates a timeout is not applied to the database operation. \n\nReturns: true if the connection is valid, false otherwise \nIn case someone else have suggestions or ideas on how to best implement this functionality, here are some high-level initial thoughts on how to implement it:\n\n  -to check the validity of the connection, issue a simple query like\n   e.g., \"VALUES (1)\"\n\n  -to implement the timeout, use the setQueryTimeout() method. \n\nThis will hopefully be sufficient in the embedded version as I expect that for all error situations where the connection no longer is valid, an exception will be thrown when issuing the query.\n\nFor the Derby client we probably need some timeout mechanism in the client code (in addition to setting the query timeout) in order to detect that the server has not responded within before the specified timeout has elapsed. I have not studied the network code in details yet to find out if it already has code or hooks for specifying a timeout on the DRDA request to the server. Any suggestions on how to best implement this are welcome.\n\nIn embedded would it  be sufficient just to call the isClosed() method?\n\nDan, thanks for the suggestion of only using isClosed in the embedded driver. I have also wondered if calling isClosed would be sufficient, and actually I have not been able to create a scenario where isClosed returns false followed by simple query that fails.\n\nThe main reasons for including execution of a simple query also in the embedded driver are:\n\n * I do not know the code well enough to be sure that there will not be situations where isClosed returns false and a query returns e.g., a timeout or exception due to some resource constraints, deadlock or other error situations.\n\n * It will make the behavior and implementation more similar between what is done in the embedded and in the client driver.\n\nI will probably submit a patch for how isValid can be implemented for the Embedded server containing both a check for isClosed and a query. If you or other on the list still thinks it is unnecessary to include execution of a query I will remove it.\n\n\nThe query case actually seems somewhat harder to me, and one needs to understand the code far more, than the isClosed approach.\nMaybe this knowledge needs to exist for the client implementation anyway. I think one has to see how many ways the query can fail and\nthen see how many map to the connection being not valid. I don't believe the query failing, always means the connection is not valid.\nIf the query failed due to out of memory error, then the connection is still valid.\n\nThere's no requirement for the embedded and client dirver to have identical implementations, the embedded gains performance\nby having direct access to the engine, something that is clearly not possible with the client. This naturally leads to different implementations\nfor various methods.\nThanks for commenting on this, Dan. I agree that using a query is more complicated than just checking for isClosed. So if checking for isClosed is sufficient to verify that the connection is \"valid\" we should go for that approach in the embedded driver as it is less complex and has better performance. \n\nStill, I think the purpose of adding the isValid method to the JDBC standard is to positively determine that it is possible to run queries on it. I am not convinced that your example of a simple query on the connection failing due to out of memory should still return that the connection is \"valid\"? I expect this is a method that will be used together with a connection pool implementation where either the pool or the user will use this for \"ensuring\" the connection is \"valid\" before it is used for something. And having a connection that returns out of memory errors on every query is not something that an application would think is a \"useful\" connection to have around (on the other side, creating a new connection does probably not make the situation any better in this case). The JavaDoc for isValid (see the test in the Jira issue) strongly indicates that we actually should take the cost of running a query against the database.\n\nAnyway, I have no strong opinions on whether to just check isClosed or issue a query against the database. But since I now happen to have a patch that solves this using a query I will upload this patch tonight. Tomorrow moring I will upload a new patch that is only checking for isClosed. I do not expect anyone to do a review or commit any of these, but it might trigger some more comments and opinions from other on the list. \nThe patch contains one alternative implementation of  Connection.isValid() for the embedded driver by verifying that the connection\nis open (by calling isClosed()) and by running a simple query (\"VALUES (1)\") against the database. If the connection is closed or if the query returns any SQL exception, isValid returns false. To support the timeout defined as a parameter to isValid, setQueryTimeout is used.\n\nTesting:\n\nThe patch extends the TestConnectionMethods.java test with test for isValid in the following cases:\n\n  -wrong parameter values (negative timeout)\n  -isValid with no timeout\n  -isValid with a specified timeout\n  -isValid on a connection that is closed\n  -isValid on a \"open connection\" to a database that is shutdown\n\nI plan to submit an alternative patch that is checking only for isClosed as well as a more complete patch containing an implementation of isValid for the Derby client driver.\n\nsvn status reports:\n\nM      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnection.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java\n\nI have run the JDBC4 tests using Java 1.6 and derbyall using 1.5 under Solaris 10 x86. Only errors seen in the regression test was reported.\n\nThe patch is complete for the embedded driver and could be reviewed and committed, but I expect that we should wait until we have decided if using only isClosed is a better and sufficient solution.\n\n\nHi, Olav.  It's not clear to me what a committer needs to do with this patch.  You have checked the box saying you intend it for inclusion to the project, but you also say other, alternate patches are on  the way.  Do you want a committer to commit this, or is it just for review?\nHi, David. The main purpose of sending in the patch was to get opinions from more people on what would be the best alternative solution to check if a connection is valid in the embedded driver. The current alternatives are:\n\n  a) check if connection is not closed followed by a simple query against the database (this is implemented by the patch I submitted yesterday)\n  b) just check that the connection is not closed (I plan to submit an alternative patch for this soon)\n\nDan has suggested that checking for isClosed could be sufficient in the embedded version. It would be good to hear if other have opinions about this. If I do not get other suggestions I will probably propose that the next patch (checking only for isClosed) being reviewed and commited.\nThis patch (embedded1090-isclosed.diff)  implementations Connection.isValid() for the embedded driver by verifying that the connection \nis not closed (by calling isClosed()). If the connection is closed, isValid returns false, otherwise it returns true. The timeout defined as a parameter to isValid is not used.\n\nCompared to the previous patch I sent a few days ago (embedded1090-query.diff), this patch does not run any query against Derby to validate the\nconnection. My proposal (also based on suggestions from Dan) is that we only check for isClosed() in the embedded driver. I have not experienced any situation where isClosed returned false and the query failed. If we later discover situations where the connection is not \"valid\" even if isValid returns true, we can add a query as done in my first patch to isValid.\n\nTesting: \n\nThe patch extends the TestConnectionMethods.java test with test for isValid in the following cases: \n\n  -wrong parameter values (negative timeout) \n  -isValid with no timeout \n  -isValid with a specified timeout \n  -isValid on a connection that is closed \n  -isValid on a \"open connection\" to a database that is shutdown \n\nsvn status reports: \n\nM      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java\n\nI have run the JDBC4 tests using Java 1.6 and derbyall using Java 1.5 under Solaris 10 x86. Only errors seen in the regression test was reported (runtimeinfo failed in derbynetmats).\n\nThe patch is complete for the embedded driver and can be reviewed and committed.\nLooks good to me. The jdbc4 tests run cleanly. Derbyall only has errors which I see in a clean client: wisconsin, sysinfo, sysinfo_withproperties, xaSimplePositive, and a new failure in SURTest caused by:\n\n> java.lang.NoSuchMethodError: main\n> Exception in thread \"main\"\nTest Failed.\n\nI have committed embedded1090_isClosed.diff at subversion revision 388771.\nThis patch (client1090_patch1.diff) implements the Connection.isValid for the network client. The connection is valid if (a) it is not closed (checked isClosed()) and (b) a simple query (\"VALUES (1)\") is executed successfully. Any exception thrown by the query execution is treated as if the connection is not valid.\n\nIf a timeout is specified this is handled by setting a query timeout for executing the query (queryTimeout() is used). \n\nThe implementation handles most failure situations, with the exception of a hanging server that is not returning any reply to the client. I plan to submit a fix for this in a separte patch. \n\nThe isValid() call is tested for the following scenarios:\n\n  -illegal parameter values (negative timeout)\n  -no timeout value\n  -with a timeout specified\n  -on a connection to a database that has been shutdown\n  -on a connection to a network server that has been stopped\n\nsvn status reports:\n\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java\nM      java/client/org/apache/derby/client/net/NetConnection40.java\n\nI have run the JDBC4 tests and derbyall with the patch. Only failure was in tools/derbyrunjartest.java.\n\nThe patch can be reviewed and committed.\nI have looked at the patch, and I think it looks good, and can be committed.\n\nI concur, looks good. JDBC4 tests run cleanly. Derbyall runs cleanly modulo wisconsin noise. Committed at subversion revision 396028.\nDyre and Rick, thanks for reviewing and committing the patch.\nThe first implementation of Connection.isValid() for the client driver handles most failuire situations. One situation that is not handled is if the server \"hangs\" and the client does not receive a reply. The application will be hanging \"forever\" in the isValid() call due to the blocking read on the socket even if a timeout value has been specified. I plan to submit a fix to this problem by setting a timeout on the socket before the read is called on the socket (using java.net.socket.setSoTimeout). One potential problem with using socket.setSoTimeout is that its implementation is platform dependent. Some operating systems might not support the timeout value and block forever on socket operations even if a timeout is set.\n\nI would appreciate to hear if anybody has better or alternative solutions on how to handle the problem with blocking socket read and hanging server. \n\n\nThis patch (client1090_patch2.diff) addresses the problem of Connection.isValid() hanging infinite if the server is either \"hanging\" or not sending a reply. \n\nThe reason for the client to hang in these situations is that blocking read (and write) is used for receiving replies from the Derby network server. To avoid the client hanging infinite in the blocking read when the caller has specified a timeout to isValid() we set a maximum timeout value on the socket (by using java.net.socket.setSoTimeout()) before the query is sent to the server. Thus, if the server does not respond within the specified timeout period the blocking read will return with an exception.\nIf this exception is thrown, isValid will return false for this connection. The timeout on the socket is reset to whatever value it had before the call to isValid. Thus, this socket timeout should only influence on the query issued by the isValid code.\n\nThe implementation has been tested by setting a very low timeout value and introducing a delay in the network server.\n\nsvn status reports:\n\nM      java/client/org/apache/derby/client/net/NetAgent.java\nM      java/client/org/apache/derby/client/net/NetConnection40.java\n\nI have run the JDBC4 tests and derbyall with the patch. Only failure was in tools/derbyrunjartest.java.\n\nThe patch can be reviewed and committed.\nLooks solid. JDBC4 tests run cleanly. So does derbyall modulo the wisconsin noise. Committed at subversion revision 397899.\nThis patch (brokeredlogical1090.diff) implemets support for Connection.isValid for pooled and XA connections. \n\nTesting of isValid for pooled and XA connections is implemented in the jdbc4/ConnectionTest.junit. This test is currently not part of either the jdbc4 suite or derbyall. \n\nsvn status reports:\n\nM      java/engine/org/apache/derby/iapi/jdbc/BrokeredConnection40.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/ConnectionTest.java\nM      java/client/org/apache/derby/client/am/LogicalConnection40.java\n\nI have run the jdbc4/ConnectionTest.junig, the JDBC4 test suite and derbyall with the patch. Only failure was in tools/derbyrunjartest.java. \n\nThe patch can be reviewed and committed.\nThe brokeredlogical1090.diff patch looks solid. JDBC4 tests pass. Derbyall passes modulo expected diffs in wisconsin and SuicideOfStreaming. Committed at subversion revision 406101.\n", "issueSearchSentences": ["The Javadoc for JDBC4 says this about Connection.isValid:", "Thus, if the server does not respond within the specified timeout period the blocking read will return with an exception.", "is open (by calling isClosed()) and by running a simple query (\"VALUES (1)\") against the database.", "isValid with a specified timeout", "isValid with a specified timeout"], "issueSearchIndexes": [2, 143, 50, 57, 93]}
{"aId": 56, "code": "public static void setContextClassLoaderIfPrivileged(Thread t, ClassLoader cl) {\n        try {\n            setContextClassLoader(t,cl);\n        } catch (SecurityException se) {\n            // ignore security exception.  Earlier versions of Derby, before the \n            // DERBY-3745 fix did not require setContextClassloader permissions.\n            // We may leak class loaders if we are not able to set this, but \n            // cannot just fail.\n        }\n    }", "comment": " Set the thread's context class loader if privileged. If not ignore security exception and continue.", "issueId": "DERBY-3745", "issueStringList": ["Derby can leak classloaders in an app server environment", "A user reported potential class loader leaks in Derby", "...The first one looks like Derby created a long-running", "thread and copying the context class loader.", "To fix, the", "context class loader should be saved/set/restored around the", "creation of the new thread so that it copies some benign class", "loader instead (e.g., null or getClass().getClassLoader()):", "0x42278e58 java/lang/Thread@302e302e", "[truncating at running thread LEAK]", "Object:  0x42278e58 java/lang/Thread@302e302e", "Children:", "0x42278ee0 java/lang/String@303f303f", "0x4226e558 java/lang/ThreadGroup@6f2e6f2e", "0x42278e40", "org/apache/derby/impl/services/monitor/AntiGC@603a603a", "0x419cfac0", "The second is another long running thread.", "The same applies:", "0x426fe7a0 java/lang/Thread@19901990", "[truncating at running thread LEAK]", "Object:  0x426fe7a0 java/lang/Thread@19901990", "Parents:", "0x4226e5a8 [Ljava/lang/Thread;@6f386f38", "0x426fe548", "org/apache/derby/iapi/services/context/ContextManager@19421942", "Children:", "0x426fe838 java/lang/String@19a319a3", "0x4226e558 java/lang/ThreadGroup@6f2e6f2e", "0x426fe4f8", "org/apache/derby/impl/services/daemon/BasicDaemon@19381938", "0x419cfac0", "The third is a TimerThread owneed , which is created when a", "Timer is created.", "The same applies:", "0x425ac538 java/util/Timer$TimerImpl@6b8a6b8a", "[truncating at running thread LEAK]", "Object:  0x425ac538 java/util/Timer$TimerImpl@6b8a6b8a", "Parents:", "0x41faaf58 [Ljava/lang/Thread;@3c583c58", "Object:  0x425ac510 java/util/Timer@6b856b85", "Parents:", "0x425ac500", "org/apache/derby/impl/services/timer/SingletonTimerFactory@56e25", "6e2", "For more info, see thread at:", "http://www.nabble.com/ClassLoader-leaks--td18121374.html", "One problem with setting the contextClasssLoader for the new threads is that we don't document that setContextClassLoader permission is required for derby.jar, so trying it I get java.security.AccessControlException: access denied (java.lang.RuntimePermission setContextClassLoader) using the default testing policy file.", "The only thing I can think of to do to fix this is to", "1) Document that derby.jar requires getContextClassLoader/setContextClasssLoader privileges.", "2) Change the code to attempt to set the context class loader to null for these threads if we have permissions and ignore security exceptions if we are not able to.", "(Leave the potential for class loader leaks)", "3) Change sample, test and default policy files to have these privileges.", "Thoughts?", "Kathey", "Attached is a patch for this issue for the 10.3 branch.", "This takes care of the leak for 10.3, but the same change on trunk still shows a leak related to com/ibm/lang/management/MemoryNotificationThread", "There must be some additional change related to jmx that is necessary.", "I  would like to go ahead and check in this change to get a fix for 10.3 and track down the trunk issue separately.", "I wasn't sure how to add a test for this, so didn't.", "I verified manually using the IBM Heap analyzer and the test program supplied by the user.", "I am running regresssion tests now.", "regression tests passed.", "I don't know enough about class loading issues to tell whether or not the approach is OK. A couple of questions, though:", "Is it Derby's responsibility to set the context class loader for every thread that it spawns, or should the application rather set the context class loader to the appropriate value (null?)", "when loading the Derby driver?", "It sounds to me like Derby behaves as expected by using the current context class loader, and I don't know if changing it could cause problems in other scenarios.", "Does Derby prevent the class loader from being garbage collected after the driver has been unloaded?", "If not, I would think it was the application's responsibility to unload the driver when it wants all resources to be freed.", "Other than that, the patch looks fine to me.", "Some nits:", "You may want to use spaces instead of tabs in SingletonTimerFactory, since that's what's used in the rest of the file.", "Some of the @param tags in PrivilegedThreadOps are empty.", "SecurityException is a RuntimeException, so the PrivilegedThreadOps should use PrivilegedAction instead of PrivilegedExceptionAction (if the code in the catch block is ever executed, the cast to SecurityException is guaranteed to fail since PrivilegedActionExceptions only wrap checked exceptions).", "Typo in javadoc for setCCLIfPrivileged: priveleged --> privileged", "Thanks Knut Anders for reviewing the patch.", "Here is a patch updated with Knut's comments.", "I asked the user that filed this case and suggested the fix to comment on the  questions.", "My understanding of the class loader issues is somewhat limited so I myself am not that comfortable with the fix.", "Perhaps Dan could take a look too.", "The reporting user is out this week.", "I will let this patch sit until he returns or we get answers to Knut's questions.", "If code is creating a background Thread for its own purposes, then it needs to ensure that it does not hold on to an application class loader.", "This is true for any code intended to run in an application server environment.", "If the driver is unloaded, then Derby did seem to properly stop threads in the testcase I looked at.", "However, in an application server environment, the Derby driver cannot be unloaded when a single application is stopped since there can be many applications running that all depend on Derby.", "Thanks for the new patch!", "If I have understood correctly what a context class loader is, I don't think the patch should do any harm (none of Derby's daemon threads should ever use the context class loader, should they?).", "I just had a feeling that we might have been trying to fix the problem the wrong place, but I think you're right that the impact of the fix should be limited, so I'm fine with it.", "If it is the case that some of Derby's threads are not stopped when the driver is unloaded, that should be treated as a bug, and a separate JIRA issue should be filed for it to get it fixed.", "(Two tiny nits: (a) one line in one of the comment in SingletonTimerFactory is indented with space+tab+space, and (b) trailing white-space has been added after the end-of-method brace in the same file)", "Here is a patch for the trunk and I will port the same change to 10.4.", "It is the same as the 10.3 patch except for the change to JMXManagementService.java to save/set/restore the context class loader around ManagementFactory.getPlatformMBeanServer() which launches a thread, at least on IBM JVM's.", "I will follow up on trunk only with the doc change and template/default policy file change.", "It looks like the indentation is wrong in JMXManagementService.findServer()."], "SplitGT": [" Set the thread's context class loader if privileged.", "If not ignore security exception and continue."], "issueString": "Derby can leak classloaders in an app server environment\nA user reported potential class loader leaks in Derby\n\n...The first one looks like Derby created a long-running\nthread and copying the context class loader.  To fix, the\ncontext class loader should be saved/set/restored around the\ncreation of the new thread so that it copies some benign class\nloader instead (e.g., null or getClass().getClassLoader()):\n\n 0x42278e58 java/lang/Thread@302e302e\n  [truncating at running thread LEAK]\n\nObject:  0x42278e58 java/lang/Thread@302e302e\nChildren:\n 0x42278ee0 java/lang/String@303f303f\n 0x4226e558 java/lang/ThreadGroup@6f2e6f2e\n 0x42278e40\norg/apache/derby/impl/services/monitor/AntiGC@603a603a\n 0x419cfac0\n\nThe second is another long running thread.  The same applies:\n\n 0x426fe7a0 java/lang/Thread@19901990\n  [truncating at running thread LEAK]\n\nObject:  0x426fe7a0 java/lang/Thread@19901990\nParents:\n 0x4226e5a8 [Ljava/lang/Thread;@6f386f38\n 0x426fe548\norg/apache/derby/iapi/services/context/ContextManager@19421942\nChildren:\n 0x426fe838 java/lang/String@19a319a3\n 0x4226e558 java/lang/ThreadGroup@6f2e6f2e\n 0x426fe4f8\norg/apache/derby/impl/services/daemon/BasicDaemon@19381938\n 0x419cfac0\n\nThe third is a TimerThread owneed , which is created when a\nTimer is created.  The same applies:\n\n 0x425ac538 java/util/Timer$TimerImpl@6b8a6b8a\n  [truncating at running thread LEAK]\n\nObject:  0x425ac538 java/util/Timer$TimerImpl@6b8a6b8a\nParents:\n 0x41faaf58 [Ljava/lang/Thread;@3c583c58\n\nObject:  0x425ac510 java/util/Timer@6b856b85\nParents:\n 0x425ac500\norg/apache/derby/impl/services/timer/SingletonTimerFactory@56e25\n6e2\n\nFor more info, see thread at:\nhttp://www.nabble.com/ClassLoader-leaks--td18121374.html\n\nOne problem with setting the contextClasssLoader for the new threads is that we don't document that setContextClassLoader permission is required for derby.jar, so trying it I get java.security.AccessControlException: access denied (java.lang.RuntimePermission setContextClassLoader) using the default testing policy file.\n\n\nThe only thing I can think of to do to fix this is to \n1) Document that derby.jar requires getContextClassLoader/setContextClasssLoader privileges.\n2) Change the code to attempt to set the context class loader to null for these threads if we have permissions and ignore security exceptions if we are not able to. (Leave the potential for class loader leaks)\n3) Change sample, test and default policy files to have these privileges.\n\nThoughts?\n\nKathey\n\nAttached is a patch for this issue for the 10.3 branch.  This takes care of the leak for 10.3, but the same change on trunk still shows a leak related to com/ibm/lang/management/MemoryNotificationThread\nThere must be some additional change related to jmx that is necessary.  I  would like to go ahead and check in this change to get a fix for 10.3 and track down the trunk issue separately.\n\nI wasn't sure how to add a test for this, so didn't.  I verified manually using the IBM Heap analyzer and the test program supplied by the user.\n\nI am running regresssion tests now.\n\nregression tests passed.\nI don't know enough about class loading issues to tell whether or not the approach is OK. A couple of questions, though:\n\n  - Is it Derby's responsibility to set the context class loader for every thread that it spawns, or should the application rather set the context class loader to the appropriate value (null?) when loading the Derby driver? It sounds to me like Derby behaves as expected by using the current context class loader, and I don't know if changing it could cause problems in other scenarios.\n\n  - Does Derby prevent the class loader from being garbage collected after the driver has been unloaded? If not, I would think it was the application's responsibility to unload the driver when it wants all resources to be freed.\n\nOther than that, the patch looks fine to me. Some nits:\n- You may want to use spaces instead of tabs in SingletonTimerFactory, since that's what's used in the rest of the file.\n- Some of the @param tags in PrivilegedThreadOps are empty.\n- SecurityException is a RuntimeException, so the PrivilegedThreadOps should use PrivilegedAction instead of PrivilegedExceptionAction (if the code in the catch block is ever executed, the cast to SecurityException is guaranteed to fail since PrivilegedActionExceptions only wrap checked exceptions).\n- Typo in javadoc for setCCLIfPrivileged: priveleged --> privileged\nThanks Knut Anders for reviewing the patch.\nHere is a patch updated with Knut's comments.  I asked the user that filed this case and suggested the fix to comment on the  questions. My understanding of the class loader issues is somewhat limited so I myself am not that comfortable with the fix.  Perhaps Dan could take a look too.\n\n\nThe reporting user is out this week.  I will let this patch sit until he returns or we get answers to Knut's questions.\n\nIf code is creating a background Thread for its own purposes, then it needs to ensure that it does not hold on to an application class loader.  This is true for any code intended to run in an application server environment.\n\nIf the driver is unloaded, then Derby did seem to properly stop threads in the testcase I looked at.  However, in an application server environment, the Derby driver cannot be unloaded when a single application is stopped since there can be many applications running that all depend on Derby.\nThanks for the new patch! If I have understood correctly what a context class loader is, I don't think the patch should do any harm (none of Derby's daemon threads should ever use the context class loader, should they?). I just had a feeling that we might have been trying to fix the problem the wrong place, but I think you're right that the impact of the fix should be limited, so I'm fine with it.\n\nIf it is the case that some of Derby's threads are not stopped when the driver is unloaded, that should be treated as a bug, and a separate JIRA issue should be filed for it to get it fixed.\n\n(Two tiny nits: (a) one line in one of the comment in SingletonTimerFactory is indented with space+tab+space, and (b) trailing white-space has been added after the end-of-method brace in the same file)\nHere is a patch for the trunk and I will port the same change to 10.4. It is the same as the 10.3 patch except for the change to JMXManagementService.java to save/set/restore the context class loader around ManagementFactory.getPlatformMBeanServer() which launches a thread, at least on IBM JVM's.\n\nI will follow up on trunk only with the doc change and template/default policy file change.\n\nIt looks like the indentation is wrong in JMXManagementService.findServer().\n", "issueSearchSentences": ["1) Document that derby.jar requires getContextClassLoader/setContextClasssLoader privileges.", "http://www.nabble.com/ClassLoader-leaks--td18121374.html", "If I have understood correctly what a context class loader is, I don't think the patch should do any harm (none of Derby's daemon threads should ever use the context class loader, should they?).", "Some of the @param tags in PrivilegedThreadOps are empty.", "thread and copying the context class loader."], "issueSearchIndexes": [50, 47, 88, 73, 4]}
{"aId": 63, "code": "public void write(int b) throws IOException {\n        writer.write(b & 0xff);\n    }", "comment": " The byte to be written is the eight low-order bits of the argument b. The 24 high-order bits of b are ignored.", "issueId": "DERBY-2618", "issueStringList": ["EmbedClob.setAsciiStream does not handle non-ascii characters correctly", "If non-ascii characters are written to the Writer returned by EmbedClob.setAsciiStream, Derby fails with a 'java.io.UTFDataFormatException' when the CLOB value is read back.", "I'm filing this bug with 'Major' priority, as the bug does not manifest itself when entering data, just when you try to get it back.", "Except from filtering the data yourself before entering it, I don't think there is any workaround.", "Sample stack trace from a modified test:", "1) testClobAsciiWrite1ParamKRISTIWAA(org.apache.derbyTesting.functionTests.tests.jdbcapi.LobStreamsTest)java.sql.SQLException: Unable to set stream: 'java.io.UTFDataFormatException'.", "at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(SQLExceptionFactory40.java:95)", "at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Util.java:88)", "at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Util.java:94)", "at org.apache.derby.impl.jdbc.Util.setStreamFailure(Util.java:246)", "at org.apache.derby.impl.jdbc.EmbedClob.length(EmbedClob.java:190)", "at org.apache.derby.impl.jdbc.EmbedPreparedStatement.setClob(EmbedPreparedStatement.java:1441)", "at org.apache.derbyTesting.functionTests.tests.jdbcapi.LobStreamsTest.testClobAsciiWrite1ParamKRISTIWAA(LobStreamsTest.java:255)", "at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)", "at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)", "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)", "at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:88)", "Caused by: java.sql.SQLException: Unable to set stream: 'java.io.UTFDataFormatException'.", "at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(SQLExceptionFactory.java:45)", "at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(SQLExceptionFactory40.java:135)", "at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(SQLExceptionFactory40.java:70)", "... 22 more", "I'm a little confused, how can non-ASCII characters be written to the OutputStream (not Writer) returned by setAsciiStream?", "JDBC defines ASCII values as 0-255, see appendix C2 JDBC 4", "\"CHAR(code) Character with ASCII code value code, where code is between 0 and 255\"", "Is there a repro that shows which ascii code values cause the problem?", "Seems there are more than one kind of bug in this area.", "From the users perspective, you can write any int to the clob ascii stream, since it is a OutputStream and has the method write(int).", "I see errors happening in two places; some when calling write, some when calling read when reading the value back.", "Would be nice if anyone could try the repro and confirm my findings, or let me know if I have been using the JDBC API incorrectly.", "Note that the repro must be run with Java SE 6 because it uses Connection.createClob().", "I have not looked at this in detail, but I think the stream used to write to the Clob must do some filtering on the value.", "This is typically ANDing with 0xff and/or replacing the incoming int with the Unicode marker for unknown character (\\uFFFD).", "Then the question is, which values are considered \"non-ASCII\"?", "According to JDBC, an ASCII value is between 0 and 255, inclusive.", "Represented as byte, you will get negative values for a part of this range.", "I assume ISO-8859-1 is the encoding standard to be used, and further that these values will be mapped directly into Unicode.", "Say the Tamil letter with Unicode value '\\u0B88' is written to the stream returned by Clob.setAsciiStream(1) with OutputStream.write(int).", "Should we do \"if i > 255 write '\\uFFFD'\", or should we ignore the higher bits and say this is value 136 (this is mentioned in the comment for ClobAsciiStream), which happens to be an unused code in ISO-8859-1?", "When/if the unknown character code is stored internally (\\uFFFD), it must be converted to '?'", "if it is read back using getAsciiStream (returns an InputStream).", "The default behavior for OutputStream.write(int), is to cast the int to char and then call the abstract method write(char[],int,int).", "No matter what the answers to the questions above are, Derby should not fail with a UTFDataFormatException when reading data you have already been allowed to insert.", "I'm on thin ice for how to correctly handle these issues, and I'm sure there are more, so please correct me and add additional information.", "Forgot to say that I also believe a subset of the issues mentioned above is also valid for the other write-methods.", "It should also be noted that there is a stack of streams, and I do now know at which level the real bug is present.", "Unassigning myself, as I won't have time to work with this issue immediately.", "> The default behavior for OutputStream.write(int), is to cast the int to char and then call the abstract method write(char[],int,int).", "That's incorrect, the defined behaviour for OutputStream.write(int) is (jdk 6 javadoc):", "\"The byte to be written is the eight low-order bits of the argument b.", "The 24 high-order bits of b are ignored.\"", "Thus when using setAsciiStream() there are no no-ASCII characters, since each write call only handles values as bytes (0-255).", "I agree Derby should not fail with a UTFDataFormatException when using setAsciiStream() but it should not treat any characters as invalid,", "all values passed into the write() calls are valid.", "Looks like ClobAsciiStream is not fulfiling the contract of OutputStream.", "For write(int) it juts passes the int value onto the writer.", "I think the write(byte) may also have the same issue, and is implemented inefficiently.", "It creates a char[] for every call,", "it should create a char[] once and re-use it.", "Partial patch which does:", "Make ClobAsciiStream obey the contract for write(int) by ignoring the high bytes of an integer.", "Optimize ClobAsciiStream.write(byte,int,int) by reusing a single array", "remove an out of place break in XXXX", "Even with these changes the repro shows UTF8Exceptions because I think the code that is implementing updating a Clob has problems.", "I thought it might be due to the extra break statement in XXX but I think there are more problems.", "jdbc4._Suite passes and jdbcapi.LobStreamsTest which are the only tests to use Clob.setAsciiStream", "The XXXX should have been ClobStreamControl in the last comment, to read", "remove an out of place break in ClobStreamControl", "Ok - I now see ClobStreamControl.getStreamPosition() is incorrect.", "It is reading UTF8 encoded *bytes* from a CLOB value but performs the checks to see if the encoding is 1,2 or 3 characters incorrectly.", "It treats the first byte read as a unicode character value, rather than an encoded byte.", "Utf8Reader.fillBuffer() or SQLChar.readExternal has correct logic to decode a UTF8 stream.", "Improved patch which attempts to fix ClobStreamControl.getStreamPosition() handling of formatted UTF8 data.", "Still does not fix the problems seen with the repro because ClobStreamControl has various errors with its handling of positions.", "One potential fix was made in ClobStreamControl.getWriter (long pos).", "The old code had:", "long charPos = getStreamPosition (0, pos);", "but getStreamPosition() is defined as returning a *byte* position for a character position, so the name of the variable is confusing.", "Possibly due to this confusion then code then subsequently did:", "new ClobUtf8Writer (this, getStreamPosition (0, charPos))", "thus the *byte* position was converted into a byte position again, which is bound to cause problems.", "The change has renamed the variable to bytePos and passed in directly into new ClobUtf8Writer.", "There are still issues with the code in ClobStreamControl but I'll put those in a different comment.", "ClobStreamControl has issues over its handling of positions, getting confused between byte position, character position, byte length and stream length.", "If anyone knows the code could they supply some guidance?", "ClobUtf8Writer maintains a field pos that is the position of the writer in bytes.", "On its write call it calls ClobStreamControl.insertString() and increments the position by the return from insertString().", "This is where the problem comes:", "ClobUtf8Writer.write() is expecting ClobStreamControl.insertString()  to return the number of (UTF8 encoded) bytes written:", "ClobStreamControl.insertString() javadoc indicates it returns the current position in bytes", "ClobStreamControl.insertString() actually returns the number of *characters* written.", "These three items are inconsistent.", "There is another caller (EmbedClob.setString) of ClobStreamControl.insertString() that does expect it to return the number of characters written, but I think that can be obtained from its parameter 'len'.", "Or is there a situation where less characters would be written?", "Thanks Dan,", "I mixed things up and looked at Writer instead of OutputStream...", "Regarding the problems you have encountered in the lower layers, I'm", "planning to spend some time looking at them as part of DERBY-2346.", "I'm thinking about opening a subtaskto handle this, as there might be a", "series of smaller patches.", "Feel free to provide input there as well.", "Kristian", "Dan, many of the inconsistencies you have found have been commented in DERBY-2346, which is pending a follow-up patch.", "The v2 patch looks correct to me.", "+1 to commit.", "My only minor nit is that I would have preferred \"int clen = Math.min(len, buffer.length);\" to \"int clen = len > buffer.length ?", "buffer.length : len;\" in ClobAsciiStream.write() (I find it a bit clearer, but others may see it differently, so feel free to ignore it).", "I have updated v2 patch with fix in ClobStreamControl.insertString.", "Problem with insertString was that it internally considered the pos argument as byte length where as all the user of this method were send char length.", "I have modified the method and the javadoc to accept pos parameter in char length.", "Cleanup required elswhere to ensure this bug is fixed.", "On patch v3, I assume this now means the position 'pos' in ClobUtf8Writer is now the position in characters, not bytes.", "If this is the case then I can update the comment for that field, which currently states it is in bytes.", "Then again ClobUtf8Writer's constructor is being called with a byte position.", "I think I will commit just the changes related to cleaning up ClobAsciiStream", "and those fixing the handling of the utf8 stream in ClobStreamControl.", "I think the byte/character position cleanup", "needs to be handled separately and consistently.", "Hello Dan,", "Are you planning to do more work on the ClobStreamControl issues at the moment?", "One of the things I would like to investigate, is separating the code for handling LOBs in memory and on disk (reorganizing the code).", "As part of this, I would be able to do a review-pass, and hopefully fix some of the bugs (or make the code clearer).", "However, if you plan to work on this issue as well, we would conflict heavily.", "As a second task, I also considered moving the LOB classes to a separate package, as the number of LOB related classes is starting to get high.", "What do you, or others, think of that?", "I would not do this now anyway.", "Third, the issue around synchronization for LOBs must be reviewed.", "I hope to give this a first shot to as part of the reorg.", "I'm only going to commit derby2618_partial_v4.txt, which is a subset of the v2 patch.", "I agree the cleanup needs to be more extensive, the code is confusing and subject", "to bugs until some clarity is brought to it, especially with respect to byte/char offsets.", "One off fixes for various items, such as the changes in the v2/v3 patch are likely to", "cause more problems, as one method is changed to take a byte/char postion", "but the change isn't followed through the complete code.", "attach with ALv2 grant", "Patch 2618_partial_v4.txt committed - svn 538311"], "SplitGT": [" The byte to be written is the eight low-order bits of the argument b.", "The 24 high-order bits of b are ignored."], "issueString": "EmbedClob.setAsciiStream does not handle non-ascii characters correctly\nIf non-ascii characters are written to the Writer returned by EmbedClob.setAsciiStream, Derby fails with a 'java.io.UTFDataFormatException' when the CLOB value is read back.\n\nI'm filing this bug with 'Major' priority, as the bug does not manifest itself when entering data, just when you try to get it back. Except from filtering the data yourself before entering it, I don't think there is any workaround.\n\nSample stack trace from a modified test:\n\n1) testClobAsciiWrite1ParamKRISTIWAA(org.apache.derbyTesting.functionTests.tests.jdbcapi.LobStreamsTest)java.sql.SQLException: Unable to set stream: 'java.io.UTFDataFormatException'.\n        at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(SQLExceptionFactory40.java:95)\n        at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Util.java:88)\n        at org.apache.derby.impl.jdbc.Util.newEmbedSQLException(Util.java:94)\n        at org.apache.derby.impl.jdbc.Util.setStreamFailure(Util.java:246)\n        at org.apache.derby.impl.jdbc.EmbedClob.length(EmbedClob.java:190)\n        at org.apache.derby.impl.jdbc.EmbedPreparedStatement.setClob(EmbedPreparedStatement.java:1441)\n        at org.apache.derbyTesting.functionTests.tests.jdbcapi.LobStreamsTest.testClobAsciiWrite1ParamKRISTIWAA(LobStreamsTest.java:255)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at org.apache.derbyTesting.junit.BaseTestCase.runBare(BaseTestCase.java:88)\nCaused by: java.sql.SQLException: Unable to set stream: 'java.io.UTFDataFormatException'.\n        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(SQLExceptionFactory.java:45)\n        at org.apache.derby.impl.jdbc.SQLExceptionFactory40.wrapArgsForTransportAcrossDRDA(SQLExceptionFactory40.java:135)\n        at org.apache.derby.impl.jdbc.SQLExceptionFactory40.getSQLException(SQLExceptionFactory40.java:70)\n        ... 22 more\nI'm a little confused, how can non-ASCII characters be written to the OutputStream (not Writer) returned by setAsciiStream?\nJDBC defines ASCII values as 0-255, see appendix C2 JDBC 4\n\n \"CHAR(code) Character with ASCII code value code, where code is between 0 and 255\"\n\nIs there a repro that shows which ascii code values cause the problem?\nSeems there are more than one kind of bug in this area.\nFrom the users perspective, you can write any int to the clob ascii stream, since it is a OutputStream and has the method write(int).\n\nI see errors happening in two places; some when calling write, some when calling read when reading the value back.\nWould be nice if anyone could try the repro and confirm my findings, or let me know if I have been using the JDBC API incorrectly. Note that the repro must be run with Java SE 6 because it uses Connection.createClob().\n\n\nI have not looked at this in detail, but I think the stream used to write to the Clob must do some filtering on the value. \nThis is typically ANDing with 0xff and/or replacing the incoming int with the Unicode marker for unknown character (\\uFFFD).\n\nThen the question is, which values are considered \"non-ASCII\"?\nAccording to JDBC, an ASCII value is between 0 and 255, inclusive. Represented as byte, you will get negative values for a part of this range. I assume ISO-8859-1 is the encoding standard to be used, and further that these values will be mapped directly into Unicode.\n\nSay the Tamil letter with Unicode value '\\u0B88' is written to the stream returned by Clob.setAsciiStream(1) with OutputStream.write(int). Should we do \"if i > 255 write '\\uFFFD'\", or should we ignore the higher bits and say this is value 136 (this is mentioned in the comment for ClobAsciiStream), which happens to be an unused code in ISO-8859-1?\n\nWhen/if the unknown character code is stored internally (\\uFFFD), it must be converted to '?' if it is read back using getAsciiStream (returns an InputStream).\n\nThe default behavior for OutputStream.write(int), is to cast the int to char and then call the abstract method write(char[],int,int).\n\nNo matter what the answers to the questions above are, Derby should not fail with a UTFDataFormatException when reading data you have already been allowed to insert.\n\nI'm on thin ice for how to correctly handle these issues, and I'm sure there are more, so please correct me and add additional information.\nForgot to say that I also believe a subset of the issues mentioned above is also valid for the other write-methods.\nIt should also be noted that there is a stack of streams, and I do now know at which level the real bug is present.\nUnassigning myself, as I won't have time to work with this issue immediately.\n> The default behavior for OutputStream.write(int), is to cast the int to char and then call the abstract method write(char[],int,int). \n\nThat's incorrect, the defined behaviour for OutputStream.write(int) is (jdk 6 javadoc):\n\n   \"The byte to be written is the eight low-order bits of the argument b. The 24 high-order bits of b are ignored.\"\n\nThus when using setAsciiStream() there are no no-ASCII characters, since each write call only handles values as bytes (0-255).\n\nI agree Derby should not fail with a UTFDataFormatException when using setAsciiStream() but it should not treat any characters as invalid,\nall values passed into the write() calls are valid.\nLooks like ClobAsciiStream is not fulfiling the contract of OutputStream.\nFor write(int) it juts passes the int value onto the writer.\nI think the write(byte) may also have the same issue, and is implemented inefficiently. It creates a char[] for every call,\nit should create a char[] once and re-use it.\nPartial patch which does:\n  - Make ClobAsciiStream obey the contract for write(int) by ignoring the high bytes of an integer.\n  - Optimize ClobAsciiStream.write(byte,int,int) by reusing a single array\n\n  - remove an out of place break in XXXX\n\nEven with these changes the repro shows UTF8Exceptions because I think the code that is implementing updating a Clob has problems. I thought it might be due to the extra break statement in XXX but I think there are more problems.\n\njdbc4._Suite passes and jdbcapi.LobStreamsTest which are the only tests to use Clob.setAsciiStream\n\n\nThe XXXX should have been ClobStreamControl in the last comment, to read\n\n  - remove an out of place break in ClobStreamControl \nOk - I now see ClobStreamControl.getStreamPosition() is incorrect. It is reading UTF8 encoded *bytes* from a CLOB value but performs the checks to see if the encoding is 1,2 or 3 characters incorrectly. It treats the first byte read as a unicode character value, rather than an encoded byte.\nUtf8Reader.fillBuffer() or SQLChar.readExternal has correct logic to decode a UTF8 stream.\nImproved patch which attempts to fix ClobStreamControl.getStreamPosition() handling of formatted UTF8 data.\n\nStill does not fix the problems seen with the repro because ClobStreamControl has various errors with its handling of positions.\n\nOne potential fix was made in ClobStreamControl.getWriter (long pos).\n\nThe old code had:\n\n long charPos = getStreamPosition (0, pos);\n\nbut getStreamPosition() is defined as returning a *byte* position for a character position, so the name of the variable is confusing.\n\nPossibly due to this confusion then code then subsequently did:\n\n new ClobUtf8Writer (this, getStreamPosition (0, charPos))\n\nthus the *byte* position was converted into a byte position again, which is bound to cause problems.\n\nThe change has renamed the variable to bytePos and passed in directly into new ClobUtf8Writer.\n\nThere are still issues with the code in ClobStreamControl but I'll put those in a different comment.\nClobStreamControl has issues over its handling of positions, getting confused between byte position, character position, byte length and stream length.\nIf anyone knows the code could they supply some guidance?\n\nClobUtf8Writer maintains a field pos that is the position of the writer in bytes. On its write call it calls ClobStreamControl.insertString() and increments the position by the return from insertString(). This is where the problem comes:\n\n  ClobUtf8Writer.write() is expecting ClobStreamControl.insertString()  to return the number of (UTF8 encoded) bytes written:\n\n  ClobStreamControl.insertString() javadoc indicates it returns the current position in bytes\n\n   ClobStreamControl.insertString() actually returns the number of *characters* written.\n\nThese three items are inconsistent.\n\nThere is another caller (EmbedClob.setString) of ClobStreamControl.insertString() that does expect it to return the number of characters written, but I think that can be obtained from its parameter 'len'. Or is there a situation where less characters would be written?\n\nThanks Dan,\n\nI mixed things up and looked at Writer instead of OutputStream...\n\nRegarding the problems you have encountered in the lower layers, I'm \nplanning to spend some time looking at them as part of DERBY-2346.\nI'm thinking about opening a subtaskto handle this, as there might be a \nseries of smaller patches. Feel free to provide input there as well.\n\n\n\n-- \nKristian\n\n\n\nDan, many of the inconsistencies you have found have been commented in DERBY-2346, which is pending a follow-up patch. The v2 patch looks correct to me. +1 to commit. My only minor nit is that I would have preferred \"int clen = Math.min(len, buffer.length);\" to \"int clen = len > buffer.length ? buffer.length : len;\" in ClobAsciiStream.write() (I find it a bit clearer, but others may see it differently, so feel free to ignore it).\nI have updated v2 patch with fix in ClobStreamControl.insertString.\nProblem with insertString was that it internally considered the pos argument as byte length where as all the user of this method were send char length. I have modified the method and the javadoc to accept pos parameter in char length.\nCleanup required elswhere to ensure this bug is fixed.\nOn patch v3, I assume this now means the position 'pos' in ClobUtf8Writer is now the position in characters, not bytes.\nIf this is the case then I can update the comment for that field, which currently states it is in bytes.\nThen again ClobUtf8Writer's constructor is being called with a byte position.\nI think I will commit just the changes related to cleaning up ClobAsciiStream\nand those fixing the handling of the utf8 stream in ClobStreamControl. I think the byte/character position cleanup\nneeds to be handled separately and consistently.\nHello Dan,\n\nAre you planning to do more work on the ClobStreamControl issues at the moment?\nOne of the things I would like to investigate, is separating the code for handling LOBs in memory and on disk (reorganizing the code). As part of this, I would be able to do a review-pass, and hopefully fix some of the bugs (or make the code clearer). However, if you plan to work on this issue as well, we would conflict heavily.\n\nAs a second task, I also considered moving the LOB classes to a separate package, as the number of LOB related classes is starting to get high. What do you, or others, think of that?\nI would not do this now anyway.\n\nThird, the issue around synchronization for LOBs must be reviewed. I hope to give this a first shot to as part of the reorg.\nI'm only going to commit derby2618_partial_v4.txt, which is a subset of the v2 patch.\nI agree the cleanup needs to be more extensive, the code is confusing and subject\nto bugs until some clarity is brought to it, especially with respect to byte/char offsets.\nOne off fixes for various items, such as the changes in the v2/v3 patch are likely to\ncause more problems, as one method is changed to take a byte/char postion\nbut the change isn't followed through the complete code.\nattach with ALv2 grant\nPatch 2618_partial_v4.txt committed - svn 538311\n", "issueSearchSentences": ["Looks like ClobAsciiStream is not fulfiling the contract of OutputStream.", "if it is read back using getAsciiStream (returns an InputStream).", "Unassigning myself, as I won't have time to work with this issue immediately.", "Seems there are more than one kind of bug in this area.", "Make ClobAsciiStream obey the contract for write(int) by ignoring the high bytes of an integer."], "issueSearchIndexes": [55, 41, 47, 27, 61]}
{"aId": 64, "code": "public static int runScript(\n\t\t  Connection conn,\n\t\t  InputStream sqlIn,\n\t\t  String inputEncoding,\n\t\t  OutputStream sqlOut,\n\t\t  String outputEncoding)\n\t\t  throws UnsupportedEncodingException\n  {\n\t  LocalizedOutput lo = \n\t\t  outputEncoding == null ?\n\t\t\t\t  LocalizedResource.getInstance().\n\t\t            getNewOutput(sqlOut)\n\t             :  \n\t\t          LocalizedResource.getInstance().\n                    getNewEncodedOutput(sqlOut, outputEncoding);\n\n\t  Main ijE;\n\t  if (JVMInfo.JDK_ID == JVMInfo.J2SE_13)\n\t  {\n\t\t  ijE = new Main(false);\n\t  }\n\t  else\n\t  {\n\t\t  // temp - allow ij to continue to work under jdk131\n\t\t  // will resolve as part of DEBRY-1609\n\t\t  // jdk13 gets error loading Main14 due to the\n\t\t  // class now being built with the jdk14 target flag.\n\t\t  // ijE = new org.apache.derby.impl.tools.ij.Main14(false);\n\t\t  ijE = new Main(false);\n\t  }\t  \n\t  \n\t  LocalizedInput li = LocalizedResource.getInstance().\n\t            getNewEncodedInput(sqlIn, inputEncoding);\n\t  \n\t  utilMain um = ijE.getutilMain(1, lo);\n\n\t  return um.goScript(conn, li);\n  }", "comment": " Run a SQL script from an InputStream and write the resulting output to the provided PrintStream.", "issueId": "DERBY-1609", "issueStringList": ["Add a runScript method to ij that takes a script as an InputStream and returns the output to a stream.", "Useful for running ij SQL scripts as part of JUnit tests and for applications to use instead of the awkward way to use ij from a program today.", "Run a SQL script from an input stream and write", "the resulting output to the provided OutputStream.", "@param conn Connection to be used as the script's default connection.", "@param sqlIn InputStream for the script.", "@param inputEncoding Encoding of the script.", "@param sqlOut OutputStream for the script's output", "@param outputEncoding Output encoding to use.", "@return Number of SQLExceptions thrown during the execution, -1 if not known.", "@throws UnsupportedEncodingException", "public static int runScript(", "Connection conn,", "InputStream sqlIn,", "String inputEncoding,", "PrintStream sqlOut,", "String outputEncoding)", "throws UnsupportedEncodingException"], "SplitGT": [" Run a SQL script from an InputStream and write the resulting output to the provided PrintStream."], "issueString": "Add a runScript method to ij that takes a script as an InputStream and returns the output to a stream.\nUseful for running ij SQL scripts as part of JUnit tests and for applications to use instead of the awkward way to use ij from a program today.\n\n  /**\n   * Run a SQL script from an input stream and write\n   * the resulting output to the provided OutputStream.\n   * \n   * @param conn Connection to be used as the script's default connection. \n   * @param sqlIn InputStream for the script.\n   * @param inputEncoding Encoding of the script.\n   * @param sqlOut OutputStream for the script's output\n   * @param outputEncoding Output encoding to use.\n   * @return Number of SQLExceptions thrown during the execution, -1 if not known.\n   * @throws UnsupportedEncodingException\n   */\n  public static int runScript(\n\t\t  Connection conn,\n\t\t  InputStream sqlIn,\n\t\t  String inputEncoding,\n\t\t  PrintStream sqlOut,\n\t\t  String outputEncoding)\n\t\t  throws UnsupportedEncodingException\n", "issueSearchSentences": ["PrintStream sqlOut,", "InputStream sqlIn,", "@throws UnsupportedEncodingException", "public static int runScript(", "Connection conn,"], "issueSearchIndexes": [16, 14, 11, 12, 13]}
{"aId": 68, "code": "private String  buildPreformattedSqlerrmc(SQLException se) {\n\t\tif (se == null)\n\t\t\treturn \"\";\n\t\t\n\t\tStringBuffer sb = new StringBuffer(); \n\t\t // String buffer to build up message\n\t\tdo {\n\t\t\tsb.append(se.getLocalizedMessage());\n\t\t\tse = se.getNextException();\n\t\t\tif (se != null)\n\t\t\t\tsb.append(SQLERRMC_PREFORMATTED_MESSAGE_DELIMITER + \n\t\t\t\t\t\t\"SQLSTATE: \" + se.getSQLState());\n\t\t} while (se != null);\t\t\t\n\t\treturn sb.toString();\t\t\n\t}", "comment": " Just send the message text localized to the server locale.", "issueId": "DERBY-285", "issueStringList": ["Network Client should not print non-ascii token separators in message when it cannot connect to the server to retrieve the error message", "If Network Client cannot connect to the database to retrieve an error message, it will print only the message tokens, the non-ascii token separators, and derby log location.", "It would be good if at least the message could be formatted to present a better message to the user without the non-ascii characters.", "To reproduce try a database shutdown.", "Because the database is shutdown, the client cannot retrieve the actual message from the server.", "It therefore just prints the tokens.", "Start network server", "java org.apache.derby.drda.NetworkServerControl start", "$ java org.apache.derby.tools.ij", "ij version 10.1", "ij> connect 'jdbc:derby://localhost:1527/wombat;create=true';", "ij> connect 'jdbc:derby://localhost:1527/wombat;shutdown=true';", "ERROR 08006: DERBY SQL error: SQLCODE: -1, SQLSTATE: 08006, SQLERRMC: wombat[]08006.D[]Database 'wombat' shutdown.", "[](server log:derby.log)", "ij>", "Note: The actual offending characters have been replaced in the output in this bug by [].", "This is because they break Jira XML retrieval!", "The offending characters appear for severe error messages where the client cannot call the server to retrieve the message text.", "So my planned solution is to not send message arguments in the sqlerrmc for severe messages, but rather send the full message text localized according the the server locale.", "This will make the error messages more readable and eliminate the offending characters."], "SplitGT": [" Just send the message text localized to the server locale."], "issueString": "Network Client should not print non-ascii token separators in message when it cannot connect to the server to retrieve the error message\nIf Network Client cannot connect to the database to retrieve an error message, it will print only the message tokens, the non-ascii token separators, and derby log location.  It would be good if at least the message could be formatted to present a better message to the user without the non-ascii characters.\n\n\nTo reproduce try a database shutdown.  Because the database is shutdown, the client cannot retrieve the actual message from the server. It therefore just prints the tokens.\n\nStart network server\n\njava org.apache.derby.drda.NetworkServerControl start\n\n$ java org.apache.derby.tools.ij\nij version 10.1\nij> connect 'jdbc:derby://localhost:1527/wombat;create=true';\nij> connect 'jdbc:derby://localhost:1527/wombat;shutdown=true';\nERROR 08006: DERBY SQL error: SQLCODE: -1, SQLSTATE: 08006, SQLERRMC: wombat[]08006.D[]Database 'wombat' shutdown.[](server log:derby.log)\nij>\n\nNote: The actual offending characters have been replaced in the output in this bug by []. This is because they break Jira XML retrieval!\nThe offending characters appear for severe error messages where the client cannot call the server to retrieve the message text. \n\nSo my planned solution is to not send message arguments in the sqlerrmc for severe messages, but rather send the full message text localized according the the server locale.  This will make the error messages more readable and eliminate the offending characters.\n\n", "issueSearchSentences": ["Network Client should not print non-ascii token separators in message when it cannot connect to the server to retrieve the error message", "If Network Client cannot connect to the database to retrieve an error message, it will print only the message tokens, the non-ascii token separators, and derby log location.", "private String  buildPreformattedSqlerrmc(SQLException se) {\n\t\tif (se == null)\n\t\t\treturn \"\";\n\t\t\n\t\tStringBuffer sb = new StringBuffer(); \n\t\t // String buffer to build up message\n\t\tdo {\n\t\t\tsb.append(se.getLocalizedMessage());\n\t\t\tse = se.getNextException();\n\t\t\tif (se != null)\n\t\t\t\tsb.append(SQLERRMC_PREFORMATTED_MESSAGE_DELIMITER + \n\t\t\t\t\t\t\"SQLSTATE: \" + se.getSQLState());\n\t\t} while (se != null);\t\t\t\n\t\treturn sb.toString();\t\t\n\t}", "The offending characters appear for severe error messages where the client cannot call the server to retrieve the message text.", "It would be good if at least the message could be formatted to present a better message to the user without the non-ascii characters."], "issueSearchIndexes": [1, 2, 0, 18, 3]}
{"aId": 69, "code": "public static long skipUntilEOF(InputStream is) throws IOException {\n        if(is == null)\n            throw new NullPointerException();\n\n        long bytes = 0;\n        while(true){\n            long r = skipPersistent(is, SKIP_FRAGMENT_SIZE);\n            bytes += r;\n            if(r < SKIP_FRAGMENT_SIZE)\n                return bytes;\n        }\n    }", "comment": " Skips until EOF, returns number of bytes skipped.", "issueId": "DERBY-3770", "issueStringList": ["Create a utility class for skipping data in an InputStream", "The contract of InputStream.skip is somewhat difficult, some would even say broken.", "See http://java.sun.com/javase/6/docs/api/java/io/InputStream.html#skip(long))", "A utility class should be created to ensure that we use the same skip procedure throughout the Derby code base.", "Suggested functionality:", "long skipFully(InputStream) : skips until EOF, returns number of bytes skipped", "void skipFully(InputStream,long) : skips requested number of bytes, throws EOFException if there is too few bytes in the stream", "I know of two different approaches, both skipping in a loop:", "a) Verify EOF with a read call when skip returns zero.", "b) Throw EOFException if skip returns zero before requested number of bytes have been skipped.", "There's related code in iapi.util.UTF8Util.", "Maybe this class, say StreamUtil, could be put in the same package?", "Hi, Kristian.", "Please check the patch, thanks!", "Junjie, I will look at the patch soon but if you get a chance, can you put a brief description of the logic of the patch in this jira entry?", "Junjie, the patch is commented pretty well and the code changes for those comments look good.", "One comment for the engine code change", "1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes).", "Should we put NullPointerException() also in the javadoc?", "Just couple comments for the new junit test", "1)testNullStream has 2 test cases to check for null inputstream.", "For some reason, if no NullPointerException is thrown, then we have following to catch it", "fail(\"Null InputStream is refused!", "\");", "The error message looks misleading.", "Should it be saying something like", "fail(\"Null InputStream is accepted!", "\");", "2)The 2 tests in testNullStream only check for NullPointerException.", "Shouldn't we be catching other exceptions and make the test fail for those exceptions.", "3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre.", "Thanks for working on this jira entry.", "Thanks for your attention, Mamta.", "I have receive your comments just now.", "Sorry to reply late.", "<<Junjie, the patch is commented pretty well and the code changes for those comments look good.", "<<One comment for the engine code change", "<<1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes).", "Should we put NullPointerException() also in the javadoc?", "I have add the declaration for NullException.", "<<Just couple comments for the new junit test", "<<1)testNullStream has 2 test cases to check for null inputstream.", "For some reason, if no NullPointerException is thrown, then we have following to catch it", "<<fail(\"Null InputStream is refused!", "\");", "<<The error message looks misleading.", "Should it be saying something like", "<<fail(\"Null InputStream is accepted!", "\");", "I have correct it.", "<<2)The 2 tests in testNullStream only check for NullPointerException.", "Shouldn't we be catching other exceptions and make the test fail for those exceptions.", "I'm not clear about this.", "What other exceptions should be tested int testNullStream()?", "For EOFException, I have tested it in testSkipFully().", "As to IOException, excluding EOFException, I don't know how to create or simulate it.", "Could you give me more advices?", "<<3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre.", "testSkipUtilEOFWithOddLength() only tests EOF with special length, I think it's better to seperate it from common length.", "Is the name of the method not clear?", "Is testSkipUtilEOFWithSpecialLength() better?", "<<Thanks for working on this jira entry.", "Mamta, please give more suggestion to improve the patch.", "Thanks again!", "Regards", "Junjie", "Junjie, sorry for not getting back to you sooner.", "What I meant bu comment 2) for the tests is something along following line.", "In most of the JDBC junit tests in Derby, if say executing a specific query is only allowed to send a specific exception, then we assert that using following (s below is java.sql.Statement)", "assertStatementError(\"42Y55\", s, \"CALL SYSCS_UTIL.SYSCS_UPDATE_STATISTICS('APP','T1',null)\");", "So, if the query above throws any exception other than \"42Y55\" then that will cause the junit test to fail saying that it expected 42Y55 but it got something else.", "I was wonderinf in the test in question here, if there was anyway of catching exceptions other than NPE", "+        try{", "+            StreamUtil.skipFully(null);", "+            fail(\"Null InputStream is accepted!", "\");", "+        }catch (NullPointerException e) {", "+            assertTrue(true);", "+        }", "I guess, if the test case above did get an exception other than NPE, we will just get out of the test fixture with that exception.", "I was curious if there was some more graceful way of catching unexpected exceptions like we do for jave.sql.Statement with assertStatementError.", "This is not a biggie and feel free to not address this issue if there is no simple way of doing what assertStatementError does.", "Mamta, thanks for your adivice.", "I have contemplated your comment , I think the test is OK in this situation.", "The NPE is checked first when calling the skipFully() method, so no other kind of exception will be thrown.", "What's your opinion?", "As to the \"more graceful way of catching unexpected exceptions\", above all, thanks for your advice, it helps me understand the test framework better.", "However, I haven't found known tools to realize it, so I would leave it as it's now.", "Regards", "Junjie", "The handling of unexpected exceptions looks fine to me.", "Since they are not caught explicitly, they will propagate out to the JUnit framework and be reported correctly there.", "It may be slightly clearer, though, if we replace assertTrue(true) with just a comment like this:", "catch (NullPointerException npe) {", "ignoring expected exception", "}", "The StreamUtil class imports sun.tools.tree.NullExpression, which seems wrong.", "Also, the javadoc comments in that class say \"@throws NullExpression\", whereas they should have said \"@throws NullPointerException\".", "It's probably also a good idea to move the code from UTF8Util.skipPersistent() into the StreamUtil class, since that method doesn't have anything to do with UTF-8 and therefore making it non-private in the UTF8Util class may cause some confusion.", "Hi, Knut.", "Thanks for your advice.", "1.)", "---test framework.", "I agree with your method to add comment \"      // ignoring expected exception \".", "However, as what I used is just like Andrew suggested in his <Pragmatic Unit Testing>, I think it can work well.", "2.)", "---wrong import.", "I have corrected in the new patch.", "3.)", "---move the code from UTF8Util.skipPersistent() into the StreamUtil class.", "It's a good suggestion, I have adopted it.", "Please check the patch!", "Regards", "Junjie", "Thanks, Junjie!", "The patch looks good to me.", "I'll run some tests and commit the patch if there are no problems.", "Committed revision 688049.", "Some questions/comments about    skipFully(InputStream is)", "What is the purpose of this method, when would it be used?", "Skipping until EOF seems a useless operation.", "SKIP_BUFFER_SIZE is a somewhat confusing name since no buffer is ever allocated.", "skipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent().", "Other input stream utility methods are in org.apache.derby.iapi.services.io, any reason to have this new class in a different package?", "Good points, Dan.", "As to the purpose of the method that skips until EOF, that's the approach we use to find the length of a resettable stream: move to EOF, count the bytes on the way, and reset the stream.", "Probably clearer to name the method skipUntilEOF instead of skipFully, though.", "I didn't notice before now, but the class iapi.io.InputStreamUtil contains a method skipBytes(InputStream,long) that looks identical to iapi.util.StreamUtil.skipFully(InputStream,long).", "Probably better to add more methods to that class, I agree.", "Minor point on the skipPersistent method, it has the following code:", "long skippedNow = in.skip(bytesToSkip - skipped);", "if (skippedNow <= 0)", "but skippedNow can never be negative so to be clearer the code should be", "long skippedNow = in.skip(bytesToSkip - skipped);", "if (skippedNow  == 0)", "Hi, Mamta and Daniel.", "Thanks for your advices.", "I have done some improvement.", "1.)", "Delete StreamUtil, move the methods to InputStreamUtil, and move the test class to suitable place.", "2.)", "Rename SKIP_BUFFER_SIZE to SKIP_FRAGMENT_SIZE to keep clear.", "3.)", "Use \"        if (skippedNow == 0)\"  in skipPersistent().", "4.)", "About skipByte(InputStream,long):", "Skip a number of bytes in the stream.", "Note that this version takes and returns", "a long instead of the int used by skipBytes.", "@exception IOException if an I/O error occurs.", "@exception EOFException if the end of the stream is reached", "@see DataInput#skipBytes", "public static long skipBytes(InputStream in, long n) throws IOException {", "while (n > 0) {", "System.out.println(\" skip n = \" + n);", "long delta = in.skip(n);", "System.out.println(\" skipped = \" + delta);", "if (delta < 0)", "throw new EOFException();", "n -= delta;", "}", "return n;", "}", "This method doesn't work well.", "First, for \"long delta = in.skip(n); \", delat won't to be negative, so we can not judge EOFException with \"if (delta < 0)\".", "The method skipPersistent() is fittest to judge EOF has arrived.", "So, I deleted skipBytes(), and replace it with skipFully() where skipBytes() is used.", "5.)", "Daniel said \"skipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent(). \"", "Howeve, skipPersistent() is useful to skipFully(), it can guarante that requested num of bytes will be skipped most probably.", "If we use the common skip() method, we can not judge enough bytes has been skipped fully even having not EOFEception.", "Please check the new patch, thanks!", "Hi, Mamta and Daniel.", "Thanks for your advices.", "I have done some improvement.", "1.)", "Delete StreamUtil, move the methods to InputStreamUtil, and move the test class to suitable place.", "2.)", "Rename SKIP_BUFFER_SIZE to SKIP_FRAGMENT_SIZE to keep clear.", "3.)", "Use \"        if (skippedNow == 0)\"  in skipPersistent().", "4.)", "About skipByte(InputStream,long):", "Skip a number of bytes in the stream.", "Note that this version takes and returns", "a long instead of the int used by skipBytes.", "@exception IOException if an I/O error occurs.", "@exception EOFException if the end of the stream is reached", "@see DataInput#skipBytes", "public static long skipBytes(InputStream in, long n) throws IOException {", "while (n > 0) {", "System.out.println(\" skip n = \" + n);", "long delta = in.skip(n);", "System.out.println(\" skipped = \" + delta);", "if (delta < 0)", "throw new EOFException();", "n -= delta;", "}", "return n;", "}", "This method doesn't work well.", "First, for \"long delta = in.skip(n); \", delat won't to be negative, so we can not judge EOFException with \"if (delta < 0)\".", "The method skipPersistent() is fittest to judge EOF has arrived.", "So, I deleted skipBytes(), and replace it with skipFully() where skipBytes() is used.", "5.)", "Daniel said \"skipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent(). \"", "Howeve, skipPersistent() is useful to skipFully(), it can guarante that requested num of bytes will be skipped most probably.", "If we use the common skip() method, we can not judge enough bytes has been skipped fully even having not EOFEception.", "Please check the new patch, thanks!", "Thanks for the new patch.", "It basically looks good.", "A couple of small issues:", "1) Package and class name in the header of InputStreamUtilTest should be updated.", "2) I think Dan's point with skipFully (now skipUntilEOF) was that you don't necessarily have to call skipPersistent until it returns 0.", "It is OK to stop calling it once it returns less bytes than requested.", "So to reduce the number of times skipPersistent is called, skipUntilEOF could do something like this:", "long bytes = 0;", "while (true) {", "long skipped = skipPersistent(is, SKIP_FRAGMENT_SIZE);", "bytes += skipped;", "if (skipped < SKIP_FRAGMENT_SIZE) {", "return bytes;", "}", "}", "3) I noticed that SKIP_FRAGMENT_SIZE had been lowered from 1024*1024 to 512*1024 in this patch.", "I don't think there's any reason to keep this constant small.", "There shouldn't be any disadvantages with having a higher value, so it might be better to set it to a very high value, for instance Integer.MAX_VALUE.", "HI, Knut.", "I adopted your advice, please check the patch.", "Thanks!", "Thank you!", "The patch looks good to me.", "I have started the regression tests and plan to commit it if there aren't any failures.", "Some small things that we may consider to change after the commit:", "1) Should the test be placed under unitTests/junit instead of functionTests/tests/engine?", "The existing tests under functionTests/tests/engine seems to boot the full Derby engine, whereas the test in the patch only tests a single internal class and probably fits better under unitTests/junit.", "2) In skipUntilEOF, the scope of the local variable r could be narrowed down (it could be declared in the body of the while loop).", "OK, Knut.", "I have adopted your advice.", "Please check it!", "Thanks!", "Committed revision 691253."], "SplitGT": [" Skips until EOF, returns number of bytes skipped."], "issueString": "Create a utility class for skipping data in an InputStream\nThe contract of InputStream.skip is somewhat difficult, some would even say broken.\nSee http://java.sun.com/javase/6/docs/api/java/io/InputStream.html#skip(long))\n\nA utility class should be created to ensure that we use the same skip procedure throughout the Derby code base.\nSuggested functionality:\n - long skipFully(InputStream) : skips until EOF, returns number of bytes skipped\n - void skipFully(InputStream,long) : skips requested number of bytes, throws EOFException if there is too few bytes in the stream\n\nI know of two different approaches, both skipping in a loop:\n a) Verify EOF with a read call when skip returns zero.\n b) Throw EOFException if skip returns zero before requested number of bytes have been skipped.\n\nThere's related code in iapi.util.UTF8Util. Maybe this class, say StreamUtil, could be put in the same package?\nHi, Kristian. Please check the patch, thanks!\nJunjie, I will look at the patch soon but if you get a chance, can you put a brief description of the logic of the patch in this jira entry?\nJunjie, the patch is commented pretty well and the code changes for those comments look good. \nOne comment for the engine code change\n1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes). Should we put NullPointerException() also in the javadoc?\n\nJust couple comments for the new junit test\n1)testNullStream has 2 test cases to check for null inputstream. For some reason, if no NullPointerException is thrown, then we have following to catch it\nfail(\"Null InputStream is refused!\");\nThe error message looks misleading. Should it be saying something like\nfail(\"Null InputStream is accepted!\");\n2)The 2 tests in testNullStream only check for NullPointerException. Shouldn't we be catching other exceptions and make the test fail for those exceptions.\n3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre.\n\nThanks for working on this jira entry.\nThanks for your attention, Mamta. I have receive your comments just now. Sorry to reply late.\n\n<<Junjie, the patch is commented pretty well and the code changes for those comments look good. \n<<One comment for the engine code change \n<<1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes). Should we put NullPointerException() also in the javadoc? \n-----I have add the declaration for NullException.\n\n<<Just couple comments for the new junit test \n<<1)testNullStream has 2 test cases to check for null inputstream. For some reason, if no NullPointerException is thrown, then we have following to catch it \n<<fail(\"Null InputStream is refused!\"); \n<<The error message looks misleading. Should it be saying something like \n<<fail(\"Null InputStream is accepted!\");\n-----I have correct it. \n<<2)The 2 tests in testNullStream only check for NullPointerException. Shouldn't we be catching other exceptions and make the test fail for those exceptions. \n-----I'm not clear about this. What other exceptions should be tested int testNullStream()? For EOFException, I have tested it in testSkipFully(). As to IOException, excluding EOFException, I don't know how to create or simulate it. Could you give me more advices?\n<<3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre. \n-----testSkipUtilEOFWithOddLength() only tests EOF with special length, I think it's better to seperate it from common length. Is the name of the method not clear? Is testSkipUtilEOFWithSpecialLength() better?\n<<Thanks for working on this jira entry. \n\nMamta, please give more suggestion to improve the patch. Thanks again!\n\nRegards\nJunjie\n\nJunjie, sorry for not getting back to you sooner.\n\nWhat I meant bu comment 2) for the tests is something along following line. In most of the JDBC junit tests in Derby, if say executing a specific query is only allowed to send a specific exception, then we assert that using following (s below is java.sql.Statement)\n        assertStatementError(\"42Y55\", s, \"CALL SYSCS_UTIL.SYSCS_UPDATE_STATISTICS('APP','T1',null)\");\nSo, if the query above throws any exception other than \"42Y55\" then that will cause the junit test to fail saying that it expected 42Y55 but it got something else.\n\nI was wonderinf in the test in question here, if there was anyway of catching exceptions other than NPE\n+        try{\n+            StreamUtil.skipFully(null);\n+            fail(\"Null InputStream is accepted!\");\n+        }catch (NullPointerException e) {\n+            assertTrue(true);\n+        }\n\nI guess, if the test case above did get an exception other than NPE, we will just get out of the test fixture with that exception. I was curious if there was some more graceful way of catching unexpected exceptions like we do for jave.sql.Statement with assertStatementError. This is not a biggie and feel free to not address this issue if there is no simple way of doing what assertStatementError does.\nMamta, thanks for your adivice. \n\nI have contemplated your comment , I think the test is OK in this situation. The NPE is checked first when calling the skipFully() method, so no other kind of exception will be thrown. What's your opinion?\n\nAs to the \"more graceful way of catching unexpected exceptions\", above all, thanks for your advice, it helps me understand the test framework better. However, I haven't found known tools to realize it, so I would leave it as it's now.\n\nRegards\nJunjie\nThe handling of unexpected exceptions looks fine to me. Since they are not caught explicitly, they will propagate out to the JUnit framework and be reported correctly there.\n\nIt may be slightly clearer, though, if we replace assertTrue(true) with just a comment like this:\n\n  catch (NullPointerException npe) {\n      // ignoring expected exception\n  }\n\nThe StreamUtil class imports sun.tools.tree.NullExpression, which seems wrong. Also, the javadoc comments in that class say \"@throws NullExpression\", whereas they should have said \"@throws NullPointerException\".\n\nIt's probably also a good idea to move the code from UTF8Util.skipPersistent() into the StreamUtil class, since that method doesn't have anything to do with UTF-8 and therefore making it non-private in the UTF8Util class may cause some confusion.\nHi, Knut. Thanks for your advice.\n\n1.)---test framework. I agree with your method to add comment \"      // ignoring expected exception \". However, as what I used is just like Andrew suggested in his <Pragmatic Unit Testing>, I think it can work well.\n\n2.)---wrong import. I have corrected in the new patch. \n\n3.)---move the code from UTF8Util.skipPersistent() into the StreamUtil class. It's a good suggestion, I have adopted it.\n\nPlease check the patch!\n\nRegards\nJunjie\nThanks, Junjie!\n\nThe patch looks good to me. I'll run some tests and commit the patch if there are no problems.\nCommitted revision 688049.\nSome questions/comments about    skipFully(InputStream is) \n\nWhat is the purpose of this method, when would it be used? Skipping until EOF seems a useless operation.\n\nSKIP_BUFFER_SIZE is a somewhat confusing name since no buffer is ever allocated.\n\nskipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent().\n\nOther input stream utility methods are in org.apache.derby.iapi.services.io, any reason to have this new class in a different package?\nGood points, Dan.\n\nAs to the purpose of the method that skips until EOF, that's the approach we use to find the length of a resettable stream: move to EOF, count the bytes on the way, and reset the stream. Probably clearer to name the method skipUntilEOF instead of skipFully, though.\n\nI didn't notice before now, but the class iapi.io.InputStreamUtil contains a method skipBytes(InputStream,long) that looks identical to iapi.util.StreamUtil.skipFully(InputStream,long). Probably better to add more methods to that class, I agree.\nMinor point on the skipPersistent method, it has the following code:\n\n            long skippedNow = in.skip(bytesToSkip - skipped);\n            if (skippedNow <= 0)\n\nbut skippedNow can never be negative so to be clearer the code should be\n\n            long skippedNow = in.skip(bytesToSkip - skipped);\n            if (skippedNow  == 0)\nHi, Mamta and Daniel. Thanks for your advices.  I have done some improvement.\n\n1.) Delete StreamUtil, move the methods to InputStreamUtil, and move the test class to suitable place.\n\n2.) Rename SKIP_BUFFER_SIZE to SKIP_FRAGMENT_SIZE to keep clear.\n\n3.) Use \"        if (skippedNow == 0)\"  in skipPersistent().\n\n4.) About skipByte(InputStream,long):\n\t/**\n\t\tSkip a number of bytes in the stream. Note that this version takes and returns\n\t\ta long instead of the int used by skipBytes.\n\n\t\t@exception IOException if an I/O error occurs.\n\t\t@exception EOFException if the end of the stream is reached\n\n\t\t@see DataInput#skipBytes\n\t*/\n\tpublic static long skipBytes(InputStream in, long n) throws IOException {\n\n\t\twhile (n > 0) {\n\t\t\t//System.out.println(\" skip n = \" + n);\n\t\t\tlong delta = in.skip(n);\n\t\t\t//System.out.println(\" skipped = \" + delta);\n\t\t\tif (delta < 0)\n\t\t\t\tthrow new EOFException();\n\t\t\tn -= delta;\n\t\t}\n\n\t\treturn n;\n\t}    \n        \nThis method doesn't work well. First, for \"long delta = in.skip(n); \", delat won't to be negative, so we can not judge EOFException with \"if (delta < 0)\". The method skipPersistent() is fittest to judge EOF has arrived.\nSo, I deleted skipBytes(), and replace it with skipFully() where skipBytes() is used.\n\n5.) Daniel said \"skipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent(). \" Howeve, skipPersistent() is useful to skipFully(), it can guarante that requested num of bytes will be skipped most probably. If we use the common skip() method, we can not judge enough bytes has been skipped fully even having not EOFEception.\n\nPlease check the new patch, thanks!\n\n\nHi, Mamta and Daniel. Thanks for your advices.  I have done some improvement.\n\n1.) Delete StreamUtil, move the methods to InputStreamUtil, and move the test class to suitable place.\n\n2.) Rename SKIP_BUFFER_SIZE to SKIP_FRAGMENT_SIZE to keep clear.\n\n3.) Use \"        if (skippedNow == 0)\"  in skipPersistent().\n\n4.) About skipByte(InputStream,long):\n\t/**\n\t\tSkip a number of bytes in the stream. Note that this version takes and returns\n\t\ta long instead of the int used by skipBytes.\n\n\t\t@exception IOException if an I/O error occurs.\n\t\t@exception EOFException if the end of the stream is reached\n\n\t\t@see DataInput#skipBytes\n\t*/\n\tpublic static long skipBytes(InputStream in, long n) throws IOException {\n\n\t\twhile (n > 0) {\n\t\t\t//System.out.println(\" skip n = \" + n);\n\t\t\tlong delta = in.skip(n);\n\t\t\t//System.out.println(\" skipped = \" + delta);\n\t\t\tif (delta < 0)\n\t\t\t\tthrow new EOFException();\n\t\t\tn -= delta;\n\t\t}\n\n\t\treturn n;\n\t}    \n        \nThis method doesn't work well. First, for \"long delta = in.skip(n); \", delat won't to be negative, so we can not judge EOFException with \"if (delta < 0)\". The method skipPersistent() is fittest to judge EOF has arrived.\nSo, I deleted skipBytes(), and replace it with skipFully() where skipBytes() is used.\n\n5.) Daniel said \"skipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent(). \" Howeve, skipPersistent() is useful to skipFully(), it can guarante that requested num of bytes will be skipped most probably. If we use the common skip() method, we can not judge enough bytes has been skipped fully even having not EOFEception.\n\nPlease check the new patch, thanks!\n\n\nThanks for the new patch. It basically looks good. A couple of small issues:\n\n1) Package and class name in the header of InputStreamUtilTest should be updated.\n\n2) I think Dan's point with skipFully (now skipUntilEOF) was that you don't necessarily have to call skipPersistent until it returns 0. It is OK to stop calling it once it returns less bytes than requested. So to reduce the number of times skipPersistent is called, skipUntilEOF could do something like this:\n\nlong bytes = 0;\nwhile (true) {\n    long skipped = skipPersistent(is, SKIP_FRAGMENT_SIZE);\n    bytes += skipped;\n    if (skipped < SKIP_FRAGMENT_SIZE) {\n        return bytes;\n    }\n}\n\n3) I noticed that SKIP_FRAGMENT_SIZE had been lowered from 1024*1024 to 512*1024 in this patch. I don't think there's any reason to keep this constant small. There shouldn't be any disadvantages with having a higher value, so it might be better to set it to a very high value, for instance Integer.MAX_VALUE.\nHI, Knut. I adopted your advice, please check the patch. Thanks!\nThank you!\n\nThe patch looks good to me. I have started the regression tests and plan to commit it if there aren't any failures.\n\nSome small things that we may consider to change after the commit:\n\n  1) Should the test be placed under unitTests/junit instead of functionTests/tests/engine? The existing tests under functionTests/tests/engine seems to boot the full Derby engine, whereas the test in the patch only tests a single internal class and probably fits better under unitTests/junit.\n\n  2) In skipUntilEOF, the scope of the local variable r could be narrowed down (it could be declared in the body of the while loop).\nOK, Knut. I have adopted your advice. Please check it!\nThanks!\nCommitted revision 691253.\n", "issueSearchSentences": ["So to reduce the number of times skipPersistent is called, skipUntilEOF could do something like this:", "while (true) {", "@see DataInput#skipBytes", "@see DataInput#skipBytes", "if (skipped < SKIP_FRAGMENT_SIZE) {"], "issueSearchIndexes": [216, 218, 152, 189, 221]}
{"aId": 73, "code": "private boolean bindParameter( ValueNode arg, int jdbcType) throws StandardException\n    {\n        if( arg.requiresTypeFromContext() && arg.getTypeId() == null)\n        {\n            arg.setType( new DataTypeDescriptor(TypeId.getBuiltInTypeId( jdbcType), true));\n            return true;\n        }\n        return false;\n    }", "comment": " Collation applies only to character string types.", "issueId": "DERBY-2777", "issueStringList": ["Parameters should take their collation from the context in which they are getting used rather than the current compilation schema", "With revision 542646, changes were made so that parameters will take their collation from current compilation schema.", "But based on the following thread http://www.nabble.com/Collation-and-parameter-markers-(-)-tf3866040.html , using the collation from the context would be the correct thing to do for the parameters.", "Fixed the parameters collation type for IN operator with revision 545319.", "Commit comments are as follows", "Fixed the combination of IN operator and parameters so that the parameters take their collation from the context and not from the current compilation schema.", "Fixed the parameters collation type in binary operators with revision 545323.", "Commit comments are as follows", "DERBY-2777", "Fixed the combination of binary operator and parameters so that the parameters take their collation from the context and not from the current compilation schema.", "eg ?", "= TABLENAME", "Fixed the parameters collation type in concatenation operation with revision 545443.", "Commit comments are as follows", "DERBY-2777", "Fixed the combination of CONCATENATION operator and parameters so that the parameters take their collation from the context and not from the current compilation schema.", "eg ?", "|| TABLENAME", "Fixed the parameters collation type in IS [NOT] NULL operation with revision 545593.", "Also fixed the test case for concatenation, Commit comments are as follows", "DERBY-2777", "Fixed the combination of IS NULL and parameters so that the parameters take their collation from the context and not from the current compilation schema.", "Also, the earlier checkin for test case of CONCATENATION was incorrect.", "This commit fixes that too.", "Fixed the parameters collation type in LENGTH operator with revision 545621.", "Commit comments are as follows", "DERBY-2777", "Fixed the combination of LENGTH operator and parameters so that the parameters take their collation from the context and not from the current compilation schema.", "In fact, it appears that LENGTH operator is not allowed to take a parameter and user would get sql exception 42X36 if LENGTH was used with a parameter.", "I have added a test case for that.", "Collation does not apply to parameters to \"+\",\"-\",\"SQRT\", \"ABS/ABSVAL\" because they only take numeric values.", "DERBY-2777", "Unary arithmetic operators \"+\",\"-\",\"SQRT\", \"ABS/ABSVAL\" only take numeric parameters and hence no need to worry about collation information on parameters to these operators.", "Checkin 545639 with following comments", "DERBY-2777", "I realized that there are no negative test case for parameter inside XMLSERIALIZE funciton.", "Adding them as part of this checkin.", "Parameters are not supported inside XMLSERIALIZE and that's what the new test cases are checking.", "No collation involved for parameter inside this function because parameter inside XMLSERIALIZE will fail at compilation time.", "Checkin 545708 with following comments", "DERBY-2777", "Make sure that for operators like BOOLEAN, the collation information is picked from the context and not from the current compilation schema.", "Checkin 545709 with following comments", "DERBY-2777", "Earlier checkins 543266 and 542646 were incorrectly trying to set collation for DATA and TIME DataTypeDescriptors.", "With this checkin, I am removing that code.", "Collation only applies to character string types.", "Checkin 545712 with following comments", "DERBY-2777", "ResultColumn was using current compilation schema's collation if there is a parameter involved.", "Instead, let the parameter pick up it's collation from it's context.", "Checkin 545716 with following comments", "DERBY-2777", "ResultSetNode was using current compilation schema's collation if there is a parameter involved.", "Instead, let the parameter pick up it's collation from it's context.", "Checkin 545950 with following comments", "DERBY-2777", "MethodCallNode was using current compilation schema's collation if there is a parameter involved.", "Instead, let the parameter pick up it's collation from it's context.", "Checkin 546002 with following comments", "DERBY-2777", "SetOperatorNode was using current compilation schema's collation if there is a parameter involved.", "Instead, let the parameter pick up it's collation from it's context.", "Checkin 546007 with following comments", "DERBY-2777", "StaticMethodCallNode was using current compilation schema's collation if there is a parameter involved.", "Instead, let the parameter pick up it's collation from it's context.", "Checkin 546023 with following comments", "DERBY-2777", "CastllNode was using current compilation schema's collation if there is a parameter involved.", "Instead, let the parameter pick up it's collation from it's context.", "All the parameter code has been checked in with various commits listed earlier in this Jira entry's various comments.", "Collation pickup logic for parameters in LIKE node is incomplete.", "I will soon make a checkin to fix that problem.", "Fixed the parameter collation setting for LIKE clause in both main (revision 553557) and 10.3.1.1 (revision 553560).", "The commit comments are as follows and it explains the fix", "DERBY-2777", "Currently, the parameters in LIKE clause always pickup their collation from the compilation schema.", "That logic is not", "complete.", "I am fixing that logic here along with addition of some tests.", "For the sake of explanation, let me use the following syntax for LIKE clause", "receiver LIKE leftOperand ESCAPE rightOperand", "With the fix in this patch, if receiver is a parameter, it will set it's collation using following logic", "1)check if leftOperand is not a parameter.", "If yes, then receiver will pick up collation from leftOperand.", "If not, goto step 2", "2)check if rightOperand is not a parameter.", "If yes, then receiver will pick up collation from rightOperand.", "If not, goto step 3", "3)receiver picks up the collation of the compilation schema because everything in the LIKE clause is ?", "Next, if leftOperand is a parameter, it will set it's collation using receiver.", "By this time, even if receiver is a", "parameter, we have set correct collation for receiver and hence leftOperand can simply rely on receiver for correct", "collation IF leftOperand is a parameter.", "Next, if rightOperand is a parameter, it will set it's collation using receiver.", "By this time, even if receiver is a", "parameter, we have set correct collation for receiver and hence rightOperand can simply rely on receiver for correct", "collation IF rightOperand is a parameter.", "reopen, it is causing the following trouble in the tinderbox:", "org.apache.derbyTesting.functionTests.suites.All fail *************************************************************", "1) testDefaultCollation(org.apache.derbyTesting.functionTests.tests.lang.CollationTest2)junit.framework.AssertionFailedError: Column value mismatch @ column '1', row 1:", "2) testPolishCollation(org.apache.derbyTesting.functionTests.tests.lang.CollationTest2)junit.framework.AssertionFailedError: Column value mismatch @ column '1', row 1:", "3) testNorwayCollation(org.apache.derbyTesting.functionTests.tests.lang.CollationTest2)junit.framework.AssertionFailedError: Column value mismatch @ column '1', row 1:", "4) testEnglishCollation(org.apache.derbyTesting.functionTests.tests.lang.CollationTest2)junit.framework.AssertionFailedError: Column value mismatch @ column '1', row 1:", "5) testDefaultJVMTerritoryCollation(org.apache.derbyTesting.functionTests.tests.lang.CollationTest2)junit.framework.AssertionFailedError: Column value mismatch @ column '1', row 1:", "Checked in a fix for the CollaitonTest2 failure.", "The changes went in main(revision 553703) and 10.3.1.1(revision 553704) and commit comments are as follows", "A trivial change to CollationTest2 test.", "Rather than relying on the number of rows in SYSCOLUMNS for the test validity,", "I am changing it so that no rows get selected from the LIKE test.", "This is so that over the time, if we end up changing", "the SYSCOLUMNS so that it will have more rows than what we have in the codeline today, we won't have to go and fix the", "test.", "I think I have found one last piece of code where the ?", "is not picking up the correct collation and that node is TernaryOperatorNode.", "Very soon, I will check in a fix for TRIM and then I will check other functions implemented in that code.", "Checked in fix for TRIM and parameters in main (revision 553727) and 10.3.1.1 codeline (revision 553731).", "The checkin comment for main was as follows", "DERBY-2777", "Currently, the parameters in TRIM clause always pickup their collation from the compilation schema.", "That logic is not", "complete.", "I am fixing that logic here along with addition of some tests.", "For the sake of explanation, let me use the following syntax for TRIM clause", "TRIM (leftOperand FROM receiver)", "With the fix in this patch, if receiver is a parameter, it will set it's collation using following logic", "1)check if leftOperand is not a parameter.", "If yes, then receiver will pick up collation from leftOperand.", "If not, goto step 2", "2)receiver picks up the collation of the compilation schema because everything in the TRIM clause is ?", "Next, if leftOperand is a parameter, it will set it's collation using receiver.", "By this time, even if receiver is a", "parameter, we have set correct collation for receiver and hence leftOperand can simply rely on receiver for correct", "collation IF leftOperand is a parameter.", "Made a simple checkin for TernaryOperatorNode into main (checkin 553735) and 10.3.1.1 codeline(checkin 553736).", "Commit comments were as follows", "DERBY-2777", "TernaryOperatorNode was incorrectly setting up collation for non-character string type.", "Collation only applies to character", "string types.", "Also, fixed a comment to be more meaningful.", "With revisions 553784 for main and revision 553787 for 10.3.1.1 codeline, fixed the LOCATE parameter problem.", "The commit comments for main were as follows", "DERBY-2777", "Currently, the parameters in LOCATE clause always pickup their collation from the compilation schema.", "That logic is not", "complete.", "I am fixing that logic here along with addition of some tests.", "For the sake of explanation, let me use the following syntax for LOCATE clause", "LOCATE (receiver, leftOperand)", "With the fix in this patch, if receiver is a parameter, it will set it's collation using following logic", "1)check if leftOperand is not a parameter.", "If yes, then receiver will pick up collation from leftOperand.", "If not, goto step 2", "2)receiver picks up the collation of the compilation schema because everything in the LOCATE clause is ?", "Next, if leftOperand is a parameter, it will set it's collation using receiver.", "By this time, even if receiver is a", "parameter, we have set correct collation for receiver and hence leftOperand can simply rely on receiver for correct", "collation IF leftOperand is a parameter.", "Checked in comment changes for SUBSTR with revision 553788 for main and 553789 for 10.3.1.1 codeline.", "The commit comments are as follows", "DERBY-2777", "No changes required for SUBSTR because SUBSTR has only one character string operand and hence if that character string", "operand is a parameter, it's context for collation will be the current compilation schema.", "Last checkin for parameter work in TernaryOperatorNode.", "The change went as revision 553794 in 10.3.1.1 and as revision 553793 in main.", "Commit comments", "DERBY-2777", "We were incorrectly trying to set collation info on non-character string types.", "This commit will remove that code.", "No more parameter work needed in TernaryOperatorNode"], "SplitGT": [" Collation applies only to character string types."], "issueString": "Parameters should take their collation from the context in which they are getting used rather than the current compilation schema\nWith revision 542646, changes were made so that parameters will take their collation from current compilation schema. But based on the following thread http://www.nabble.com/Collation-and-parameter-markers-(-)-tf3866040.html , using the collation from the context would be the correct thing to do for the parameters.\nFixed the parameters collation type for IN operator with revision 545319. Commit comments are as follows\n\nFixed the combination of IN operator and parameters so that the parameters take their collation from the context and not from the current compilation schema.\nFixed the parameters collation type in binary operators with revision 545323. Commit comments are as follows\n\nDERBY-2777\nFixed the combination of binary operator and parameters so that the parameters take their collation from the context and not from the current compilation schema. eg ? = TABLENAME\nFixed the parameters collation type in concatenation operation with revision 545443. Commit comments are as follows \n\nDERBY-2777 \nFixed the combination of CONCATENATION operator and parameters so that the parameters take their collation from the context and not from the current compilation schema. eg ? || TABLENAME \n\nFixed the parameters collation type in IS [NOT] NULL operation with revision 545593. Also fixed the test case for concatenation, Commit comments are as follows \n\nDERBY-2777\nFixed the combination of IS NULL and parameters so that the parameters take their collation from the context and not from the current compilation schema. Also, the earlier checkin for test case of CONCATENATION was incorrect. This commit fixes that too.\nFixed the parameters collation type in LENGTH operator with revision 545621. Commit comments are as follows \n\nDERBY-2777\nFixed the combination of LENGTH operator and parameters so that the parameters take their collation from the context and not from the current compilation schema. In fact, it appears that LENGTH operator is not allowed to take a parameter and user would get sql exception 42X36 if LENGTH was used with a parameter. I have added a test case for that.\nCollation does not apply to parameters to \"+\",\"-\",\"SQRT\", \"ABS/ABSVAL\" because they only take numeric values.\n\nDERBY-2777\nUnary arithmetic operators \"+\",\"-\",\"SQRT\", \"ABS/ABSVAL\" only take numeric parameters and hence no need to worry about collation information on parameters to these operators.\nCheckin 545639 with following comments\n\nDERBY-2777\nI realized that there are no negative test case for parameter inside XMLSERIALIZE funciton. Adding them as part of this checkin. Parameters are not supported inside XMLSERIALIZE and that's what the new test cases are checking. No collation involved for parameter inside this function because parameter inside XMLSERIALIZE will fail at compilation time.\nCheckin 545708 with following comments\n\nDERBY-2777\nMake sure that for operators like BOOLEAN, the collation information is picked from the context and not from the current compilation schema.\n\nCheckin 545709 with following comments\n\nDERBY-2777\nEarlier checkins 543266 and 542646 were incorrectly trying to set collation for DATA and TIME DataTypeDescriptors. With this checkin, I am removing that code. Collation only applies to character string types. \n\nCheckin 545712 with following comments\n\nDERBY-2777\nResultColumn was using current compilation schema's collation if there is a parameter involved. Instead, let the parameter pick up it's collation from it's context.\n\nCheckin 545716 with following comments \n\nDERBY-2777\nResultSetNode was using current compilation schema's collation if there is a parameter involved. Instead, let the parameter pick up it's collation from it's context.\n\n\nCheckin 545950 with following comments \n\nDERBY-2777\nMethodCallNode was using current compilation schema's collation if there is a parameter involved. Instead, let the parameter pick up it's collation from it's context.\nCheckin 546002 with following comments \n\nDERBY-2777\nSetOperatorNode was using current compilation schema's collation if there is a parameter involved. Instead, let the parameter pick up it's collation from it's context.\nCheckin 546007 with following comments \n\nDERBY-2777 \nStaticMethodCallNode was using current compilation schema's collation if there is a parameter involved. Instead, let the parameter pick up it's collation from it's context. \n\nCheckin 546023 with following comments \n\nDERBY-2777 \nCastllNode was using current compilation schema's collation if there is a parameter involved. Instead, let the parameter pick up it's collation from it's context. \nAll the parameter code has been checked in with various commits listed earlier in this Jira entry's various comments.\nCollation pickup logic for parameters in LIKE node is incomplete. I will soon make a checkin to fix that problem.\nFixed the parameter collation setting for LIKE clause in both main (revision 553557) and 10.3.1.1 (revision 553560). The commit comments are as follows and it explains the fix\n\nDERBY-2777\n\nCurrently, the parameters in LIKE clause always pickup their collation from the compilation schema. That logic is not \ncomplete. I am fixing that logic here along with addition of some tests.\n\nFor the sake of explanation, let me use the following syntax for LIKE clause\nreceiver LIKE leftOperand ESCAPE rightOperand\nWith the fix in this patch, if receiver is a parameter, it will set it's collation using following logic\n1)check if leftOperand is not a parameter. If yes, then receiver will pick up collation from leftOperand. If not, goto step 2\n2)check if rightOperand is not a parameter. If yes, then receiver will pick up collation from rightOperand. If not, goto step 3\n3)receiver picks up the collation of the compilation schema because everything in the LIKE clause is ?\n\nNext, if leftOperand is a parameter, it will set it's collation using receiver. By this time, even if receiver is a\nparameter, we have set correct collation for receiver and hence leftOperand can simply rely on receiver for correct\ncollation IF leftOperand is a parameter.\n\nNext, if rightOperand is a parameter, it will set it's collation using receiver. By this time, even if receiver is a\nparameter, we have set correct collation for receiver and hence rightOperand can simply rely on receiver for correct\ncollation IF rightOperand is a parameter.\n\nreopen, it is causing the following trouble in the tinderbox:\norg.apache.derbyTesting.functionTests.suites.All fail *************************************************************\n1) testDefaultCollation(org.apache.derbyTesting.functionTests.tests.lang.CollationTest2)junit.framework.AssertionFailedError: Column value mismatch @ column '1', row 1:\n2) testPolishCollation(org.apache.derbyTesting.functionTests.tests.lang.CollationTest2)junit.framework.AssertionFailedError: Column value mismatch @ column '1', row 1:\n3) testNorwayCollation(org.apache.derbyTesting.functionTests.tests.lang.CollationTest2)junit.framework.AssertionFailedError: Column value mismatch @ column '1', row 1:\n4) testEnglishCollation(org.apache.derbyTesting.functionTests.tests.lang.CollationTest2)junit.framework.AssertionFailedError: Column value mismatch @ column '1', row 1:\n5) testDefaultJVMTerritoryCollation(org.apache.derbyTesting.functionTests.tests.lang.CollationTest2)junit.framework.AssertionFailedError: Column value mismatch @ column '1', row 1:\n\n\nChecked in a fix for the CollaitonTest2 failure. The changes went in main(revision 553703) and 10.3.1.1(revision 553704) and commit comments are as follows\n\nA trivial change to CollationTest2 test. Rather than relying on the number of rows in SYSCOLUMNS for the test validity,\nI am changing it so that no rows get selected from the LIKE test. This is so that over the time, if we end up changing\nthe SYSCOLUMNS so that it will have more rows than what we have in the codeline today, we won't have to go and fix the\ntest.\n\nI think I have found one last piece of code where the ? is not picking up the correct collation and that node is TernaryOperatorNode. Very soon, I will check in a fix for TRIM and then I will check other functions implemented in that code.\nChecked in fix for TRIM and parameters in main (revision 553727) and 10.3.1.1 codeline (revision 553731). The checkin comment for main was as follows\n\nDERBY-2777\n\nCurrently, the parameters in TRIM clause always pickup their collation from the compilation schema. That logic is not\ncomplete. I am fixing that logic here along with addition of some tests.\n\nFor the sake of explanation, let me use the following syntax for TRIM clause\nTRIM (leftOperand FROM receiver)\nWith the fix in this patch, if receiver is a parameter, it will set it's collation using following logic\n1)check if leftOperand is not a parameter. If yes, then receiver will pick up collation from leftOperand. If not, goto step 2\n2)receiver picks up the collation of the compilation schema because everything in the TRIM clause is ?\n\nNext, if leftOperand is a parameter, it will set it's collation using receiver. By this time, even if receiver is a\nparameter, we have set correct collation for receiver and hence leftOperand can simply rely on receiver for correct\ncollation IF leftOperand is a parameter.\n\nMade a simple checkin for TernaryOperatorNode into main (checkin 553735) and 10.3.1.1 codeline(checkin 553736). Commit comments were as follows\n\nDERBY-2777\n\nTernaryOperatorNode was incorrectly setting up collation for non-character string type. Collation only applies to character\nstring types. Also, fixed a comment to be more meaningful.\n\nWith revisions 553784 for main and revision 553787 for 10.3.1.1 codeline, fixed the LOCATE parameter problem. The commit comments for main were as follows\n\nDERBY-2777\n\nCurrently, the parameters in LOCATE clause always pickup their collation from the compilation schema. That logic is not\ncomplete. I am fixing that logic here along with addition of some tests.\n\nFor the sake of explanation, let me use the following syntax for LOCATE clause\nLOCATE (receiver, leftOperand)\nWith the fix in this patch, if receiver is a parameter, it will set it's collation using following logic\n1)check if leftOperand is not a parameter. If yes, then receiver will pick up collation from leftOperand. If not, goto step 2\n2)receiver picks up the collation of the compilation schema because everything in the LOCATE clause is ?\n\nNext, if leftOperand is a parameter, it will set it's collation using receiver. By this time, even if receiver is a\nparameter, we have set correct collation for receiver and hence leftOperand can simply rely on receiver for correct\ncollation IF leftOperand is a parameter.\n\nChecked in comment changes for SUBSTR with revision 553788 for main and 553789 for 10.3.1.1 codeline. The commit comments are as follows\n\nDERBY-2777\n\nNo changes required for SUBSTR because SUBSTR has only one character string operand and hence if that character string\noperand is a parameter, it's context for collation will be the current compilation schema.\n\nLast checkin for parameter work in TernaryOperatorNode. The change went as revision 553794 in 10.3.1.1 and as revision 553793 in main.\n\nCommit comments\n\nDERBY-2777\n\nWe were incorrectly trying to set collation info on non-character string types. This commit will remove that code.\n\n\nNo more parameter work needed in TernaryOperatorNode\n", "issueSearchSentences": ["|| TABLENAME", "Adding them as part of this checkin.", "DERBY-2777", "DERBY-2777", "parameter, we have set correct collation for receiver and hence leftOperand can simply rely on receiver for correct"], "issueSearchIndexes": [18, 37, 41, 21, 94]}
{"aId": 74, "code": "void addWaiters(Dictionary waiters) {\n        for (Iterator it = locks.values().iterator(); it.hasNext(); ) {\n            Control control = (Control) it.next();\n            control.addWaiters(waiters);\n        }\n    }", "comment": " <br> MT - must be synchronized on this LockSet object.", "issueId": "DERBY-1704", "issueStringList": ["Allow more concurrency in the lock manager", "I have seen indications of severe monitor contention in SinglePool", "(the current lock manager) when multiple threads access a Derby", "database concurrently.", "When a thread wants to lock an object, it needs", "to obtain the monitor for both SinglePool and LockSet (both of them", "are global synchronization points).", "This leads to poor scalability.", "We should investigate how to allow more concurrency in the lock", "manager, and either extend SinglePool or implement a new manager.", "Just to see how the performance would be affected if the global", "synchronization points were eliminated, I split the hash tables in", "SinglePool and LockSet into 16 partitions (that is, 16 hash tables),", "and used the hash key to decide which partition an object should be", "placed in.", "There was no global synchronization, only synchronization", "on the partition.", "I have attached graphs for some performance tests with single-record", "selects (the entire database was in the page cache).", "The graphs show", "the results on a machine with a single CPU (1cpu.png), one with two", "CPUs (2cpu.png) and one with eight CPUs (8cpu.png).", "They indicate that", "there is no significant effect (neither positive nor negative) on the", "single-CPU machine, but with multiple CPUs (and multiple threads) the", "performance increases when the global synchronization points have been", "eliminated.", "(Don't pay too much attention to the actual TPS numbers, since the", "three machines didn't have identical processors.)", "Attaching the patch used to partition the hash tables.", "It is only", "attached for reference, not for inclusion.", "I have not updated or added", "comments, and I have not tried very hard to make the names of", "variables and methods meaningful.", "If someone wants to implement a new", "lock manager based on the ideas in this patch, please feel free to do", "so.", "FWIW, derbyall ran cleanly with the patch.", "While I don't know exactly what indications you've seen", "of the lock contention in the lock manager, we've seen the", "exact same thing in our investigations in our \"SMP", "scalability in Derby\" project.", "(We == me and Per Ottar", "Ribe Pahr).", "Anyway, we used DTrace with a JDK1.6 beta release to", "measure monitor contention in a simple embedded derby", "scenario consisting of 8 threads doing simple \"SELECT A", "FROM FOO WHERE A=?", "; COMMIT;\" loops.", "FOO is a table", "consisting of about 100 000 rows of A, an integer and the", "primary key, and a CHAR(96) FOR BIT DATA filler.", "The dtrace script measured three things: The classes of", "objects whose monitors were most contented - in terms", "of number of contentions and the wait time threads spent", "waiting for their monitors.", "In addition, it took a snapshot of", "the call stack at the point of contention to figure out which", "method the contention occured in.", "Here's our measurements, we hope they're useful, if only", "to confirm that you're onto something.", "=)", "PS: You want a fixed-point font to read this.", "Point your web", "browser at http://folk.ntnu.no/andersmo/monitor_contention.txt", "to get a plain old text file.", "=)", "TOP BLOCKING OBJECTS:", "Monitor class                                        Contention count", "org/apache/derby/impl/services/locks/ActiveLock                   2", "java/lang/ref/ReferenceQueue$Lock                                 2", "org/apache/derby/impl/services/cache/CachedItem                   2", "org/apache/derby/impl/services/reflect/ReflectLoaderJava2         3", "java/io/PrintStream                                               5", "org/apache/derby/impl/store/raw/data/StoredPage                  10", "sun/misc/Launcher$AppClassLoader                                 10", "org/apache/derby/impl/sql/GenericPreparedStatement               10", "org/apache/derby/impl/store/raw/xact/XactFactory                 11", "org/apache/derby/impl/store/raw/xact/TransactionTable            29", "java/util/Hashtable                                              34", "org/apache/derby/impl/store/raw/data/AllocationCache             36", "org/apache/derby/impl/services/cache/Clock                      257", "org/apache/derby/impl/services/locks/SinglePool                 577", "org/apache/derby/impl/services/locks/LockSet                   7851", "TOP BLOCKING OBJECTS BY WAIT TIME:", "Monitor class                                          Wait time (ms)", "java/lang/ref/ReferenceQueue$Lock                                 2", "org/apache/derby/impl/services/locks/ActiveLock                   2", "org/apache/derby/impl/services/cache/CachedItem                   6", "org/apache/derby/impl/store/raw/data/StoredPage                  11", "org/apache/derby/impl/services/reflect/ReflectLoaderJava2        13", "org/apache/derby/impl/store/raw/data/AllocationCache            110", "org/apache/derby/impl/sql/GenericPreparedStatement              120", "org/apache/derby/impl/store/raw/xact/TransactionTable           129", "java/util/Hashtable                                             198", "org/apache/derby/impl/store/raw/xact/XactFactory                350", "sun/misc/Launcher$AppClassLoader                                660", "java/io/PrintStream                                             709", "org/apache/derby/impl/services/cache/Clock                     1380", "org/apache/derby/impl/services/locks/SinglePool                3137", "org/apache/derby/impl/services/locks/LockSet                  16194", "TOP BLOCKING METHOD SIGNATURES:", "org/apache/derby/impl/services/locks/LockSet.lockObject(Ljava/lang/Object;Lorg/apache/derby/iapi/services/locks/Lockable;Ljava/l", "ang/Object;ILorg/apache/derby/iapi/services/locks/Latch;)Lorg/apache/derby/impl/services/locks/Lock;*", "55", "org/apache/derby/impl/services/cache/Clock.find(Ljava/lang/Object;)Lorg/apache/derby/iapi/services/cache/Cacheable;*", "56", "org/apache/derby/impl/services/locks/LockSet.lockObject(Ljava/lang/Object;Lorg/apache/derby/iapi/services/locks/Lockable;Ljava/l", "ang/Object;ILorg/apache/derby/iapi/services/locks/Latch;)Lorg/apache/derby/impl/services/locks/Lock;*", "56", "org/apache/derby/impl/services/cache/Clock.release(Lorg/apache/derby/iapi/services/cache/Cacheable;)V*", "65", "org/apache/derby/impl/services/locks/SinglePool.lockAnObject(Ljava/lang/Object;Ljava/lang/Object;Lorg/apache/derby/iapi/services", "locks/Lockable;Ljava/lang/Object;ILorg/apache/derby/iapi/services/locks/Latch;)Lorg/apache/derby/impl/services/locks/Lock;*", "79", "java/util/Hashtable.get(Ljava/lang/Object;)Ljava/lang/Object;*", "84", "org/apache/derby/impl/services/locks/SinglePool.unlock(Ljava/lang/Object;Ljava/lang/Object;Lorg/apache/derby/iapi/services/locks", "Lockable;Ljava/lang/Object;)I", "85", "org/apache/derby/impl/services/locks/SinglePool.lockObject(Ljava/lang/Object;Ljava/lang/Object;Lorg/apache/derby/iapi/services/l", "ocks/Lockable;Ljava/lang/Object;I)Z", "103", "org/apache/derby/impl/services/locks/LockSpace.unlockGroup(Lorg/apache/derby/impl/services/locks/LockSet;Ljava/lang/Object;)V", "110", "org/apache/derby/impl/services/locks/LockSet.unlock(Lorg/apache/derby/iapi/services/locks/Latch;I)V*", "153", "java/util/Hashtable.get(Ljava/lang/Object;)Ljava/lang/Object;*", "221", "org/apache/derby/impl/services/locks/SinglePool.lockAnObject(Ljava/lang/Object;Ljava/lang/Object;Lorg/apache/derby/iapi/services", "locks/Lockable;Ljava/lang/Object;ILorg/apache/derby/iapi/services/locks/Latch;)Lorg/apache/derby/impl/services/locks/Lock;", "260", "org/apache/derby/impl/services/locks/SinglePool.unlatch(Lorg/apache/derby/iapi/services/locks/Latch;)V", "264", "org/apache/derby/impl/services/locks/SinglePool.unlock(Ljava/lang/Object;Ljava/lang/Object;Lorg/apache/derby/iapi/services/locks", "Lockable;Ljava/lang/Object;)I", "330", "org/apache/derby/impl/services/locks/SinglePool.latchObject(Ljava/lang/Object;Lorg/apache/derby/iapi/services/locks/Lockable;Lja", "va/lang/Object;I)Z", "459", "org/apache/derby/impl/services/locks/LockSet.lockObject(Ljava/lang/Object;Lorg/apache/derby/iapi/services/locks/Lockable;Ljava/l", "ang/Object;ILorg/apache/derby/iapi/services/locks/Latch;)Lorg/apache/derby/impl/services/locks/Lock;*", "559", "org/apache/derby/impl/services/locks/LockSet.unlock(Lorg/apache/derby/iapi/services/locks/Latch;I)V*", "1714", "org/apache/derby/impl/services/locks/LockSet.lockObject(Ljava/lang/Object;Lorg/apache/derby/iapi/services/locks/Lockable;Ljava/l", "ang/Object;ILorg/apache/derby/iapi/services/locks/Latch;)Lorg/apache/derby/impl/services/locks/Lock;*", "2840", "Oh, forgot to mention that the tests were run on a SMP machine - an old Sun Enterprise 450 with 4x400MHz CPUs (and a bit error on bit 12 on memory module 1701 - yay ECC.", ";-).", "The Derby release used was 10.1.3.1 - (417277), the official release from the web page.", "If time permits we'll see about testing Knut Anders' patch with DTrace as well.", "I am planning to partition the hash table in LockSet along the lines", "of the split-hashtables.diff patch.", "For the other hash table on which there is monitor contention (the one", "in SinglePool), I think it is better to remove the hash table", "entirely.", "That hash table maps a compatibility space to a", "LockSpace.", "Since there is a one-to-one mapping between compatibility", "spaces and LockSpaces, we could change it so that each compatibility", "space is a LockSpace object and remove the need for the hash", "table.", "This would (a) remove the contention problem, and (b) save some", "CPU cycles because we don't have to go through the hash table.", "If this sounds OK, I will create two sub-tasks: one for partitioning", "the table in LockSet, and one for removing the table in SinglePool.", "I haven't had time to look at the patch  but the original intention was for there to be a multi-thread lock manager", "using multiple LockSets, e.g.", "a MultiPool implementation instead of a SinglePool implementation.", "Just FYI.", "With the multiple synchronization how is deadlock detection to be handled?", "Thanks.", "Do you think it would be better to leave SinglePool as it is", "and create a new (perhaps optional) MultiPool implementation instead?", "I haven't looked very closely at the deadlock detection code yet, but", "I hope it won't be necessary with too many changes.", "One possibility is", "to obtain the synchronization locks on all partitions before the", "waiters graph is built.", "Of course, some precautions are needed in", "order to avoid java-level deadlocks when are multiple synchronization", "locks possibly obtained in different order.", "Knut Anders", "In the patch I used when running the tests, monitor contention on LockSet was reduced by having multiple hash tables in each LockSet.", "I think it might be cleaner to have multiple LockSets, where each LockSet contains one hash table.", "Will look more into it and report back.", "In the meantime, I plan to submit some cleanup patches that hopefully will make the final patch smaller and easier to understand regardless of which approach is chosen.", "Attached cleanup1.diff.", "I observed that LockSet extends Hashtable, but all calls to Hashtable's methods are already synchronized on the LockSet, so it could just as well use a HashMap.", "The attached patch makes LockSet contain a HashMap instead of extending Hashtable.", "I ran some tests with the DERBY-1961 test client (single-record select on a dual-cpu machine, Solaris 10, Java SE 6) and saw ~2% throughput improvement for a single client and from 15% to 25% improvement for multiple (2-64) clients.", "Derbyall and the JUnit tests passed on Solaris 10/Java SE 6.", "Reviews would be appreciated.", "cleanup1.diff looks good, but I have a couple of questions:", "LockSet has was declared \"public final\", but is now just \"final\".", "Is it intentional?", "In general, I have a hard time understanding the multithreading-related comments used in Derby (not specific to this patch).", "For example, the comment for LockSet says:", "\"MT - Mutable - Container Object : Thread Safe\".", "I really don't understand what that means.", "Is it still true when LockSet no longer inherits from a synchronized container?", "I think what is meant here is that only those methods declared \"synchronized\" are MT-safe.", "A client wanting to use any of the other methods must synchronize on the LockSet object.", "Correct?", "The method addWaiters(Dictionary) is not synchronized, and the comment says \"MT - must be synchronized on this LockSet object\".", "But in Deadock.getWaiters(LockSet) it is called without synchronization.", "Presumably this is ok since the old code iterated using an enumeration over an unlocked LockSet, (unless the lock is higher up the stack, and cannot be seen in the diff).", "But a comment would have been nice :)", "Thank you for looking at the patch!", "I'll try to answer your questions below.", "1) The change of LockSet from \"public final\" to \"final\" was intentional.", "LockSet is an internal implementation class that is not supposed to be accessed from other packages.", "2) I'm not sure what the exact meaning of the MT comment is.", "I would assume that it meant something like \"calls to public (or non-private) methods of this class can be regarded as atomic operations\".", "I'm not sure that this statement is completely true before the patch, but it is definitely not true after the patch, so the comment should be updated.", "3) getWaiters() is a private helper method for Deadlock.look() which is only invoked from inside a synchronized block in LockSet, so getWaiters() is in fact always synchronized on the LockSet.", "This would probably have been clearer if Deadlock.look() had one of those infamous MT comments.", ":) I'll add one.", "I have attached v2 of cleanup1.", "I went through LockSet's methods to determine which of them were not thread safe without extra synchronization and updated their javadoc comments.", "Changes from the first version:", "MT comment for LockSet class changed to \"MT - Mutable - Container Object : All non-private methods of this class are thread safe unless otherwise stated by their javadoc comments.\"", "Added javadoc comments to LockSet.oneMoreWaiter() and LockSet.oneLessWaiter() with information about required synchronization.", "Removed what seems to be a false comment in LockSet.anyoneBlocked() (\"no synchronization needed because reads of ints are atomic\").", "It is true that reads of ints are atomic, but synchronization is still needed to avoid that an old cached value is read instead of the real value.", "Declared LockSet.anyoneBlocked() as synchronized to avoid the problem mentioned above.", "Currently, I don't think it is a problem since all calls to anyoneBlocked() come (indirectly) from the unit tests T_AccessFactory and T_LockFactory, but it would be good to fix it anyway.", "Added javadoc and MT comment to Deadlock.look().", "I have started a new run of derbyall.", "New version looks good.", "+1", "Thanks for the review!", "Committed cleanup1.v2 with revision 498999."], "SplitGT": [" <br> MT - must be synchronized on this LockSet object."], "issueString": "Allow more concurrency in the lock manager\nI have seen indications of severe monitor contention in SinglePool\n(the current lock manager) when multiple threads access a Derby\ndatabase concurrently. When a thread wants to lock an object, it needs\nto obtain the monitor for both SinglePool and LockSet (both of them\nare global synchronization points). This leads to poor scalability.\n\nWe should investigate how to allow more concurrency in the lock\nmanager, and either extend SinglePool or implement a new manager.\nJust to see how the performance would be affected if the global\nsynchronization points were eliminated, I split the hash tables in\nSinglePool and LockSet into 16 partitions (that is, 16 hash tables),\nand used the hash key to decide which partition an object should be\nplaced in. There was no global synchronization, only synchronization\non the partition.\n\nI have attached graphs for some performance tests with single-record\nselects (the entire database was in the page cache). The graphs show\nthe results on a machine with a single CPU (1cpu.png), one with two\nCPUs (2cpu.png) and one with eight CPUs (8cpu.png). They indicate that\nthere is no significant effect (neither positive nor negative) on the\nsingle-CPU machine, but with multiple CPUs (and multiple threads) the\nperformance increases when the global synchronization points have been\neliminated.\n\n(Don't pay too much attention to the actual TPS numbers, since the\nthree machines didn't have identical processors.)\nAttaching the patch used to partition the hash tables. It is only\nattached for reference, not for inclusion. I have not updated or added\ncomments, and I have not tried very hard to make the names of\nvariables and methods meaningful. If someone wants to implement a new\nlock manager based on the ideas in this patch, please feel free to do\nso. FWIW, derbyall ran cleanly with the patch.\nWhile I don't know exactly what indications you've seen \nof the lock contention in the lock manager, we've seen the\nexact same thing in our investigations in our \"SMP \nscalability in Derby\" project. (We == me and Per Ottar \nRibe Pahr).\n\nAnyway, we used DTrace with a JDK1.6 beta release to\nmeasure monitor contention in a simple embedded derby\nscenario consisting of 8 threads doing simple \"SELECT A\nFROM FOO WHERE A=?; COMMIT;\" loops. FOO is a table\nconsisting of about 100 000 rows of A, an integer and the \nprimary key, and a CHAR(96) FOR BIT DATA filler.\n\nThe dtrace script measured three things: The classes of\nobjects whose monitors were most contented - in terms\nof number of contentions and the wait time threads spent\nwaiting for their monitors. In addition, it took a snapshot of\nthe call stack at the point of contention to figure out which\nmethod the contention occured in.\n\nHere's our measurements, we hope they're useful, if only\nto confirm that you're onto something. =)\n\nPS: You want a fixed-point font to read this. Point your web \nbrowser at http://folk.ntnu.no/andersmo/monitor_contention.txt \nto get a plain old text file. =)\n\nTOP BLOCKING OBJECTS:\n\nMonitor class                                        Contention count\n  org/apache/derby/impl/services/locks/ActiveLock                   2\n  java/lang/ref/ReferenceQueue$Lock                                 2\n  org/apache/derby/impl/services/cache/CachedItem                   2\n  org/apache/derby/impl/services/reflect/ReflectLoaderJava2         3\n  java/io/PrintStream                                               5\n  org/apache/derby/impl/store/raw/data/StoredPage                  10\n  sun/misc/Launcher$AppClassLoader                                 10\n  org/apache/derby/impl/sql/GenericPreparedStatement               10\n  org/apache/derby/impl/store/raw/xact/XactFactory                 11\n  org/apache/derby/impl/store/raw/xact/TransactionTable            29\n  java/util/Hashtable                                              34\n  org/apache/derby/impl/store/raw/data/AllocationCache             36\n  org/apache/derby/impl/services/cache/Clock                      257\n  org/apache/derby/impl/services/locks/SinglePool                 577\n  org/apache/derby/impl/services/locks/LockSet                   7851\n\nTOP BLOCKING OBJECTS BY WAIT TIME:\n\nMonitor class                                          Wait time (ms)\n  java/lang/ref/ReferenceQueue$Lock                                 2\n  org/apache/derby/impl/services/locks/ActiveLock                   2\n  org/apache/derby/impl/services/cache/CachedItem                   6\n  org/apache/derby/impl/store/raw/data/StoredPage                  11\n  org/apache/derby/impl/services/reflect/ReflectLoaderJava2        13\n  org/apache/derby/impl/store/raw/data/AllocationCache            110\n  org/apache/derby/impl/sql/GenericPreparedStatement              120\n  org/apache/derby/impl/store/raw/xact/TransactionTable           129\n  java/util/Hashtable                                             198\n  org/apache/derby/impl/store/raw/xact/XactFactory                350\n  sun/misc/Launcher$AppClassLoader                                660\n  java/io/PrintStream                                             709\n  org/apache/derby/impl/services/cache/Clock                     1380\n  org/apache/derby/impl/services/locks/SinglePool                3137\n  org/apache/derby/impl/services/locks/LockSet                  16194\n\nTOP BLOCKING METHOD SIGNATURES:\n\n  org/apache/derby/impl/services/locks/LockSet.lockObject(Ljava/lang/Object;Lorg/apache/derby/iapi/services/locks/Lockable;Ljava/l\nang/Object;ILorg/apache/derby/iapi/services/locks/Latch;)Lorg/apache/derby/impl/services/locks/Lock;*\n               55\n\n  org/apache/derby/impl/services/cache/Clock.find(Ljava/lang/Object;)Lorg/apache/derby/iapi/services/cache/Cacheable;*\n               56\n\n  org/apache/derby/impl/services/locks/LockSet.lockObject(Ljava/lang/Object;Lorg/apache/derby/iapi/services/locks/Lockable;Ljava/l\nang/Object;ILorg/apache/derby/iapi/services/locks/Latch;)Lorg/apache/derby/impl/services/locks/Lock;*\n               56\n\n  org/apache/derby/impl/services/cache/Clock.release(Lorg/apache/derby/iapi/services/cache/Cacheable;)V*\n               65\n\n  org/apache/derby/impl/services/locks/SinglePool.lockAnObject(Ljava/lang/Object;Ljava/lang/Object;Lorg/apache/derby/iapi/services\n/locks/Lockable;Ljava/lang/Object;ILorg/apache/derby/iapi/services/locks/Latch;)Lorg/apache/derby/impl/services/locks/Lock;*\n               79\n\n  java/util/Hashtable.get(Ljava/lang/Object;)Ljava/lang/Object;*\n               84\n\n  org/apache/derby/impl/services/locks/SinglePool.unlock(Ljava/lang/Object;Ljava/lang/Object;Lorg/apache/derby/iapi/services/locks\n/Lockable;Ljava/lang/Object;)I\n               85\n\n  org/apache/derby/impl/services/locks/SinglePool.lockObject(Ljava/lang/Object;Ljava/lang/Object;Lorg/apache/derby/iapi/services/l\nocks/Lockable;Ljava/lang/Object;I)Z\n              103\n\n  org/apache/derby/impl/services/locks/LockSpace.unlockGroup(Lorg/apache/derby/impl/services/locks/LockSet;Ljava/lang/Object;)V\n              110\n\n  org/apache/derby/impl/services/locks/LockSet.unlock(Lorg/apache/derby/iapi/services/locks/Latch;I)V*\n              153\n\n  java/util/Hashtable.get(Ljava/lang/Object;)Ljava/lang/Object;*\n              221\n\n  org/apache/derby/impl/services/locks/SinglePool.lockAnObject(Ljava/lang/Object;Ljava/lang/Object;Lorg/apache/derby/iapi/services\n/locks/Lockable;Ljava/lang/Object;ILorg/apache/derby/iapi/services/locks/Latch;)Lorg/apache/derby/impl/services/locks/Lock;\n              260\n\n  org/apache/derby/impl/services/locks/SinglePool.unlatch(Lorg/apache/derby/iapi/services/locks/Latch;)V\n              264\n\n  org/apache/derby/impl/services/locks/SinglePool.unlock(Ljava/lang/Object;Ljava/lang/Object;Lorg/apache/derby/iapi/services/locks\n/Lockable;Ljava/lang/Object;)I\n              330\n\n  org/apache/derby/impl/services/locks/SinglePool.latchObject(Ljava/lang/Object;Lorg/apache/derby/iapi/services/locks/Lockable;Lja\nva/lang/Object;I)Z\n              459\n\n  org/apache/derby/impl/services/locks/LockSet.lockObject(Ljava/lang/Object;Lorg/apache/derby/iapi/services/locks/Lockable;Ljava/l\nang/Object;ILorg/apache/derby/iapi/services/locks/Latch;)Lorg/apache/derby/impl/services/locks/Lock;*\n              559\n\n  org/apache/derby/impl/services/locks/LockSet.unlock(Lorg/apache/derby/iapi/services/locks/Latch;I)V*\n             1714\n\n  org/apache/derby/impl/services/locks/LockSet.lockObject(Ljava/lang/Object;Lorg/apache/derby/iapi/services/locks/Lockable;Ljava/l\nang/Object;ILorg/apache/derby/iapi/services/locks/Latch;)Lorg/apache/derby/impl/services/locks/Lock;*\n             2840\n\nOh, forgot to mention that the tests were run on a SMP machine - an old Sun Enterprise 450 with 4x400MHz CPUs (and a bit error on bit 12 on memory module 1701 - yay ECC. ;-). The Derby release used was 10.1.3.1 - (417277), the official release from the web page. If time permits we'll see about testing Knut Anders' patch with DTrace as well.\nI am planning to partition the hash table in LockSet along the lines\nof the split-hashtables.diff patch.\n\nFor the other hash table on which there is monitor contention (the one\nin SinglePool), I think it is better to remove the hash table\nentirely. That hash table maps a compatibility space to a\nLockSpace. Since there is a one-to-one mapping between compatibility\nspaces and LockSpaces, we could change it so that each compatibility\nspace is a LockSpace object and remove the need for the hash\ntable. This would (a) remove the contention problem, and (b) save some\nCPU cycles because we don't have to go through the hash table.\n\nIf this sounds OK, I will create two sub-tasks: one for partitioning\nthe table in LockSet, and one for removing the table in SinglePool.\nI haven't had time to look at the patch  but the original intention was for there to be a multi-thread lock manager\nusing multiple LockSets, e.g. a MultiPool implementation instead of a SinglePool implementation. Just FYI.\n\nWith the multiple synchronization how is deadlock detection to be handled?\n\nThanks. Do you think it would be better to leave SinglePool as it is\nand create a new (perhaps optional) MultiPool implementation instead?\n\n\nI haven't looked very closely at the deadlock detection code yet, but\nI hope it won't be necessary with too many changes. One possibility is\nto obtain the synchronization locks on all partitions before the\nwaiters graph is built. Of course, some precautions are needed in\norder to avoid java-level deadlocks when are multiple synchronization\nlocks possibly obtained in different order.\n\n-- \nKnut Anders\n\nIn the patch I used when running the tests, monitor contention on LockSet was reduced by having multiple hash tables in each LockSet. I think it might be cleaner to have multiple LockSets, where each LockSet contains one hash table. Will look more into it and report back. In the meantime, I plan to submit some cleanup patches that hopefully will make the final patch smaller and easier to understand regardless of which approach is chosen.\nAttached cleanup1.diff.\n\nI observed that LockSet extends Hashtable, but all calls to Hashtable's methods are already synchronized on the LockSet, so it could just as well use a HashMap. The attached patch makes LockSet contain a HashMap instead of extending Hashtable. I ran some tests with the DERBY-1961 test client (single-record select on a dual-cpu machine, Solaris 10, Java SE 6) and saw ~2% throughput improvement for a single client and from 15% to 25% improvement for multiple (2-64) clients.\n\nDerbyall and the JUnit tests passed on Solaris 10/Java SE 6. Reviews would be appreciated.\ncleanup1.diff looks good, but I have a couple of questions:\n\nLockSet has was declared \"public final\", but is now just \"final\". Is it intentional?\n\nIn general, I have a hard time understanding the multithreading-related comments used in Derby (not specific to this patch). For example, the comment for LockSet says:\n\"MT - Mutable - Container Object : Thread Safe\". I really don't understand what that means. Is it still true when LockSet no longer inherits from a synchronized container?\n\nI think what is meant here is that only those methods declared \"synchronized\" are MT-safe. A client wanting to use any of the other methods must synchronize on the LockSet object. Correct?\n\nThe method addWaiters(Dictionary) is not synchronized, and the comment says \"MT - must be synchronized on this LockSet object\". But in Deadock.getWaiters(LockSet) it is called without synchronization. Presumably this is ok since the old code iterated using an enumeration over an unlocked LockSet, (unless the lock is higher up the stack, and cannot be seen in the diff). But a comment would have been nice :)\n\n\nThank you for looking at the patch! I'll try to answer your questions below.\n\n1) The change of LockSet from \"public final\" to \"final\" was intentional. LockSet is an internal implementation class that is not supposed to be accessed from other packages.\n\n2) I'm not sure what the exact meaning of the MT comment is. I would assume that it meant something like \"calls to public (or non-private) methods of this class can be regarded as atomic operations\". I'm not sure that this statement is completely true before the patch, but it is definitely not true after the patch, so the comment should be updated.\n\n3) getWaiters() is a private helper method for Deadlock.look() which is only invoked from inside a synchronized block in LockSet, so getWaiters() is in fact always synchronized on the LockSet. This would probably have been clearer if Deadlock.look() had one of those infamous MT comments. :) I'll add one.\nI have attached v2 of cleanup1. I went through LockSet's methods to determine which of them were not thread safe without extra synchronization and updated their javadoc comments. Changes from the first version:\n\n* MT comment for LockSet class changed to \"MT - Mutable - Container Object : All non-private methods of this class are thread safe unless otherwise stated by their javadoc comments.\"\n\n* Added javadoc comments to LockSet.oneMoreWaiter() and LockSet.oneLessWaiter() with information about required synchronization.\n\n* Removed what seems to be a false comment in LockSet.anyoneBlocked() (\"no synchronization needed because reads of ints are atomic\"). It is true that reads of ints are atomic, but synchronization is still needed to avoid that an old cached value is read instead of the real value.\n\n* Declared LockSet.anyoneBlocked() as synchronized to avoid the problem mentioned above. Currently, I don't think it is a problem since all calls to anyoneBlocked() come (indirectly) from the unit tests T_AccessFactory and T_LockFactory, but it would be good to fix it anyway.\n\n* Added javadoc and MT comment to Deadlock.look().\n\nI have started a new run of derbyall.\nNew version looks good. +1\nThanks for the review! Committed cleanup1.v2 with revision 498999.\n", "issueSearchSentences": ["to obtain the synchronization locks on all partitions before the", "Attaching the patch used to partition the hash tables.", "LockSet has was declared \"public final\", but is now just \"final\".", "Thanks.", "Correct?"], "issueSearchIndexes": [180, 30, 197, 174, 206]}
{"aId": 75, "code": "public EngineParameterMetaData getEmbedParameterSetMetaData()\n    \tthrows SQLException\n\t{\n\t  checkExecStatus();\n\t  return new EmbedParameterSetMetaData(\n\t\t\t\tgetParms(), preparedStatement.getParameterTypes());\n\n\t}", "comment": " Immitate the function in JDBC 3.0 Retrieves the number, types and properties of this PreparedStatement object's parameters.", "issueId": "DERBY-1015", "issueStringList": ["Define interface between network server and engine through Java interfaces.", "API between the network server and engine is not well defined, leading to inconsistent & multiple ways of handling the different objects returned, such as reflection, explicit casting etc.", "This in turn has lead to bugs such as DERBY-966 .", "DERBY-1005, and DERBY-1006, and access to underlying objects by the application that should be hidden.", "Define interfaces, such as EngineConnection, that both EmbedConnection and BrokeredConnection implement.", "Thus the network server can rely on the fact that any connection it obtains will implement EngineConnection, and call the required methods through that interface.", "Most likely will need EngineConnection, EnginePreparedStatement and EngineResultSet..", "These interfaces would be internal to derby and not exposed to applications.", "I am proposing the following interface for the EnginePreparedStatement for use in the network server.", "snippet:", "+public interface EnginePreparedStatement extends PreparedStatement {", "+", "+ /**", "+  * Immitate the function in JDBC 3.0", "+  *", "+  * Retrieves the number, types and properties of this PreparedStatement", "+  * object's parameters.", "+  *", "+  * @return a EmbedParameterSetMetaData object that contains information about the", "+  * number, types and properties of this PreparedStatement object's parameters.", "+  * @exception SQLException if a database access error occurs", "+    */", "+    public EmbedParameterSetMetaData getEmbedParameterSetMetaData()", "+    throws SQLException;", "+", "+", "+}", "EmbedPreparedStatement implements EnginePreparedStatement", "BrokeredPreparedStatement implements EnginePreparedStatement", "Thoughts/comments ?", "Thanks.", "I wonder if this new interface should be returning EmbedParameterSetMetaData or should an interface be defined for the parameter meta data?", "Of course once jdk 1.3 stops being supported the returned type could be the regular JDBD class.", "Thanks for the feedbac, Dan.", "Looking at this some more, I think it is better to define a new interface for ParameterMetaData for the following reasons:", "no need to import a impl class in iapi", "this implementation seems clean for use in server.", "So the new interface EnginePreparedStatement will return EngineParameterMetaData instead of EmbedParameterSetMetaData.", "Here are the two interfaces I am proposing:", "NEW INTERFACE: EngineParameterMetaData", "An internal api only, mainly for use in the network server.", "This interface imitates the ParameterMetaData interface from JDBC3.0", "We want to provide the ParameterMetaData functionality to JDKs before JDBC3.0.", "org.apache.derby.iapi.jdbc.EnginePreparedStatement interface returns an object", "of this type on a getEmbedParameterSetMetaData", "Once,JDK1.3 stops being supported, this interface can be removed and", "instead the JDBC 3.0 class ParameterMetaData can be used", "public interface EngineParameterMetaData  {", "public int getParameterCount();", "public int isNullable(int param) throws SQLException;", "public boolean isSigned(int param) throws SQLException;", "public int getPrecision(int param) throws SQLException;", "public int getScale(int param) throws SQLException;", "public int getParameterType(int param) throws SQLException;", "public String getParameterTypeName(int param) throws SQLException;", "public String getParameterClassName(int param) throws SQLException;", "public int getParameterMode(int param) throws SQLException;", "}", "(Note: javadoc comments for the methods will be added in the actual patch)", "EmbedParameterSetMetaData implements EngineParameterMetaData", "NEW INTERFACE: EnginePreparedStatement", "Additional methods the embedded engine exposes on its", "PreparedStatement object implementations.", "An internal api only, mainly", "for the network server.", "Allows consistent interaction between embedded", "PreparedStatement and Brokered PreparedStatements.", "public interface EnginePreparedStatement extends PreparedStatement {", "Immitate the getParameterMetaData() that is in JDBC 3.0", "Once,JDK1.3 stops being supported, instead of returning EngineParameterMetaData", "the JDBC 3.0 Class - ParameterMetaData can be used.", "Retrieves the number, types and properties of this PreparedStatement", "object's parameters.", "@return a EngineParameterMetaData object that contains information about the", "number, types and properties of this PreparedStatement object's parameters.", "@exception SQLException if a database access error occurs", "public EngineParameterMetaData getEmbedParameterSetMetaData()", "throws SQLException;", "}", "EmbedPreparedStatement implements EnginePreparedStatement", "BrokeredPreparedStatement implements EnginePreparedStatement", "Thoughts/comments ?", "Thanks.", "I have been looking at derby1015 in context of fixing derby-1227.", "I am attaching a patch 'derby1015.diff.txt' and corresponding 'derby1015.stat.txt' for feedback.", "This patch is a partial fix for the issues mentioned in derby-1015.", "Partial since, it only defines new interface for the PreparedStatement and ParameterMetaData.", "This patch does the following", "1) Defines two new interfaces for use in network server.", "EnginePreparedStatement - This will be used to get a consistent interaction between the BrokeredPreparedStatement and the EmbedPreparedStatement", "EngineParameterMetaData - This interface is defined for the ParameterMetaData.", "EmbedPreparedStatement implements EnginePreparedStatement", "BrokeredPreparedStatement implements EnginePreparedStatement", "EmbedParameterSetMetaData implements EngineParameterMetaData", "The interface details are as mentioned in the previous comment.", "http://issues.apache.org/jira/browse/DERBY-1015#action_12418344", "2) Code changes to make use of the newly defined interfaces in the network server.", "svn stat:", "M      java\\engine\\org\\apache\\derby\\impl\\jdbc\\EmbedPreparedStatement.java", "M      java\\engine\\org\\apache\\derby\\impl\\jdbc\\EmbedParameterSetMetaData.java", "M      java\\engine\\org\\apache\\derby\\iapi\\jdbc\\BrokeredPreparedStatement.java", "A      java\\engine\\org\\apache\\derby\\iapi\\jdbc\\EngineParameterMetaData.java", "A      java\\engine\\org\\apache\\derby\\iapi\\jdbc\\EnginePreparedStatement.java", "M      java\\drda\\org\\apache\\derby\\impl\\drda\\DRDAStatement.java", "M      java\\drda\\org\\apache\\derby\\impl\\drda\\DRDAConnThread.java", "I ran derbyall on linux/ibm142 and tests ran OK.", "I looked at the code coverage for the code snippet in derby-1227 and I see that our current tests already exercise that codepath.", "Not sure how best to address testing for this patch.", "I'd appreciate suggestions/feedback.", "I tried to run javadoc to verify if all the javadoc comments were ok, but  have not been successful in getting it to work.", "I'll look at my setup again.", "Thanks.", "I am attaching a phase 2 patch ( derby1015.p2.diff.txt, derby1015.p2.stat.txt)  to address adding the new interface for ResultSet.", "This patch derby1015.p2.diff.txt  can be applied independently of the derby1015.diff.txt.", "The changes in this patch include", "add a new interface EngineResultSet  for use in Network Server", "make changes in network server code to make use of this interface instead of EmbedResultSet.", "Ran derbyall on linux/ibm142 OK on linux.", "Can someone please review this patch.", "Thanks.", "Please note, there are two pending patches waiting for review.", "derby1015.diff.txt, derby1015.p2.diff.txt.", "These two patches will cover the case of adding new interfaces for PreparedStatement, ResultSet, ParameterMetaData and make use of these interfaces in the server code.", "Since Dan already added the new interfaces for Statement and Connection., I believe with these two patches(derby1015.diff.txt, derby1015.p2.diff.txt), the cases mentioned in the jira description will be covered.", "As an aside, I did a search for Embed* in drda code and came across cases where the server code uses EmbedSQLException.", "I wonder if the server should be using EmbedSQLException or should a interface be defined for use in the server.", "Comments/Thoughts ?", "Thanks.", "I looked at the patches, and they look quite good, very simple and direct, and creating what I think is a very useful and important abstraction between the network server and the engine.", "I think it would be good to complete the abstraction and not depend directly on any engine classes, including EmbedSQLException, but I would argue that should be a separate JIRA.", "I'll work on getting this committed.", "Since David is further ahead than me here I will defer to him for the commit", "Committed revision 421435.", "Passes derbynetclientmats on JDK 1.5"], "SplitGT": [" Immitate the function in JDBC 3.0 Retrieves the number, types and properties of this PreparedStatement object's parameters."], "issueString": "Define interface between network server and engine through Java interfaces.\nAPI between the network server and engine is not well defined, leading to inconsistent & multiple ways of handling the different objects returned, such as reflection, explicit casting etc. This in turn has lead to bugs such as DERBY-966 . DERBY-1005, and DERBY-1006, and access to underlying objects by the application that should be hidden.\n\nDefine interfaces, such as EngineConnection, that both EmbedConnection and BrokeredConnection implement. Thus the network server can rely on the fact that any connection it obtains will implement EngineConnection, and call the required methods through that interface.\n\nMost likely will need EngineConnection, EnginePreparedStatement and EngineResultSet.. These interfaces would be internal to derby and not exposed to applications.\n\nI am proposing the following interface for the EnginePreparedStatement for use in the network server. \n\nsnippet:\n\n+public interface EnginePreparedStatement extends PreparedStatement {\n+ \n+ /**\n+  * Immitate the function in JDBC 3.0\n+  *\n+  * Retrieves the number, types and properties of this PreparedStatement\n+  * object's parameters.\n+  *\n+  * @return a EmbedParameterSetMetaData object that contains information about the\n+  * number, types and properties of this PreparedStatement object's parameters.\n+  * @exception SQLException if a database access error occurs\n+    */\n+    public EmbedParameterSetMetaData getEmbedParameterSetMetaData()\n+    throws SQLException;\n+    \n+    \n+}\n\nEmbedPreparedStatement implements EnginePreparedStatement\nBrokeredPreparedStatement implements EnginePreparedStatement\n\nThoughts/comments ?   Thanks.\nI wonder if this new interface should be returning EmbedParameterSetMetaData or should an interface be defined for the parameter meta data? Of course once jdk 1.3 stops being supported the returned type could be the regular JDBD class.\nThanks for the feedbac, Dan. \n\nLooking at this some more, I think it is better to define a new interface for ParameterMetaData for the following reasons:\n-- no need to import a impl class in iapi \n-- this implementation seems clean for use in server. \n\nSo the new interface EnginePreparedStatement will return EngineParameterMetaData instead of EmbedParameterSetMetaData.\n\nHere are the two interfaces I am proposing:  \n\nNEW INTERFACE: EngineParameterMetaData\n\n/**\n * An internal api only, mainly for use in the network server. \n * \n * This interface imitates the ParameterMetaData interface from JDBC3.0\n * We want to provide the ParameterMetaData functionality to JDKs before JDBC3.0. \n * org.apache.derby.iapi.jdbc.EnginePreparedStatement interface returns an object \n * of this type on a getEmbedParameterSetMetaData\n * Once,JDK1.3 stops being supported, this interface can be removed and \n * instead the JDBC 3.0 class ParameterMetaData can be used\n */\npublic interface EngineParameterMetaData  {\n    public int getParameterCount();\n    public int isNullable(int param) throws SQLException;\n    public boolean isSigned(int param) throws SQLException;\n    public int getPrecision(int param) throws SQLException;        \n    public int getScale(int param) throws SQLException;\n    public int getParameterType(int param) throws SQLException;\n    public String getParameterTypeName(int param) throws SQLException;\n    public String getParameterClassName(int param) throws SQLException;\n    public int getParameterMode(int param) throws SQLException;\n    }\n\n(Note: javadoc comments for the methods will be added in the actual patch)\n\nEmbedParameterSetMetaData implements EngineParameterMetaData\n\n-----------------------------------------------------------------------------------------------------------------------------------------------\nNEW INTERFACE: EnginePreparedStatement\n\n/**\n * Additional methods the embedded engine exposes on its \n * PreparedStatement object implementations. An internal api only, mainly \n * for the network server. Allows consistent interaction between embedded \n * PreparedStatement and Brokered PreparedStatements.\n * \n */\npublic interface EnginePreparedStatement extends PreparedStatement {\n    \n    /**\n     * Immitate the getParameterMetaData() that is in JDBC 3.0\n     * Once,JDK1.3 stops being supported, instead of returning EngineParameterMetaData\n     * the JDBC 3.0 Class - ParameterMetaData can be used.\n     *\n     * Retrieves the number, types and properties of this PreparedStatement\n     * object's parameters.\n     *\n     * @return a EngineParameterMetaData object that contains information about the\n     * number, types and properties of this PreparedStatement object's parameters.\n     * @exception SQLException if a database access error occurs\n     */\n    public EngineParameterMetaData getEmbedParameterSetMetaData()\n        throws SQLException;\n    \n}\n\nEmbedPreparedStatement implements EnginePreparedStatement\nBrokeredPreparedStatement implements EnginePreparedStatement \n--------------------------------------------------------------------------------------------------------------\nThoughts/comments ? Thanks. \nI have been looking at derby1015 in context of fixing derby-1227. I am attaching a patch 'derby1015.diff.txt' and corresponding 'derby1015.stat.txt' for feedback.\n\n-- This patch is a partial fix for the issues mentioned in derby-1015.  Partial since, it only defines new interface for the PreparedStatement and ParameterMetaData. \n\nThis patch does the following\n\n1) Defines two new interfaces for use in network server. \n\nEnginePreparedStatement - This will be used to get a consistent interaction between the BrokeredPreparedStatement and the EmbedPreparedStatement\nEngineParameterMetaData - This interface is defined for the ParameterMetaData.\n\nEmbedPreparedStatement implements EnginePreparedStatement\nBrokeredPreparedStatement implements EnginePreparedStatement\nEmbedParameterSetMetaData implements EngineParameterMetaData\n\nThe interface details are as mentioned in the previous comment. \nhttp://issues.apache.org/jira/browse/DERBY-1015#action_12418344\n\n\n2) Code changes to make use of the newly defined interfaces in the network server.  \n\nsvn stat:\nM      java\\engine\\org\\apache\\derby\\impl\\jdbc\\EmbedPreparedStatement.java\nM      java\\engine\\org\\apache\\derby\\impl\\jdbc\\EmbedParameterSetMetaData.java\nM      java\\engine\\org\\apache\\derby\\iapi\\jdbc\\BrokeredPreparedStatement.java\nA      java\\engine\\org\\apache\\derby\\iapi\\jdbc\\EngineParameterMetaData.java\nA      java\\engine\\org\\apache\\derby\\iapi\\jdbc\\EnginePreparedStatement.java\nM      java\\drda\\org\\apache\\derby\\impl\\drda\\DRDAStatement.java\nM      java\\drda\\org\\apache\\derby\\impl\\drda\\DRDAConnThread.java\n\n\nI ran derbyall on linux/ibm142 and tests ran OK.\n\nI looked at the code coverage for the code snippet in derby-1227 and I see that our current tests already exercise that codepath.  Not sure how best to address testing for this patch.  I'd appreciate suggestions/feedback.\n\nI tried to run javadoc to verify if all the javadoc comments were ok, but  have not been successful in getting it to work.   I'll look at my setup again.\n\nThanks.\n\n\nI am attaching a phase 2 patch ( derby1015.p2.diff.txt, derby1015.p2.stat.txt)  to address adding the new interface for ResultSet.  \n\nThis patch derby1015.p2.diff.txt  can be applied independently of the derby1015.diff.txt.   \n\nThe changes in this patch include\n-- add a new interface EngineResultSet  for use in Network Server\n--  make changes in network server code to make use of this interface instead of EmbedResultSet.\n\nRan derbyall on linux/ibm142 OK on linux. \n\nCan someone please review this patch.  Thanks. \n\nPlease note, there are two pending patches waiting for review. \nderby1015.diff.txt, derby1015.p2.diff.txt.\n\nThese two patches will cover the case of adding new interfaces for PreparedStatement, ResultSet, ParameterMetaData and make use of these interfaces in the server code. \n\nSince Dan already added the new interfaces for Statement and Connection., I believe with these two patches(derby1015.diff.txt, derby1015.p2.diff.txt), the cases mentioned in the jira description will be covered.   \n\nAs an aside, I did a search for Embed* in drda code and came across cases where the server code uses EmbedSQLException. I wonder if the server should be using EmbedSQLException or should a interface be defined for use in the server.  Comments/Thoughts ?\n\nThanks.\nI looked at the patches, and they look quite good, very simple and direct, and creating what I think is a very useful and important abstraction between the network server and the engine.  \n\nI think it would be good to complete the abstraction and not depend directly on any engine classes, including EmbedSQLException, but I would argue that should be a separate JIRA.\n\nI'll work on getting this committed.\nSince David is further ahead than me here I will defer to him for the commit\nCommitted revision 421435.  Passes derbynetclientmats on JDK 1.5\n", "issueSearchSentences": ["+    */", "@exception SQLException if a database access error occurs", "+    public EmbedParameterSetMetaData getEmbedParameterSetMetaData()", "public EngineParameterMetaData getEmbedParameterSetMetaData()", "this implementation seems clean for use in server."], "issueSearchIndexes": [22, 76, 23, 77, 37]}
{"aId": 78, "code": "private void setColumnListToNotNull(ConstraintDefinitionNode cdn)\n\t{\n\t\tResultColumnList rcl = cdn.getColumnList();\n\t\tint rclSize = rcl.size();\n\t\tfor (int index = 0; index < rclSize; index++)\n\t\t{\n\t\t\tString colName = ((ResultColumn) rcl.elementAt(index)).getName();\n            DataTypeDescriptor dtd = getColumnDataTypeDescriptor(colName);\n            dtd.setNullability(false);\n        }\n\t}", "comment": " Set all columns in that appear in a PRIMARY KEY constraint in a CREATE TABLE statement to NOT NULL.", "issueId": "DERBY-158", "issueStringList": ["PRIMARY KEY does not imply NOT NULL", "PRIMARY KEY does not imply NOT NULL.", "Derby issues error message:", "ij> create table tab (i integer primary key);", "ERROR 42831: 'I' cannot be a column of a primary key or unique key because it can contain null values.", "This is neither compliant with SQL-92 nor with SQL-99 (Feature E141-08, I think).", "Patch to TableElementList that implicitly adds NOT NULL to columns included in a PRIMARY KEY constraint contained in a CREATE TABLE statement.", "However, it does not allow UNIQUE to be added in CREATE TABLE if any of the columns are NULL; similarly UNIQUE or PRIMARY KEY constraints cannot be added with ALTER TABLE if any of the columns are nullable.", "I am posting this first for review as a couple of tests still need to be updated.", "Patch to TableElementList plus test changes.", "If I don't hear anything I'll commit this in a couple of days."], "SplitGT": [" Set all columns in that appear in a PRIMARY KEY constraint in a CREATE TABLE statement to NOT NULL."], "issueString": "PRIMARY KEY does not imply NOT NULL\nPRIMARY KEY does not imply NOT NULL. Derby issues error message:\n\nij> create table tab (i integer primary key);\nERROR 42831: 'I' cannot be a column of a primary key or unique key because it can contain null values.\n\nThis is neither compliant with SQL-92 nor with SQL-99 (Feature E141-08, I think).\n\nPatch to TableElementList that implicitly adds NOT NULL to columns included in a PRIMARY KEY constraint contained in a CREATE TABLE statement. However, it does not allow UNIQUE to be added in CREATE TABLE if any of the columns are NULL; similarly UNIQUE or PRIMARY KEY constraints cannot be added with ALTER TABLE if any of the columns are nullable.\n\nI am posting this first for review as a couple of tests still need to be updated.\nPatch to TableElementList plus test changes.\nIf I don't hear anything I'll commit this in a couple of days.\n", "issueSearchSentences": ["However, it does not allow UNIQUE to be added in CREATE TABLE if any of the columns are NULL; similarly UNIQUE or PRIMARY KEY constraints cannot be added with ALTER TABLE if any of the columns are nullable.", "private void setColumnListToNotNull(ConstraintDefinitionNode cdn)\n\t{\n\t\tResultColumnList rcl = cdn.getColumnList();\n\t\tint rclSize = rcl.size();\n\t\tfor (int index = 0; index < rclSize; index++)\n\t\t{\n\t\t\tString colName = ((ResultColumn) rcl.elementAt(index)).getName();\n            DataTypeDescriptor dtd = getColumnDataTypeDescriptor(colName);\n            dtd.setNullability(false);\n        }\n\t}", "PRIMARY KEY does not imply NOT NULL", "PRIMARY KEY does not imply NOT NULL.", "Derby issues error message:"], "issueSearchIndexes": [8, 0, 1, 2, 3]}
{"aId": 79, "code": "public boolean isValid(int timeout) throws SQLException {\n        // Validate that the timeout has a legal value\n        if (timeout < 0) {\n            throw Util.generateCsSQLException(SQLState.INVALID_API_PARAMETER,\n                                              new Integer(timeout), \"timeout\",\n                                              \"java.sql.Connection.isValid\");\n        }\n\n        // Check if the connection is closed\n        if (isClosed()) {\n            return false;\n        }\n\n        // Do a simple query against the database\n        synchronized(this) {\n            try {\n                // If this is the first time this method is called on this \n                // connection we prepare the query \n                if (isValidStmt == null) {\n                    isValidStmt = prepareStatement(\"VALUES (1)\");\n                }\n\n                // Set the query timeout\n                isValidStmt.setQueryTimeout(timeout);\n\n                // Run the query against the database\n                ResultSet rs = isValidStmt.executeQuery();\n                rs.close();\n            } catch(SQLException e) {\n                // If an SQL exception is thrown the connection is not valid,\n                // we ignore the exception and return false.\n                return false;\n            }\n\t }\n\n        return true;  // The connection is valid\n    }", "comment": " Checks if the connection has not been closed and is still valid. The validity is checked by running a simple query against the database.", "issueId": "DERBY-1090", "issueStringList": ["Implement Connection.isValid as defined by JDBC4", "The Javadoc for JDBC4 says this about Connection.isValid:", "boolean isValid(int timeout) throws SQLException", "Returns true if the connection has not been closed and is still valid.", "The driver shall submit a query on the connection or use some other mechanism that positively verifies the connection is still valid when this method is called.", "The query submitted by the driver to validate the connection shall be executed in the context of the current transaction.", "Parameters: timeout - - The time in seconds to wait for the database operation used to validate the connection to complete.", "If the timeout period expires before the operation completes, this method returns false.", "A value of 0 indicates a timeout is not applied to the database operation.", "Returns: true if the connection is valid, false otherwise", "In case someone else have suggestions or ideas on how to best implement this functionality, here are some high-level initial thoughts on how to implement it:", "to check the validity of the connection, issue a simple query like", "e.g., \"VALUES (1)\"", "to implement the timeout, use the setQueryTimeout() method.", "This will hopefully be sufficient in the embedded version as I expect that for all error situations where the connection no longer is valid, an exception will be thrown when issuing the query.", "For the Derby client we probably need some timeout mechanism in the client code (in addition to setting the query timeout) in order to detect that the server has not responded within before the specified timeout has elapsed.", "I have not studied the network code in details yet to find out if it already has code or hooks for specifying a timeout on the DRDA request to the server.", "Any suggestions on how to best implement this are welcome.", "In embedded would it  be sufficient just to call the isClosed() method?", "Dan, thanks for the suggestion of only using isClosed in the embedded driver.", "I have also wondered if calling isClosed would be sufficient, and actually I have not been able to create a scenario where isClosed returns false followed by simple query that fails.", "The main reasons for including execution of a simple query also in the embedded driver are:", "I do not know the code well enough to be sure that there will not be situations where isClosed returns false and a query returns e.g., a timeout or exception due to some resource constraints, deadlock or other error situations.", "It will make the behavior and implementation more similar between what is done in the embedded and in the client driver.", "I will probably submit a patch for how isValid can be implemented for the Embedded server containing both a check for isClosed and a query.", "If you or other on the list still thinks it is unnecessary to include execution of a query I will remove it.", "The query case actually seems somewhat harder to me, and one needs to understand the code far more, than the isClosed approach.", "Maybe this knowledge needs to exist for the client implementation anyway.", "I think one has to see how many ways the query can fail and", "then see how many map to the connection being not valid.", "I don't believe the query failing, always means the connection is not valid.", "If the query failed due to out of memory error, then the connection is still valid.", "There's no requirement for the embedded and client dirver to have identical implementations, the embedded gains performance", "by having direct access to the engine, something that is clearly not possible with the client.", "This naturally leads to different implementations", "for various methods.", "Thanks for commenting on this, Dan.", "I agree that using a query is more complicated than just checking for isClosed.", "So if checking for isClosed is sufficient to verify that the connection is \"valid\" we should go for that approach in the embedded driver as it is less complex and has better performance.", "Still, I think the purpose of adding the isValid method to the JDBC standard is to positively determine that it is possible to run queries on it.", "I am not convinced that your example of a simple query on the connection failing due to out of memory should still return that the connection is \"valid\"?", "I expect this is a method that will be used together with a connection pool implementation where either the pool or the user will use this for \"ensuring\" the connection is \"valid\" before it is used for something.", "And having a connection that returns out of memory errors on every query is not something that an application would think is a \"useful\" connection to have around (on the other side, creating a new connection does probably not make the situation any better in this case).", "The JavaDoc for isValid (see the test in the Jira issue) strongly indicates that we actually should take the cost of running a query against the database.", "Anyway, I have no strong opinions on whether to just check isClosed or issue a query against the database.", "But since I now happen to have a patch that solves this using a query I will upload this patch tonight.", "Tomorrow moring I will upload a new patch that is only checking for isClosed.", "I do not expect anyone to do a review or commit any of these, but it might trigger some more comments and opinions from other on the list.", "The patch contains one alternative implementation of  Connection.isValid() for the embedded driver by verifying that the connection", "is open (by calling isClosed()) and by running a simple query (\"VALUES (1)\") against the database.", "If the connection is closed or if the query returns any SQL exception, isValid returns false.", "To support the timeout defined as a parameter to isValid, setQueryTimeout is used.", "Testing:", "The patch extends the TestConnectionMethods.java test with test for isValid in the following cases:", "wrong parameter values (negative timeout)", "isValid with no timeout", "isValid with a specified timeout", "isValid on a connection that is closed", "isValid on a \"open connection\" to a database that is shutdown", "I plan to submit an alternative patch that is checking only for isClosed as well as a more complete patch containing an implementation of isValid for the Derby client driver.", "svn status reports:", "M      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnection.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java", "I have run the JDBC4 tests using Java 1.6 and derbyall using 1.5 under Solaris 10 x86.", "Only errors seen in the regression test was reported.", "The patch is complete for the embedded driver and could be reviewed and committed, but I expect that we should wait until we have decided if using only isClosed is a better and sufficient solution.", "Hi, Olav.", "It's not clear to me what a committer needs to do with this patch.", "You have checked the box saying you intend it for inclusion to the project, but you also say other, alternate patches are on  the way.", "Do you want a committer to commit this, or is it just for review?", "Hi, David.", "The main purpose of sending in the patch was to get opinions from more people on what would be the best alternative solution to check if a connection is valid in the embedded driver.", "The current alternatives are:", "a) check if connection is not closed followed by a simple query against the database (this is implemented by the patch I submitted yesterday)", "b) just check that the connection is not closed (I plan to submit an alternative patch for this soon)", "Dan has suggested that checking for isClosed could be sufficient in the embedded version.", "It would be good to hear if other have opinions about this.", "If I do not get other suggestions I will probably propose that the next patch (checking only for isClosed) being reviewed and commited.", "This patch (embedded1090-isclosed.diff)  implementations Connection.isValid() for the embedded driver by verifying that the connection", "is not closed (by calling isClosed()).", "If the connection is closed, isValid returns false, otherwise it returns true.", "The timeout defined as a parameter to isValid is not used.", "Compared to the previous patch I sent a few days ago (embedded1090-query.diff), this patch does not run any query against Derby to validate the", "connection.", "My proposal (also based on suggestions from Dan) is that we only check for isClosed() in the embedded driver.", "I have not experienced any situation where isClosed returned false and the query failed.", "If we later discover situations where the connection is not \"valid\" even if isValid returns true, we can add a query as done in my first patch to isValid.", "Testing:", "The patch extends the TestConnectionMethods.java test with test for isValid in the following cases:", "wrong parameter values (negative timeout)", "isValid with no timeout", "isValid with a specified timeout", "isValid on a connection that is closed", "isValid on a \"open connection\" to a database that is shutdown", "svn status reports:", "M      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java", "I have run the JDBC4 tests using Java 1.6 and derbyall using Java 1.5 under Solaris 10 x86.", "Only errors seen in the regression test was reported (runtimeinfo failed in derbynetmats).", "The patch is complete for the embedded driver and can be reviewed and committed.", "Looks good to me.", "The jdbc4 tests run cleanly.", "Derbyall only has errors which I see in a clean client: wisconsin, sysinfo, sysinfo_withproperties, xaSimplePositive, and a new failure in SURTest caused by:", "> java.lang.NoSuchMethodError: main", "> Exception in thread \"main\"", "Test Failed.", "I have committed embedded1090_isClosed.diff at subversion revision 388771.", "This patch (client1090_patch1.diff) implements the Connection.isValid for the network client.", "The connection is valid if (a) it is not closed (checked isClosed()) and (b) a simple query (\"VALUES (1)\") is executed successfully.", "Any exception thrown by the query execution is treated as if the connection is not valid.", "If a timeout is specified this is handled by setting a query timeout for executing the query (queryTimeout() is used).", "The implementation handles most failure situations, with the exception of a hanging server that is not returning any reply to the client.", "I plan to submit a fix for this in a separte patch.", "The isValid() call is tested for the following scenarios:", "illegal parameter values (negative timeout)", "no timeout value", "with a timeout specified", "on a connection to a database that has been shutdown", "on a connection to a network server that has been stopped", "svn status reports:", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java", "M      java/client/org/apache/derby/client/net/NetConnection40.java", "I have run the JDBC4 tests and derbyall with the patch.", "Only failure was in tools/derbyrunjartest.java.", "The patch can be reviewed and committed.", "I have looked at the patch, and I think it looks good, and can be committed.", "I concur, looks good.", "JDBC4 tests run cleanly.", "Derbyall runs cleanly modulo wisconsin noise.", "Committed at subversion revision 396028."], "SplitGT": [" Checks if the connection has not been closed and is still valid.", "The validity is checked by running a simple query against the database."], "issueString": "Implement Connection.isValid as defined by JDBC4\nThe Javadoc for JDBC4 says this about Connection.isValid:\n\nboolean isValid(int timeout) throws SQLException\n\nReturns true if the connection has not been closed and is still valid. The driver shall submit a query on the connection or use some other mechanism that positively verifies the connection is still valid when this method is called. \n\nThe query submitted by the driver to validate the connection shall be executed in the context of the current transaction. \n\nParameters: timeout - - The time in seconds to wait for the database operation used to validate the connection to complete. If the timeout period expires before the operation completes, this method returns false. A value of 0 indicates a timeout is not applied to the database operation. \n\nReturns: true if the connection is valid, false otherwise \nIn case someone else have suggestions or ideas on how to best implement this functionality, here are some high-level initial thoughts on how to implement it:\n\n  -to check the validity of the connection, issue a simple query like\n   e.g., \"VALUES (1)\"\n\n  -to implement the timeout, use the setQueryTimeout() method. \n\nThis will hopefully be sufficient in the embedded version as I expect that for all error situations where the connection no longer is valid, an exception will be thrown when issuing the query.\n\nFor the Derby client we probably need some timeout mechanism in the client code (in addition to setting the query timeout) in order to detect that the server has not responded within before the specified timeout has elapsed. I have not studied the network code in details yet to find out if it already has code or hooks for specifying a timeout on the DRDA request to the server. Any suggestions on how to best implement this are welcome.\n\nIn embedded would it  be sufficient just to call the isClosed() method?\n\nDan, thanks for the suggestion of only using isClosed in the embedded driver. I have also wondered if calling isClosed would be sufficient, and actually I have not been able to create a scenario where isClosed returns false followed by simple query that fails.\n\nThe main reasons for including execution of a simple query also in the embedded driver are:\n\n * I do not know the code well enough to be sure that there will not be situations where isClosed returns false and a query returns e.g., a timeout or exception due to some resource constraints, deadlock or other error situations.\n\n * It will make the behavior and implementation more similar between what is done in the embedded and in the client driver.\n\nI will probably submit a patch for how isValid can be implemented for the Embedded server containing both a check for isClosed and a query. If you or other on the list still thinks it is unnecessary to include execution of a query I will remove it.\n\n\nThe query case actually seems somewhat harder to me, and one needs to understand the code far more, than the isClosed approach.\nMaybe this knowledge needs to exist for the client implementation anyway. I think one has to see how many ways the query can fail and\nthen see how many map to the connection being not valid. I don't believe the query failing, always means the connection is not valid.\nIf the query failed due to out of memory error, then the connection is still valid.\n\nThere's no requirement for the embedded and client dirver to have identical implementations, the embedded gains performance\nby having direct access to the engine, something that is clearly not possible with the client. This naturally leads to different implementations\nfor various methods.\nThanks for commenting on this, Dan. I agree that using a query is more complicated than just checking for isClosed. So if checking for isClosed is sufficient to verify that the connection is \"valid\" we should go for that approach in the embedded driver as it is less complex and has better performance. \n\nStill, I think the purpose of adding the isValid method to the JDBC standard is to positively determine that it is possible to run queries on it. I am not convinced that your example of a simple query on the connection failing due to out of memory should still return that the connection is \"valid\"? I expect this is a method that will be used together with a connection pool implementation where either the pool or the user will use this for \"ensuring\" the connection is \"valid\" before it is used for something. And having a connection that returns out of memory errors on every query is not something that an application would think is a \"useful\" connection to have around (on the other side, creating a new connection does probably not make the situation any better in this case). The JavaDoc for isValid (see the test in the Jira issue) strongly indicates that we actually should take the cost of running a query against the database.\n\nAnyway, I have no strong opinions on whether to just check isClosed or issue a query against the database. But since I now happen to have a patch that solves this using a query I will upload this patch tonight. Tomorrow moring I will upload a new patch that is only checking for isClosed. I do not expect anyone to do a review or commit any of these, but it might trigger some more comments and opinions from other on the list. \nThe patch contains one alternative implementation of  Connection.isValid() for the embedded driver by verifying that the connection\nis open (by calling isClosed()) and by running a simple query (\"VALUES (1)\") against the database. If the connection is closed or if the query returns any SQL exception, isValid returns false. To support the timeout defined as a parameter to isValid, setQueryTimeout is used.\n\nTesting:\n\nThe patch extends the TestConnectionMethods.java test with test for isValid in the following cases:\n\n  -wrong parameter values (negative timeout)\n  -isValid with no timeout\n  -isValid with a specified timeout\n  -isValid on a connection that is closed\n  -isValid on a \"open connection\" to a database that is shutdown\n\nI plan to submit an alternative patch that is checking only for isClosed as well as a more complete patch containing an implementation of isValid for the Derby client driver.\n\nsvn status reports:\n\nM      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnection.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java\n\nI have run the JDBC4 tests using Java 1.6 and derbyall using 1.5 under Solaris 10 x86. Only errors seen in the regression test was reported.\n\nThe patch is complete for the embedded driver and could be reviewed and committed, but I expect that we should wait until we have decided if using only isClosed is a better and sufficient solution.\n\n\nHi, Olav.  It's not clear to me what a committer needs to do with this patch.  You have checked the box saying you intend it for inclusion to the project, but you also say other, alternate patches are on  the way.  Do you want a committer to commit this, or is it just for review?\nHi, David. The main purpose of sending in the patch was to get opinions from more people on what would be the best alternative solution to check if a connection is valid in the embedded driver. The current alternatives are:\n\n  a) check if connection is not closed followed by a simple query against the database (this is implemented by the patch I submitted yesterday)\n  b) just check that the connection is not closed (I plan to submit an alternative patch for this soon)\n\nDan has suggested that checking for isClosed could be sufficient in the embedded version. It would be good to hear if other have opinions about this. If I do not get other suggestions I will probably propose that the next patch (checking only for isClosed) being reviewed and commited.\nThis patch (embedded1090-isclosed.diff)  implementations Connection.isValid() for the embedded driver by verifying that the connection \nis not closed (by calling isClosed()). If the connection is closed, isValid returns false, otherwise it returns true. The timeout defined as a parameter to isValid is not used.\n\nCompared to the previous patch I sent a few days ago (embedded1090-query.diff), this patch does not run any query against Derby to validate the\nconnection. My proposal (also based on suggestions from Dan) is that we only check for isClosed() in the embedded driver. I have not experienced any situation where isClosed returned false and the query failed. If we later discover situations where the connection is not \"valid\" even if isValid returns true, we can add a query as done in my first patch to isValid.\n\nTesting: \n\nThe patch extends the TestConnectionMethods.java test with test for isValid in the following cases: \n\n  -wrong parameter values (negative timeout) \n  -isValid with no timeout \n  -isValid with a specified timeout \n  -isValid on a connection that is closed \n  -isValid on a \"open connection\" to a database that is shutdown \n\nsvn status reports: \n\nM      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java\n\nI have run the JDBC4 tests using Java 1.6 and derbyall using Java 1.5 under Solaris 10 x86. Only errors seen in the regression test was reported (runtimeinfo failed in derbynetmats).\n\nThe patch is complete for the embedded driver and can be reviewed and committed.\nLooks good to me. The jdbc4 tests run cleanly. Derbyall only has errors which I see in a clean client: wisconsin, sysinfo, sysinfo_withproperties, xaSimplePositive, and a new failure in SURTest caused by:\n\n> java.lang.NoSuchMethodError: main\n> Exception in thread \"main\"\nTest Failed.\n\nI have committed embedded1090_isClosed.diff at subversion revision 388771.\nThis patch (client1090_patch1.diff) implements the Connection.isValid for the network client. The connection is valid if (a) it is not closed (checked isClosed()) and (b) a simple query (\"VALUES (1)\") is executed successfully. Any exception thrown by the query execution is treated as if the connection is not valid.\n\nIf a timeout is specified this is handled by setting a query timeout for executing the query (queryTimeout() is used). \n\nThe implementation handles most failure situations, with the exception of a hanging server that is not returning any reply to the client. I plan to submit a fix for this in a separte patch. \n\nThe isValid() call is tested for the following scenarios:\n\n  -illegal parameter values (negative timeout)\n  -no timeout value\n  -with a timeout specified\n  -on a connection to a database that has been shutdown\n  -on a connection to a network server that has been stopped\n\nsvn status reports:\n\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java\nM      java/client/org/apache/derby/client/net/NetConnection40.java\n\nI have run the JDBC4 tests and derbyall with the patch. Only failure was in tools/derbyrunjartest.java.\n\nThe patch can be reviewed and committed.\nI have looked at the patch, and I think it looks good, and can be committed.\n\nI concur, looks good. JDBC4 tests run cleanly. Derbyall runs cleanly modulo wisconsin noise. Committed at subversion revision 396028.\n", "issueSearchSentences": ["is open (by calling isClosed()) and by running a simple query (\"VALUES (1)\") against the database.", "A value of 0 indicates a timeout is not applied to the database operation.", "Any exception thrown by the query execution is treated as if the connection is not valid.", "The connection is valid if (a) it is not closed (checked isClosed()) and (b) a simple query (\"VALUES (1)\") is executed successfully.", "The current alternatives are:"], "issueSearchIndexes": [50, 9, 111, 110, 74]}
{"aId": 84, "code": "public  void    setColumnNames( String[] columnNames )\n        throws SQLException\n    {\n        if ( _columnNames != null ) { throw makeSQLException( SQLState.LANG_CANNOT_CHANGE_COLUMN_NAMES ); }\n\n        _columnNames = ArrayUtil.copy( columnNames );\n    }", "comment": " This is useful for AwareVTIs, which need to figure out their column names after analyzing their execution context.", "issueId": "DERBY-6117", "issueStringList": ["Extend the Table Functions java interface to pass more query context information from Derby", "General requirement is to extend the Table Functions java interface (through RestrictedVTI or another interface) and pass more context information from Derby to Table Functions - esp in query execution phase.", "Greater urgency is required for the first 2 items below, especially the ability to access the original SQL which was available with VTIs.", "This is critical to the GaianDB project - we extract HINTs from the query (where we pass meta data like user credentials), and also extract full original complex predicate expressions (involving functions etc - which cannot be expressed with a Restriction) - to push on in our query prorogation...", "In order of importance + simplicity:", "1 - Original SQL (this used to be available with VTIs through VTIEnvironment for both compilation and execution phases)", "2 - Name of function that was called", "3 - User Info (ID, etc) - (this can currently be passed in the SQL hint)", "4 - Richer predicate expressions (incl functions, etc)", "5 - Context within Join query (e.g.", "inner or outer table, join type)", "6 - Other Query Plan information", "7 - Anything else...?", "Original forum discussion:", "http://apache-database.10148.n7.nabble.com/Limitations-of-Table-Functions-vs-old-VTIs-td127988.html#a127995", "i agree with all above, especially the name of the function called.", "adding information from", "https://issues.apache.org/jira/browse/DERBY-6115", "1) derby should support passing IN to initScan", "2) derby should transform IN to an OR clause as a work around to not passing down IN scan", "3) function should have access to information about the function's return type, i.e.", "the if the result type is a table definition, function should have access to that definition.", "this is necessary when a function is declared with multiple names and return types.", "for example, with foreign table loads, we want to pre-transform data from remote result set in 1 thread, then hand to derby thread.", "we need to know what the main derby thread reading resultset wants in sqltype for each column.", "4) derby should introspect resultset to see which column names are searchable, and thus, fast for querying,  perhaps isSearchable on ResultSetMetaData is the right / wrong thing to do.", "maybe can do this with VTIConsting ?", "5) derby should do multi-probe on vti function if vti function indicates on a metaData that isSearchable is true, or that it implements perfectly the initscan restriction.", "6) vti function should be able to tell derby that it correctly implements the vti restriction, either for a given one, or for any, and derby should not request the column in initscan columnNames, and derby  should not check again the restriction.", "( for example, assume foreign table with username and picture as BLOB) , a query for select username where picture is not null, currently, derby will pass select username and picture as columnnames, and function will have to pull all the username and blob data and hand to derby, just to allow derby to check again is not null, even though function already did this .", "This is a HUGE performance issue we are experiencing.", "i'm sure i'll have more issues to add :)", "Note that part of item (3) can be obtained by calling DriverManager.getConnection( \"jdbc:default:connection\" ) in order to get the connection and then executing a \"values current_user\" statement.", "\ufeff\ufeffAttaching derby-6117-01-aa-AwareVTI.diff.", "This patch introduces the AwareVTI interface.", "This is a first step toward giving table functions more context about their execution environments.", "I am running tests now.", "Introduces two new classes/interfaces:", "o VTIContext - This is a simple class which contains the following information:", "The name of the schema holding the table function.", "The non-schema-qualified name of the table function.", "The text of the statement invoking the table function.", "o AwareVTI - Table functions which implement this interface are handed the VTIContext describing their execution environment.", "VTITemplate now implements AwareVTI so most table functions will get this functionality for free.", "VTIContext exposes the following methods:", "{noformat}", "public  String  vtiSchema() { return _vtiSchema; }", "public  String  vtiTable()  { return _vtiTable; }", "public  String  statementText() { return _statementText; }", "{noformat}", "AwareVTI contains these method:", "{noformat}", "public  VTIContext  getContext();", "public  void    setContext( VTIContext context );", "{noformat}", "Touches the following files:", "A       java/engine/org/apache/derby/vti/VTIContext.java", "A       java/engine/org/apache/derby/vti/AwareVTI.java", "M       java/engine/org/apache/derby/vti/VTITemplate.java", "Introduces the new classes and wires them into most existing table functions.", "M       java/engine/org/apache/derby/iapi/sql/execute/ResultSetFactory.java", "M       java/engine/org/apache/derby/impl/sql/compile/MethodCallNode.java", "M       java/engine/org/apache/derby/impl/sql/compile/FromVTI.java", "M       java/engine/org/apache/derby/impl/sql/compile/StaticMethodCallNode.java", "M       java/engine/org/apache/derby/impl/sql/execute/GenericResultSetFactory.java", "M       java/engine/org/apache/derby/impl/sql/execute/VTIResultSet.java", "Compile-time and execution-time machinery to support VTIContext.", "A       java/testing/org/apache/derbyTesting/functionTests/tests/lang/AwareVTITest.java", "A       java/testing/org/apache/derbyTesting/functionTests/tests/lang/DummyAwareVTI.java", "M       java/testing/org/apache/derbyTesting/functionTests/tests/lang/_Suite.java", "Basic tests for this new feature.", "M       tools/javadoc/publishedapi.ant", "Adds AwareVTI and VTIContext to the public api.", "Attaching derby-6117-01-ab-AwareVTI.diff.", "This fixes an NPE during compilation of old-style VTIs, introduced by the previous rev of the patch.", "Re-starting the tests.", "Touches the same files as the previous rev.", "Tests passed cleanly for me on derby-6117-01-ab-AwareVTI.diff except for the query plan instability recently introduced into org.apache.derbyTesting.functionTests.tests.lang.SelectivityTest by other work.", "Attaching derby-6117-02-aa-changeColumnNamesInStringColumnVTI.diff.", "This patch makes it possible to create a StringColumnVTI with no column names and then set the column names later.", "I am running tests now.", "This feature is useful for AwareVTIs which determine their column names only after analyzing their execution context.", "Touches the following files:", "M       java/engine/org/apache/derby/vti/StringColumnVTI.java", "If the StringColumnVTI is created without any column names, then the column names can be set once later on.", "M       java/engine/org/apache/derby/loc/messages.xml", "M       java/shared/org/apache/derby/shared/common/reference/SQLState.java", "New error raised if you try to change the column names after they've already been set.", "M       java/testing/org/apache/derbyTesting/functionTests/tests/lang/AwareVTITest.java", "Test for this behavior."], "SplitGT": [" This is useful for AwareVTIs, which need to figure out their column names after analyzing their execution context."], "issueString": "Extend the Table Functions java interface to pass more query context information from Derby\nGeneral requirement is to extend the Table Functions java interface (through RestrictedVTI or another interface) and pass more context information from Derby to Table Functions - esp in query execution phase.\n\nGreater urgency is required for the first 2 items below, especially the ability to access the original SQL which was available with VTIs. This is critical to the GaianDB project - we extract HINTs from the query (where we pass meta data like user credentials), and also extract full original complex predicate expressions (involving functions etc - which cannot be expressed with a Restriction) - to push on in our query prorogation...\n\nIn order of importance + simplicity:\n--------------------------------------------------\n1 - Original SQL (this used to be available with VTIs through VTIEnvironment for both compilation and execution phases)\n2 - Name of function that was called\n\n3 - User Info (ID, etc) - (this can currently be passed in the SQL hint)\n4 - Richer predicate expressions (incl functions, etc)\n5 - Context within Join query (e.g. inner or outer table, join type)\n6 - Other Query Plan information\n7 - Anything else...?\n\nOriginal forum discussion:\nhttp://apache-database.10148.n7.nabble.com/Limitations-of-Table-Functions-vs-old-VTIs-td127988.html#a127995\ni agree with all above, especially the name of the function called.\n\nadding information from\n\nhttps://issues.apache.org/jira/browse/DERBY-6115\n\n1) derby should support passing IN to initScan\n2) derby should transform IN to an OR clause as a work around to not passing down IN scan\n3) function should have access to information about the function's return type, i.e. the if the result type is a table definition, function should have access to that definition.  this is necessary when a function is declared with multiple names and return types.  for example, with foreign table loads, we want to pre-transform data from remote result set in 1 thread, then hand to derby thread.  we need to know what the main derby thread reading resultset wants in sqltype for each column. \n4) derby should introspect resultset to see which column names are searchable, and thus, fast for querying,  perhaps isSearchable on ResultSetMetaData is the right / wrong thing to do.  maybe can do this with VTIConsting ?\n5) derby should do multi-probe on vti function if vti function indicates on a metaData that isSearchable is true, or that it implements perfectly the initscan restriction.\n6) vti function should be able to tell derby that it correctly implements the vti restriction, either for a given one, or for any, and derby should not request the column in initscan columnNames, and derby  should not check again the restriction. ( for example, assume foreign table with username and picture as BLOB) , a query for select username where picture is not null, currently, derby will pass select username and picture as columnnames, and function will have to pull all the username and blob data and hand to derby, just to allow derby to check again is not null, even though function already did this .  This is a HUGE performance issue we are experiencing.  \n\ni'm sure i'll have more issues to add :)\nNote that part of item (3) can be obtained by calling DriverManager.getConnection( \"jdbc:default:connection\" ) in order to get the connection and then executing a \"values current_user\" statement.\n\ufeff\ufeffAttaching derby-6117-01-aa-AwareVTI.diff. This patch introduces the AwareVTI interface. This is a first step toward giving table functions more context about their execution environments. I am running tests now.\n\nIntroduces two new classes/interfaces:\n\no VTIContext - This is a simple class which contains the following information:\n\n  - The name of the schema holding the table function.\n  - The non-schema-qualified name of the table function.\n  - The text of the statement invoking the table function.\n\no AwareVTI - Table functions which implement this interface are handed the VTIContext describing their execution environment.\n\nVTITemplate now implements AwareVTI so most table functions will get this functionality for free.\n\nVTIContext exposes the following methods:\n\n{noformat}\n    /** Return the name of the schema holding the table function */\n    public  String  vtiSchema() { return _vtiSchema; }\n\n    /** Return the unqualified table function name */\n    public  String  vtiTable()  { return _vtiTable; }\n\n    /** Return the text of the statement which invoked the table function */\n    public  String  statementText() { return _statementText; }\n{noformat}\n\nAwareVTI contains these method:\n\n{noformat}\n    /** Get the table function context */\n    public  VTIContext  getContext();\n\n    /** Set the table function context */\n    public  void    setContext( VTIContext context );\n{noformat}\n\n\n\nTouches the following files:\n\n----------------\n\nA       java/engine/org/apache/derby/vti/VTIContext.java\nA       java/engine/org/apache/derby/vti/AwareVTI.java\nM       java/engine/org/apache/derby/vti/VTITemplate.java\n\nIntroduces the new classes and wires them into most existing table functions.\n\n----------------\n\nM       java/engine/org/apache/derby/iapi/sql/execute/ResultSetFactory.java\nM       java/engine/org/apache/derby/impl/sql/compile/MethodCallNode.java\nM       java/engine/org/apache/derby/impl/sql/compile/FromVTI.java\nM       java/engine/org/apache/derby/impl/sql/compile/StaticMethodCallNode.java\nM       java/engine/org/apache/derby/impl/sql/execute/GenericResultSetFactory.java\nM       java/engine/org/apache/derby/impl/sql/execute/VTIResultSet.java\n\nCompile-time and execution-time machinery to support VTIContext.\n\n----------------\n\nA       java/testing/org/apache/derbyTesting/functionTests/tests/lang/AwareVTITest.java\nA       java/testing/org/apache/derbyTesting/functionTests/tests/lang/DummyAwareVTI.java\nM       java/testing/org/apache/derbyTesting/functionTests/tests/lang/_Suite.java\n\nBasic tests for this new feature.\n\n----------------\n\nM       tools/javadoc/publishedapi.ant\n\nAdds AwareVTI and VTIContext to the public api.\n\nAttaching derby-6117-01-ab-AwareVTI.diff. This fixes an NPE during compilation of old-style VTIs, introduced by the previous rev of the patch. Re-starting the tests.\n\nTouches the same files as the previous rev.\n\nTests passed cleanly for me on derby-6117-01-ab-AwareVTI.diff except for the query plan instability recently introduced into org.apache.derbyTesting.functionTests.tests.lang.SelectivityTest by other work.\nAttaching derby-6117-02-aa-changeColumnNamesInStringColumnVTI.diff. This patch makes it possible to create a StringColumnVTI with no column names and then set the column names later. I am running tests now.\n\nThis feature is useful for AwareVTIs which determine their column names only after analyzing their execution context.\n\n\nTouches the following files:\n\n---------------\n\nM       java/engine/org/apache/derby/vti/StringColumnVTI.java\n\nIf the StringColumnVTI is created without any column names, then the column names can be set once later on.\n\n---------------\n\nM       java/engine/org/apache/derby/loc/messages.xml\nM       java/shared/org/apache/derby/shared/common/reference/SQLState.java\n\nNew error raised if you try to change the column names after they've already been set.\n\n---------------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/lang/AwareVTITest.java\n\nTest for this behavior.\n\n", "issueSearchSentences": ["public  VTIContext  getContext();", "{noformat}", "public  String  vtiSchema() { return _vtiSchema; }", "public  String  vtiTable()  { return _vtiTable; }", "{noformat}"], "issueSearchIndexes": [53, 46, 47, 48, 52]}
{"aId": 89, "code": "public void reposition(long requestedPos)\n            throws IOException{\n        if (SanityManager.DEBUG) {\n            if (requestedPos < 0) {\n                SanityManager.THROWASSERT(\"Negative position: \" + requestedPos);\n            }\n        }\n        if (requestedPos > length()) {\n            pos = 0;\n            throw new EOFException();\n        }\n        pos = requestedPos;\n    }", "comment": " Repositions the stream to the requested byte position.", "issueId": "DERBY-3935", "issueStringList": ["Introduce interface for a position aware stream", "Add an interface for streams that are aware of their position and that can reposition itself on request.", "Initially there will be two such stream objects; PositionedStoreStream and LOBInputStream.", "The interface will be used to allow the Clob implementation (including UTF8Reader) to handle the various internal Clob representations in a consistent manner when it comes to positioning the underlying byte stream.", "'derby-3935-1a-PositionedStream.diff' is the first revision of the PositionedStream interface.", "Two streams implement the interface: PositionedStoreStream and LOBInputStream.", "The interface has the following methods:", "asInputStream() : convenience method to return a reference to the stream as InputStream.", "getPosition() : returns the current position of the stream.", "reposition(long) : repositions the stream to the requested position.", "Patch ready for review.", "The patch looks fine to me.", "+1 to commit.", "(Tiny nit: LOBInputStream.reposition() doesn't need to be declared as throws EOFException since it's also declared to throw IOException.", "Keeping both the @throws tags in the comment is fine, though.)", "By the way, would it make sense at some point to merge the PositionedStream interface with Resetable?", "Or perhaps make PositionedStream extend Resetable?", "Resetable.resetStream() is just a special case of PositionedStream.reposition(), and it seems like both PositionStoreStream and LOBInputStream have methods that match the functionality defined by Resetable (PSS actually implements Resetable).", "Removing the patch available flag, as it is very likely that a new patch will be attached soon.", "I need to consider the options, and the throws clause needs to be fixed anyway.", "Regarding Resetable and PositionedStream (PS), the former is more tightly bound to store.", "For instance, initStream handles locking, which is probably not required for data streams outside of store.", "I don't see any immediate need to add the three methods resetStream, initStream and closeStream to LOBInputStream.", "I'm opting for committing what I have now, and look at combining the interfaces later if it turns out that is the best thing to do.", "I attached revision 1b, which adds two debug blocks (checking for a negative requested position), removed the throws clause for EOFException and fixed some errors in the JavaDoc.", "After rerunning the tests, I intend to commit patch 1b.", "Committed patch 1b (with one modification) to trunk with revision 720517.", "I removed the final keyword from the method signature of reposition in the interface.", "I'm keeping the issue open for a while, as there might be more changes to be done."], "SplitGT": [" Repositions the stream to the requested byte position."], "issueString": "Introduce interface for a position aware stream\nAdd an interface for streams that are aware of their position and that can reposition itself on request.\nInitially there will be two such stream objects; PositionedStoreStream and LOBInputStream.\n\nThe interface will be used to allow the Clob implementation (including UTF8Reader) to handle the various internal Clob representations in a consistent manner when it comes to positioning the underlying byte stream.\n'derby-3935-1a-PositionedStream.diff' is the first revision of the PositionedStream interface.\nTwo streams implement the interface: PositionedStoreStream and LOBInputStream.\n\nThe interface has the following methods:\n - asInputStream() : convenience method to return a reference to the stream as InputStream.\n - getPosition() : returns the current position of the stream.\n - reposition(long) : repositions the stream to the requested position.\n\nPatch ready for review.\nThe patch looks fine to me. +1 to commit.\n\n(Tiny nit: LOBInputStream.reposition() doesn't need to be declared as throws EOFException since it's also declared to throw IOException. Keeping both the @throws tags in the comment is fine, though.)\nBy the way, would it make sense at some point to merge the PositionedStream interface with Resetable? Or perhaps make PositionedStream extend Resetable? Resetable.resetStream() is just a special case of PositionedStream.reposition(), and it seems like both PositionStoreStream and LOBInputStream have methods that match the functionality defined by Resetable (PSS actually implements Resetable).\nRemoving the patch available flag, as it is very likely that a new patch will be attached soon.\nI need to consider the options, and the throws clause needs to be fixed anyway.\nRegarding Resetable and PositionedStream (PS), the former is more tightly bound to store.\nFor instance, initStream handles locking, which is probably not required for data streams outside of store. I don't see any immediate need to add the three methods resetStream, initStream and closeStream to LOBInputStream.\nI'm opting for committing what I have now, and look at combining the interfaces later if it turns out that is the best thing to do.\n\nI attached revision 1b, which adds two debug blocks (checking for a negative requested position), removed the throws clause for EOFException and fixed some errors in the JavaDoc.\nAfter rerunning the tests, I intend to commit patch 1b.\nCommitted patch 1b (with one modification) to trunk with revision 720517.\nI removed the final keyword from the method signature of reposition in the interface.\n\nI'm keeping the issue open for a while, as there might be more changes to be done.\n", "issueSearchSentences": ["+1 to commit.", "getPosition() : returns the current position of the stream.", "I'm opting for committing what I have now, and look at combining the interfaces later if it turns out that is the best thing to do.", "I don't see any immediate need to add the three methods resetStream, initStream and closeStream to LOBInputStream.", "public void reposition(long requestedPos)\n            throws IOException{\n        if (SanityManager.DEBUG) {\n            if (requestedPos < 0) {\n                SanityManager.THROWASSERT(\"Negative position: \" + requestedPos);\n            }\n        }\n        if (requestedPos > length()) {\n            pos = 0;\n            throw new EOFException();\n        }\n        pos = requestedPos;\n    }"], "issueSearchIndexes": [13, 9, 24, 23, 0]}
{"aId": 92, "code": "private boolean unionCompatible( ValueNode left, ValueNode right )\n        throws StandardException\n    {\n        TypeId leftTypeId = left.getTypeId();\n        TypeId rightTypeId = right.getTypeId();\n        ClassFactory cf = getClassFactory();\n\n        if (\n            !left.getTypeCompiler().storable(rightTypeId, cf) &&\n            !right.getTypeCompiler().storable(leftTypeId, cf)\n            )\n        { return false; }\n\n        if ( leftTypeId.isBooleanTypeId() != rightTypeId.isBooleanTypeId() ) { return false; }\n\n        return true;\n    }", "comment": " The rules for union compatibility are found in the SQL Standard, part 2, section 7.3 (<query expression>), syntax rule 20.b.ii. That in turn, refers you to section 9.3 (Result of data type combinations).", "issueId": "DERBY-4692", "issueStringList": ["Unions between BOOLEAN and non-BOOLEAN datatypes should be rejected", "DERBY-4684 fixed problems in implicit casts to BOOLEAN.", "However, the query which created the implicit casts should raise an error for other reasons:", "select isindex from sys.sysconglomerates where conglomeratename = 'foo'", "union", "values ( 'true' )", "This should fail because if either of the datatypes being UNIONed is BOOLEAN, then both should be BOOLEAN.", "Here is my reasoning, copied from the related discussion on DERBY:", "1) The rules for determining whether two datatypes are union compatible are stated in the SQL Standard in part 2, section 7.3 (<query expression>), syntax rule 20.b.ii.", "2) That, in turn, refers the reader to section 9.3 (Result of data type combinations).", "3) Section 9.3, syntax rule 3.g says that if either of two values to be merged is BOOLEAN, then both must be BOOLEAN.", "Attaching derby-4692-01-aa-badUnions.diff.", "This patch prevents you from UNIONing BOOLEAN and non-BOOLEAN types.", "Regression tests passed cleanly for me after applying this patch.", "I am not sure that Derby is enforcing the Standard rules for UNION compatibility.", "Derby may be enforcing a weaker set of rules.", "Bringing Derby into full compliance with the Standard could break many existing applications so I do not recommend fixing this logic.", "However, as we re-enable BOOLEAN, it makes sense to me that the rules for BOOLEAN should be correct.", "Touches the following files:", "M      java/engine/org/apache/derby/impl/sql/compile/ResultColumnList.java", "Make sure that if either side of a UNION is BOOLEAN, then both sides are BOOLEAN.", "M      java/testing/org/apache/derbyTesting/functionTests/tests/lang/BooleanValuesTest.java", "Change this regression test to reject the UNION queries which allowed mixing of BOOLEAN and non-BOOLEAN values.", "Committed patch at subversion revision 952263."], "SplitGT": [" The rules for union compatibility are found in the SQL Standard, part 2, section 7.3 (<query expression>), syntax rule 20.b.ii.", "That in turn, refers you to section 9.3 (Result of data type combinations)."], "issueString": "Unions between BOOLEAN and non-BOOLEAN datatypes should be rejected\nDERBY-4684 fixed problems in implicit casts to BOOLEAN. However, the query which created the implicit casts should raise an error for other reasons:\n\nselect isindex from sys.sysconglomerates where conglomeratename = 'foo'\nunion\nvalues ( 'true' )\n\nThis should fail because if either of the datatypes being UNIONed is BOOLEAN, then both should be BOOLEAN. Here is my reasoning, copied from the related discussion on DERBY:\n\n1) The rules for determining whether two datatypes are union compatible are stated in the SQL Standard in part 2, section 7.3 (<query expression>), syntax rule 20.b.ii.\n\n2) That, in turn, refers the reader to section 9.3 (Result of data type combinations).\n\n3) Section 9.3, syntax rule 3.g says that if either of two values to be merged is BOOLEAN, then both must be BOOLEAN.\nAttaching derby-4692-01-aa-badUnions.diff. This patch prevents you from UNIONing BOOLEAN and non-BOOLEAN types. Regression tests passed cleanly for me after applying this patch.\n\nI am not sure that Derby is enforcing the Standard rules for UNION compatibility. Derby may be enforcing a weaker set of rules. Bringing Derby into full compliance with the Standard could break many existing applications so I do not recommend fixing this logic. However, as we re-enable BOOLEAN, it makes sense to me that the rules for BOOLEAN should be correct.\n\nTouches the following files:\n\n---------\n\nM      java/engine/org/apache/derby/impl/sql/compile/ResultColumnList.java\n\nMake sure that if either side of a UNION is BOOLEAN, then both sides are BOOLEAN.\n\n---------\n\nM      java/testing/org/apache/derbyTesting/functionTests/tests/lang/BooleanValuesTest.java\n\nChange this regression test to reject the UNION queries which allowed mixing of BOOLEAN and non-BOOLEAN values.\n\nCommitted patch at subversion revision 952263.\n", "issueSearchSentences": ["union", "M      java/engine/org/apache/derby/impl/sql/compile/ResultColumnList.java", "values ( 'true' )", "2) That, in turn, refers the reader to section 9.3 (Result of data type combinations).", "private boolean unionCompatible( ValueNode left, ValueNode right )\n        throws StandardException\n    {\n        TypeId leftTypeId = left.getTypeId();\n        TypeId rightTypeId = right.getTypeId();\n        ClassFactory cf = getClassFactory();\n\n        if (\n            !left.getTypeCompiler().storable(rightTypeId, cf) &&\n            !right.getTypeCompiler().storable(leftTypeId, cf)\n            )\n        { return false; }\n\n        if ( leftTypeId.isBooleanTypeId() != rightTypeId.isBooleanTypeId() ) { return false; }\n\n        return true;\n    }"], "issueSearchIndexes": [5, 20, 6, 10, 0]}
{"aId": 94, "code": "void reposition(long requestedCharPos)\n            throws IOException, StandardException {\n        if (SanityManager.DEBUG) {\n            SanityManager.ASSERT(this.positionedIn != null);\n            SanityManager.ASSERT(requestedCharPos > 0);\n        }\n        // See if we can continue reading, or do nothing at all, to get to the\n        // right position.\n        if (requestedCharPos > readerCharCount) {\n            // The second part corrects for the internal buffer position.\n            long toSkip = (requestedCharPos - readerCharCount) +\n                    (charactersInBuffer - readPositionInBuffer) -1;\n            persistentSkip(toSkip);\n        } else {\n            // See if the requested position is within the current buffer.\n            long lowerBufferBorder = readerCharCount - charactersInBuffer;\n            if (requestedCharPos <= lowerBufferBorder) {\n                // Have to reset and start from scratch.\n                resetUTF8Reader();\n                persistentSkip(requestedCharPos -1);\n            } else {\n                // We have the requested position in the buffer already.\n                readPositionInBuffer =\n                        (int)(requestedCharPos - lowerBufferBorder -1);\n            }\n        }\n    }", "comment": " There are three types of repositioning, ordered after increasing cost: Reposition within current character buffer (small hops forwards and potentially backwards - in range 1 char to MAXIMUM_BUFFER_SIZE chars)Forward stream from current position (hops forwards) Reset stream and skip data (hops backwards)", "issueId": "DERBY-3825", "issueStringList": ["StoreStreamClob.getReader(charPos) performs poorly", "StoreStreamClob.getReader(charPos) performs poorly because it resets the underlying stream and skips data until it reached the requested character position.", "Not only does the data has to be skipped, it also has to be decoded (UTF-8).", "The problem is exposed through EmbedClob.getSubString, which causes extremely bad performance for the client driver because the locator based Clob implementation uses this method.", "For the record, there is another read buffer size issue that exaggerates the problem (it will probably be handled under DERBY-3769, and also DERBY-3818).", "'derby-3825-0a-preview.diff' is a preview patch.", "It is incomplete and not for commit.", "It introduces a new method for InternalClob: getInternalReader(charPos).", "The idea is to keep only one such reader per clob that can be used internally - that is not published to the user.", "The most prominent example is Clob.getSubString().", "There are two performance gains:", "1) Repositioning capabilities (see below).", "2) Less object creation (GC).", "The repositioning functionality is added to UTF8Reader, and can be split into three types - ordered after increasing cost:", "a) Reposition within current character buffer (small hops forwards and potentially backwards - in range 1 char to 8K chars)", "b) Forward stream from current position (hops forwards)", "c) Reset stream and skip data (hops backwards)", "The more I work with this, the more I feel the functionality should be pushed closer to store.", "Preview patch ready for comments.", "'derby-3825-1a-reset_readpositioninbuffer.diff' is a small cleanup patch moving the resetting of the readPositionInBuffer variable into fillBuffer.", "Committed to trunk with revision 689803.", "Patch 2a introduces an internal reader and adds repositioning logic to UTF8Reader.", "Note that I have made getInternalReader merely forward to getReader in TemporaryClob.", "I will commit the simple Clob regression tests and run it with and without this patch to document the effect.", "Regression tests passed (JDK 1.6.0, Solaris 10).", "Patch ready for review.", "Just noticed I forgot the license header in the new test.", "I'll add it in the next rev.", "I read through the patch, and it looks correct to me.", "The repositioning logic was rather complex, mainly because of the buffering and the mix of 1-based indexes on the JDBC level and 0-based indexes on the buffer level, but it looks to me as if all cases are handled correctly.", "I have also tested the patch by fetching a 32 MB CLOB with getSubString().", "Without the patch, it took so long time that I hit Ctrl-C in the end (waited for minutes).", "With the patch, it took 3-4 seconds to fetch the CLOB.", "So the patch seems to work very well!", "This was with a CLOB stored in a table.", "When I tested the same with a CLOB created by Connection.createClob(), I still observed that getSubString() took a very long time.", "I suppose this is what's meant by the TODO comment in TemporaryClob?", "I noticed a TODO that suggested that localization was going to be added in UTF8Reader.skipPersistent().", "Is this planned in a follow-up patch?", "Other places in the code, we just throw an EOFException with no message in similar situations.", "Perhaps the detailed error message could be put in a THROWASSERT() so that it is only used in debug builds?", "The class javadoc for UTF8ReaderTest says that it tests \"package-private methods in {@code UTF8Reader}.\"", "As far as I can see, it only tests the public methods of UTF8Reader.", "Patch 2b addresses the following:", "added license to UTF8ReaderTest", "changed class comment in UTF8ReaderTest", "added DEBUG block with detailed EOFException", "Regarding Knut Anders' comments (from top to bottom):", "Thanks for looking at the repositioning logic.", "It is a bit complex, but it should be pretty well tested functionally.", "Can it be optimized?", "Regarding the poor performance you observed, I need to look into it.", "I will create a new Jira for it.", "Implementing getInternalReader is one issue, but I think there are more severe problems in this code path (it is using some special reader objects).", "Hopefully the ClobAccessTest should demonstrate the problem.", "I resolved the localization issue by throwing a detailed EOFException from inside a debug block.", "I chose this over an assert, as an assert makes a test fail (expects EOFException).", "I changed the comment, it was not very precise.", "I need a package-private test because of StoreStreamClob, which is the only user of UTF8Reader.reposition at the moment and I wanted a little bit more control than what I get going through the JDBC API.", "Thanks for looking at the patch!", "Unless there are more comments on patch 2b, I expect to commit it shortly.", "Thanks for the updated patch, Kristian.", "I think it looks ready for", "commit.", "> Thanks for looking at the repositioning logic.", "It is a bit complex,", "> but it should be pretty well tested functionally.", "Can it be", "> optimized?", "I don't see how it can be optimized without changing the format, since", "random access to a lob is currently not supported by the store.", "It may perhaps be easier to read it if the call to resetUTF8Reader()", "is moved to the beginning of the method.", "Then there will be just two", "cases to consider for the repositioning: the requested position is", "either after the current position or in the buffer.", "This means that we", "don't need the nested if statements.", "Something along these lines:", "if (requestedCharPos <= readerCharCount - charactersInBuffer) {", "resetUTF8Reader();", "}", "long currentCharPos =", "readerCharCount - charactersInBuffer + readPositionInBuffer;", "long difference = (requestedCharPos - 1) - currentCharPos;", "if (difference <= 0) {", "move back in the buffer", "readPositionInBuffer += difference;", "} else {", "skip forward", "persistentSkip(difference);", "}", "Thanks again, Knut Anders.", "I committed patch 2b to trunk with revision 704547, and will look at the suggested simplification(s) in a separate patch."], "SplitGT": [" There are three types of repositioning, ordered after increasing cost: Reposition within current character buffer (small hops forwards and potentially backwards - in range 1 char to MAXIMUM_BUFFER_SIZE chars)Forward stream from current position (hops forwards) Reset stream and skip data (hops backwards)"], "issueString": "StoreStreamClob.getReader(charPos) performs poorly\nStoreStreamClob.getReader(charPos) performs poorly because it resets the underlying stream and skips data until it reached the requested character position. Not only does the data has to be skipped, it also has to be decoded (UTF-8).\nThe problem is exposed through EmbedClob.getSubString, which causes extremely bad performance for the client driver because the locator based Clob implementation uses this method.\n\nFor the record, there is another read buffer size issue that exaggerates the problem (it will probably be handled under DERBY-3769, and also DERBY-3818).\n'derby-3825-0a-preview.diff' is a preview patch. It is incomplete and not for commit.\n\nIt introduces a new method for InternalClob: getInternalReader(charPos).\nThe idea is to keep only one such reader per clob that can be used internally - that is not published to the user. The most prominent example is Clob.getSubString().\nThere are two performance gains:\n 1) Repositioning capabilities (see below).\n 2) Less object creation (GC).\n\nThe repositioning functionality is added to UTF8Reader, and can be split into three types - ordered after increasing cost:\n a) Reposition within current character buffer (small hops forwards and potentially backwards - in range 1 char to 8K chars)\n b) Forward stream from current position (hops forwards)\n c) Reset stream and skip data (hops backwards)\n\nThe more I work with this, the more I feel the functionality should be pushed closer to store.\n\nPreview patch ready for comments.\n'derby-3825-1a-reset_readpositioninbuffer.diff' is a small cleanup patch moving the resetting of the readPositionInBuffer variable into fillBuffer.\n\nCommitted to trunk with revision 689803.\nPatch 2a introduces an internal reader and adds repositioning logic to UTF8Reader.\n\nNote that I have made getInternalReader merely forward to getReader in TemporaryClob.\nI will commit the simple Clob regression tests and run it with and without this patch to document the effect.\n\nRegression tests passed (JDK 1.6.0, Solaris 10).\nPatch ready for review.\nJust noticed I forgot the license header in the new test. I'll add it in the next rev.\nI read through the patch, and it looks correct to me. The repositioning logic was rather complex, mainly because of the buffering and the mix of 1-based indexes on the JDBC level and 0-based indexes on the buffer level, but it looks to me as if all cases are handled correctly.\n\nI have also tested the patch by fetching a 32 MB CLOB with getSubString(). Without the patch, it took so long time that I hit Ctrl-C in the end (waited for minutes). With the patch, it took 3-4 seconds to fetch the CLOB. So the patch seems to work very well! This was with a CLOB stored in a table. When I tested the same with a CLOB created by Connection.createClob(), I still observed that getSubString() took a very long time. I suppose this is what's meant by the TODO comment in TemporaryClob?\n\nI noticed a TODO that suggested that localization was going to be added in UTF8Reader.skipPersistent(). Is this planned in a follow-up patch? Other places in the code, we just throw an EOFException with no message in similar situations. Perhaps the detailed error message could be put in a THROWASSERT() so that it is only used in debug builds?\n\nThe class javadoc for UTF8ReaderTest says that it tests \"package-private methods in {@code UTF8Reader}.\" As far as I can see, it only tests the public methods of UTF8Reader.\nPatch 2b addresses the following:\n - added license to UTF8ReaderTest\n - changed class comment in UTF8ReaderTest\n - added DEBUG block with detailed EOFException\n\nRegarding Knut Anders' comments (from top to bottom):\n - Thanks for looking at the repositioning logic. It is a bit complex, but it should be pretty well tested functionally. Can it be optimized?\n - Regarding the poor performance you observed, I need to look into it. I will create a new Jira for it. Implementing getInternalReader is one issue, but I think there are more severe problems in this code path (it is using some special reader objects). Hopefully the ClobAccessTest should demonstrate the problem.\n - I resolved the localization issue by throwing a detailed EOFException from inside a debug block. I chose this over an assert, as an assert makes a test fail (expects EOFException).\n - I changed the comment, it was not very precise. I need a package-private test because of StoreStreamClob, which is the only user of UTF8Reader.reposition at the moment and I wanted a little bit more control than what I get going through the JDBC API.\n\nThanks for looking at the patch!\nUnless there are more comments on patch 2b, I expect to commit it shortly.\nThanks for the updated patch, Kristian. I think it looks ready for\ncommit.\n\n> Thanks for looking at the repositioning logic. It is a bit complex,\n> but it should be pretty well tested functionally. Can it be\n> optimized?\n\nI don't see how it can be optimized without changing the format, since\nrandom access to a lob is currently not supported by the store.\n\nIt may perhaps be easier to read it if the call to resetUTF8Reader()\nis moved to the beginning of the method. Then there will be just two\ncases to consider for the repositioning: the requested position is\neither after the current position or in the buffer. This means that we\ndon't need the nested if statements. Something along these lines:\n\nif (requestedCharPos <= readerCharCount - charactersInBuffer) {\n    resetUTF8Reader();\n}\n\nlong currentCharPos =\n    readerCharCount - charactersInBuffer + readPositionInBuffer;\n\nlong difference = (requestedCharPos - 1) - currentCharPos;\n\nif (difference <= 0) {\n    // move back in the buffer\n    readPositionInBuffer += difference;\n} else {\n    // skip forward\n    persistentSkip(difference);\n}\nThanks again, Knut Anders.\n\nI committed patch 2b to trunk with revision 704547, and will look at the suggested simplification(s) in a separate patch.\n", "issueSearchSentences": ["Something along these lines:", "readerCharCount - charactersInBuffer + readPositionInBuffer;", "long currentCharPos =", "cases to consider for the repositioning: the requested position is", "Then there will be just two"], "issueSearchIndexes": [79, 84, 83, 75, 74]}
{"aId": 96, "code": "UpdateableBlobStream (EmbedBlob blob, InputStream is, long pos, long len) \n    throws IOException, SQLException {\n        this(blob, is);\n        //The length requested cannot exceed the length\n        //of the underlying Blob object. Hence chose the\n        //minimum of the length of the underlying Blob\n        //object and requested length.\n        maxPos = Math.min(blob.length(), pos + len);\n        \n        //Skip to the requested position\n        //inside the stream.\n        skip(pos);\n    }", "comment": " Construct an UpdateableBlobStream using the InputStream received as parameter. The initial position in the stream is set to pos and the stream is restricted to a length of len.", "issueId": "DERBY-2730", "issueStringList": ["Implement not implemented Embedded methods Blob.getBinaryStream(long pos, long length) and Clob.", "getCharacterStream(long pos, long length)", "The following methods were introduced in the java.sql.Clob and java.sql.Blob interface as part of JDBC 4.0 and need to be implemented.", "Clob", "getCharacterStream(long pos, long length)", "Blob", "getBinaryStream(long pos, long length)", "The implementation on the Network Client is already done as part of Derby-2444", "DERBY-2711 introduces a wrapper class UpdateableBlobStream which shall be used", "to return a subset of the underlying Blob object to the user.", "I have used the patch attached to the issue Derby-2711 to implement this patch.", "This patch", "hence contains the changes introduced by Derby-2711 also.", "Pls note that this patch is *not* for a commit.", "M      java/engine/org/apache/derby/impl/jdbc/EmbedBlob.java", "Added implementation for the getBinaryStream(long position, long length) method", "that wraps the stream returned from the getBinaryStream method inside the", "UpdateableBlobStream, using the constructor that accepts a position", "and length as parameter, to return a subset of the Blob value.", "A      java/engine/org/apache/derby/impl/jdbc/UpdateableBlobStream.java", "Added a constructor that accepts position and length as parameter.", "Modified", "the read methods to use the restriction on the position and length of the", "stream.", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/BlobTest.java", "A      java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/BlobUpdateableStreamTest.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/_Suite.java", "The other changes are related to Derby-2711", "Pls consider this patch for reviews and comments", "1) Looks fair enough, although I will not consider the review done until after DERBY-2711 is committed and a clean patch submitted.", "2) There's no explanation why Clob.getCharacterStream isn't a part of this patch.", "Thank you for the reviews and comments.", "> 1) Looks fair enough, although I will not consider the review done until after DERBY-2711 is committed and a clean patch submitted.", "The Derby-2711 changes will not exist when I submit a follow-up patch once Derby-2711", "is committed.", "You have mentioned clean patch, so I just wanted to ensure that you did", "feel unhappy with the alignment, non-presence of whit-space diffs and other general", "standard requirements of clean code.", "Pls do mention if the code is falling in  quality in any of these and", "I will correct them duly.", "> 2) There's no explanation why Clob.getCharacterStream isn't a part of this patch.", "I am sorry I should have mentioned this in the comments.", "Derby-2712 seems to be making changes to the wrapper in the same way", "Derby-2711 does.", "I could therefore not pull-out a patch as I have done in the", "case of Derby-2711 and make changes in way of a review patch since any", "changes to current classes would have had a conflict from the patch for Derby-2712.", "Can someone familiar with Derby-2712 pls tell me if the assumption I have made in the", "above comment is correct?", "I saw no white-space or layout issues.", "By \"clean patch\" in my comment, I meant a stand-alone patch independent of other non-committed changes.", "Thanks again for the comments, I shall make the changes as soon as Derby-2711 is committed and submit the patch.", "Derby-2711 has been committed.", "I have removed these changes from", "the patch previously marked as not for commit.", "I ran the modified BlobTest and it ran without failures.", "I have started a junit All run and shall revert back with", "the results.", "Pls consider this patch for reviews and comments", "The tests I had started on Saturday did not complete, I have started a", "new test run today.", "The tests seemed to be", "hanging and from the output of junit.textui.TestRunner I was not able to", "affirm which test was hanging and also", "if it was due to my change.", "I will run tests again and revert back with the results today.", "I", "Apologize for this unexpected delay.", "I just found out that there was a problem in the machine I was running", "tests.", "But I will anyway run", "tests once more today to re-affirm the that there are no problems in the", "implementation.", "Awkward first sentence in javadoc for new  UpdateableBlobStream constructor.", "The rest is ok.", "I had to initialize maxPos to -1 in the constructor of UpdateableBlobStream", "that does not accept length as parameter.", "I was planning to produce a", "follow-up", "just now.", "I will correct this issue along with the maxPos one.", "Thank you", "for", "taking a look at this.", "I have made the following changes in the follow-up", "1) I have initialized maxPos to -1 in the constructor that", "does not accept length as a parameter.", "2) I have updated the javadoc to say the following", "Construct an <code>UpdateableBlobStream<code> using the", "<code>InputStream</code> received as parameter.", "The initial", "position in the stream is set to <code>pos</code> and the", "stream is restricted to a length of <code>len</code>.", "Pls do mention if this is OK", "I ran BlobClob4BlobTest without failures and have started a junit All run.", "Sorry about the delayed test runs.", "I shall post the results as soon as the test", "completes.", "The getCharacterStream(long, long) implementation is blocked by", "the changes in Derby-2712.", "Pls note that this is only for the getCharacterStream implementation.", "I have run tests on GetBinaryStreamImpl_v2.diff and saw no failures.", "If everything is OK I request", "for this patch to be considered for a commit.", "getBinaryStream ok.", "Committed revision 546838.", "Thanks a ton for the commit Bernt !", "!", "Pls find the implementation of Clob.getCharacterStream(long, long).", "The logic", "followed is very similar to the getBinaryStream(long, long) implementation.", "I am running junit All on this patch and shall revert back with the test results.", "I ran junit All on this patch and found no failures.", "ClobUpdateableReader (EmbedClob clob, long pos, long len)  throws an SQLException but the javadoc has @throws IOException.", "Same goes for UpdateableBlobStream (i missed it in the previous review).", "Also: in both constructors (ClobUpdateableReader and UpdateableBlobStream), you do", "SQLException sqle = new SQLException();", "sqle.initCause(ioe);", "throw sqle;", "I.e.", ": an SQLException with no message and no sql state is thrown.", "I think it should have both.", "I will fix this Bernt!", "Thanx for the review.", "Thank you for the review on the patch.", "I found a clue on how to handle this from already exisiting", "usage of the other Updatable stream constructors.", "I removed the try catch in the updatable streams and", "moved them into the corresponding Lob classes where", "they were being used.", "Here I called the Util.setStreamFailure", "passing the IOException as parameter.", "I ran the jdbc4/BlobTest, jdbc4/ClobTest and jdbcapi/BlobClob4BlobTest", "and saw no failures.", "I have started a junit All run and shall revert back with results.", "Patch ok.", "Committed revision 547203.", "Thank you for the commit Bernt !", "!", "Unless I get wild protests, I will change the following line in the ClobUpdateableReader constructor as below:", "+        maxPos = Math.min(clob.length(), pos + len);", "to be simply", "maxPos = pos + len;", "The reason is that the clob.length() call can be very expensive.", "At this point, we might have already exhausted the stream two times.", "Doing it even once more is unnecessary in this case:", "First of all the check is already done in EmbedClob.getCharacterStream(long,long).", "This must be done to comply with the JDBC spec.", "Second, even if the former test was removed, ClobUpdateableReader would behave properly if maxPos turns out to be set to a value larger then the actual size of the Clob.", "The underlying stream would simply return -1, which is exactly what the maxPos variable is used for anyway.", "The change will go in with another change in a yet-to-be-created-Jira (I will create a link to it).", "I am OK with this kristian."], "SplitGT": [" Construct an UpdateableBlobStream using the InputStream received as parameter.", "The initial position in the stream is set to pos and the stream is restricted to a length of len."], "issueString": "Implement not implemented Embedded methods Blob.getBinaryStream(long pos, long length) and Clob. getCharacterStream(long pos, long length)\nThe following methods were introduced in the java.sql.Clob and java.sql.Blob interface as part of JDBC 4.0 and need to be implemented.\n\nClob\n------\n\ngetCharacterStream(long pos, long length)\n\nBlob\n------\n\ngetBinaryStream(long pos, long length)\n\nThe implementation on the Network Client is already done as part of Derby-2444\nDERBY-2711 introduces a wrapper class UpdateableBlobStream which shall be used\nto return a subset of the underlying Blob object to the user.\nI have used the patch attached to the issue Derby-2711 to implement this patch. This patch \nhence contains the changes introduced by Derby-2711 also. \n\nPls note that this patch is *not* for a commit.\n\nM      java/engine/org/apache/derby/impl/jdbc/EmbedBlob.java\n\nAdded implementation for the getBinaryStream(long position, long length) method\nthat wraps the stream returned from the getBinaryStream method inside the \nUpdateableBlobStream, using the constructor that accepts a position\nand length as parameter, to return a subset of the Blob value.\n\nA      java/engine/org/apache/derby/impl/jdbc/UpdateableBlobStream.java\n\nAdded a constructor that accepts position and length as parameter. Modified\nthe read methods to use the restriction on the position and length of the\nstream.\n\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/BlobTest.java\nA      java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/BlobUpdateableStreamTest.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/_Suite.java\n\nThe other changes are related to Derby-2711\n\nPls consider this patch for reviews and comments\n1) Looks fair enough, although I will not consider the review done until after DERBY-2711 is committed and a clean patch submitted.\n2) There's no explanation why Clob.getCharacterStream isn't a part of this patch.\nThank you for the reviews and comments.\n\n> 1) Looks fair enough, although I will not consider the review done until after DERBY-2711 is committed and a clean patch submitted. \n\nThe Derby-2711 changes will not exist when I submit a follow-up patch once Derby-2711 \nis committed. \n\nYou have mentioned clean patch, so I just wanted to ensure that you did\nfeel unhappy with the alignment, non-presence of whit-space diffs and other general\nstandard requirements of clean code. \n\nPls do mention if the code is falling in  quality in any of these and \nI will correct them duly.\n\n> 2) There's no explanation why Clob.getCharacterStream isn't a part of this patch.\n\nI am sorry I should have mentioned this in the comments. \n\nDerby-2712 seems to be making changes to the wrapper in the same way\nDerby-2711 does. I could therefore not pull-out a patch as I have done in the\ncase of Derby-2711 and make changes in way of a review patch since any\nchanges to current classes would have had a conflict from the patch for Derby-2712.\n\nCan someone familiar with Derby-2712 pls tell me if the assumption I have made in the\nabove comment is correct?\nI saw no white-space or layout issues. By \"clean patch\" in my comment, I meant a stand-alone patch independent of other non-committed changes.\nThanks again for the comments, I shall make the changes as soon as Derby-2711 is committed and submit the patch.\nDerby-2711 has been committed. I have removed these changes from\nthe patch previously marked as not for commit.\n\nI ran the modified BlobTest and it ran without failures.\n\nI have started a junit All run and shall revert back with\nthe results.\n\nPls consider this patch for reviews and comments\nThe tests I had started on Saturday did not complete, I have started a \nnew test run today. The tests seemed to be\nhanging and from the output of junit.textui.TestRunner I was not able to \naffirm which test was hanging and also\nif it was due to my change.\n\nI will run tests again and revert back with the results today. I \nApologize for this unexpected delay.\n\n\n\nI just found out that there was a problem in the machine I was running \ntests. But I will anyway run\ntests once more today to re-affirm the that there are no problems in the \nimplementation.\n\n\n\n\nAwkward first sentence in javadoc for new  UpdateableBlobStream constructor. The rest is ok.\nI had to initialize maxPos to -1 in the constructor of UpdateableBlobStream\nthat does not accept length as parameter.  I was planning to produce a \nfollow-up\njust now. I will correct this issue along with the maxPos one. Thank you \nfor\ntaking a look at this.\n\n\n\n\nI have made the following changes in the follow-up\n\n1) I have initialized maxPos to -1 in the constructor that\n     does not accept length as a parameter.\n2) I have updated the javadoc to say the following\n\n     * Construct an <code>UpdateableBlobStream<code> using the \n     * <code>InputStream</code> received as parameter. The initial\n     * position in the stream is set to <code>pos</code> and the\n     * stream is restricted to a length of <code>len</code>.\n\n     Pls do mention if this is OK\n\nI ran BlobClob4BlobTest without failures and have started a junit All run.\n\nSorry about the delayed test runs. I shall post the results as soon as the test\ncompletes.\n\nThe getCharacterStream(long, long) implementation is blocked by \nthe changes in Derby-2712.\n\nPls note that this is only for the getCharacterStream implementation.\nI have run tests on GetBinaryStreamImpl_v2.diff and saw no failures. If everything is OK I request\nfor this patch to be considered for a commit.\ngetBinaryStream ok.\nCommitted revision 546838.\n\nThanks a ton for the commit Bernt !!\n\n\n\n\nPls find the implementation of Clob.getCharacterStream(long, long). The logic\nfollowed is very similar to the getBinaryStream(long, long) implementation.\n\nI am running junit All on this patch and shall revert back with the test results.\nI ran junit All on this patch and found no failures.\n\n\n\n\nClobUpdateableReader (EmbedClob clob, long pos, long len)  throws an SQLException but the javadoc has @throws IOException. Same goes for UpdateableBlobStream (i missed it in the previous review).\n\nAlso: in both constructors (ClobUpdateableReader and UpdateableBlobStream), you do\n            SQLException sqle = new SQLException();\n            sqle.initCause(ioe);\n            throw sqle;\nI.e.: an SQLException with no message and no sql state is thrown. I think it should have both.\n\nI will fix this Bernt! Thanx for the review.\n\n\n\n\nThank you for the review on the patch. \n\nI found a clue on how to handle this from already exisiting\nusage of the other Updatable stream constructors.\n\nI removed the try catch in the updatable streams and\nmoved them into the corresponding Lob classes where\nthey were being used. Here I called the Util.setStreamFailure\npassing the IOException as parameter.\n\nI ran the jdbc4/BlobTest, jdbc4/ClobTest and jdbcapi/BlobClob4BlobTest\nand saw no failures.\n\nI have started a junit All run and shall revert back with results.\nPatch ok.\nCommitted revision 547203.\n\nThank you for the commit Bernt !!\n\n\n\n\nUnless I get wild protests, I will change the following line in the ClobUpdateableReader constructor as below:\n+        maxPos = Math.min(clob.length(), pos + len);\nto be simply\n           maxPos = pos + len;\n\nThe reason is that the clob.length() call can be very expensive. At this point, we might have already exhausted the stream two times. Doing it even once more is unnecessary in this case:\n * First of all the check is already done in EmbedClob.getCharacterStream(long,long). This must be done to comply with the JDBC spec.\n * Second, even if the former test was removed, ClobUpdateableReader would behave properly if maxPos turns out to be set to a value larger then the actual size of the Clob. The underlying stream would simply return -1, which is exactly what the maxPos variable is used for anyway.\n\nThe change will go in with another change in a yet-to-be-created-Jira (I will create a link to it).\nI am OK with this kristian.\n\n\n\n", "issueSearchSentences": ["getCharacterStream(long pos, long length)", "DERBY-2711 introduces a wrapper class UpdateableBlobStream which shall be used", "Unless I get wild protests, I will change the following line in the ClobUpdateableReader constructor as below:", "UpdateableBlobStream, using the constructor that accepts a position", "Implement not implemented Embedded methods Blob.getBinaryStream(long pos, long length) and Clob."], "issueSearchIndexes": [5, 9, 140, 18, 1]}
{"aId": 101, "code": "public int getJDBCMajorVersion() throws SQLException {\n        checkForClosedConnection();\n        return 4;\n    }", "comment": " Retrieves the major JDBC version number for this driver.", "issueId": "DERBY-1546", "issueStringList": ["Derby JDBC 4.0 driver returns 3 for JDBC driver major version", "For 10.2 the DatabaseMetaData.getJDBCMajorVersion() is returning \"3\" for", "the Derby JDBC 4.0 driver.", "It should return 4.", "This is easily", "reproduced by running a simple test to obtain a connection and", "output the value,", "Database product: Apache Derby", "Database version: 10.2.0.4 alpha", "Driver name:      Apache Derby Embedded JDBC Driver", "Driver version:   10.2.0.4 alpha", "JDBC driver major version: 3", "JDBC driver minor version: 0", "Test code:", "org.apache.derby.jdbc.EmbeddedConnectionPoolDataSource40 ds =", "new", "org.apache.derby.jdbc.EmbeddedConnectionPoolDataSource40();", "ds.setDatabaseName(\"C:\\\\drivers\\\\derby\\\\databases\\\\JDBC40DB\");", "ds.setUser(\"dbuser1\");", "ds.setPassword(\"dbpwd1\");", "PooledConnection pooledConn =", "ds.getPooledConnection();", "Connection conn = pooledConn.getConnection();", "System.out.println(\"Database product: \" +", "conn.getMetaData().getDatabaseProductName());", "System.out.println(\"Database version: \" +", "conn.getMetaData().getDatabaseProductVersion());", "System.out.println(\"Driver name:      \" +", "conn.getMetaData().getDriverName());", "System.out.println(\"Driver version:   \" +", "conn.getMetaData().getDriverVersion());", "System.out.println(\"JDBC driver major version: \" +", "conn.getMetaData().getJDBCMajorVersion());", "System.out.println(\"JDBC driver minor version: \" +", "conn.getMetaData().getJDBCMinorVersion());", "Relevant Derby Embedded code in EmbedDatabaseMetaData is:", "JDBC 3.0", "Retrieves the major JDBC version number for this driver.", "@return JDBC version major number", "public int getJDBCMajorVersion()", "{", "return 3;", "}", "and client code in org.apache.derby.client.am.DatabaseMetaData:", "public int getJDBCMajorVersion() throws SQLException {", "checkForClosedConnection();", "return 3;", "}", "I am not sure if this should be JVM dependent or if it should always return 4  regardless of the JVM version.", "This is the correct behavior if you are running on jvm 1.4 or 1.5.", "If you are running on 1.6, the major version should be 4.", "It isn't, so this is a bug.", "derby-1546-v1.diff makes getJDBCMajorVersion() return 4 when using the", "JDBC 4.0 driver and 3 otherwise (the method was not present in JDBC", "2.0, so there is no need to return 2 for the 2.0 driver).", "Description of the changes:", "EmbedDatabaseMetaData40 and NetDatabaseMetaData40 override", "getJDBCMajorVersion() and getJDBCMinorVersion().", "jdbcapi/dbMetaDataJdbc30.java was modified to print \"AS EXPECTED\"", "instead of the returned value from the JDBC version methods (of", "course, it prints something else if the version is not as", "expected).", "This was done in order to avoid the need for separate", "jdk16 canons.", "TestUtil.getJDBCMajorVersion() was updated to recognize JDBC major", "version > 3.", "Fixed a bug in build.xml in functionTests/util.", "TestUtil.java is", "incorrectly compiled with source and target level 1.4.", "It works", "correctly after an 'ant clobber' because some other 1.3 class", "depends on it and causes it to be compiled as part of another ant", "target, but if TestUtil.java is the only file that needs", "recompilation, jdk 1.4 is used.", "Derbyall runs cleanly (with the exception of the DERBY-1578 failures)", "on Sun JVM 1.5 and 1.6.", "Reviews would be greatly appreciated!", "Thanks.", "Hi Knut Anders.", "Thanks for the ample explanation of the changes.", "They look good to me.", "Thank you for looking at the patch, Rick.", "Committed revision 425987."], "SplitGT": [" Retrieves the major JDBC version number for this driver."], "issueString": "Derby JDBC 4.0 driver returns 3 for JDBC driver major version\nFor 10.2 the DatabaseMetaData.getJDBCMajorVersion() is returning \"3\" for \nthe Derby JDBC 4.0 driver.  It should return 4.  This is easily \nreproduced by running a simple test to obtain a connection and \noutput the value,\n\nDatabase product: Apache Derby\nDatabase version: 10.2.0.4 alpha\nDriver name:      Apache Derby Embedded JDBC Driver\nDriver version:   10.2.0.4 alpha\nJDBC driver major version: 3\nJDBC driver minor version: 0\n\nTest code:\n\n        \norg.apache.derby.jdbc.EmbeddedConnectionPoolDataSource40 ds =\n            new \norg.apache.derby.jdbc.EmbeddedConnectionPoolDataSource40();\n\n        \nds.setDatabaseName(\"C:\\\\drivers\\\\derby\\\\databases\\\\JDBC40DB\");\n\n        ds.setUser(\"dbuser1\");\n        ds.setPassword(\"dbpwd1\");\n\n        PooledConnection pooledConn = \nds.getPooledConnection();\n        Connection conn = pooledConn.getConnection();\n\n        System.out.println(\"Database product: \" + \nconn.getMetaData().getDatabaseProductName());\n        System.out.println(\"Database version: \" + \nconn.getMetaData().getDatabaseProductVersion());\n        System.out.println(\"Driver name:      \" + \nconn.getMetaData().getDriverName());\n        System.out.println(\"Driver version:   \" + \nconn.getMetaData().getDriverVersion());\n        System.out.println(\"JDBC driver major version: \" + \nconn.getMetaData().getJDBCMajorVersion());\n        System.out.println(\"JDBC driver minor version: \" + \nconn.getMetaData().getJDBCMinorVersion());\n\n\nRelevant Derby Embedded code in EmbedDatabaseMetaData is:\n * JDBC 3.0\n    *\n    * Retrieves the major JDBC version number for this driver.\n    *\n    * @return JDBC version major number\n\t*/\n\tpublic int getJDBCMajorVersion()\n\t{\n\t\treturn 3;\n\t}\n\nand client code in org.apache.derby.client.am.DatabaseMetaData:\npublic int getJDBCMajorVersion() throws SQLException {\n        checkForClosedConnection();\n        return 3;\n    }\n\nI am not sure if this should be JVM dependent or if it should always return 4  regardless of the JVM version.\n\n\nThis is the correct behavior if you are running on jvm 1.4 or 1.5.\n\nIf you are running on 1.6, the major version should be 4. It isn't, so this is a bug.\nderby-1546-v1.diff makes getJDBCMajorVersion() return 4 when using the\nJDBC 4.0 driver and 3 otherwise (the method was not present in JDBC\n2.0, so there is no need to return 2 for the 2.0 driver).\n\nDescription of the changes:\n\n  * EmbedDatabaseMetaData40 and NetDatabaseMetaData40 override\n    getJDBCMajorVersion() and getJDBCMinorVersion().\n\n  * jdbcapi/dbMetaDataJdbc30.java was modified to print \"AS EXPECTED\"\n    instead of the returned value from the JDBC version methods (of\n    course, it prints something else if the version is not as\n    expected). This was done in order to avoid the need for separate\n    jdk16 canons.\n\n  * TestUtil.getJDBCMajorVersion() was updated to recognize JDBC major\n    version > 3.\n\n  * Fixed a bug in build.xml in functionTests/util. TestUtil.java is\n    incorrectly compiled with source and target level 1.4. It works\n    correctly after an 'ant clobber' because some other 1.3 class\n    depends on it and causes it to be compiled as part of another ant\n    target, but if TestUtil.java is the only file that needs\n    recompilation, jdk 1.4 is used.\n\nDerbyall runs cleanly (with the exception of the DERBY-1578 failures)\non Sun JVM 1.5 and 1.6. Reviews would be greatly appreciated! Thanks.\nHi Knut Anders. Thanks for the ample explanation of the changes. They look good to me.\nThank you for looking at the patch, Rick. Committed revision 425987.\n", "issueSearchSentences": ["and client code in org.apache.derby.client.am.DatabaseMetaData:", "@return JDBC version major number", "public int getJDBCMajorVersion() throws SQLException {", "{", "checkForClosedConnection();"], "issueSearchIndexes": [44, 39, 45, 41, 46]}
{"aId": 106, "code": "public synchronized Collection values() {\n\t\tArrayList al = new ArrayList();\n\t\tfor (Iterator i = cache_.values().iterator(); i.hasNext();){\n\t\t\tal.add(((CachedItem)i.next()).getEntry());\n\t\t}\n\t\treturn al;\n\t}", "comment": " Return a Collection of the Cacheables currently in the cache.", "issueId": "DERBY-2114", "issueStringList": ["Let Clock embed a HashMap rather than inherit from Hashtable", "Clock currently inherits from Hashtable, but the use of Hashtable is really an implementation detail that would benefit from being hidden as private member.", "All access to the hashtable happens inside sychronized blocks so it is safe to substitute a HashMap.", "This change appears to trigger a small increase in throughput, as measured by the average TPS number obtained by running the select client from DERBY-1961 repeatedly.", "When comparing the average of 7 100 sec runs  against trunk (r478151) I see 2% improvement in throughput:", "Trunk: 23094.577 TPS", "Patch: 23563.977 TPS (+2.032%)", "Unfortunately, it was not so easy.", "The VTI interface needs to cast Clock to Hashtable, so with the change one gets a ClassCast exception in some tests.", "Closing this issue since the fix had unexpected side effects.", "Reopening this issue since I now have an idea about how to solve the VTI problem.", "The real problem was not really related to VTIs, but to the implementation of StatementCache.", "Its constructor looks up the LanguageConnectionContext's statementCache which is of type CacheManager, and implemented by Clock.", "Since the CacheManager interface doesn't support iteration over the elements of the cache, a hack has been introduced here.", "The knowledge that a CacheManager really is a Clock AND that Clock extends Hashtable is used to cast lcc.statementCache to Hashtable.", "This Hashtable is then used to do the iteration.", "However, this hack defeats the purpose of having the CacheManager interface since it creates a solid unwanted dependency between the implementation of StatementCache and the implementation of Clock.", "If iteration is to be allowed it is better to extend the CacheManager interface with the necessary methods (They can't simply be added to Clock, since StatementCache isn't allowed to downcast to Clock  which isn't public in its package.)", "Attaching a patch (v1) for this.", "derbyall and suites.All pass.", "Please review.", "The patch generally looks good.", "I verified that the unsynchronized HashMap methods were called either from the inside of a block synchronized on the Clock object or from a method whose javadoc said the caller should be synchronized on Clock.", "The only exception was the new Clock.values() method, which requires the caller to be synchronized but doesn't say so in its javadoc.", "Perhaps you could add a comment about it in the javadoc?", "I was wondering whether it would be better if the new values() method returned a copy of the values in the cache.", "The reason is this code in diag.StatementCache's constructor:", "+\t\t\tsynchronized(lcc.statementCache) {", "+\t\t\t\tfinal Collection values = lcc.statementCache.values();", "+\t\t\t\tdata = new Vector(values.size());", "+\t\t\t\tfor (Iterator i = values.iterator(); i.hasNext(); ) {", "+\t\t\t\t\tCachedItem ci = (CachedItem) i.next();", "+\t\t\t\t\tCachedStatement cs = (CachedStatement) ci.getEntry();", "+\t\t\t\t\tGenericPreparedStatement ps = (GenericPreparedStatement)", "+\t\t\t\t\t\tcs.getPreparedStatement();", "+\t\t\t\t\tdata.addElement(ps);", "+\t\t\t\t}", "+\t\t\t} // synchronized(lcc.statementCache)", "By requiring the caller to synchronize on the Clock object, I feel that we are exposing an implementation detail that could be hidden.", "If we return a copy, the synchronization could be done inside values() instead.", "Since it is only used in a diagnostic VTI, I don't think the extra cost of creating a shallow copy should be a problem.", "Sounds like a good idea.", "Well, honestly I've not considered how well StatementCache was", "implemented, as this wasn't my itch.", "That said, I'm sure a lot could", "be done.", "But why create two copies?", "Why not just return a Vector of", "PreparedStatements directly, then?", "dt", "> Well, honestly I've not considered how well StatementCache was implemented, as this wasn't my itch.", "This is not so much about the implementation of StatementCache.", "My worry is that by requiring the callers of CacheManager.values() to synchronize on the CacheManager and hold the synchronization while traversing the returned collection, it will be harder to replace Clock with another implementation of CacheManager later because the interface implicitly dictates how the internal synchronization must be implemented.", "If someone wants to rewrite the cache manager, say, to allow threads to enter it concurrently, she couldn't just implement the interface and plug in the new implementation since the interface required that there was a global synchronization point.", "> But why create two copies?", "Why not just return a Vector of PreparedStatements directly, then?", "That's possible, but I'm not sure it's a good idea to introduce a dependency from CacheManager/Clock to PreparedStatement.", "Since this is diagnostic code, I wouldn't worry too much about copying it twice.", "Keeping the interface cleaner is more important in this case, I think.", "By the way, if we make values() return a copy, I think it is better if it returns a collection of Cacheables instead of a collection of CachedItems, since Cacheable is iapi and CachedItem is impl.", "(Actually, I think the use in diag.StatementCache is the only reason why CachedItem is public and not package private.)", "New patch, v2.", "suites.All pass.", "Thank you for addressing my comments!", "There is one thing I missed in the previous review:", "+\tpublic boolean containsKey(Object k) {", "+\t\tsynchronized(cache_) {", "+\tpublic Collection values() {", "+\t\tsynchronized (cache_) {", "I believe these two methods should have been synchronized on this, not on cache_.", "I have made that change to the patch and started the regression tests.", "Will commit if the tests don't fail.", "Committed revision 519644."], "SplitGT": [" Return a Collection of the Cacheables currently in the cache."], "issueString": "Let Clock embed a HashMap rather than inherit from Hashtable\nClock currently inherits from Hashtable, but the use of Hashtable is really an implementation detail that would benefit from being hidden as private member. All access to the hashtable happens inside sychronized blocks so it is safe to substitute a HashMap. This change appears to trigger a small increase in throughput, as measured by the average TPS number obtained by running the select client from DERBY-1961 repeatedly.\nWhen comparing the average of 7 100 sec runs  against trunk (r478151) I see 2% improvement in throughput:\n\nTrunk: 23094.577 TPS\nPatch: 23563.977 TPS (+2.032%)\n\n\n\nUnfortunately, it was not so easy. The VTI interface needs to cast Clock to Hashtable, so with the change one gets a ClassCast exception in some tests. \nClosing this issue since the fix had unexpected side effects.\nReopening this issue since I now have an idea about how to solve the VTI problem. \n\nThe real problem was not really related to VTIs, but to the implementation of StatementCache. Its constructor looks up the LanguageConnectionContext's statementCache which is of type CacheManager, and implemented by Clock. Since the CacheManager interface doesn't support iteration over the elements of the cache, a hack has been introduced here. The knowledge that a CacheManager really is a Clock AND that Clock extends Hashtable is used to cast lcc.statementCache to Hashtable. This Hashtable is then used to do the iteration. However, this hack defeats the purpose of having the CacheManager interface since it creates a solid unwanted dependency between the implementation of StatementCache and the implementation of Clock. \n\nIf iteration is to be allowed it is better to extend the CacheManager interface with the necessary methods (They can't simply be added to Clock, since StatementCache isn't allowed to downcast to Clock  which isn't public in its package.) \nAttaching a patch (v1) for this. derbyall and suites.All pass. Please review.\nThe patch generally looks good. I verified that the unsynchronized HashMap methods were called either from the inside of a block synchronized on the Clock object or from a method whose javadoc said the caller should be synchronized on Clock. The only exception was the new Clock.values() method, which requires the caller to be synchronized but doesn't say so in its javadoc. Perhaps you could add a comment about it in the javadoc?\n\nI was wondering whether it would be better if the new values() method returned a copy of the values in the cache. The reason is this code in diag.StatementCache's constructor:\n+\t\t\tsynchronized(lcc.statementCache) {\n+\t\t\t\tfinal Collection values = lcc.statementCache.values();\n+\t\t\t\tdata = new Vector(values.size());\n+\t\t\t\tfor (Iterator i = values.iterator(); i.hasNext(); ) {\n+\t\t\t\t\tCachedItem ci = (CachedItem) i.next();\n+\t\t\t\t\tCachedStatement cs = (CachedStatement) ci.getEntry();\n+\t\t\t\t\tGenericPreparedStatement ps = (GenericPreparedStatement) \n+\t\t\t\t\t\tcs.getPreparedStatement();\n+\t\t\t\t\tdata.addElement(ps);\n+\t\t\t\t}\n+\t\t\t} // synchronized(lcc.statementCache)\n\nBy requiring the caller to synchronize on the Clock object, I feel that we are exposing an implementation detail that could be hidden. If we return a copy, the synchronization could be done inside values() instead. Since it is only used in a diagnostic VTI, I don't think the extra cost of creating a shallow copy should be a problem.\n\n\nSounds like a good idea.\n\n\nWell, honestly I've not considered how well StatementCache was\nimplemented, as this wasn't my itch. That said, I'm sure a lot could\nbe done. But why create two copies? Why not just return a Vector of\nPreparedStatements directly, then?\n\n-- \ndt\n\n> Well, honestly I've not considered how well StatementCache was implemented, as this wasn't my itch.\nThis is not so much about the implementation of StatementCache. My worry is that by requiring the callers of CacheManager.values() to synchronize on the CacheManager and hold the synchronization while traversing the returned collection, it will be harder to replace Clock with another implementation of CacheManager later because the interface implicitly dictates how the internal synchronization must be implemented. If someone wants to rewrite the cache manager, say, to allow threads to enter it concurrently, she couldn't just implement the interface and plug in the new implementation since the interface required that there was a global synchronization point.\n\n> But why create two copies? Why not just return a Vector of PreparedStatements directly, then?\nThat's possible, but I'm not sure it's a good idea to introduce a dependency from CacheManager/Clock to PreparedStatement. Since this is diagnostic code, I wouldn't worry too much about copying it twice. Keeping the interface cleaner is more important in this case, I think.\n\nBy the way, if we make values() return a copy, I think it is better if it returns a collection of Cacheables instead of a collection of CachedItems, since Cacheable is iapi and CachedItem is impl. (Actually, I think the use in diag.StatementCache is the only reason why CachedItem is public and not package private.)\nNew patch, v2. suites.All pass.\nThank you for addressing my comments! There is one thing I missed in the previous review:\n\n+\tpublic boolean containsKey(Object k) {\n+\t\tsynchronized(cache_) {\n\n+\tpublic Collection values() {\n+\t\tsynchronized (cache_) {\n\nI believe these two methods should have been synchronized on this, not on cache_. I have made that change to the patch and started the regression tests. Will commit if the tests don't fail.\nCommitted revision 519644.\n", "issueSearchSentences": ["+\t\t\t\tdata = new Vector(values.size());", "+\t\tsynchronized(cache_) {", "+\t\t\tsynchronized(lcc.statementCache) {", "+\tpublic boolean containsKey(Object k) {", "+\tpublic Collection values() {"], "issueSearchIndexes": [30, 67, 28, 66, 68]}
{"aId": 113, "code": "public StringDataValue getValue(RuleBasedCollator collatorForComparison)\n\t{\n\t\tif (collatorForComparison != null)\n\t\t{\n\t\t\t//non-null collatorForComparison means use this collator sensitive\n\t\t\t//implementation of SQLClob\n\t\t    setCollator(collatorForComparison);\n\t\t    return this;\t\t\t\n\t\t} else {\n\t\t\t//null collatorForComparison means use UCS_BASIC for collation.\n\t\t\t//For that, we need to use the base class SQLClob\n\t\t\tSQLClob s = new SQLClob();\n\t\t\ts.copyState(this);\n\t\t\treturn s;\n\t\t}\n\t}", "comment": " We do not anticipate this method on collation sensitive DVD to be ever called in Derby 10.3 In future, when Derby will start supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs.", "issueId": "DERBY-2534", "issueStringList": ["Add new api \"public StringDataValue getValue(RuleBasedCollator)\" on StringDataValue.", "This method will return either the base DVDs for char datatypes or it will return collation sensitive DVD for char datatypes.", "In Derby 10.3, the collation of char datatypes can be different depending on what kind of collation is requested by the user at the database create time through the optional JDBC url attribute COLLATION.", "The collation type associated with the DTD will determine which kind of DVD needs to be generated.", "(Note that, irrespective of what collation is used, the format id of the char datatypes remain same.)", "In order to support this behavior of generating the base DVD or the collation sensitive DVD for character datatypes, we need to add a new api to StringDataValue which will look as follows", "Gets either SQLChar/SQLVarchar/SQLLongvarchar/SQLClob(base classes) or", "CollatorSQLChar/CollatorSQLVarchar/CollatorSQLLongvarch/CollatorSQLClob", "(subclasses).", "Whether this method returns the base class or the subclass", "depends on the value of the RuleBasedCollator.", "If RuleBasedCollator is", "null, then the object returned would be baseclass otherwise it would be", "subcalss.", "public StringDataValue getValue(RuleBasedCollator collatorForComparison);", "I am attaching a patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt to this Jira entry which I plan to commit soon.", "The patch adds a new api to StringDataValue interface and the new api looks as follows", "public StringDataValue getValue(RuleBasedCollator collatorForComparison);", "The new api will be needed in quite a few different places.", "2 distinct uses that I can see at this point are", "1)Store will have a format id and collation type when it is trying to construct a DVD template.", "Using the formatid, we will first always get the base class DVD for char datatypes namely SQLChar, SQLVarchar, SQLLongvarchar or SQLClob.", "Next, if the collation type is not 0  ie it is not UCS_BASIC, then we want to use Collation sensitive DVDs of base char DVDs because we want to use the passed Collator for collation rather than the default UCS_BASIC Collator.", "The collation sensitive DVDs of char datatypes are CollatorSQLChar, CollatorSQLVarchar, CollatorSQLLongvarchar and CollatorSQLClob.", "In order to derive these collation sensitive DVDs of character datatypes, we will use this new api called getValue on base character DVDs.", "The getValue method will have the Collator object as parameter to it.", "If the Collator object is null, then we can continue to use the base DVD.", "But if the Collator object is not null, then we want to construct collation sensitive DVD.", "The new api on StringDataValue will help achieve this behavior.", "2)Another place which I can envision using this new api is in DataTypeDescriptor.getNull() method which returns a DVD.", "Currently, the implementation of this method looks as follows", "public DataValueDescriptor getNull() {", "return typeId.getNull();", "}", "So, if the typeid of DTD is character data type, this method will always return base char DVD, no matter what is the collation type of the DTD.", "But, if the DTD has a territory based collation set for it, then this method should return collation sensitive char DVD.", "This functionality can be achieved by using the new api on StringDataValue.", "I do not anticipate this new method ever getting called on collation sensitive DVDs in Derby 10.3 In future, when Derby will start  supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs but for Derby 10.3, the new api in collation sensitive DVDs is just a place holder.", "Another change to note is I changed all the collation sensitive subclasses to have their method setCollator changed from private to protected.", "This is so that the getValue method from their correspoding base classes can call the setCollator method on subclasses.", "The files changed by this patch are", "svn stat -q", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLLongvarchar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\StringDataValue.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLChar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLClob.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLVarchar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLChar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLClob.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLVarchar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLLongvarchar.java", "The code compiles ok with my changes.", "None of the tests should get impacted because currently, this new api on StringDataValue is  not called by any other code in Derby.", "Just commited the patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt with revision 526668.", "If anyone has any feedback, please share them.", "I will address them in subsequent patches."], "SplitGT": [" We do not anticipate this method on collation sensitive DVD to be ever called in Derby 10.3 In future, when Derby will start supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs."], "issueString": "Add new api \"public StringDataValue getValue(RuleBasedCollator)\" on StringDataValue. This method will return either the base DVDs for char datatypes or it will return collation sensitive DVD for char datatypes.\nIn Derby 10.3, the collation of char datatypes can be different depending on what kind of collation is requested by the user at the database create time through the optional JDBC url attribute COLLATION. The collation type associated with the DTD will determine which kind of DVD needs to be generated. (Note that, irrespective of what collation is used, the format id of the char datatypes remain same.) In order to support this behavior of generating the base DVD or the collation sensitive DVD for character datatypes, we need to add a new api to StringDataValue which will look as follows\n\n\t/**\n\t * Gets either SQLChar/SQLVarchar/SQLLongvarchar/SQLClob(base classes) or \n\t * CollatorSQLChar/CollatorSQLVarchar/CollatorSQLLongvarch/CollatorSQLClob\n\t * (subclasses). Whether this method returns the base class or the subclass \n\t * depends on the value of the RuleBasedCollator. If RuleBasedCollator is \n\t * null, then the object returned would be baseclass otherwise it would be \n\t * subcalss.\n\t */\n\tpublic StringDataValue getValue(RuleBasedCollator collatorForComparison);\n\nI am attaching a patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt to this Jira entry which I plan to commit soon. The patch adds a new api to StringDataValue interface and the new api looks as follows\npublic StringDataValue getValue(RuleBasedCollator collatorForComparison);\n\nThe new api will be needed in quite a few different places. 2 distinct uses that I can see at this point are\n1)Store will have a format id and collation type when it is trying to construct a DVD template. Using the formatid, we will first always get the base class DVD for char datatypes namely SQLChar, SQLVarchar, SQLLongvarchar or SQLClob. Next, if the collation type is not 0  ie it is not UCS_BASIC, then we want to use Collation sensitive DVDs of base char DVDs because we want to use the passed Collator for collation rather than the default UCS_BASIC Collator. The collation sensitive DVDs of char datatypes are CollatorSQLChar, CollatorSQLVarchar, CollatorSQLLongvarchar and CollatorSQLClob. In order to derive these collation sensitive DVDs of character datatypes, we will use this new api called getValue on base character DVDs. The getValue method will have the Collator object as parameter to it. If the Collator object is null, then we can continue to use the base DVD. But if the Collator object is not null, then we want to construct collation sensitive DVD. The new api on StringDataValue will help achieve this behavior.\n2)Another place which I can envision using this new api is in DataTypeDescriptor.getNull() method which returns a DVD. Currently, the implementation of this method looks as follows\n\tpublic DataValueDescriptor getNull() {\n\t\treturn typeId.getNull();\n\t}\nSo, if the typeid of DTD is character data type, this method will always return base char DVD, no matter what is the collation type of the DTD. But, if the DTD has a territory based collation set for it, then this method should return collation sensitive char DVD. This functionality can be achieved by using the new api on StringDataValue.\n\nI do not anticipate this new method ever getting called on collation sensitive DVDs in Derby 10.3 In future, when Derby will start  supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs but for Derby 10.3, the new api in collation sensitive DVDs is just a place holder.\n\nAnother change to note is I changed all the collation sensitive subclasses to have their method setCollator changed from private to protected. This is so that the getValue method from their correspoding base classes can call the setCollator method on subclasses.\n\nThe files changed by this patch are\nsvn stat -q\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLLongvarchar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\StringDataValue.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLChar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLClob.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLVarchar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLChar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLClob.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLVarchar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLLongvarchar.java\n\nThe code compiles ok with my changes. None of the tests should get impacted because currently, this new api on StringDataValue is  not called by any other code in Derby.\n\nJust commited the patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt with revision 526668. If anyone has any feedback, please share them. I will address them in subsequent patches.\n", "issueSearchSentences": ["subcalss.", "The patch adds a new api to StringDataValue interface and the new api looks as follows", "The getValue method will have the Collator object as parameter to it.", "Using the formatid, we will first always get the base class DVD for char datatypes namely SQLChar, SQLVarchar, SQLLongvarchar or SQLClob.", "Add new api \"public StringDataValue getValue(RuleBasedCollator)\" on StringDataValue."], "issueSearchIndexes": [14, 17, 26, 22, 1]}
{"aId": 116, "code": "public static short getUpgradedSecurityMechanism(String password) {\n        // if password is null, in that case the only acceptable security \n        // mechanism is USRIDONL, which is the default security mechanism. \n        if ( password == null )\n            return propertyDefault_securityMechanism;\n\n        // if password is available, then a security mechanism is picked in following\n        // order if support is available\n        // 1. EUSRIDPWD\n        // 2. USRIDPWD\n        // when we have support for more security mechanisms on server \n        // and client, we should update this upgrade logic to pick \n        // secure security mechanisms before trying out the USRIDPWD\n        \n        if (SUPPORTS_EUSRIDPWD)\n            return (short)NetConfiguration.SECMEC_EUSRIDPWD;\n        else \n            return (short)NetConfiguration.SECMEC_USRIDPWD;\n    }", "comment": " This method has logic to upgrade security mechanism to a better (more secure) one if it is possible. Currently derby server only has support for USRIDPWD,USRIDONL, EUSRIDPWD and this method only considers these possibilities. USRIDPWD, EUSRIDPWD require a password, USRIDONL is the only security mechanism which does not require password. 1. if password is not available, then security mechanism possible is USRIDONL 2. if password is available, if client supports EUSRIDPWD, then EUSRIDPWD is returned 3. if password is available, if client does not support EUSRIDPWD, then USRIDPWD is returned.", "issueId": "DERBY-962", "issueStringList": ["Upgrade default security mechanism in client to use encrypted userid password if client can support it.", "Currently in the client, if userid and password are set in the connection url, the default security mechanism is upgraded to USRIDPWD (which is clear text userid and password).", "This seems to be a security hole here.", "Current client  driver supports encrypted userid/password (EUSRIDPWD) via the use of DH key-agreement protocol - however current Open Group DRDA specifications imposes small prime and base generator values (256 bits) that prevents other JCE's  (apt from ibm jce) to be used as java cryptography providers.", "Some thoughts:", "client can make a check to see if it the jvm it is running in supports the encryption necessary for EUSRIDPWD.", "If it supports, then the client can upgrade to EUSRIDPWD.", "if the jvm the client is running is , doesnt support encryption requirements for EUSRIDPWD, then the security mechanism will be set to USRIDPWD.", "DERBY-528 will add support for strong userid and password which is another option to send encrypted passwords across the wire.", "When this gets added, maybe this can be considered as one of the upgrade options after EUSRIDPWD.", "The current behavior even if the security mechanism is explicitly set in the connection url, the upgrade is done--  should this happen.", "I think we should not upgrade (override) if user has explicitly set the security mechanism.", "Thoughts ?", "see ClientBaseDataSource# getUpgradedSecurityMechanism()  for code where the upgrade from USRIDONL to USRIDPWD is done.", "I agree, Sunitha.", "If the user says something like:", "connect 'jdbc:derby://localhost:1527/testdb;create=true;securityMechanism=4;user=bryan;password=bryan';", "we should not quietly change the securityMechanism to 3 and quietly send the password in the clear.", "That's a bad default to have.", "The user has given us conflicting information, and we should ask them to either change the securityMechanism to one which supports a password, or remove the password.", "I can see the appeal of quietly upgrading to a secure securityMechanism (one which doesn't expose the password over the wire), but in general my preference would be to give them an error saying that their request is ambiguous, rather than trying to guess what sort of alternate securityMechanism they may have wanted.", "I just started looking at this issue on how to know if the jvm in which the client is running can support encrypted userid and password mechanism or not;  to decide if we can upgrade the default security mechanism.", "I wanted to share some thoughts I have, so I could get early feedback from the list.", "Current client  driver supports encrypted userid/password (EUSRIDPWD) via the use of DH key-agreement protocol - however current Open Group DRDA specifications imposes small prime and base generator values (256 bits) that prevents other JCE's  (apt from ibm jce) to be used as java cryptography providers.", "org.apache.derby.client.am.EncryptionManager (EM) constructor is responsible for instantiating the appropriate Provider and the KeyPairGenerator.", "The Sun JCE throws java.security.InvalidAlgorithmParameterException exception when trying to use the 256bits prime.", "I think we can conclude if the EM throws an exception, then the JCE doesnt support the required algorithms.", "=> An exception from this constructor indicates that it is not possible to use encrypted userid/password.", "The next step seems to me to decide where to put the call to new EncryptionManager(EM)", "#A.Put in static initializer block in ClientBaseDataSource and store the result in a static variable.", "The ClientBaseDataSource seems to be place where all the url attribute values' gets and sets methods are present.", "Also the upgrade logic for the security mechanism is in this class.", "something like:", "static boolean SUPPORTS_EUSRIDPWD = false;", "static", "{", "try", "{", "new org.apache.derby.client.am.EncryptionManager(null);", "SUPPORTS_EUSRIDPWD = true;", "}catch(Exception e)", "{", "ignore", "}", "}", "#B.", "Another place this check could go was in the ClientDriver itself since this will be loaded  in the JVM.", "In the static initializer of ClientDriver, new of EM can be done to check if it will go through OK.", "If so, a static 'protected' variable in ClientDriver can be used to store the state that the driver supports the algorithms required for encrypted userid/password.", "1.", "Are there any issues with adding code to the static initializer block of the Client Driver.", "I see the following comment in ClientDriver which sounds a little scary to me.", "static {", "This may possibly hit the race-condition bug of java 1.1.", "The Configuration static clause should execute before the following line does.", "if (Configuration.exceptionsOnLoadResources != null) {", "......", "}", "I can see that the Configuration static initializer needs to run before the access to the static variable Configuration.exceptionsOnLoadResources.", "I'm curious and would like to look at it sometime.", "If someone could point me to some reference of this bug, I'd be grateful.", "I googled but didnt find any related to the static intializer blocks.", "#C Explicitly check the jvm and decide.", "Not a good way for e.g.", "if SunJCE supports the DH with 256 bits prime some day, we would have to remember to remove this check that disables encrypted userid/password for this particular JVM.", "I like #A because it seems clean.", "What do others think ?", "Comments/Thoughts.", "Thanks much,", "Sunitha.", "Table with combinations of userid/password/security mechanism and what client sends to the server.", "Uploading now, so I can include this link in the testcase comment..", "This patch 'Derby962.forreview.diff.txt' is a patch for review.", "This patch needs derby 1080 for it to work.", "Also there is one testfile which is common between the derby-1080 and this patch and hence it is likely this patch may not apply cleanly once derby1080 gets reviewed and committed.", "I generated the diff keeping the changes of derby1080 for the test file (derbynet/testSecMec.java).", "This patch 'Derby962.forreview.diff.txt' improves the upgrade security mechanism logic to do the following.", "1.", "If securityMechanism is explicitly specified in the connection request then client will not override it.", "2.", "Dynamically figure out if the jvm in which the client is loaded, supports encrypted userid and", "password security (EUSRIDPWD) or not and use this information to upgrade to a more secure default", "security mechanism.", "3.", "Thus if user has not specified the security mechanism, in that case the client will try to see if", "it can upgrade the security mechanism and use the new upgraded security mechanism for connection to the server.", "Logic in ClientBaseDataSource#getUpgradedSecurityMechanism()", "+     * This method has logic to upgrade security mechanism to a better (more secure) one", "+     * if it is possible.", "Currently derby server only has support for USRIDPWD,USRIDONL,", "+     * EUSRIDPWD and this method only considers these possibilities.", "+     * USRIDPWD, EUSRIDPWD require a password, USRIDONL is the only security mechanism", "+     * which does not require password.", "+     * 1. if password is not available, then security mechanism possible is USRIDONL", "+     * 2. if password is available, if client supports EUSRIDPWD, then EUSRIDPWD is", "+     * returned", "+     * 3. if password is available, if client does not support EUSRIDPWD, then USRIDPWD", "+     * is returned.", "Testing:", "Added tests with possible permutations for user, password and security mechanism on a connection request.", "see derbynet/testSecMec.java#testAllCombinationsOfUserPasswordSecMecInput()", "I have attached a table to this jira entry (962_table.txt) that gives information about what security mechanism the client sends to the server on different possible inputs.", "Ran derbyall on linux/ibm142 ok with known failures.", "Ran derbynet/testSecMec.java on windows with sane classes for both derbynet(JCC2.4 and JCC2.6)", "derbynetclientmats with ibm131/ibm15/jdk131/jdk15/ibm142/jdk142.", "Please note: this patch depends and requires fix for derby1080.", "Most likely when 1080 gets reviewed and committed, this patch may not cleanly apply.", "Can someone please review this change.", "Thanks.", "Thanks Sunitha for working on this issue and working toward a secure network client and server.", "I looked at your table and the code patch diff, but did not apply it because I had trouble doing so, so this review is probably pretty rough.", "Your table is very useful and I think it should be incorporated into the test  or code comments.", "Perhaps the following could be clarified.", "In your explanation of columns in the table you refer to the columns as a), b) etc.", "It would be good to put those letters in the column headers.", "In your explanations section also list how the numeric values map to the security mechanisms for reference.", "It is further down on the page, but I noticed that after loooking them up.", "The first section of the table is for the case where  no security mechanism is specified.", "It would be good to call that  out in a header as  you do before the other sections of the table.", "In the code, I am unsure about the impact of adding this code to the static initializer block.", "I know you had asked about it earlier and I wish I had insight to the implications but just don't.", "Hopefully someone else does.", "static", "+    {", "+        try", "+        {", "+            // The EncryptionManager class will instantiate objects of the required", "+            // security algorithms that are needed for EUSRIDPWD", "+            // An exception will be thrown if support is not available", "+            // in the JCE implementation in the JVM in which the client", "+            // is loaded.", "+            new org.apache.derby.client.am.EncryptionManager(null);", "+            SUPPORTS_EUSRIDPWD = true;", "+        }catch(Exception e)", "+        {", "+            // if an exception is thrown, ignore exception.", "+            // set SUPPORTS_EUSRIDPWD to false indicating that the client", "+            // does not support EUSRIDPWD security mechanism", "+            SUPPORTS_EUSRIDPWD = false;", "+        }", "+    }", "Maybe it would be good to change SECMEC_HAS_NOT_EXPLICITLY_SET   to something like SECMEC_DEFAULT for clarification.", "Something about the negatives in variable names always confuses me.", "Kathey", "This issue requires DERBY-1080 to be fixed.", "Also both these issues affect one same file so patch for 962 wont cleanly apply for the file (testSecMec.java).", "Sunitha said:", ">This variable is used to indicate that the security mechanism has not been >set on datasource or connection request.", "I can change it to >SECMEC_DEFAULT if that is preferred.", ">Its just that SECMEC_DEFAULT seems to suggest that it is the default >security mechanism which it isnt.", "The default security mechanism for the client is USRIDONL (0x04)", "I tend to think that  the default security mechanism is not USRIDONLY but in fact is  variable depending on whether password is specified and whether  the JVM can support EUSRIDPPWD, but the name as you have it is ok.", "I don't feel that strongly about it.", "This issue was blocked by derby-1080.", "Now that 1080 is committed, I have regenerated the patch for 962 and am attaching Derby962.diff.txt and Derby962.stat.txt.", "The changes in this patch are the same as compared to the changes in Derby962_forreview.txt that were specific to derby 962,  except for the following:", "I have added the table that was in  962_table.txt into the test code  per Kathey's comments and also added some comments from the jira to the test code.", "I ran derbynetclientmats and derbynetmats ok on linux/ibm142 with the known failures in Surtest.", "I ran testSecMec on windows with JCC2.4, JCC2.6 and derbyclient on ibm and sun jvms , versions 131,141,142,15 ok.", "derbyall is still running.", "I will post results here as they finish.", "Can someone please review this change.", "Thanks.", "With the patch Derby962.diff.txt,  derbyall run finished on linux/ibm142 with the known failures ( SurTest, NSInSameJVM).", "I don't have any more comments on this patch.", "It looks good to me.", "Thanks for putting the summary in the test.", "I think that will really help anyone  looking at this in the future.", "It would be great if someone else could look at this patch too.", "I will check in first thing tomorrow  if we don't get any more comments.", "Thanks", "Kathey"], "SplitGT": [" This method has logic to upgrade security mechanism to a better (more secure) one if it is possible.", "Currently derby server only has support for USRIDPWD,USRIDONL, EUSRIDPWD and this method only considers these possibilities.", "USRIDPWD, EUSRIDPWD require a password, USRIDONL is the only security mechanism which does not require password.", "1. if password is not available, then security mechanism possible is USRIDONL 2. if password is available, if client supports EUSRIDPWD, then EUSRIDPWD is returned 3. if password is available, if client does not support EUSRIDPWD, then USRIDPWD is returned."], "issueString": "Upgrade default security mechanism in client to use encrypted userid password if client can support it.\nCurrently in the client, if userid and password are set in the connection url, the default security mechanism is upgraded to USRIDPWD (which is clear text userid and password).  This seems to be a security hole here. \n\nCurrent client  driver supports encrypted userid/password (EUSRIDPWD) via the use of DH key-agreement protocol - however current Open Group DRDA specifications imposes small prime and base generator values (256 bits) that prevents other JCE's  (apt from ibm jce) to be used as java cryptography providers.  \n\nSome thoughts:\n-- client can make a check to see if it the jvm it is running in supports the encryption necessary for EUSRIDPWD. If it supports, then the client can upgrade to EUSRIDPWD. \n-- if the jvm the client is running is , doesnt support encryption requirements for EUSRIDPWD, then the security mechanism will be set to USRIDPWD.\n\n-- DERBY-528 will add support for strong userid and password which is another option to send encrypted passwords across the wire. When this gets added, maybe this can be considered as one of the upgrade options after EUSRIDPWD. \nThe current behavior even if the security mechanism is explicitly set in the connection url, the upgrade is done--  should this happen.\n\nI think we should not upgrade (override) if user has explicitly set the security mechanism. Thoughts ?\n\nsee ClientBaseDataSource# getUpgradedSecurityMechanism()  for code where the upgrade from USRIDONL to USRIDPWD is done.\n\nI agree, Sunitha. If the user says something like:\n\nconnect 'jdbc:derby://localhost:1527/testdb;create=true;securityMechanism=4;user=bryan;password=bryan'; \n\nwe should not quietly change the securityMechanism to 3 and quietly send the password in the clear. That's a bad default to have.\n\nThe user has given us conflicting information, and we should ask them to either change the securityMechanism to one which supports a password, or remove the password.\n\nI can see the appeal of quietly upgrading to a secure securityMechanism (one which doesn't expose the password over the wire), but in general my preference would be to give them an error saying that their request is ambiguous, rather than trying to guess what sort of alternate securityMechanism they may have wanted.\n\nI just started looking at this issue on how to know if the jvm in which the client is running can support encrypted userid and password mechanism or not;  to decide if we can upgrade the default security mechanism.  \n\nI wanted to share some thoughts I have, so I could get early feedback from the list.\n\nCurrent client  driver supports encrypted userid/password (EUSRIDPWD) via the use of DH key-agreement protocol - however current Open Group DRDA specifications imposes small prime and base generator values (256 bits) that prevents other JCE's  (apt from ibm jce) to be used as java cryptography providers.  \n\n-- org.apache.derby.client.am.EncryptionManager (EM) constructor is responsible for instantiating the appropriate Provider and the KeyPairGenerator.  The Sun JCE throws java.security.InvalidAlgorithmParameterException exception when trying to use the 256bits prime. \n\nI think we can conclude if the EM throws an exception, then the JCE doesnt support the required algorithms.\n=> An exception from this constructor indicates that it is not possible to use encrypted userid/password.\n\nThe next step seems to me to decide where to put the call to new EncryptionManager(EM)\n#A.Put in static initializer block in ClientBaseDataSource and store the result in a static variable.  The ClientBaseDataSource seems to be place where all the url attribute values' gets and sets methods are present. Also the upgrade logic for the security mechanism is in this class.\n\nsomething like:\nstatic boolean SUPPORTS_EUSRIDPWD = false;\nstatic\n{\n    try\n    {\n        \n        new org.apache.derby.client.am.EncryptionManager(null);\n        SUPPORTS_EUSRIDPWD = true;\n    }catch(Exception e)\n    {\n       //ignore\n    }\n}\n\n---------------\n\n#B. Another place this check could go was in the ClientDriver itself since this will be loaded  in the JVM. In the static initializer of ClientDriver, new of EM can be done to check if it will go through OK. If so, a static 'protected' variable in ClientDriver can be used to store the state that the driver supports the algorithms required for encrypted userid/password.\n\n1. Are there any issues with adding code to the static initializer block of the Client Driver. I see the following comment in ClientDriver which sounds a little scary to me. \n\nstatic {\n       // This may possibly hit the race-condition bug of java 1.1.\n        // The Configuration static clause should execute before the following line does.\n\t if (Configuration.exceptionsOnLoadResources != null) {\n......\n}\n\nI can see that the Configuration static initializer needs to run before the access to the static variable Configuration.exceptionsOnLoadResources. \n\nI'm curious and would like to look at it sometime. If someone could point me to some reference of this bug, I'd be grateful. I googled but didnt find any related to the static intializer blocks. \n--------------\n\n#C Explicitly check the jvm and decide.  Not a good way for e.g. if SunJCE supports the DH with 256 bits prime some day, we would have to remember to remove this check that disables encrypted userid/password for this particular JVM. \n\nI like #A because it seems clean.    What do others think ? \n\nComments/Thoughts.\n\nThanks much,\nSunitha. \nTable with combinations of userid/password/security mechanism and what client sends to the server. Uploading now, so I can include this link in the testcase comment..\nThis patch 'Derby962.forreview.diff.txt' is a patch for review. This patch needs derby 1080 for it to work. Also there is one testfile which is common between the derby-1080 and this patch and hence it is likely this patch may not apply cleanly once derby1080 gets reviewed and committed.  I generated the diff keeping the changes of derby1080 for the test file (derbynet/testSecMec.java).\n\nThis patch 'Derby962.forreview.diff.txt' improves the upgrade security mechanism logic to do the following.\n\n1. If securityMechanism is explicitly specified in the connection request then client will not override it.\n2. Dynamically figure out if the jvm in which the client is loaded, supports encrypted userid and \npassword security (EUSRIDPWD) or not and use this information to upgrade to a more secure default \nsecurity mechanism.\n3. Thus if user has not specified the security mechanism, in that case the client will try to see if \nit can upgrade the security mechanism and use the new upgraded security mechanism for connection to the server.\n\nLogic in ClientBaseDataSource#getUpgradedSecurityMechanism()\n+     * This method has logic to upgrade security mechanism to a better (more secure) one \n+     * if it is possible.   Currently derby server only has support for USRIDPWD,USRIDONL,\n+     * EUSRIDPWD and this method only considers these possibilities. \n+     * USRIDPWD, EUSRIDPWD require a password, USRIDONL is the only security mechanism\n+     * which does not require password.\n+     * 1. if password is not available, then security mechanism possible is USRIDONL\n+     * 2. if password is available, if client supports EUSRIDPWD, then EUSRIDPWD is \n+     * returned\n+     * 3. if password is available, if client does not support EUSRIDPWD, then USRIDPWD\n+     * is returned.\n\nTesting:\n-- Added tests with possible permutations for user, password and security mechanism on a connection request.  \nsee derbynet/testSecMec.java#testAllCombinationsOfUserPasswordSecMecInput()\n\nI have attached a table to this jira entry (962_table.txt) that gives information about what security mechanism the client sends to the server on different possible inputs.  \n\n-- Ran derbyall on linux/ibm142 ok with known failures.\n-- Ran derbynet/testSecMec.java on windows with sane classes for both derbynet(JCC2.4 and JCC2.6) \n/derbynetclientmats with ibm131/ibm15/jdk131/jdk15/ibm142/jdk142.\n\nPlease note: this patch depends and requires fix for derby1080. Most likely when 1080 gets reviewed and committed, this patch may not cleanly apply. \n\nCan someone please review this change. Thanks.  \n\nThanks Sunitha for working on this issue and working toward a secure network client and server.\nI looked at your table and the code patch diff, but did not apply it because I had trouble doing so, so this review is probably pretty rough. \n\nYour table is very useful and I think it should be incorporated into the test  or code comments.  Perhaps the following could be clarified. \n\n-  In your explanation of columns in the table you refer to the columns as a), b) etc.  It would be good to put those letters in the column headers.\n\n- In your explanations section also list how the numeric values map to the security mechanisms for reference.\n  It is further down on the page, but I noticed that after loooking them up.\n\n- The first section of the table is for the case where  no security mechanism is specified.  It would be good to call that  out in a header as  you do before the other sections of the table.\n\n\nIn the code, I am unsure about the impact of adding this code to the static initializer block.    I know you had asked about it earlier and I wish I had insight to the implications but just don't.   Hopefully someone else does.\n\n static\n+    {\n+        try\n+        {\n+            // The EncryptionManager class will instantiate objects of the required \n+            // security algorithms that are needed for EUSRIDPWD\n+            // An exception will be thrown if support is not available\n+            // in the JCE implementation in the JVM in which the client\n+            // is loaded.\n+            new org.apache.derby.client.am.EncryptionManager(null);\n+            SUPPORTS_EUSRIDPWD = true;\n+        }catch(Exception e)\n+        {\n+            // if an exception is thrown, ignore exception.\n+            // set SUPPORTS_EUSRIDPWD to false indicating that the client \n+            // does not support EUSRIDPWD security mechanism\n+            SUPPORTS_EUSRIDPWD = false;\n+        }\n+    }\n\n\nMaybe it would be good to change SECMEC_HAS_NOT_EXPLICITLY_SET   to something like SECMEC_DEFAULT for clarification.  Something about the negatives in variable names always confuses me.\n\nKathey\n\n\n\nThis issue requires DERBY-1080 to be fixed. Also both these issues affect one same file so patch for 962 wont cleanly apply for the file (testSecMec.java).\nSunitha said:\n>This variable is used to indicate that the security mechanism has not been >set on datasource or connection request.  I can change it to >SECMEC_DEFAULT if that is preferred.\n>Its just that SECMEC_DEFAULT seems to suggest that it is the default >security mechanism which it isnt.  The default security mechanism for the client is USRIDONL (0x04)\n\nI tend to think that  the default security mechanism is not USRIDONLY but in fact is  variable depending on whether password is specified and whether  the JVM can support EUSRIDPPWD, but the name as you have it is ok.  I don't feel that strongly about it.\n\n\nThis issue was blocked by derby-1080.  Now that 1080 is committed, I have regenerated the patch for 962 and am attaching Derby962.diff.txt and Derby962.stat.txt.    \n\nThe changes in this patch are the same as compared to the changes in Derby962_forreview.txt that were specific to derby 962,  except for the following:\n-- I have added the table that was in  962_table.txt into the test code  per Kathey's comments and also added some comments from the jira to the test code. \n\nI ran derbynetclientmats and derbynetmats ok on linux/ibm142 with the known failures in Surtest.    I ran testSecMec on windows with JCC2.4, JCC2.6 and derbyclient on ibm and sun jvms , versions 131,141,142,15 ok. \n\nderbyall is still running. I will post results here as they finish. \n\nCan someone please review this change. Thanks. \nWith the patch Derby962.diff.txt,  derbyall run finished on linux/ibm142 with the known failures ( SurTest, NSInSameJVM).  \n\nI don't have any more comments on this patch. It looks good to me.  Thanks for putting the summary in the test. I think that will really help anyone  looking at this in the future.   It would be great if someone else could look at this patch too.  I will check in first thing tomorrow  if we don't get any more comments.\n\n\nThanks\n\nKathey\n\n\n\n\n", "issueSearchSentences": ["+     * which does not require password.", "+     * returned", "+     * 1. if password is not available, then security mechanism possible is USRIDONL", "+     * EUSRIDPWD and this method only considers these possibilities.", "Upgrade default security mechanism in client to use encrypted userid password if client can support it."], "issueSearchIndexes": [93, 96, 94, 91, 1]}
{"aId": 117, "code": "public static void skipFully(InputStream is, long skippedBytes)\n    throws IOException {\n        if(is == null)\n            throw new NullPointerException();\n\n        if(skippedBytes <= 0)\n            return;\n\n        long bytes = skipPersistent(is, skippedBytes);\n\n        if(bytes < skippedBytes)\n            throw new EOFException();\n    }", "comment": " Skips requested number of bytes, throws EOFException if there is too few bytes in the stream.", "issueId": "DERBY-3770", "issueStringList": ["Create a utility class for skipping data in an InputStream", "The contract of InputStream.skip is somewhat difficult, some would even say broken.", "See http://java.sun.com/javase/6/docs/api/java/io/InputStream.html#skip(long))", "A utility class should be created to ensure that we use the same skip procedure throughout the Derby code base.", "Suggested functionality:", "long skipFully(InputStream) : skips until EOF, returns number of bytes skipped", "void skipFully(InputStream,long) : skips requested number of bytes, throws EOFException if there is too few bytes in the stream", "I know of two different approaches, both skipping in a loop:", "a) Verify EOF with a read call when skip returns zero.", "b) Throw EOFException if skip returns zero before requested number of bytes have been skipped.", "There's related code in iapi.util.UTF8Util.", "Maybe this class, say StreamUtil, could be put in the same package?", "Hi, Kristian.", "Please check the patch, thanks!", "Junjie, I will look at the patch soon but if you get a chance, can you put a brief description of the logic of the patch in this jira entry?", "Junjie, the patch is commented pretty well and the code changes for those comments look good.", "One comment for the engine code change", "1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes).", "Should we put NullPointerException() also in the javadoc?", "Just couple comments for the new junit test", "1)testNullStream has 2 test cases to check for null inputstream.", "For some reason, if no NullPointerException is thrown, then we have following to catch it", "fail(\"Null InputStream is refused!", "\");", "The error message looks misleading.", "Should it be saying something like", "fail(\"Null InputStream is accepted!", "\");", "2)The 2 tests in testNullStream only check for NullPointerException.", "Shouldn't we be catching other exceptions and make the test fail for those exceptions.", "3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre.", "Thanks for working on this jira entry.", "Thanks for your attention, Mamta.", "I have receive your comments just now.", "Sorry to reply late.", "<<Junjie, the patch is commented pretty well and the code changes for those comments look good.", "<<One comment for the engine code change", "<<1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes).", "Should we put NullPointerException() also in the javadoc?", "I have add the declaration for NullException.", "<<Just couple comments for the new junit test", "<<1)testNullStream has 2 test cases to check for null inputstream.", "For some reason, if no NullPointerException is thrown, then we have following to catch it", "<<fail(\"Null InputStream is refused!", "\");", "<<The error message looks misleading.", "Should it be saying something like", "<<fail(\"Null InputStream is accepted!", "\");", "I have correct it.", "<<2)The 2 tests in testNullStream only check for NullPointerException.", "Shouldn't we be catching other exceptions and make the test fail for those exceptions.", "I'm not clear about this.", "What other exceptions should be tested int testNullStream()?", "For EOFException, I have tested it in testSkipFully().", "As to IOException, excluding EOFException, I don't know how to create or simulate it.", "Could you give me more advices?", "<<3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre.", "testSkipUtilEOFWithOddLength() only tests EOF with special length, I think it's better to seperate it from common length.", "Is the name of the method not clear?", "Is testSkipUtilEOFWithSpecialLength() better?", "<<Thanks for working on this jira entry.", "Mamta, please give more suggestion to improve the patch.", "Thanks again!", "Regards", "Junjie", "Junjie, sorry for not getting back to you sooner.", "What I meant bu comment 2) for the tests is something along following line.", "In most of the JDBC junit tests in Derby, if say executing a specific query is only allowed to send a specific exception, then we assert that using following (s below is java.sql.Statement)", "assertStatementError(\"42Y55\", s, \"CALL SYSCS_UTIL.SYSCS_UPDATE_STATISTICS('APP','T1',null)\");", "So, if the query above throws any exception other than \"42Y55\" then that will cause the junit test to fail saying that it expected 42Y55 but it got something else.", "I was wonderinf in the test in question here, if there was anyway of catching exceptions other than NPE", "+        try{", "+            StreamUtil.skipFully(null);", "+            fail(\"Null InputStream is accepted!", "\");", "+        }catch (NullPointerException e) {", "+            assertTrue(true);", "+        }", "I guess, if the test case above did get an exception other than NPE, we will just get out of the test fixture with that exception.", "I was curious if there was some more graceful way of catching unexpected exceptions like we do for jave.sql.Statement with assertStatementError.", "This is not a biggie and feel free to not address this issue if there is no simple way of doing what assertStatementError does.", "Mamta, thanks for your adivice.", "I have contemplated your comment , I think the test is OK in this situation.", "The NPE is checked first when calling the skipFully() method, so no other kind of exception will be thrown.", "What's your opinion?", "As to the \"more graceful way of catching unexpected exceptions\", above all, thanks for your advice, it helps me understand the test framework better.", "However, I haven't found known tools to realize it, so I would leave it as it's now.", "Regards", "Junjie", "The handling of unexpected exceptions looks fine to me.", "Since they are not caught explicitly, they will propagate out to the JUnit framework and be reported correctly there.", "It may be slightly clearer, though, if we replace assertTrue(true) with just a comment like this:", "catch (NullPointerException npe) {", "ignoring expected exception", "}", "The StreamUtil class imports sun.tools.tree.NullExpression, which seems wrong.", "Also, the javadoc comments in that class say \"@throws NullExpression\", whereas they should have said \"@throws NullPointerException\".", "It's probably also a good idea to move the code from UTF8Util.skipPersistent() into the StreamUtil class, since that method doesn't have anything to do with UTF-8 and therefore making it non-private in the UTF8Util class may cause some confusion.", "Hi, Knut.", "Thanks for your advice.", "1.)", "---test framework.", "I agree with your method to add comment \"      // ignoring expected exception \".", "However, as what I used is just like Andrew suggested in his <Pragmatic Unit Testing>, I think it can work well.", "2.)", "---wrong import.", "I have corrected in the new patch.", "3.)", "---move the code from UTF8Util.skipPersistent() into the StreamUtil class.", "It's a good suggestion, I have adopted it.", "Please check the patch!", "Regards", "Junjie", "Thanks, Junjie!", "The patch looks good to me.", "I'll run some tests and commit the patch if there are no problems.", "Committed revision 688049.", "Some questions/comments about    skipFully(InputStream is)", "What is the purpose of this method, when would it be used?", "Skipping until EOF seems a useless operation.", "SKIP_BUFFER_SIZE is a somewhat confusing name since no buffer is ever allocated.", "skipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent().", "Other input stream utility methods are in org.apache.derby.iapi.services.io, any reason to have this new class in a different package?"], "SplitGT": [" Skips requested number of bytes, throws EOFException if there is too few bytes in the stream."], "issueString": "Create a utility class for skipping data in an InputStream\nThe contract of InputStream.skip is somewhat difficult, some would even say broken.\nSee http://java.sun.com/javase/6/docs/api/java/io/InputStream.html#skip(long))\n\nA utility class should be created to ensure that we use the same skip procedure throughout the Derby code base.\nSuggested functionality:\n - long skipFully(InputStream) : skips until EOF, returns number of bytes skipped\n - void skipFully(InputStream,long) : skips requested number of bytes, throws EOFException if there is too few bytes in the stream\n\nI know of two different approaches, both skipping in a loop:\n a) Verify EOF with a read call when skip returns zero.\n b) Throw EOFException if skip returns zero before requested number of bytes have been skipped.\n\nThere's related code in iapi.util.UTF8Util. Maybe this class, say StreamUtil, could be put in the same package?\nHi, Kristian. Please check the patch, thanks!\nJunjie, I will look at the patch soon but if you get a chance, can you put a brief description of the logic of the patch in this jira entry?\nJunjie, the patch is commented pretty well and the code changes for those comments look good. \nOne comment for the engine code change\n1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes). Should we put NullPointerException() also in the javadoc?\n\nJust couple comments for the new junit test\n1)testNullStream has 2 test cases to check for null inputstream. For some reason, if no NullPointerException is thrown, then we have following to catch it\nfail(\"Null InputStream is refused!\");\nThe error message looks misleading. Should it be saying something like\nfail(\"Null InputStream is accepted!\");\n2)The 2 tests in testNullStream only check for NullPointerException. Shouldn't we be catching other exceptions and make the test fail for those exceptions.\n3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre.\n\nThanks for working on this jira entry.\nThanks for your attention, Mamta. I have receive your comments just now. Sorry to reply late.\n\n<<Junjie, the patch is commented pretty well and the code changes for those comments look good. \n<<One comment for the engine code change \n<<1)The 2 new methods skipFully(InputStream is) and skipFully(InputStream is, long skippedBytes) in their javadocs only talk about IOException and EOFException for skipFully(InputStream is, long skippedBytes). Should we put NullPointerException() also in the javadoc? \n-----I have add the declaration for NullException.\n\n<<Just couple comments for the new junit test \n<<1)testNullStream has 2 test cases to check for null inputstream. For some reason, if no NullPointerException is thrown, then we have following to catch it \n<<fail(\"Null InputStream is refused!\"); \n<<The error message looks misleading. Should it be saying something like \n<<fail(\"Null InputStream is accepted!\");\n-----I have correct it. \n<<2)The 2 tests in testNullStream only check for NullPointerException. Shouldn't we be catching other exceptions and make the test fail for those exceptions. \n-----I'm not clear about this. What other exceptions should be tested int testNullStream()? For EOFException, I have tested it in testSkipFully(). As to IOException, excluding EOFException, I don't know how to create or simulate it. Could you give me more advices?\n<<3)Don't have to address this but should we consider combining testSkipUtilEOFWithOddLength and testSkipUtilEOF into one test fixutre. \n-----testSkipUtilEOFWithOddLength() only tests EOF with special length, I think it's better to seperate it from common length. Is the name of the method not clear? Is testSkipUtilEOFWithSpecialLength() better?\n<<Thanks for working on this jira entry. \n\nMamta, please give more suggestion to improve the patch. Thanks again!\n\nRegards\nJunjie\n\nJunjie, sorry for not getting back to you sooner.\n\nWhat I meant bu comment 2) for the tests is something along following line. In most of the JDBC junit tests in Derby, if say executing a specific query is only allowed to send a specific exception, then we assert that using following (s below is java.sql.Statement)\n        assertStatementError(\"42Y55\", s, \"CALL SYSCS_UTIL.SYSCS_UPDATE_STATISTICS('APP','T1',null)\");\nSo, if the query above throws any exception other than \"42Y55\" then that will cause the junit test to fail saying that it expected 42Y55 but it got something else.\n\nI was wonderinf in the test in question here, if there was anyway of catching exceptions other than NPE\n+        try{\n+            StreamUtil.skipFully(null);\n+            fail(\"Null InputStream is accepted!\");\n+        }catch (NullPointerException e) {\n+            assertTrue(true);\n+        }\n\nI guess, if the test case above did get an exception other than NPE, we will just get out of the test fixture with that exception. I was curious if there was some more graceful way of catching unexpected exceptions like we do for jave.sql.Statement with assertStatementError. This is not a biggie and feel free to not address this issue if there is no simple way of doing what assertStatementError does.\nMamta, thanks for your adivice. \n\nI have contemplated your comment , I think the test is OK in this situation. The NPE is checked first when calling the skipFully() method, so no other kind of exception will be thrown. What's your opinion?\n\nAs to the \"more graceful way of catching unexpected exceptions\", above all, thanks for your advice, it helps me understand the test framework better. However, I haven't found known tools to realize it, so I would leave it as it's now.\n\nRegards\nJunjie\nThe handling of unexpected exceptions looks fine to me. Since they are not caught explicitly, they will propagate out to the JUnit framework and be reported correctly there.\n\nIt may be slightly clearer, though, if we replace assertTrue(true) with just a comment like this:\n\n  catch (NullPointerException npe) {\n      // ignoring expected exception\n  }\n\nThe StreamUtil class imports sun.tools.tree.NullExpression, which seems wrong. Also, the javadoc comments in that class say \"@throws NullExpression\", whereas they should have said \"@throws NullPointerException\".\n\nIt's probably also a good idea to move the code from UTF8Util.skipPersistent() into the StreamUtil class, since that method doesn't have anything to do with UTF-8 and therefore making it non-private in the UTF8Util class may cause some confusion.\nHi, Knut. Thanks for your advice.\n\n1.)---test framework. I agree with your method to add comment \"      // ignoring expected exception \". However, as what I used is just like Andrew suggested in his <Pragmatic Unit Testing>, I think it can work well.\n\n2.)---wrong import. I have corrected in the new patch. \n\n3.)---move the code from UTF8Util.skipPersistent() into the StreamUtil class. It's a good suggestion, I have adopted it.\n\nPlease check the patch!\n\nRegards\nJunjie\nThanks, Junjie!\n\nThe patch looks good to me. I'll run some tests and commit the patch if there are no problems.\nCommitted revision 688049.\nSome questions/comments about    skipFully(InputStream is) \n\nWhat is the purpose of this method, when would it be used? Skipping until EOF seems a useless operation.\n\nSKIP_BUFFER_SIZE is a somewhat confusing name since no buffer is ever allocated.\n\nskipPersistent() states that if a fewer number of bytes is skipped then it is guaranteed that eof has been reached, but skipFully() does not take advantage of this, instead it will always perform an extra call to skipPersistent().\n\nOther input stream utility methods are in org.apache.derby.iapi.services.io, any reason to have this new class in a different package?\n", "issueSearchSentences": ["One comment for the engine code change", "<<One comment for the engine code change", "long skipFully(InputStream) : skips until EOF, returns number of bytes skipped", "a) Verify EOF with a read call when skip returns zero.", "Suggested functionality:"], "issueSearchIndexes": [17, 37, 6, 9, 5]}
{"aId": 118, "code": "private void updateIfRequired () throws IOException {\n        if (materialized)\n            return;\n        if (blob.isMaterialized()) {\n            materialized = true;\n            try {\n                stream = blob.getBinaryStream();\n            } catch (SQLException ex) {\n                IOException ioe = new IOException (ex.getMessage());\n                ioe.initCause (ex);\n                throw ioe;\n            }\n            long leftToSkip = pos;\n            while (leftToSkip > 0) {\n                long skipped = stream.skip (leftToSkip);\n                if (skipped == 0) {\n                    //skipping zero byte check stream has reached eof\n                    if (stream.read() < 0) {\n                         throw new IOException (\n                                 MessageService.getCompleteMessage (\n                                 SQLState.STREAM_EOF, new Object [0]));\n                    }\n                    else {\n                        skipped = 1;\n                    }\n                }\n                leftToSkip -= skipped;\n            }\n        }\n    }", "comment": " Checks if this object is using materialized blob if not it checks if the blob was materialized since this stream was last access.", "issueId": "DERBY-2711", "issueStringList": ["If large blob is updated after InputStream is fetched (using getBinaryStream), the stream continues to point ot old data", "While using a large blob (so that blob doesn't gets materialized while fetching from database) getBinaryStream returns stream linked to dvd.", "After blob is is updated internally the blob data is materialized in LOBStreamControl class but the stream continues to point to dvd hence giving out old data.", "I have introduced a new stream class UpdateableBlobStream to handle the switching from dvd stream to LOBInputStream.", "blob.getBinaryStream now returns UpdateableBlobStream is the blob is not yet materialized.", "This stream keeps tracks of current position of the stream, and checks if blob is materialized since it was last accessed.", "If the blob is materialized it gets the stream again from blob and updates the stream and sets the position of the stream by calling skip.", "If the blob has been truncated and now is smaller than the current position user will get an IOException.", "Modified Files", "java/engine/org/apache/derby/impl/jdbc/EmbedBlob.java", "getBinaryStream now returns UpdateableBlobStream if the blob is not materialized.", "New File", "java/engine/org/apache/derby/impl/jdbc/UpdateableBlobStream.java", "This class handles the switching from dvd stream to LOBInputStream", "Tests", "java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/BlobUpdateableStreamTest.java", "Added a new test to test switching from dvd stream to LOBInputStream.", "java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/_Suite.java", "Added an entry for BlobUpdateableStreamTest.java", "I'm running tests for the change now.", "I have a few requests/questions for the patch:", "a) It can no longer be cleanly applied because of a (trivial) conflict in _Suite (easy to fix)", "b) One line in the new file contains tabs.", "c) Is it necessary to copy all the JavaDoc from InputStream.read?", "I think a shorter JavaDoc and a reference to InputStream would suffice, but maybe people disagree with this?", "d) Another suggestion, not a requirement, it to rename updateIfRequired to something like updateStream and only call it when necessary.", "This would require 'if (!materialized && blob.isMaterialized())' all places where updateIfRequired is called currently.", "This is more a personal preference of mine, so you are free to ignore it :)", "I just want to point out that once a Blob has been \"materialized\", that is transferred from the store to what I tend to call a temporary blob, it cannot go back to be a Blob working on top of a store stream.", "For this to happen you must reinsert the Blob into the database and fetch it again, thus getting a new Blob object to work on.", "The patch looks good functionally, and I expect to commit it tomorrow if the tests run cleanly.", "thanks,", "In this patch I have addressed points a b and c of Kristian.", "a.", "Resolved conflicts.", "b.", "Removed Excess docs and added link to java.io.InputStream", "c. Replaced tab by spaces.", "Committed 'derby-2711v2.diff' to trunk with revision 545495.", "Tests ran cleanly except for the current noise in the tinderbox/nightlies (46+1 failing tests).", "A small additional patch with non-functional changes will follow.", "Thank you Anurag!", "'derby-2711-3a-additional.diff' must be committed on top of v2, and does the following:", "Made variable blob final.", "Throws exception that was caught and wrapped.", "Added a comment that the stream will update itself and reflect the new content in all read/skip methods.", "Changed normal comments into JavaDoc for updateIfRequired.", "In addition it removes trailing whitespace and cleans up a few JavaDoc things.", "Committed 'derby-2711-3a-additional.diff' to trunk with revision 545501."], "SplitGT": [" Checks if this object is using materialized blob if not it checks if the blob was materialized since this stream was last access."], "issueString": "If large blob is updated after InputStream is fetched (using getBinaryStream), the stream continues to point ot old data\nWhile using a large blob (so that blob doesn't gets materialized while fetching from database) getBinaryStream returns stream linked to dvd. After blob is is updated internally the blob data is materialized in LOBStreamControl class but the stream continues to point to dvd hence giving out old data.\nI have introduced a new stream class UpdateableBlobStream to handle the switching from dvd stream to LOBInputStream.\nblob.getBinaryStream now returns UpdateableBlobStream is the blob is not yet materialized. This stream keeps tracks of current position of the stream, and checks if blob is materialized since it was last accessed. If the blob is materialized it gets the stream again from blob and updates the stream and sets the position of the stream by calling skip. If the blob has been truncated and now is smaller than the current position user will get an IOException.\n\nModified Files\n  java/engine/org/apache/derby/impl/jdbc/EmbedBlob.java\n         getBinaryStream now returns UpdateableBlobStream if the blob is not materialized.\nNew File\n   java/engine/org/apache/derby/impl/jdbc/UpdateableBlobStream.java\n         This class handles the switching from dvd stream to LOBInputStream\n\nTests\njava/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/BlobUpdateableStreamTest.java\n Added a new test to test switching from dvd stream to LOBInputStream.\njava/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/_Suite.java\n  Added an entry for BlobUpdateableStreamTest.java\n\n\n \nI'm running tests for the change now.\n\nI have a few requests/questions for the patch:\n a) It can no longer be cleanly applied because of a (trivial) conflict in _Suite (easy to fix)\n b) One line in the new file contains tabs.\n c) Is it necessary to copy all the JavaDoc from InputStream.read? I think a shorter JavaDoc and a reference to InputStream would suffice, but maybe people disagree with this?\n d) Another suggestion, not a requirement, it to rename updateIfRequired to something like updateStream and only call it when necessary. This would require 'if (!materialized && blob.isMaterialized())' all places where updateIfRequired is called currently. This is more a personal preference of mine, so you are free to ignore it :)\n\nI just want to point out that once a Blob has been \"materialized\", that is transferred from the store to what I tend to call a temporary blob, it cannot go back to be a Blob working on top of a store stream. For this to happen you must reinsert the Blob into the database and fetch it again, thus getting a new Blob object to work on.\n\nThe patch looks good functionally, and I expect to commit it tomorrow if the tests run cleanly.\n\nthanks,\nIn this patch I have addressed points a b and c of Kristian.\n\na. Resolved conflicts.\nb. Removed Excess docs and added link to java.io.InputStream\nc. Replaced tab by spaces.\nCommitted 'derby-2711v2.diff' to trunk with revision 545495.\nTests ran cleanly except for the current noise in the tinderbox/nightlies (46+1 failing tests).\nA small additional patch with non-functional changes will follow.\n\nThank you Anurag!\n'derby-2711-3a-additional.diff' must be committed on top of v2, and does the following:\n * Made variable blob final.\n * Throws exception that was caught and wrapped.\n * Added a comment that the stream will update itself and reflect the new content in all read/skip methods.\n * Changed normal comments into JavaDoc for updateIfRequired.\n\nIn addition it removes trailing whitespace and cleans up a few JavaDoc things.\nCommitted 'derby-2711-3a-additional.diff' to trunk with revision 545501.\n", "issueSearchSentences": ["This stream keeps tracks of current position of the stream, and checks if blob is materialized since it was last accessed.", "If the blob is materialized it gets the stream again from blob and updates the stream and sets the position of the stream by calling skip.", "java/engine/org/apache/derby/impl/jdbc/EmbedBlob.java", "blob.getBinaryStream now returns UpdateableBlobStream is the blob is not yet materialized.", "d) Another suggestion, not a requirement, it to rename updateIfRequired to something like updateStream and only call it when necessary."], "issueSearchIndexes": [6, 7, 10, 5, 26]}
{"aId": 119, "code": "public long getMaxLogicalLOBSize() { return ((long) Limits.DB2_LOB_MAXWIDTH) * 2; }", "comment": " Added in JDBC 4.2. This is the maximum number of bytes in a LOB.", "issueId": "DERBY-6000", "issueStringList": ["Implement support for JDBC 4.2", "Open JDK 8 will include maintenance rev 4.2 of JDBC.", "The public discussion of JDBC 4.2 will take place here: http://openjdk.java.net/jeps/170.", "We will want to build Derby support for JDBC 4.2 after a public spec appears.", "At this time, it is unclear what Derby release will carry this support.", "Attaching JDBC_4.2_Changes.html, the first rev of a functional spec for this work.", "The changes are defined by the javadoc specdiffs published by JDBC spec lead Lance Andersen.", "The latest specdiffs can be found here: http://cr.openjdk.java.net/~lancea/8005080/specdiffs.01/", "I have built Open JDK 8 on my mac by following the instructions here:", "https://wikis.oracle.com/display/OpenJDK/Mac+OS+X+Port", "However, the mercurial source indicated on that page does not contain the recent Open JDK checkin of JDBC 4.2.", "To get that more complete source, I issued the following command:", "hg clone http://hg.openjdk.java.net/jdk8/tl", "Probably a similar sequence of steps on the platform of your choice will help you build an Open JDK 8 which contains the JDBC 4.2 changes.", "Attaching derby-6000-01-aa-executeLargeUpdateEmbedded.diff.", "This patch adds the new Statement.executeLargeUpdate() methods introduced by JDBC 4.2.", "I am running tests now.", "This patch adds the following new methods to Derby's embedded JDBC 3.0 implementation of java.sql.Statement:", "public  long executeLargeUpdate( String sql ) throws SQLException;", "public  long executeLargeUpdate( String sql, int autoGeneratedKeys) throws SQLException;", "public  long executeLargeUpdate( String sql, int[] columnIndexes ) throws SQLException;", "public  long executeLargeUpdate( String sql, String[] columnNames ) throws SQLException;", "This involved three changes:", "1) Changing the type of the update counter from int to long.", "2) Adding the new methods.", "3) Forwarding the executeUpdate() overloads to the corresponding newly added executeLargeUpdate() overloads.", "I have put off adding regression tests until I have added parallel methods to the client JDBC implementation.", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/sql/ResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/TemporaryRowHolderResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/BasicNoPutResultSetImpl.java", "M       java/engine/org/apache/derby/impl/sql/execute/RealResultSetStatisticsFactory.java", "M       java/engine/org/apache/derby/impl/sql/execute/DMLWriteResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/DeleteResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/NoRowsResultSetImpl.java", "M       java/engine/org/apache/derby/impl/sql/execute/UpdateResultSet.java", "Step (1).", "M       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedPreparedStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java", "Steps (2) and (3).", "Tests passed cleanly for me on derby-6000-01-aa-executeLargeUpdateEmbedded.diff.", "Committed at subversion revision 1438600.", "Attaching derby-6000-02-ad-executeLargeUpdateClient.diff.", "This adds large update support to Statements in the client JDBC driver.", "I am running tests now.", "This adds the following method to the embedded driver:", "Statement.getLargeUpdateCount()", "...and the following methods to the client driver:", "Statement.executeLargeUpdate( String )", "Statement.executeLargeUpdate( String, int )", "Statement.executeLargeUpdate( String, int[] )", "Statement.executeLargeUpdate( String, String[] )", "Statement.getLargeUpdateCount()", "The following changes are made:", "1) The update count on the client side is expanded from an int to a long.", "2) The update count is passed from the server to the client in the SQLCard descriptor.", "Previously, only an int sized update count was passed.", "Now a long sized update count is passed.", "This is done by leaving the low order 32 bits of the update count in the slot of the SQLCard which was previously used for the update count.", "Then the upper 32 bits are put in a previously unused slot of the SQLCard.", "This should mean that when clients and servers are at different revs, the client will still get the correct update count except in cases when the update count is greater than Integer.MAX_VALUE.", "In those oddball cases, the client used to receive garbage from the server.", "In these mixed rev situations, the client will continue to receive garbage for the update count if the number of updated rows exceeds Integer.MAX_VALUE.", "3) Magic numbers were eliminated when processing the SQLCard.", "Hopefully, this will make this code easier to study and debug.", "4) Factory methods were added for client-side BatchUpdateExceptions.", "These will be expanded when we add support for the new BatchUpdateException constructor added by JDBC 4.2.", "5) The new methods were added.", "6) The engine ResultSet code was tweaked to let tests force the engine to return absurdly large update counts.", "Otherwise, it is practically impossible to test the large update methods since this involves generating more than 2 billion rows for each test case.", "7) Tests were added for large updates for both the embedded and client drivers.", "Touches the following files:", "M       java/drda/org/apache/derby/impl/drda/DRDAConnThread.java", "M       java/client/org/apache/derby/client/am/PreparedStatement.java", "M       java/client/org/apache/derby/client/am/Agent.java", "Changes for (1) and (2).", "M       java/client/org/apache/derby/client/net/NetConnectionReply.java", "M       java/client/org/apache/derby/client/net/NetCursor.java", "M       java/client/org/apache/derby/client/am/Sqlca.java", "Changes for (3).", "M       java/client/org/apache/derby/client/am/Utils.java", "M       java/client/org/apache/derby/client/am/BatchUpdateException.java", "Changes for (4).", "M       java/engine/org/apache/derby/iapi/jdbc/EnginePreparedStatement.java", "M       java/client/org/apache/derby/client/am/Statement.java", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java", "M       java/drda/org/apache/derby/impl/drda/DRDAStatement.java", "M       java/client/org/apache/derby/client/am/LogicalStatementEntity.java", "Changes for (5).", "M       java/engine/org/apache/derby/impl/sql/execute/DMLWriteResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/RowUtil.java", "Changes for (6).", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/XA40Test.java", "Changes for (7).", "Tests passed cleanly for me on derby-6000-02-ad-executeLargeUpdateClient.diff.", "Committed derby-6000-02-ad-executeLargeUpdateClient.diff at subversion revision 1439883.", "Attaching derby-6000-03-aa-executeLargeBatch.diff.", "This patch adds large batch support.", "I am running tests now.", "Adds the following method to the embedded and client drivers:", "Statement.executeLargeBatch()", "Most of the machinery needed for this was added as part of implementing large updates.", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/Util.java", "Embedded changes.", "M       java/client/org/apache/derby/client/am/Statement.java", "M       java/client/org/apache/derby/client/am/LogicalStatementEntity.java", "Client changes.", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java", "M       java/testing/org/apache/derbyTesting/junit/BaseTestCase.java", "New tests.", "Tests passed cleanly for me on derby-6000-03-aa-executeLargeBatch.diff.", "Committed at subversion revision 1440035.", "Attaching derby-6000-04-aa-setLargeMaxRows.diff.", "This patch adds support for setting/getting large limits on returned row counts.", "I will run regression tests.", "This patch adds the following JDBC 4.2 methods to the embedded and client drivers:", "Statement.setLargeMaxRows( long )", "Statement.getLargeMaxRows()", "Mostly this involved changing the datatype of some variables from int to long and then adding the new methods.", "As with the previous patch, some debug entry points were added so that we can test the new methods without actually generating more than 2 billion rows.", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/sql/Activation.java", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java", "M       java/engine/org/apache/derby/impl/sql/execute/ScrollInsensitiveResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/BaseActivation.java", "M       java/engine/org/apache/derby/impl/sql/GenericActivationHolder.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedResultSet.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java", "Embedded changes.", "M       java/client/org/apache/derby/client/am/Statement.java", "M       java/client/org/apache/derby/client/am/Cursor.java", "M       java/client/org/apache/derby/client/am/LogicalStatementEntity.java", "M       java/client/org/apache/derby/client/am/ResultSet.java", "Client changes.", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java", "New tests.", "Tests passed cleanly for me on derby-6000-04-aa-setLargeMaxRows.diff.", "Committed at subversion revision 1440656.", "Attaching derby-6000-05-aa-executeLargeUpdatePS.diff.", "This patch adds JDBC 4.2 large update support to PreparedStatements.", "I am running tests now.", "This patch adds the following method to the embedded and client implementations of PreparedStatement:", "public long executeLargeUpdate()", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredPreparedStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EnginePreparedStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedPreparedStatement.java", "Embedded changes.", "M       java/client/org/apache/derby/client/am/PreparedStatement.java", "M       java/client/org/apache/derby/client/am/LogicalPreparedStatement.java", "Client changes.", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/PreparedStatementTest.java", "New tests.", "Tests passed cleanly for me on derby-6000-05-aa-executeLargeUpdatePS.diff.", "Committed at subversion revision 1441088.", "Attaching derby-6000-06-aa-DatabaseMetaData.diff.", "This patch makes the JDBC 4.2 changes to DatabaseMetaData.", "I will run regression tests.", "This patch makes the following changes to the embedded and client drivers:", "1) Changes the datatype of the CARDINALITY and PAGES columns returned by getIndexInfo().", "The column types are changed from INT to BIGINT.", "2) Adds a getMaxLogicalLOBSize() method.", "This method is supposed to return the maximum size of a LOB in bytes.", "For Derby that is the maximum size of a CLOB.", "A CLOB can have Integer.MAX_VALUE chars, which works out to Integer.MAX_VALUE * 2 bytes.", "3) Adds a supportsRefCursors() method.", "This returns false because Derby does not support the Types.REF_CURSOR type.", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/reference/Limits.java", "M       java/engine/org/apache/derby/impl/jdbc/metadata.properties", "M       java/engine/org/apache/derby/impl/jdbc/EmbedDatabaseMetaData.java", "Embedded changes.", "M       java/client/org/apache/derby/client/am/LogicalDatabaseMetaData40.java", "M       java/client/org/apache/derby/client/am/DatabaseMetaData.java", "Client changes.", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/Wrapper41DBMD.java", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/DatabaseMetaDataTest.java", "A       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/Wrapper42DBMD.java", "Tests.", "Tests passed cleanly for me on derby-6000-06-aa-DatabaseMetaData.diff except for the heisenbug in NetworkServerControlClientCommandTest.", "testPingWithWrongHost.", "Committed derby-6000-06-aa-DatabaseMetaData.diff at subversion revision 1441436."], "SplitGT": [" Added in JDBC 4.2.", "This is the maximum number of bytes in a LOB."], "issueString": "Implement support for JDBC 4.2\nOpen JDK 8 will include maintenance rev 4.2 of JDBC. The public discussion of JDBC 4.2 will take place here: http://openjdk.java.net/jeps/170. We will want to build Derby support for JDBC 4.2 after a public spec appears. At this time, it is unclear what Derby release will carry this support.\nAttaching JDBC_4.2_Changes.html, the first rev of a functional spec for this work. The changes are defined by the javadoc specdiffs published by JDBC spec lead Lance Andersen. The latest specdiffs can be found here: http://cr.openjdk.java.net/~lancea/8005080/specdiffs.01/\nI have built Open JDK 8 on my mac by following the instructions here:\n\nhttps://wikis.oracle.com/display/OpenJDK/Mac+OS+X+Port\n\nHowever, the mercurial source indicated on that page does not contain the recent Open JDK checkin of JDBC 4.2. To get that more complete source, I issued the following command:\n\nhg clone http://hg.openjdk.java.net/jdk8/tl\n\nProbably a similar sequence of steps on the platform of your choice will help you build an Open JDK 8 which contains the JDBC 4.2 changes.\n\n\nAttaching derby-6000-01-aa-executeLargeUpdateEmbedded.diff. This patch adds the new Statement.executeLargeUpdate() methods introduced by JDBC 4.2. I am running tests now.\n\nThis patch adds the following new methods to Derby's embedded JDBC 3.0 implementation of java.sql.Statement:\n\n    public  long executeLargeUpdate( String sql ) throws SQLException;\n    public  long executeLargeUpdate( String sql, int autoGeneratedKeys) throws SQLException;\n    public  long executeLargeUpdate( String sql, int[] columnIndexes ) throws SQLException;\n    public  long executeLargeUpdate( String sql, String[] columnNames ) throws SQLException;\n\nThis involved three changes:\n\n1) Changing the type of the update counter from int to long.\n\n2) Adding the new methods.\n\n3) Forwarding the executeUpdate() overloads to the corresponding newly added executeLargeUpdate() overloads.\n\nI have put off adding regression tests until I have added parallel methods to the client JDBC implementation.\n\n\nTouches the following files:\n\n-----------------------\n\nM       java/engine/org/apache/derby/iapi/sql/ResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/TemporaryRowHolderResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/BasicNoPutResultSetImpl.java\nM       java/engine/org/apache/derby/impl/sql/execute/RealResultSetStatisticsFactory.java\nM       java/engine/org/apache/derby/impl/sql/execute/DMLWriteResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/DeleteResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/NoRowsResultSetImpl.java\nM       java/engine/org/apache/derby/impl/sql/execute/UpdateResultSet.java\n\nStep (1).\n\n-----------------------\n\nM       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedPreparedStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java\n\nSteps (2) and (3).\n\nTests passed cleanly for me on derby-6000-01-aa-executeLargeUpdateEmbedded.diff. Committed at subversion revision 1438600.\nAttaching derby-6000-02-ad-executeLargeUpdateClient.diff. This adds large update support to Statements in the client JDBC driver. I am running tests now.\n\nThis adds the following method to the embedded driver:\n\n  Statement.getLargeUpdateCount()\n\n...and the following methods to the client driver:\n\n  Statement.executeLargeUpdate( String )\n  Statement.executeLargeUpdate( String, int )\n  Statement.executeLargeUpdate( String, int[] )\n  Statement.executeLargeUpdate( String, String[] )\n  Statement.getLargeUpdateCount()\n\nThe following changes are made:\n\n1) The update count on the client side is expanded from an int to a long.\n\n2) The update count is passed from the server to the client in the SQLCard descriptor. Previously, only an int sized update count was passed. Now a long sized update count is passed. This is done by leaving the low order 32 bits of the update count in the slot of the SQLCard which was previously used for the update count. Then the upper 32 bits are put in a previously unused slot of the SQLCard. This should mean that when clients and servers are at different revs, the client will still get the correct update count except in cases when the update count is greater than Integer.MAX_VALUE. In those oddball cases, the client used to receive garbage from the server. In these mixed rev situations, the client will continue to receive garbage for the update count if the number of updated rows exceeds Integer.MAX_VALUE.\n\n3) Magic numbers were eliminated when processing the SQLCard. Hopefully, this will make this code easier to study and debug.\n\n4) Factory methods were added for client-side BatchUpdateExceptions. These will be expanded when we add support for the new BatchUpdateException constructor added by JDBC 4.2.\n\n5) The new methods were added.\n\n6) The engine ResultSet code was tweaked to let tests force the engine to return absurdly large update counts. Otherwise, it is practically impossible to test the large update methods since this involves generating more than 2 billion rows for each test case.\n\n7) Tests were added for large updates for both the embedded and client drivers.\n\n\nTouches the following files:\n\n-----------------------\n\nM       java/drda/org/apache/derby/impl/drda/DRDAConnThread.java\nM       java/client/org/apache/derby/client/am/PreparedStatement.java\nM       java/client/org/apache/derby/client/am/Agent.java\n\nChanges for (1) and (2).\n\n-----------------------\n\nM       java/client/org/apache/derby/client/net/NetConnectionReply.java\nM       java/client/org/apache/derby/client/net/NetCursor.java\nM       java/client/org/apache/derby/client/am/Sqlca.java\n\nChanges for (3).\n\n-----------------------\n\nM       java/client/org/apache/derby/client/am/Utils.java\nM       java/client/org/apache/derby/client/am/BatchUpdateException.java\n\nChanges for (4).\n\n-----------------------\n\nM       java/engine/org/apache/derby/iapi/jdbc/EnginePreparedStatement.java\nM       java/client/org/apache/derby/client/am/Statement.java\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java\nM       java/drda/org/apache/derby/impl/drda/DRDAStatement.java\nM       java/client/org/apache/derby/client/am/LogicalStatementEntity.java\n\nChanges for (5).\n\n-----------------------\n\nM       java/engine/org/apache/derby/impl/sql/execute/DMLWriteResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/RowUtil.java\n\nChanges for (6).\n\n-----------------------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/XA40Test.java\n\nChanges for (7).\n\nTests passed cleanly for me on derby-6000-02-ad-executeLargeUpdateClient.diff.\nCommitted derby-6000-02-ad-executeLargeUpdateClient.diff at subversion revision 1439883.\nAttaching derby-6000-03-aa-executeLargeBatch.diff. This patch adds large batch support. I am running tests now.\n\nAdds the following method to the embedded and client drivers:\n\n  Statement.executeLargeBatch()\n\nMost of the machinery needed for this was added as part of implementing large updates.\n\n\nTouches the following files:\n\n----------\n\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/Util.java\n\nEmbedded changes.\n\n----------\n\nM       java/client/org/apache/derby/client/am/Statement.java\nM       java/client/org/apache/derby/client/am/LogicalStatementEntity.java\n\nClient changes.\n\n----------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java\nM       java/testing/org/apache/derbyTesting/junit/BaseTestCase.java\n\nNew tests.\n\nTests passed cleanly for me on derby-6000-03-aa-executeLargeBatch.diff. Committed at subversion revision 1440035.\nAttaching derby-6000-04-aa-setLargeMaxRows.diff. This patch adds support for setting/getting large limits on returned row counts. I will run regression tests.\n\nThis patch adds the following JDBC 4.2 methods to the embedded and client drivers:\n\n  Statement.setLargeMaxRows( long )\n  Statement.getLargeMaxRows()\n\nMostly this involved changing the datatype of some variables from int to long and then adding the new methods. As with the previous patch, some debug entry points were added so that we can test the new methods without actually generating more than 2 billion rows.\n\nTouches the following files:\n\n----------\n\nM       java/engine/org/apache/derby/iapi/sql/Activation.java\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java\nM       java/engine/org/apache/derby/impl/sql/execute/ScrollInsensitiveResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/BaseActivation.java\nM       java/engine/org/apache/derby/impl/sql/GenericActivationHolder.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedResultSet.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java\n\nEmbedded changes.\n\n----------\n\nM       java/client/org/apache/derby/client/am/Statement.java\nM       java/client/org/apache/derby/client/am/Cursor.java\nM       java/client/org/apache/derby/client/am/LogicalStatementEntity.java\nM       java/client/org/apache/derby/client/am/ResultSet.java\n\nClient changes.\n\n----------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java\n\nNew tests.\n\nTests passed cleanly for me on derby-6000-04-aa-setLargeMaxRows.diff. Committed at subversion revision 1440656.\nAttaching derby-6000-05-aa-executeLargeUpdatePS.diff. This patch adds JDBC 4.2 large update support to PreparedStatements. I am running tests now.\n\nThis patch adds the following method to the embedded and client implementations of PreparedStatement:\n\n  public long executeLargeUpdate()\n\n\n\nTouches the following files:\n\n--------------\n\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredPreparedStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EnginePreparedStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedPreparedStatement.java\n\nEmbedded changes.\n\n--------------\n\nM       java/client/org/apache/derby/client/am/PreparedStatement.java\nM       java/client/org/apache/derby/client/am/LogicalPreparedStatement.java\n\nClient changes.\n\n--------------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/PreparedStatementTest.java\n\nNew tests.\n\nTests passed cleanly for me on derby-6000-05-aa-executeLargeUpdatePS.diff. Committed at subversion revision 1441088.\nAttaching derby-6000-06-aa-DatabaseMetaData.diff. This patch makes the JDBC 4.2 changes to DatabaseMetaData. I will run regression tests.\n\nThis patch makes the following changes to the embedded and client drivers:\n\n1) Changes the datatype of the CARDINALITY and PAGES columns returned by getIndexInfo(). The column types are changed from INT to BIGINT.\n\n2) Adds a getMaxLogicalLOBSize() method. This method is supposed to return the maximum size of a LOB in bytes. For Derby that is the maximum size of a CLOB. A CLOB can have Integer.MAX_VALUE chars, which works out to Integer.MAX_VALUE * 2 bytes.\n\n3) Adds a supportsRefCursors() method. This returns false because Derby does not support the Types.REF_CURSOR type.\n\n\nTouches the following files:\n\n--------------\n\nM       java/engine/org/apache/derby/iapi/reference/Limits.java\nM       java/engine/org/apache/derby/impl/jdbc/metadata.properties\nM       java/engine/org/apache/derby/impl/jdbc/EmbedDatabaseMetaData.java\n\nEmbedded changes.\n\n--------------\n\nM       java/client/org/apache/derby/client/am/LogicalDatabaseMetaData40.java\nM       java/client/org/apache/derby/client/am/DatabaseMetaData.java\n\nClient changes.\n\n--------------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/Wrapper41DBMD.java\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/DatabaseMetaDataTest.java\nA       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/Wrapper42DBMD.java\n\nTests.\n\nTests passed cleanly for me on derby-6000-06-aa-DatabaseMetaData.diff except for the heisenbug in NetworkServerControlClientCommandTest. testPingWithWrongHost.\nCommitted derby-6000-06-aa-DatabaseMetaData.diff at subversion revision 1441436.\n", "issueSearchSentences": ["This patch adds the following method to the embedded and client implementations of PreparedStatement:", "This patch adds the following new methods to Derby's embedded JDBC 3.0 implementation of java.sql.Statement:", "This patch adds the following JDBC 4.2 methods to the embedded and client drivers:", "public  long executeLargeUpdate( String sql ) throws SQLException;", "public  long executeLargeUpdate( String sql, int autoGeneratedKeys) throws SQLException;"], "issueSearchIndexes": [153, 18, 126, 19, 20]}
{"aId": 124, "code": "public ReaderToUTF8Stream(Reader appReader,\n                              int valueLength,\n                              int numCharsToTruncate,\n                              String typeName) {\n        this.reader = new LimitReader(appReader);\n        reader.setLimit(valueLength);\n        buffer = new byte[BUFSIZE];\n        blen = -1;        \n        this.charsToTruncate = numCharsToTruncate;\n        this.valueLength = valueLength;\n        this.maximumLength = -1;\n        this.typeName = typeName;\n    }", "comment": " If the stream is shorter or longer than specified, an exception is thrown during read.", "issueId": "DERBY-1473", "issueStringList": ["Add cut-off and truncation logic to streaming classes in the embedded driver", "When streaming data to Derby, the application stream will be wrapped in a Derby-specific stream to convert the data to the correct representation.", "At a minimum, this consists of getting the data to the on-disk format used by Derby.", "The wrapping stream can be extended to provide the following features at an earlier stage:", "a) Data cut-off when the maximum allowed size is exceeded", "b) Truncation of trailing blanks where allowed", "Both features can reduce the amount of data needed to be kept in memory on insertion.", "Implementing this will require additional column/data type information in the streaming class(es).", "The implementation must be able to handle streams for which the length is specified and also streams with unknown/unspecified length.", "Updated affect version, fix version, priority and urgency.", "I set priority to major, because without this issue fixed, the length less overloads can only handle streams that can fit in memory.", "I set urgency to normal.", "Personally, I would have set it to urgent, but I don't know if the community feel that way.", "I will work to complete this task for 10.2.", "'derby-1473-1a-streaming.diff' adds the capability to handle length less streams properly.", "Such streams are now capped at the maximum length of the column it is inserted into.", "If the stream is longer than the limit, a DerbyIOException (subclass of IOException) is thrown, causing a statement severity StandardException to be thrown.", "The exception handling system takes care of cleaning up.", "If a stream is shorter or longer than the specified length, an exception is thrown as required by JDBC 3.0.", "How the exceptions thrown by the streaming classes are reported, differ between embedded and client.", "DERBY-1657 tracks this (see also DERBY-1658).", "I decided to split the changes to the engine and the testing into different patches.", "A testing patch will be submitted shortly.", "Note that both patches must be commited before derbyall is run, or else some tests will fail (characterStreams, resultSetStream and streamingColumn).", "derbyall passed, but due to a last minute change I am doing another run (will post result tomorrow).", "Patch ready for review/commit.", "The committer needs to add a new file (see stat file).", "'derby-1473-2a-streamingtests.diff' adds tests for the new (and old) streaming code in the embedded driver.", "I have some additional unit tests, but since I do not know where to put them yet, I have not included them.", "I also have a BigCLOBTest, but it fails for the client driver.", "DERBY-1559 might fix some of the problems I see, and I will rerun my tests now and then to keep an eye on the status.", "Streaming 2G LOBs now works for embedded.", "Patch is ready for review/commit.", "Patches 1a and 2a should be committed together, I split them up to ease the review.", "Posting the results from my final derbyall runs for the patches 1a and 2a combined:", "Solaris 10 (x86)", "JDK 1.3 : 22 failures, 557 tests", "JDK 5.0 : 1 failure, 691 tests", "upgradeTests/Upgrade_10_1_10_2.java", "JDK 6    : 2 failures, 734 tests", "store/OnlineBackupTest1.java", "upgradeTests/Upgrade_10_1_10_2.java", "Linux (Gentoo 2.6.16, amd64)", "JDK 1.4  : 0 failures, 685 tests", "JDK 6     : 3 failures, 653 tests, derbynetmats skipped", "derbynetclientmats/jdbcapi/XATest.java", "lang/prediacatPushdown.sql", "lang/wisconsin.java", "I believe the upgradetest is failing because if my environment (not finding the jars).", "The JDK1.3 errors are not due to my patch, but I will follow up on them.", "predicatePushdown and wisconsin seem to choose different query plans.", "Not sure about XATest, must look into the diff.", "I have started reviewing the patch.", "I haven't finished the review yet,", "but I'll post the comments I have so far.", "CharAlphabet.java contains some UTF-8 encoded characters, and I had", "to change my locale to be able to compile it.", "These characters", "should probably be escaped.", "RawToBinaryFormatStream(InputStream, int) first checks whether", "length is less than zero, and throws an exception if it is.", "After", "that check, there's a new one \"if (length >= 0) {...} else {...}\",", "but at that time length is guaranteed to be greater than or equal to", "zero.", "RawToBinaryFormatStream and ReaderToUTF8Stream sometimes throw", "IllegalArgumentException.", "I not sure whether I think this is a good", "or a bad approach.", "I think it is good because internal errors in", "Derby will be exposed and can be fixed.", "I also think it not so good", "because the conditions that are checked are not critical, and it", "would make sense to carry on in insane mode (for instance, typeName", "== null won't be a problem until an error message using the type", "name is constructed, and maximumLength < 0 will be treated more or", "less as 0).", "I think either it should be rewritten using", "SanityManager.ASSERT, or it should have a comment saying why", "IllegalArgumentException is used and that it won't be exposed to the", "users unless there's a programming error in Derby.", "In RawToBinaryFormatStream.checkSufficientData(), the body of the", "\"if (c != -1)\" clause has become very large.", "I think it would be", "clearer if it had braces around it (although the diff would be three", "lines longer).", "Thanks.", "I have reviewed the rest of the patch, and I have no more comments.", "Hi Knut Anders,", "Fixed.", "Thanks for catching this.", "It's a leftover from the previos implementation.", "This constructor is no longer allowed to be used for length less streams.", "I deleted the else-block.", "I have added comments to the two constructors.", "I would appreciate guidelines of how to use IllegalArgumentExceptions, SanityManager.ASSERT or similar.", "I do want to signal invalid use of the class, as it can cause much confusion if the illegal arguments are ignored and execution proceeds as normal.", "I have added braces around the block.", "I also made some changes for the patch to work with the move of JUnit infrastructure classes, and refreshed the patches.", "I ran the jdbc40 suite for a sanity check (1 expected error - TestQueryObject), and have a new derbyall running.", "Patches are now at revision b.", "derbyall completed with three failures, all \"expected\"; blobclob4BLOB and 2x QueryObjectTest.", "Thanks for addressing my comments, Kristian!", "You removed the else clause in RawToBinaryFormatStream's constructor,", "but I think you could also remove the if check, since the condition", "will always be true.", "Could you also elaborate on how the new class DerbyIOException is", "going to be used?", "As it is now, it is only thrown, and not caught", "anywhere.", "The javadoc for the class says:", "Without this distinction, the user would not be able to easily write", "<code>catch</code>-blocks to handle specific errors happening when", "reading streams.", "Does this mean our users should check for a DerbyIOException?", "I removed the if-block and uploaded a new patch (1c deprecates 1b).", "Our uses will not have to deal with DerbyIOException at all.", "The point of introducing it, is to separate between exceptions thrown by Derby itself and those thrown by the user/application stream.", "An example for the former, is when Derby detects that the stream is shorter than its specified length.", "The user can then catch this and check for the appropriate SQLState if he/she wishes to.", "I planned to catch it in InsertOperation and UpdateOperation, then extract the SQLState and generate and throw an exception with the correct SQLState.", "Currently, a very general exception is thrown, with the IOException (or DerbyIOException) chained deep down.", "See DERBY-1657 for a little more information (the issue is already linked to this one).", "I had originally implemented these changes, but decided to postpone them because the issues around impact on existing applications must be discussed first.", "The introduction (and current use of) DerbyIOException should not impact users in any way.", "Thanks Kristian.", "I tried to commit the patch, but there are conflicts with the ongoing JUnit reorganization in PreparedStatementTest.", "Could you please resolve the conflicts and upload a new test patch?", "Hi again Knut Anders,", "Yes, the following commit caused the conflicts for the 2b patch:", "Author: djd", "Date: Wed Aug 23 13:42:13 2006", "New Revision: 434169", "URL: http://svn.apache.org/viewvc?rev=434169&view=rev", "Log:", "Update the jdbc4 JUnit tests to use the recent additions, such as the single connection provided", "by BaseJDBCTestCase and the test decorator base class BaseJDBCTestSetup.", "I have resolved the conflicts and uploaded a new test patch (derby-1473-2c-streamingtests.diff).", "I also changed some of my original patch to follow the new ways of doing things.", "Only PreparedStatementTest has been altered.", "I have committed 1c and 2c into trunk with revision 437127.", "The changes merged cleanly into 10.2, and I plan to commit if derbyall doesn't fail.", "Committed into 10.2 with revision 437146."], "SplitGT": [" If the stream is shorter or longer than specified, an exception is thrown during read."], "issueString": "Add cut-off and truncation logic to streaming classes in the embedded driver\nWhen streaming data to Derby, the application stream will be wrapped in a Derby-specific stream to convert the data to the correct representation. At a minimum, this consists of getting the data to the on-disk format used by Derby.\n\nThe wrapping stream can be extended to provide the following features at an earlier stage:\n a) Data cut-off when the maximum allowed size is exceeded\n b) Truncation of trailing blanks where allowed\n\nBoth features can reduce the amount of data needed to be kept in memory on insertion.\nImplementing this will require additional column/data type information in the streaming class(es). The implementation must be able to handle streams for which the length is specified and also streams with unknown/unspecified length.\nUpdated affect version, fix version, priority and urgency.\nI set priority to major, because without this issue fixed, the length less overloads can only handle streams that can fit in memory.\nI set urgency to normal. Personally, I would have set it to urgent, but I don't know if the community feel that way.\n\nI will work to complete this task for 10.2.\n'derby-1473-1a-streaming.diff' adds the capability to handle length less streams properly. Such streams are now capped at the maximum length of the column it is inserted into. If the stream is longer than the limit, a DerbyIOException (subclass of IOException) is thrown, causing a statement severity StandardException to be thrown. The exception handling system takes care of cleaning up.\n\nIf a stream is shorter or longer than the specified length, an exception is thrown as required by JDBC 3.0.\nHow the exceptions thrown by the streaming classes are reported, differ between embedded and client. DERBY-1657 tracks this (see also DERBY-1658).\n\nI decided to split the changes to the engine and the testing into different patches. A testing patch will be submitted shortly. Note that both patches must be commited before derbyall is run, or else some tests will fail (characterStreams, resultSetStream and streamingColumn). derbyall passed, but due to a last minute change I am doing another run (will post result tomorrow).\n\nPatch ready for review/commit. The committer needs to add a new file (see stat file).\n'derby-1473-2a-streamingtests.diff' adds tests for the new (and old) streaming code in the embedded driver.\nI have some additional unit tests, but since I do not know where to put them yet, I have not included them.\n\nI also have a BigCLOBTest, but it fails for the client driver. DERBY-1559 might fix some of the problems I see, and I will rerun my tests now and then to keep an eye on the status. Streaming 2G LOBs now works for embedded.\n\nPatch is ready for review/commit.\nPatches 1a and 2a should be committed together, I split them up to ease the review.\nPosting the results from my final derbyall runs for the patches 1a and 2a combined:\n* Solaris 10 (x86)\n  JDK 1.3 : 22 failures, 557 tests\n  JDK 5.0 : 1 failure, 691 tests\n                    upgradeTests/Upgrade_10_1_10_2.java\n  JDK 6    : 2 failures, 734 tests\n                   store/OnlineBackupTest1.java\n                   upgradeTests/Upgrade_10_1_10_2.java\n                     \n\n* Linux (Gentoo 2.6.16, amd64)\n   JDK 1.4  : 0 failures, 685 tests\n   JDK 6     : 3 failures, 653 tests, derbynetmats skipped\n                      derbynetclientmats/jdbcapi/XATest.java\n                      lang/prediacatPushdown.sql\n                      lang/wisconsin.java\n\nI believe the upgradetest is failing because if my environment (not finding the jars).\nThe JDK1.3 errors are not due to my patch, but I will follow up on them.\npredicatePushdown and wisconsin seem to choose different query plans.\nNot sure about XATest, must look into the diff.\nI have started reviewing the patch. I haven't finished the review yet,\nbut I'll post the comments I have so far.\n\n- CharAlphabet.java contains some UTF-8 encoded characters, and I had\n  to change my locale to be able to compile it. These characters\n  should probably be escaped.\n\n- RawToBinaryFormatStream(InputStream, int) first checks whether\n  length is less than zero, and throws an exception if it is. After\n  that check, there's a new one \"if (length >= 0) {...} else {...}\",\n  but at that time length is guaranteed to be greater than or equal to\n  zero.\n\n- RawToBinaryFormatStream and ReaderToUTF8Stream sometimes throw\n  IllegalArgumentException. I not sure whether I think this is a good\n  or a bad approach. I think it is good because internal errors in\n  Derby will be exposed and can be fixed. I also think it not so good\n  because the conditions that are checked are not critical, and it\n  would make sense to carry on in insane mode (for instance, typeName\n  == null won't be a problem until an error message using the type\n  name is constructed, and maximumLength < 0 will be treated more or\n  less as 0). I think either it should be rewritten using\n  SanityManager.ASSERT, or it should have a comment saying why\n  IllegalArgumentException is used and that it won't be exposed to the\n  users unless there's a programming error in Derby.\n\n- In RawToBinaryFormatStream.checkSufficientData(), the body of the\n  \"if (c != -1)\" clause has become very large. I think it would be\n  clearer if it had braces around it (although the diff would be three\n  lines longer).\n\nThanks.\nI have reviewed the rest of the patch, and I have no more comments.\nHi Knut Anders,\n\n- Fixed.\n\n- Thanks for catching this. It's a leftover from the previos implementation. This constructor is no longer allowed to be used for length less streams. I deleted the else-block.\n\n- I have added comments to the two constructors. I would appreciate guidelines of how to use IllegalArgumentExceptions, SanityManager.ASSERT or similar. I do want to signal invalid use of the class, as it can cause much confusion if the illegal arguments are ignored and execution proceeds as normal.\n\n- I have added braces around the block.\n\nI also made some changes for the patch to work with the move of JUnit infrastructure classes, and refreshed the patches. I ran the jdbc40 suite for a sanity check (1 expected error - TestQueryObject), and have a new derbyall running.\n\nPatches are now at revision b.\nderbyall completed with three failures, all \"expected\"; blobclob4BLOB and 2x QueryObjectTest.\nThanks for addressing my comments, Kristian!\n\nYou removed the else clause in RawToBinaryFormatStream's constructor,\nbut I think you could also remove the if check, since the condition\nwill always be true.\n\nCould you also elaborate on how the new class DerbyIOException is\ngoing to be used? As it is now, it is only thrown, and not caught\nanywhere. The javadoc for the class says:\n\n  Without this distinction, the user would not be able to easily write\n  <code>catch</code>-blocks to handle specific errors happening when\n  reading streams.\n\nDoes this mean our users should check for a DerbyIOException?\nI removed the if-block and uploaded a new patch (1c deprecates 1b).\n\nOur uses will not have to deal with DerbyIOException at all.\nThe point of introducing it, is to separate between exceptions thrown by Derby itself and those thrown by the user/application stream. An example for the former, is when Derby detects that the stream is shorter than its specified length. The user can then catch this and check for the appropriate SQLState if he/she wishes to. \n\nI planned to catch it in InsertOperation and UpdateOperation, then extract the SQLState and generate and throw an exception with the correct SQLState. Currently, a very general exception is thrown, with the IOException (or DerbyIOException) chained deep down. See DERBY-1657 for a little more information (the issue is already linked to this one).\n\nI had originally implemented these changes, but decided to postpone them because the issues around impact on existing applications must be discussed first. The introduction (and current use of) DerbyIOException should not impact users in any way.\nThanks Kristian. I tried to commit the patch, but there are conflicts with the ongoing JUnit reorganization in PreparedStatementTest. Could you please resolve the conflicts and upload a new test patch?\nHi again Knut Anders,\n\nYes, the following commit caused the conflicts for the 2b patch:\nAuthor: djd\nDate: Wed Aug 23 13:42:13 2006\nNew Revision: 434169\n\nURL: http://svn.apache.org/viewvc?rev=434169&view=rev\nLog:\nUpdate the jdbc4 JUnit tests to use the recent additions, such as the single connection provided\nby BaseJDBCTestCase and the test decorator base class BaseJDBCTestSetup.\n\nI have resolved the conflicts and uploaded a new test patch (derby-1473-2c-streamingtests.diff). I also changed some of my original patch to follow the new ways of doing things. Only PreparedStatementTest has been altered.\n\nI have committed 1c and 2c into trunk with revision 437127. The changes merged cleanly into 10.2, and I plan to commit if derbyall doesn't fail.\nCommitted into 10.2 with revision 437146.\n", "issueSearchSentences": ["Fixed.", "IllegalArgumentException.", "Personally, I would have set it to urgent, but I don't know if the community feel that way.", "because the conditions that are checked are not critical, and it", "reading streams."], "issueSearchIndexes": [90, 67, 13, 73, 114]}
{"aId": 126, "code": "UpdateableBlobStream (EmbedBlob blob, InputStream is, long pos, long len) \n    throws SQLException {\n        this(blob, is);\n        //The length requested cannot exceed the length\n        //of the underlying Blob object. Hence chose the\n        //minimum of the length of the underlying Blob\n        //object and requested length.\n        maxPos = Math.min(blob.length(), pos + len);\n        \n        try {\n            //Skip to the requested position\n            //inside the stream.\n            skip(pos);\n        }\n        catch(IOException ioe) {\n            //Skip throws an IOException. Wrap the\n            //exception inside a SQLException and \n            //throw it to the caller.\n            \n            SQLException sqle = new SQLException();\n            sqle.initCause(ioe);\n            throw sqle;\n        }\n    }", "comment": " Construct an UpdateableBlobStream using the InputStream received as parameter. The initial position in the stream is set to pos and the stream is restricted to a length of len.", "issueId": "DERBY-2730", "issueStringList": ["Implement not implemented Embedded methods Blob.getBinaryStream(long pos, long length) and Clob.", "getCharacterStream(long pos, long length)", "The following methods were introduced in the java.sql.Clob and java.sql.Blob interface as part of JDBC 4.0 and need to be implemented.", "Clob", "getCharacterStream(long pos, long length)", "Blob", "getBinaryStream(long pos, long length)", "The implementation on the Network Client is already done as part of Derby-2444", "DERBY-2711 introduces a wrapper class UpdateableBlobStream which shall be used", "to return a subset of the underlying Blob object to the user.", "I have used the patch attached to the issue Derby-2711 to implement this patch.", "This patch", "hence contains the changes introduced by Derby-2711 also.", "Pls note that this patch is *not* for a commit.", "M      java/engine/org/apache/derby/impl/jdbc/EmbedBlob.java", "Added implementation for the getBinaryStream(long position, long length) method", "that wraps the stream returned from the getBinaryStream method inside the", "UpdateableBlobStream, using the constructor that accepts a position", "and length as parameter, to return a subset of the Blob value.", "A      java/engine/org/apache/derby/impl/jdbc/UpdateableBlobStream.java", "Added a constructor that accepts position and length as parameter.", "Modified", "the read methods to use the restriction on the position and length of the", "stream.", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/BlobTest.java", "A      java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/BlobUpdateableStreamTest.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/_Suite.java", "The other changes are related to Derby-2711", "Pls consider this patch for reviews and comments", "1) Looks fair enough, although I will not consider the review done until after DERBY-2711 is committed and a clean patch submitted.", "2) There's no explanation why Clob.getCharacterStream isn't a part of this patch.", "Thank you for the reviews and comments.", "> 1) Looks fair enough, although I will not consider the review done until after DERBY-2711 is committed and a clean patch submitted.", "The Derby-2711 changes will not exist when I submit a follow-up patch once Derby-2711", "is committed.", "You have mentioned clean patch, so I just wanted to ensure that you did", "feel unhappy with the alignment, non-presence of whit-space diffs and other general", "standard requirements of clean code.", "Pls do mention if the code is falling in  quality in any of these and", "I will correct them duly.", "> 2) There's no explanation why Clob.getCharacterStream isn't a part of this patch.", "I am sorry I should have mentioned this in the comments.", "Derby-2712 seems to be making changes to the wrapper in the same way", "Derby-2711 does.", "I could therefore not pull-out a patch as I have done in the", "case of Derby-2711 and make changes in way of a review patch since any", "changes to current classes would have had a conflict from the patch for Derby-2712.", "Can someone familiar with Derby-2712 pls tell me if the assumption I have made in the", "above comment is correct?", "I saw no white-space or layout issues.", "By \"clean patch\" in my comment, I meant a stand-alone patch independent of other non-committed changes.", "Thanks again for the comments, I shall make the changes as soon as Derby-2711 is committed and submit the patch.", "Derby-2711 has been committed.", "I have removed these changes from", "the patch previously marked as not for commit.", "I ran the modified BlobTest and it ran without failures.", "I have started a junit All run and shall revert back with", "the results.", "Pls consider this patch for reviews and comments", "The tests I had started on Saturday did not complete, I have started a", "new test run today.", "The tests seemed to be", "hanging and from the output of junit.textui.TestRunner I was not able to", "affirm which test was hanging and also", "if it was due to my change.", "I will run tests again and revert back with the results today.", "I", "Apologize for this unexpected delay.", "I just found out that there was a problem in the machine I was running", "tests.", "But I will anyway run", "tests once more today to re-affirm the that there are no problems in the", "implementation.", "Awkward first sentence in javadoc for new  UpdateableBlobStream constructor.", "The rest is ok.", "I had to initialize maxPos to -1 in the constructor of UpdateableBlobStream", "that does not accept length as parameter.", "I was planning to produce a", "follow-up", "just now.", "I will correct this issue along with the maxPos one.", "Thank you", "for", "taking a look at this.", "I have made the following changes in the follow-up", "1) I have initialized maxPos to -1 in the constructor that", "does not accept length as a parameter.", "2) I have updated the javadoc to say the following", "Construct an <code>UpdateableBlobStream<code> using the", "<code>InputStream</code> received as parameter.", "The initial", "position in the stream is set to <code>pos</code> and the", "stream is restricted to a length of <code>len</code>.", "Pls do mention if this is OK", "I ran BlobClob4BlobTest without failures and have started a junit All run.", "Sorry about the delayed test runs.", "I shall post the results as soon as the test", "completes.", "The getCharacterStream(long, long) implementation is blocked by", "the changes in Derby-2712.", "Pls note that this is only for the getCharacterStream implementation.", "I have run tests on GetBinaryStreamImpl_v2.diff and saw no failures.", "If everything is OK I request", "for this patch to be considered for a commit.", "getBinaryStream ok.", "Committed revision 546838.", "Thanks a ton for the commit Bernt !", "!", "Pls find the implementation of Clob.getCharacterStream(long, long).", "The logic", "followed is very similar to the getBinaryStream(long, long) implementation.", "I am running junit All on this patch and shall revert back with the test results."], "SplitGT": [" Construct an UpdateableBlobStream using the InputStream received as parameter.", "The initial position in the stream is set to pos and the stream is restricted to a length of len."], "issueString": "Implement not implemented Embedded methods Blob.getBinaryStream(long pos, long length) and Clob. getCharacterStream(long pos, long length)\nThe following methods were introduced in the java.sql.Clob and java.sql.Blob interface as part of JDBC 4.0 and need to be implemented.\n\nClob\n------\n\ngetCharacterStream(long pos, long length)\n\nBlob\n------\n\ngetBinaryStream(long pos, long length)\n\nThe implementation on the Network Client is already done as part of Derby-2444\nDERBY-2711 introduces a wrapper class UpdateableBlobStream which shall be used\nto return a subset of the underlying Blob object to the user.\nI have used the patch attached to the issue Derby-2711 to implement this patch. This patch \nhence contains the changes introduced by Derby-2711 also. \n\nPls note that this patch is *not* for a commit.\n\nM      java/engine/org/apache/derby/impl/jdbc/EmbedBlob.java\n\nAdded implementation for the getBinaryStream(long position, long length) method\nthat wraps the stream returned from the getBinaryStream method inside the \nUpdateableBlobStream, using the constructor that accepts a position\nand length as parameter, to return a subset of the Blob value.\n\nA      java/engine/org/apache/derby/impl/jdbc/UpdateableBlobStream.java\n\nAdded a constructor that accepts position and length as parameter. Modified\nthe read methods to use the restriction on the position and length of the\nstream.\n\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/BlobTest.java\nA      java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/BlobUpdateableStreamTest.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/_Suite.java\n\nThe other changes are related to Derby-2711\n\nPls consider this patch for reviews and comments\n1) Looks fair enough, although I will not consider the review done until after DERBY-2711 is committed and a clean patch submitted.\n2) There's no explanation why Clob.getCharacterStream isn't a part of this patch.\nThank you for the reviews and comments.\n\n> 1) Looks fair enough, although I will not consider the review done until after DERBY-2711 is committed and a clean patch submitted. \n\nThe Derby-2711 changes will not exist when I submit a follow-up patch once Derby-2711 \nis committed. \n\nYou have mentioned clean patch, so I just wanted to ensure that you did\nfeel unhappy with the alignment, non-presence of whit-space diffs and other general\nstandard requirements of clean code. \n\nPls do mention if the code is falling in  quality in any of these and \nI will correct them duly.\n\n> 2) There's no explanation why Clob.getCharacterStream isn't a part of this patch.\n\nI am sorry I should have mentioned this in the comments. \n\nDerby-2712 seems to be making changes to the wrapper in the same way\nDerby-2711 does. I could therefore not pull-out a patch as I have done in the\ncase of Derby-2711 and make changes in way of a review patch since any\nchanges to current classes would have had a conflict from the patch for Derby-2712.\n\nCan someone familiar with Derby-2712 pls tell me if the assumption I have made in the\nabove comment is correct?\nI saw no white-space or layout issues. By \"clean patch\" in my comment, I meant a stand-alone patch independent of other non-committed changes.\nThanks again for the comments, I shall make the changes as soon as Derby-2711 is committed and submit the patch.\nDerby-2711 has been committed. I have removed these changes from\nthe patch previously marked as not for commit.\n\nI ran the modified BlobTest and it ran without failures.\n\nI have started a junit All run and shall revert back with\nthe results.\n\nPls consider this patch for reviews and comments\nThe tests I had started on Saturday did not complete, I have started a \nnew test run today. The tests seemed to be\nhanging and from the output of junit.textui.TestRunner I was not able to \naffirm which test was hanging and also\nif it was due to my change.\n\nI will run tests again and revert back with the results today. I \nApologize for this unexpected delay.\n\n\n\nI just found out that there was a problem in the machine I was running \ntests. But I will anyway run\ntests once more today to re-affirm the that there are no problems in the \nimplementation.\n\n\n\n\nAwkward first sentence in javadoc for new  UpdateableBlobStream constructor. The rest is ok.\nI had to initialize maxPos to -1 in the constructor of UpdateableBlobStream\nthat does not accept length as parameter.  I was planning to produce a \nfollow-up\njust now. I will correct this issue along with the maxPos one. Thank you \nfor\ntaking a look at this.\n\n\n\n\nI have made the following changes in the follow-up\n\n1) I have initialized maxPos to -1 in the constructor that\n     does not accept length as a parameter.\n2) I have updated the javadoc to say the following\n\n     * Construct an <code>UpdateableBlobStream<code> using the \n     * <code>InputStream</code> received as parameter. The initial\n     * position in the stream is set to <code>pos</code> and the\n     * stream is restricted to a length of <code>len</code>.\n\n     Pls do mention if this is OK\n\nI ran BlobClob4BlobTest without failures and have started a junit All run.\n\nSorry about the delayed test runs. I shall post the results as soon as the test\ncompletes.\n\nThe getCharacterStream(long, long) implementation is blocked by \nthe changes in Derby-2712.\n\nPls note that this is only for the getCharacterStream implementation.\nI have run tests on GetBinaryStreamImpl_v2.diff and saw no failures. If everything is OK I request\nfor this patch to be considered for a commit.\ngetBinaryStream ok.\nCommitted revision 546838.\n\nThanks a ton for the commit Bernt !!\n\n\n\n\nPls find the implementation of Clob.getCharacterStream(long, long). The logic\nfollowed is very similar to the getBinaryStream(long, long) implementation.\n\nI am running junit All on this patch and shall revert back with the test results.\n", "issueSearchSentences": ["DERBY-2711 introduces a wrapper class UpdateableBlobStream which shall be used", "getCharacterStream(long pos, long length)", "UpdateableBlobStream, using the constructor that accepts a position", "Modified", "Implement not implemented Embedded methods Blob.getBinaryStream(long pos, long length) and Clob."], "issueSearchIndexes": [9, 5, 18, 22, 1]}
{"aId": 129, "code": "public boolean inReplicationMasterMode() {\n            return inReplicationMasterMode;\n        }", "comment": " Used to determine if the replication master mode has been started, and the logging for unlogged operations needs to be enabled.", "issueId": "DERBY-3551", "issueStringList": ["Implement procedure SYSCS_UTIL.SYSCS_PREPARE_REPLICATION()", "Jorgen says-", "I suggest that the replication step in which the master database is frozen is replaced by a new system procedure to solve index and import:", "Old: SYSCS_UTIL.SYSCS_FREEZE_DATABASE()", "New: SYSCS_UTIL.SYSCS_PREPARE_REPLICATION()", "The new system procedure should:", "1) Freeze the database", "2) Check if there are any ongoing transactions with unlogged operations.", "If so - unfreeze and abort.", "Otherwise:", "3) Enable logging of unlogged operations", "I have been trying to understand how I can enable logging for unlogged operations.", "My guide so far has been JIRA comments and code related to DERBY-239 -", "Need a online backup feature that does not block update operations when online backup", "is in progress.", "Derby-239 enables logging for unlogged operations by turning on the logArchived mode.", "Turning on logArchived mode from my understanding, archives logs as well as logs unlogged", "operations.", "But for replication archiving of logs is not necessary, we need to only turn on the logging.", "I am investigating further on how this alone can be done.", "In trying to search for a way to enable only logging of unlogged operations and", "not the archiving support available the following observations were very important", "1) Logic to enable logging is found in the BaseDataFileFactory", "(org.apache.derby.impl.store.raw.data.BaseDataFileFactory, line no 672)", "2) Logic for archiving is present in LogToFile", "This partitioning of logic was to the advantage of this issue and made the coding", "logic very simple", "Follows a brief explanation of the solution developed", "When log archiving needs to be done it is enabled by using a flag in the", "following way in the BaseDataFileFactory", "if (logFactory.logArchived()) {", "mode &= ~(ContainerHandle.MODE_UNLOGGED | ContainerHandle.MODE_CREATE_UNLOGGED);", "}", "(The ContainerHandle class contains a very good explanation of the MODE_UNLOGGED,", "MODE_CREATE_UNLOGGED flags.)", "Now in addition to just enabling the flags when logArchiving is required the flags need", "to be enabled when replication is active too.", "To achieve this the above code was changed to", "if (logFactory.logArchived() || logFactory.replicationLogUnlogged()) {", "mode &= ~(ContainerHandle.MODE_UNLOGGED | ContainerHandle.MODE_CREATE_UNLOGGED);", "}", "Doing the above solved the problem for a simple index creation, what remains to be seen", "is how it works for imports.", "Attaching a patch for people who might be interested in testing the solution.", "Another interesting decision will be as to whether a stored procedure will be required now?", "(I do not have an answer for this right now, but I surely shall be revisiting Derby-239 to learn", "more about unlogged operations being started before logging is enabled)", "Please note that Derby3551_1 is not for a commit.", "It is just for testing the solution.", "There are many other questions remaining unanswered.", "1) Is a stored procedure for starting replication required?", "2) What are the behaviour of imports?", "(There is a separate issue for jars)", "3) Tests need to be written for unlogged operations in the context of replication", "(there is a separate JIRA for this too)", "I feel that the stored procedure will not be required.", "Turning on logging with the present logic will happen when the master is booted (", "connection url with startMaster=true)", "Turning our attention to the future enhancements planned for 10.5 as mentioned", "in the functional specification", "How to start replication - Future enhancement (10.5)", "When replication is started, the slave checks that the database does not already exist,", "and that the user is authorized to create a database.", "The slave then starts to listen for", "a master on the specified host and port.", "The master connects to the slave and performs a", "handshake to ensure that only one master connects to a slave.", "The master then sends the", "whole database, including the active log files, to the slave via this connection.", "Hence,", "the database is only booted, not created, on the slave.", "The database copying operation happens when the master is connection to the slave.", "This is", "also where we turn on logging for unlogged operations.", "The stored procedure will then result in a series of redundant steps that would need to be", "performed again when we do the shipping automatically in the future enhancements for 10.5.", "That said,", "I think we need to move the steps mentioned above, to when we start the master controller.", "But", "I think this can wait till the above enhancements are implemented.", "For now the series of steps the user follows to start replication combined with the following", "check during replication startup", "\"Check if any unlogged operations are currently running, if yes unfreeze and throw an exception", "saying that replication cannot be started since the database has unlogged operations running\"", "Should suffice.", ">\"Check if any unlogged operations are currently running, if yes unfreeze and throw an exception", ">saying that replication cannot be started since the database has unlogged operations running\"", "Not sure if we should unfreeze or just throw an exception informing an user about the unlogged", "operations and let the user unfreeze the database", "I have modified Derby3551_1.diff to now throw an error when", "unlogged operations are running.", "I feel we should not unfreeze", "and instead should let the user unfreeze.", "I tested the patch Derby3551_2 with imports and it", "worked fine.", "Attached is a ij script that automatically", "exports and imports data, from tables it creates by", "itself.", "It tests the procedures", "SYSCS_UTIL.SYSCS_IMPORT_DATA and", "SYSCS_UTIL.SYSCS_IMPORT_TABLE_LOBS_FROM_EXTFILE", "To use it to test imports in replication just do the", "initial replication setup in ij and then do", "run 'runscript_import.sql';", "I thought the script might be helpful for people", "who wants to test imports with this patch without", "going through the creation of the tables and files", "necessary.", "I had also earlier tested this patch for a simple", "index creation and it worked fine.", "Since I guess unlogged operations will be blocked when the database is frozen, I think it will be safe to delay the check until starting the master.", "I think the proposed patch looks good.", "Do you plan to add some test cases?", "Some suggestions on wording:", "LogToFile#replicationLogUnlogged:  This method returns whether db is in master mode or not, and I think inReplicationMasterMode or something would be a better name.", "(The way the javadoc is written, it may lead you to think that you should call this method to activate logging.)", "messages.xml: I would say 'cannot be started' , not 'booted' since the operation is called startMaster.'", "> Since I guess unlogged operations will be blocked when the database is frozen,", "> I think it will be safe to delay the check until starting the master.", "correct, That is why I thought that a combination of the steps, the user should follow", "and a check to see if the freeze has frozen any already started unlogged operation, should", "suffice.", "> I think the proposed patch looks good.", "Do you plan to add some test cases?", "I intend to add tests in http://issues.apache.org/jira/browse/Derby-3553.", "I was hoping", "to move to installation of jars and look at what will be required there and then move to", "writing tests for unlogged operations.", "> * LogToFile#replicationLogUnlogged: This method returns whether db is in master", "> mode or not, and I think inReplicationMasterMode or something would be a better name.", "> (The way the javadoc is written, it may lead you to think that you should call this method to", "> activate logging.)", "Changed the method name to inReplicationMasterMode().", "I also changed the javadoc to the following", "Used to determine if the replication master mode has been started,", "and the logging for unlogged operations needs to be enabled.", "> * messages.xml: I would say 'cannot be started' , not 'booted' since the operation is called", "> startMaster.'", "Changed 'booted' to 'started'.", "Thanks for addressing my comments, Naraynan.", "Committed version 3 of the patch at revision 640631."], "SplitGT": [" Used to determine if the replication master mode has been started, and the logging for unlogged operations needs to be enabled."], "issueString": "Implement procedure SYSCS_UTIL.SYSCS_PREPARE_REPLICATION()\nJorgen says-\n\nI suggest that the replication step in which the master database is frozen is replaced by a new system procedure to solve index and import:\n\nOld: SYSCS_UTIL.SYSCS_FREEZE_DATABASE()\nNew: SYSCS_UTIL.SYSCS_PREPARE_REPLICATION()\n\nThe new system procedure should:\n1) Freeze the database\n2) Check if there are any ongoing transactions with unlogged operations. If so - unfreeze and abort. Otherwise:\n3) Enable logging of unlogged operations \nI have been trying to understand how I can enable logging for unlogged operations. \nMy guide so far has been JIRA comments and code related to DERBY-239 - \nNeed a online backup feature that does not block update operations when online backup \nis in progress.\n\nDerby-239 enables logging for unlogged operations by turning on the logArchived mode.\nTurning on logArchived mode from my understanding, archives logs as well as logs unlogged\noperations.\n\nBut for replication archiving of logs is not necessary, we need to only turn on the logging.\n\nI am investigating further on how this alone can be done.\nIn trying to search for a way to enable only logging of unlogged operations and\nnot the archiving support available the following observations were very important\n\n1) Logic to enable logging is found in the BaseDataFileFactory \n  (org.apache.derby.impl.store.raw.data.BaseDataFileFactory, line no 672)\n2) Logic for archiving is present in LogToFile\n\nThis partitioning of logic was to the advantage of this issue and made the coding\nlogic very simple\n\nFollows a brief explanation of the solution developed\n\nWhen log archiving needs to be done it is enabled by using a flag in the\nfollowing way in the BaseDataFileFactory\n\nif (logFactory.logArchived()) {\n    mode &= ~(ContainerHandle.MODE_UNLOGGED | ContainerHandle.MODE_CREATE_UNLOGGED);\n}\n\n(The ContainerHandle class contains a very good explanation of the MODE_UNLOGGED, \nMODE_CREATE_UNLOGGED flags.)\n\nNow in addition to just enabling the flags when logArchiving is required the flags need\nto be enabled when replication is active too. To achieve this the above code was changed to\n\nif (logFactory.logArchived() || logFactory.replicationLogUnlogged()) {\n    mode &= ~(ContainerHandle.MODE_UNLOGGED | ContainerHandle.MODE_CREATE_UNLOGGED);\n}\n\nDoing the above solved the problem for a simple index creation, what remains to be seen\nis how it works for imports.\n\nAttaching a patch for people who might be interested in testing the solution.\n\nAnother interesting decision will be as to whether a stored procedure will be required now?\n(I do not have an answer for this right now, but I surely shall be revisiting Derby-239 to learn\nmore about unlogged operations being started before logging is enabled)\nPlease note that Derby3551_1 is not for a commit. It is just for testing the solution.\nThere are many other questions remaining unanswered.\n\n1) Is a stored procedure for starting replication required?\n\n2) What are the behaviour of imports? (There is a separate issue for jars)\n\n3) Tests need to be written for unlogged operations in the context of replication\n    (there is a separate JIRA for this too)\n\n\nI feel that the stored procedure will not be required.\n\nTurning on logging with the present logic will happen when the master is booted (\nconnection url with startMaster=true)\n\nTurning our attention to the future enhancements planned for 10.5 as mentioned\nin the functional specification\n\n----------------------------------------------------------------------------------------\nHow to start replication - Future enhancement (10.5)\n\nWhen replication is started, the slave checks that the database does not already exist, \nand that the user is authorized to create a database. The slave then starts to listen for \na master on the specified host and port. The master connects to the slave and performs a \nhandshake to ensure that only one master connects to a slave. The master then sends the \nwhole database, including the active log files, to the slave via this connection. Hence, \nthe database is only booted, not created, on the slave.\n------------------------------------------------------------------------------------------\n\nThe database copying operation happens when the master is connection to the slave. This is\nalso where we turn on logging for unlogged operations.\n\nThe stored procedure will then result in a series of redundant steps that would need to be\nperformed again when we do the shipping automatically in the future enhancements for 10.5.\n\nThat said,\n\nI think we need to move the steps mentioned above, to when we start the master controller. But\nI think this can wait till the above enhancements are implemented. \n\nFor now the series of steps the user follows to start replication combined with the following \ncheck during replication startup\n\n\"Check if any unlogged operations are currently running, if yes unfreeze and throw an exception\nsaying that replication cannot be started since the database has unlogged operations running\"\n\nShould suffice.\n>\"Check if any unlogged operations are currently running, if yes unfreeze and throw an exception\n>saying that replication cannot be started since the database has unlogged operations running\" \n\nNot sure if we should unfreeze or just throw an exception informing an user about the unlogged\noperations and let the user unfreeze the database\nI have modified Derby3551_1.diff to now throw an error when\nunlogged operations are running. I feel we should not unfreeze\nand instead should let the user unfreeze.\nI tested the patch Derby3551_2 with imports and it\nworked fine. \n\nAttached is a ij script that automatically\nexports and imports data, from tables it creates by\nitself.\n\nIt tests the procedures\n\nSYSCS_UTIL.SYSCS_IMPORT_DATA and\n\nSYSCS_UTIL.SYSCS_IMPORT_TABLE_LOBS_FROM_EXTFILE\n\nTo use it to test imports in replication just do the\ninitial replication setup in ij and then do\n\nrun 'runscript_import.sql';\n\nI thought the script might be helpful for people\nwho wants to test imports with this patch without\ngoing through the creation of the tables and files\nnecessary.\nI had also earlier tested this patch for a simple\nindex creation and it worked fine.\nSince I guess unlogged operations will be blocked when the database is frozen, I think it will be safe to delay the check until starting the master.\n\nI think the proposed patch looks good. Do you plan to add some test cases? \nSome suggestions on wording:\n\n * LogToFile#replicationLogUnlogged:  This method returns whether db is in master mode or not, and I think inReplicationMasterMode or something would be a better name.  (The way the javadoc is written, it may lead you to think that you should call this method to activate logging.)\n\n * messages.xml: I would say 'cannot be started' , not 'booted' since the operation is called startMaster.'\n> Since I guess unlogged operations will be blocked when the database is frozen, \n> I think it will be safe to delay the check until starting the master. \n\ncorrect, That is why I thought that a combination of the steps, the user should follow\nand a check to see if the freeze has frozen any already started unlogged operation, should\nsuffice.\n\n> I think the proposed patch looks good. Do you plan to add some test cases?\n\nI intend to add tests in http://issues.apache.org/jira/browse/Derby-3553. I was hoping\nto move to installation of jars and look at what will be required there and then move to\nwriting tests for unlogged operations.\n\n> * LogToFile#replicationLogUnlogged: This method returns whether db is in master \n> mode or not, and I think inReplicationMasterMode or something would be a better name. \n> (The way the javadoc is written, it may lead you to think that you should call this method to \n> activate logging.)\n\nChanged the method name to inReplicationMasterMode(). I also changed the javadoc to the following\n\n* Used to determine if the replication master mode has been started,\n* and the logging for unlogged operations needs to be enabled.\n\n> * messages.xml: I would say 'cannot be started' , not 'booted' since the operation is called \n> startMaster.'\n\nChanged 'booted' to 'started'.\nThanks for addressing my comments, Naraynan.\nCommitted version 3 of the patch at revision 640631.\n", "issueSearchSentences": ["> activate logging.)", "> * LogToFile#replicationLogUnlogged: This method returns whether db is in master", "Some suggestions on wording:", "public boolean inReplicationMasterMode() {\n            return inReplicationMasterMode;\n        }", "Implement procedure SYSCS_UTIL.SYSCS_PREPARE_REPLICATION()"], "issueSearchIndexes": [132, 129, 114, 0, 1]}
{"aId": 130, "code": "public boolean isClosed() throws SQLException {\n        // If active, verify state by consulting parent connection.\n        if (active) {\n            try {\n                checkExecStatus();\n            } catch (SQLException sqle) {\n            }\n        }\n        return !active;\n    }", "comment": " Tell whether this statment has been closed or not.", "issueId": "DERBY-953", "issueStringList": ["Add miscellaneous Statement methods introduced by JDBC 4", "As described in the JDBC 4 spec, sections 13.1 and 3.1.", "This adds support for new Statement methods added by JDBC4 and not addressed by other JIRAs: isClosed() and getResultSetHoldability().", "Uploaded patch 'DERBY-953-1a.diff' for implementing Statement.isClosed() on both client and embedded side.", "There seems to be a bug in Derby, where Statements are not closed when the parent connection is.", "The problem is not seem when testing the client side, but it might still be the case that the problem do occur \"under the hood\" on the server/embedded side.", "Created issue DERBY-1095 for the bug.", "No tests are uploaded yet, as they are dependent on some JUnit changes.", "Will be handled as a separate Jira issue.", "Derbyall has not been run for this patch, as it is only created two new methods that return variables.", "All tests will be run as part of the testing issue.", "The new tests will basically test the existing implementation.", "I leave it up to a committer if the patch is delayed until the testing is in place or not, as the patch is rather simple.", "As a side note, it is possible to implement isClosed() to return the intended values despite the bug described.", "However, in my opinion, this will only mask the bug, thus it is better to implement it as it is done in the current patch and wait for the bug to be fixed.", "If we want to have correct results despite the bug, we only need to have isClosed() check the status of the parent connection before checking it's own state, but the Statement would actually not be closed even though isClosed() says it is...", "BTW: getResultSetHoldability() is already implemented (JDBC3?", ").", "Statement.isClosed() will not return correct values on the embedded side when parent connection is closed until the blocking issue DERBY-1095 is resolved.", "'DERBY-953-2a.diff' implements EmbedStatement.isClosed() in different way.", "If the statement is marked as active, it goes to the parent connection to verify this.", "Tests have been run locally, but they are not yet submitted for commit.", "See DERBY-1097 for testing code.", "Derbyall has not been run, the patch only adds new code that is not used anywhere yet.", "Implementation is in line with the comment for the initial submission, and with the comments on DERBY-1095.", "Nothing have been changed for the client side since the previous patch.", "See 'DERBY-953-1a.stat' for svn status (unchanged).", "Please review, and when acceptable, commit.", "I don't like the approach of using an exception to determine if the statement is closed.", "I see your motivation -- you want to reuse the code that sets active to false.", "I think the better way to do this is to refactor out the code inside checkExecStatus() that sets the active field, thusly:", "protected final boolean checkActive() throws SQLException {", "if (!getConnection().isClosed())", "return true;", "active = false;", "return false;", "}", "protected final void checkExecStatus() throws SQLException {", "if ( !", "checkActive() ) {", "throw Util.noCurrentConnection();", "}", "}", "public boolean isClosed() throws SQLException {", "if ( active )", "checkActive();", "return !active;", "}", "The code snippet posted in the previous comment still has the same problem as the original code, which was the reason why I returned true in the catch block.", "A NoCurrentConnection exception can be thrown in getConnection().", "active would then still not be set to false, and isClosed would throw this exception.", "I do not like that isClosed can throw an exception in this case, and in this situation I would dare say a NoCurrentConnection is the same as the statement being closed and we could simply return true.", "So I don't quite see how the new proposal would solve the issue.", "It would also introduce yet another method for checking the state, taking the number up to three; checkStatus, checkExecStatus and checkActive.", "If you still want this to happen, give me a little more pushback, I'm not yet convinced I want to do this.", "I do however see that I could have checked that the exception thrown actually is a NoCurrentConnection exception, and then re-throw the exception if it is not.", "Would that ease your concerns?", "Sorry, I missed that about getConnection().", "But my point still stands, we shouldn't use exceptions for making decisions mainline execution.", "We can refactor getConnection() using the same approach:", "Try to get the connection.", "Returns null if it's not valid", "protected final Connection getConnectionInternal() {", "java.sql.Connection appConn = getEmbedConnection().getApplicationConnection();", "if (appConn != applicationConnection) {", "appCon = null;", "return appConn;", "}", "Check the status without throwing an exception.", "Returns true if the statement", "is active and has a valid, open connection, false otherwise", "protected final boolean checkExecNoException() {", "Connection conn = getConnectionInternal();", "if ( conn == null  || conn.isClosed() )", "active = false;", "return active;", "}", "protected final void checkExecStatus() throws SQLException {", "checkStatus();", "if ( !", "checkExecStatusNoException() )", "throw Util.noCurrentConnection()", "}", "public final java.sql.Connection getConnection() throws SQLException {", "checkStatus();", "java.sql.Connection appConn = getConnectionInternal();", "if ( appConn == null )", "throw Util.noCurrentConnection();", "}", "public final boolean isClosed() throws SQLException {", "return (  !", "active ||  checkExecStatusNoException() );", "}", "'DERBY-953-3a.diff' is a patch implementing pretty much what David suggested.", "I made some corrections, and I also had to add a try-catch block to the 'checkExecStatusNoException'-method, because we are using the Connection-interface there, not the EmbedConnection implementation.", "It is not quite clear to me if we can get another Connection-implementation there, but I have assumed so.", "If the connection is *always* an EmbedConnection, we could cast.", "Other comments:", "1) The patch has some white-space changes.", "The file contains a mix of tabs and spaces, and I chose to use spaces for the patch.", "2) The patch also has some Javadoc fixes.", "3) My StatementTest passes (embedded and DerbyNetClient, JCC excluded due to missing JDBC4 support).", "4) I ran derbyall, but made some minor changes afterwards.", "The first one passed, the second run is ongoing.", "I will report if errors occur.", "Patch can be reviewed and committed.", "I was expecting the patch to be very similar to the one for ResultSet.isClosed(), but it seems to have gained in complexity for little value.", "Not sure I understand David's comment about \"using exception for mainline decisions\", I don't see that happening in the simpler version", "of the patch (ie.", "one similar to the changes made for ResultSet.isClosed()).", "An execption is only used when the Statement is closed, that's", "not the mainline execution, it's the exception case.", "Sorry, I wasn't able to comment earlier, I've been busy,.", "I could be stubborn about my point of view, but I think that's not worthwhile.", "Dan has a good point, and Kristian has also pointed out to me that there are exceptions all the way down so there's no way to avoid catching an exception.", "So I must humbly apologize to Kristian and say I think I have to agree with Dan that the first patch is simpler and is more in line with ResultSet.isClosed().", "I would like it to check for a *specific* SQL State (e.g.", "SQLState.NO_CURRENT_CONNECTION) rather than swallow any old exception.", "I'll make that change and commit.", "David", "Why do you need to check for a specific state, the field active tells you everything you need to know?", "A ResultSet can still be open and the check methods throw no current connection, this is the case when the ResultSet is open", "in a global transaction but the transaction is detached from the connection.", "Statement may fall along the same lines.", "I think this is the correct fix, a slightly modified version of the second patch, removing the assumption that if", "checkExecStatus throws an exception that the statement is closed.", "This them matches the ResultSet.isClosed() approach.", "+     * Tell whether this statment has been closed or not.", "+     *", "+     * @return <code>true</code> is closed, <code>false</code> otherwise.", "+     * @exception SQLException if a database access error occurs.", "+     */", "+    public boolean isClosed()", "+        throws SQLException {", "+        // If active, verify state by consulting parent connection.", "+        if (active) {", "+            try {", "+                checkExecStatus();", "+            } catch (SQLException sqle) {", "+            }", "+        }", "+        return !active;", "+    }", "Thanks for your tips on this, Dan.", "Your version looks just right.", "I'll wait to hear from Kristian, but if he's OK, I can make the change you suggest and commit.", "One question on this: your example swallows *any* SqlException.", "I think this assumes that the only possible exception is going to be NO_CURRENT_CONNECTION.", "Is that a fair assumption?", "I can't say I fully understand the code.", "Shouldn't we be throwing other exceptions besides NO_CURRENT_CONNECTION?", "No, that's not the assumption I made.", "The assumption is that after a call to checkExecStatus() the active field will correctly represent the closed/open state of the Statement.", "I can add comments to three methods that are involved in this code stating what exceptions they throw if you think that will help.", "I guess I just feel uncomfortable with swallowing *all* exceptions.", "Can you explain it to me like I were a novice why that's OK in this case?", "Why wouldn't it be better to check for the specific exception?", "Not really sure what explanations you are looking for David, I just clarified the javadoc comments for EmbedStatement.checkStatus and checkExecStatus based upon a few minutes of code inspection.", "Modifying the javadoc firms up the contract this method is exposing and thus the code in isClosed() is allowed to make assumptions", "based upon that contract.", "The  checkExecStatus method only throws execeptions in two cases, one the statement is closed and two the statement is part of a non-active global transaction.", "In either of those two cases and the no exception case after the execution the active field correctly represents the open state of the Statement.", "One exception thrown is the NO_CURRENT_CONNECTION sql state, means either :", "the Statement is open but in a suspended transaction (isClosed needs to return false)", "the Statement has been closed implicitly due to its connection being closed and this is the first", "call against the Statement that has noticed the connection has been closed.", "(isClosed needs to return true)", "The other is ALREADY_CLOSED, means either :", "the Statement has been explictly closed  (isClosed needs to return true)", "the Statement has been closed implicitly and a previous checkExecStatus threw a  NO_CURRENT_CONNECTION (isClosed needs to return true)", "Thus only catching NO_CURRENT_CONNECTION would be wrong as ALREADY_CLOSED is a valid exception that could occur", "here and require isClosed() to return true.", "Thus we are left with needing to catch the two exceptions that this method can throw, which seems,", "to me, to be the same as catching everything.", "Thanks, Dan, this was what I'm looking for.", "I'm working on committing this patch."], "SplitGT": [" Tell whether this statment has been closed or not."], "issueString": "Add miscellaneous Statement methods introduced by JDBC 4\nAs described in the JDBC 4 spec, sections 13.1 and 3.1.\n\nThis adds support for new Statement methods added by JDBC4 and not addressed by other JIRAs: isClosed() and getResultSetHoldability().\nUploaded patch 'DERBY-953-1a.diff' for implementing Statement.isClosed() on both client and embedded side.\nThere seems to be a bug in Derby, where Statements are not closed when the parent connection is. The problem is not seem when testing the client side, but it might still be the case that the problem do occur \"under the hood\" on the server/embedded side. Created issue DERBY-1095 for the bug.\n\nNo tests are uploaded yet, as they are dependent on some JUnit changes. Will be handled as a separate Jira issue.\nDerbyall has not been run for this patch, as it is only created two new methods that return variables.\nAll tests will be run as part of the testing issue. The new tests will basically test the existing implementation.\n\nI leave it up to a committer if the patch is delayed until the testing is in place or not, as the patch is rather simple.\n\nAs a side note, it is possible to implement isClosed() to return the intended values despite the bug described. However, in my opinion, this will only mask the bug, thus it is better to implement it as it is done in the current patch and wait for the bug to be fixed.\nIf we want to have correct results despite the bug, we only need to have isClosed() check the status of the parent connection before checking it's own state, but the Statement would actually not be closed even though isClosed() says it is...\n\nBTW: getResultSetHoldability() is already implemented (JDBC3?).\nStatement.isClosed() will not return correct values on the embedded side when parent connection is closed until the blocking issue DERBY-1095 is resolved.\n'DERBY-953-2a.diff' implements EmbedStatement.isClosed() in different way. If the statement is marked as active, it goes to the parent connection to verify this. Tests have been run locally, but they are not yet submitted for commit. See DERBY-1097 for testing code.\nDerbyall has not been run, the patch only adds new code that is not used anywhere yet.\nImplementation is in line with the comment for the initial submission, and with the comments on DERBY-1095.\nNothing have been changed for the client side since the previous patch. See 'DERBY-953-1a.stat' for svn status (unchanged).\n\nPlease review, and when acceptable, commit.\nI don't like the approach of using an exception to determine if the statement is closed.  I see your motivation -- you want to reuse the code that sets active to false.  I think the better way to do this is to refactor out the code inside checkExecStatus() that sets the active field, thusly:\n\nprotected final boolean checkActive() throws SQLException {\n  if (!getConnection().isClosed())\n    return true;\n\n  active = false;\n  return false;\n}\n\nprotected final void checkExecStatus() throws SQLException {\n  if ( ! checkActive() ) {\n    throw Util.noCurrentConnection();\n  }\n}\n\npublic boolean isClosed() throws SQLException {\n  if ( active )\n    checkActive();\n\n  return !active;\n}\nThe code snippet posted in the previous comment still has the same problem as the original code, which was the reason why I returned true in the catch block.\nA NoCurrentConnection exception can be thrown in getConnection(). active would then still not be set to false, and isClosed would throw this exception. I do not like that isClosed can throw an exception in this case, and in this situation I would dare say a NoCurrentConnection is the same as the statement being closed and we could simply return true.\n\nSo I don't quite see how the new proposal would solve the issue. It would also introduce yet another method for checking the state, taking the number up to three; checkStatus, checkExecStatus and checkActive.\n\nIf you still want this to happen, give me a little more pushback, I'm not yet convinced I want to do this.\nI do however see that I could have checked that the exception thrown actually is a NoCurrentConnection exception, and then re-throw the exception if it is not.\nWould that ease your concerns?\n\n\n\nSorry, I missed that about getConnection().  But my point still stands, we shouldn't use exceptions for making decisions mainline execution.\n\nWe can refactor getConnection() using the same approach:\n\n/**\n * Try to get the connection.  Returns null if it's not valid\n */\nprotected final Connection getConnectionInternal() {\n    java.sql.Connection appConn = getEmbedConnection().getApplicationConnection();\n    if (appConn != applicationConnection) {\n        appCon = null;\n\n    return appConn;\n}\n\n/**\n* Check the status without throwing an exception.  Returns true if the statement\n* is active and has a valid, open connection, false otherwise\n*/\nprotected final boolean checkExecNoException() {\n    Connection conn = getConnectionInternal();\n    if ( conn == null  || conn.isClosed() )\n      active = false;\n\n    return active;\n}\n\nprotected final void checkExecStatus() throws SQLException {\n   checkStatus();\n\n   if ( ! checkExecStatusNoException() )\n       throw Util.noCurrentConnection()\n}\n\npublic final java.sql.Connection getConnection() throws SQLException {\n    checkStatus();\n\n    java.sql.Connection appConn = getConnectionInternal();\n\n    if ( appConn == null ) \n        throw Util.noCurrentConnection();\n}\n\npublic final boolean isClosed() throws SQLException {\n    return (  ! active ||  checkExecStatusNoException() );\n}\n\n  \n'DERBY-953-3a.diff' is a patch implementing pretty much what David suggested. I made some corrections, and I also had to add a try-catch block to the 'checkExecStatusNoException'-method, because we are using the Connection-interface there, not the EmbedConnection implementation. It is not quite clear to me if we can get another Connection-implementation there, but I have assumed so. If the connection is *always* an EmbedConnection, we could cast.\n\nOther comments:\n1) The patch has some white-space changes. The file contains a mix of tabs and spaces, and I chose to use spaces for the patch.\n2) The patch also has some Javadoc fixes.\n3) My StatementTest passes (embedded and DerbyNetClient, JCC excluded due to missing JDBC4 support).\n4) I ran derbyall, but made some minor changes afterwards. The first one passed, the second run is ongoing. I will report if errors occur.\n\nPatch can be reviewed and committed.\nI was expecting the patch to be very similar to the one for ResultSet.isClosed(), but it seems to have gained in complexity for little value.\n\nNot sure I understand David's comment about \"using exception for mainline decisions\", I don't see that happening in the simpler version\nof the patch (ie. one similar to the changes made for ResultSet.isClosed()). An execption is only used when the Statement is closed, that's\nnot the mainline execution, it's the exception case.\n\nSorry, I wasn't able to comment earlier, I've been busy,.\nI could be stubborn about my point of view, but I think that's not worthwhile.  Dan has a good point, and Kristian has also pointed out to me that there are exceptions all the way down so there's no way to avoid catching an exception.\n\nSo I must humbly apologize to Kristian and say I think I have to agree with Dan that the first patch is simpler and is more in line with ResultSet.isClosed().\n\nI would like it to check for a *specific* SQL State (e.g. SQLState.NO_CURRENT_CONNECTION) rather than swallow any old exception.   I'll make that change and commit.\n\nDavid\nWhy do you need to check for a specific state, the field active tells you everything you need to know?\n\nA ResultSet can still be open and the check methods throw no current connection, this is the case when the ResultSet is open\nin a global transaction but the transaction is detached from the connection.\n\nStatement may fall along the same lines.\n\n\nI think this is the correct fix, a slightly modified version of the second patch, removing the assumption that if\ncheckExecStatus throws an exception that the statement is closed. This them matches the ResultSet.isClosed() approach.\n\n     /**\n+     * Tell whether this statment has been closed or not.\n+     *\n+     * @return <code>true</code> is closed, <code>false</code> otherwise.\n+     * @exception SQLException if a database access error occurs.\n+     */\n+    public boolean isClosed() \n+        throws SQLException {\n+        // If active, verify state by consulting parent connection.\n+        if (active) {\n+            try {\n+                checkExecStatus();\n+            } catch (SQLException sqle) {\n+            }\n+        }\n+        return !active;\n+    }\nThanks for your tips on this, Dan.  Your version looks just right.  I'll wait to hear from Kristian, but if he's OK, I can make the change you suggest and commit.\nOne question on this: your example swallows *any* SqlException.  I think this assumes that the only possible exception is going to be NO_CURRENT_CONNECTION.  Is that a fair assumption?  I can't say I fully understand the code.  Shouldn't we be throwing other exceptions besides NO_CURRENT_CONNECTION?\nNo, that's not the assumption I made. The assumption is that after a call to checkExecStatus() the active field will correctly represent the closed/open state of the Statement. I can add comments to three methods that are involved in this code stating what exceptions they throw if you think that will help.\nI guess I just feel uncomfortable with swallowing *all* exceptions.  Can you explain it to me like I were a novice why that's OK in this case?  Why wouldn't it be better to check for the specific exception?\nNot really sure what explanations you are looking for David, I just clarified the javadoc comments for EmbedStatement.checkStatus and checkExecStatus based upon a few minutes of code inspection. Modifying the javadoc firms up the contract this method is exposing and thus the code in isClosed() is allowed to make assumptions\nbased upon that contract.\n\nThe  checkExecStatus method only throws execeptions in two cases, one the statement is closed and two the statement is part of a non-active global transaction.\nIn either of those two cases and the no exception case after the execution the active field correctly represents the open state of the Statement.\n\nOne exception thrown is the NO_CURRENT_CONNECTION sql state, means either :\n                    the Statement is open but in a suspended transaction (isClosed needs to return false)\n                    the Statement has been closed implicitly due to its connection being closed and this is the first\n                    call against the Statement that has noticed the connection has been closed. (isClosed needs to return true)\n\nThe other is ALREADY_CLOSED, means either :\n                     the Statement has been explictly closed  (isClosed needs to return true)\n                     the Statement has been closed implicitly and a previous checkExecStatus threw a  NO_CURRENT_CONNECTION (isClosed needs to return true)\n\n\nThus only catching NO_CURRENT_CONNECTION would be wrong as ALREADY_CLOSED is a valid exception that could occur\nhere and require isClosed() to return true. Thus we are left with needing to catch the two exceptions that this method can throw, which seems,\nto me, to be the same as catching everything.\n\n\n\nThanks, Dan, this was what I'm looking for.  I'm working on committing this patch.\n", "issueSearchSentences": ["+        throws SQLException {", "public boolean isClosed() throws SQLException {", "+        // If active, verify state by consulting parent connection.", "}", "+                checkExecStatus();"], "issueSearchIndexes": [134, 44, 135, 43, 138]}
{"aId": 131, "code": "private static FormatableBitSet getDeleteReadMap\n\t(\n\t\tTableDescriptor\t\t\t\tbaseTable,\n\t\tVector\t\t\t\t\t\tconglomVector,\n\t\tGenericDescriptorList\t\trelevantTriggers,\n\t\tboolean[]\t\t\t\t\tneedsDeferredProcessing\n\t)\n\t\tthrows StandardException\n\t{\n\t\tint\t\tcolumnCount = baseTable.getMaxColumnID();\n\t\tFormatableBitSet\tcolumnMap = new FormatableBitSet(columnCount + 1);\n\n\t\t/* \n\t\t** Get a list of the indexes that need to be \n\t\t** updated.  ColumnMap contains all indexed\n\t\t** columns where 1 or more columns in the index\n\t\t** are going to be modified.\n\t\t**\n\t\t** Notice that we don't need to add constraint\n\t\t** columns.  This is because we add all key constraints\n\t\t** (e.g. foreign keys) as a side effect of adding their\n\t\t** indexes above.  And we don't need to deal with\n\t\t** check constraints on a delete.\n\t\t**\n\t\t** Adding indexes also takes care of the replication \n\t\t** requirement of having the primary key.\n\t\t*/\n\t\tDMLModStatementNode.getXAffectedIndexes(baseTable,  null, columnMap, conglomVector );\n\n\t\t/*\n\t \t** If we have any DELETE triggers, then do one of the following\n\t \t** 1)If all of the triggers have MISSING referencing clause, then that\n\t \t** means that the trigger actions do not have access to before and \n\t \t** after values. In that case, there is no need to blanketly decide to\n\t \t** include all the columns in the read map just because there are\n\t \t** triggers defined on the table.\n\t \t** 2)Since one/more triggers have REFERENCING clause on them, get all \n\t \t** the columns because we don't know what the user will ultimately reference.\n\t \t*/\n\t\tbaseTable.getAllRelevantTriggers( StatementType.DELETE, (int[])null, relevantTriggers );\n\n\t\tif (relevantTriggers.size() > 0)\n\t\t{\n\t\t\tneedsDeferredProcessing[0] = true;\n\t\t\t\n\t\t\tboolean needToIncludeAllColumns = false;\n\t\t\tEnumeration descs = relevantTriggers.elements();\n\t\t\twhile (descs.hasMoreElements())\n\t\t\t{\n\t\t\t\tTriggerDescriptor trd = (TriggerDescriptor) descs.nextElement();\n\t\t\t\t//Does this trigger have REFERENCING clause defined on it\n\t\t\t\tif (!trd.getReferencingNew() && !trd.getReferencingOld())\n\t\t\t\t\tcontinue;\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tneedToIncludeAllColumns = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (needToIncludeAllColumns) {\n\t\t\t\tfor (int i = 1; i <= columnCount; i++)\n\t\t\t\t{\n\t\t\t\t\tcolumnMap.set(i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn\tcolumnMap;\n\t}", "comment": " 4)\tfinds all DELETE triggers on the table 5)\tif there are any DELETE triggers, then do one of the following a)If all of the triggers have MISSING referencing clause, then that means that the trigger actions do not have access to before and after values. In that case, there is no need to blanketly decide to include all the columns in the read map just because there are triggers defined on the table. b)Since one/more triggers have REFERENCING clause on them, get all the columns because we don't know what the user will ultimately reference.", "issueId": "DERBY-4538", "issueStringList": ["If the CREATE TRIGGER does not have the REFERENCING clause, then there is no need to keep before and after values for the triggering table", "In order for the trigger action to have access to before and after values of the triggering table, the CREATE TRIGGER should use the REFERENCING clause.", "Without the REFERENCING clause, old and new values of triggering table can't be accessed by the trigger action.", "Based on this, we can improve Derby memory utilization by not keeping old and new values if REFERENCING clause is missing.", "It will be good to see if the code already does this optimization and if not, then introducing this optimization will definitely be very useful when the triggering table could have LOB columns.", "I am attaching a patch (not ready for commit yet), DERBY4538_NoReferencingClause_diff_v1.txt.", "This patch takes care of UPDATE triggers with no REFERENCING clause defined on them.", "During Update, Derby tries to determine which columns need to be read from the triggering table.", "As soon as we find out that the update table has triggers defined on it, we decide to read all the columns.", "We can improve on this algorithm My patch is attempting to be more intelligant about what columns should be read.", "The new logic is as follows.", "*", "If we have any triggers, then do one of the following", "1)If all of the triggers have MISSING referencing clause, then that", "means that the trigger actions do not have access to before and", "after values.", "In that case, there is no need to blanketly decide to", "include all the columns in the read map just because there are", "triggers defined on the table.", "2)Since one/more triggers have REFERENCING clause on them, get all", "the columns because we don't know what the user will ultimately reference.", "Would love to hear if anyone has any feedback on this approach.", "Similar changes need to go in for INSERT and UPDATE statements.", "I will post a patch which will include those changes once i have it ready.", "Attaching patch DERBY4538_NoReferencingClause_diff_v2.txt which is ready for commit.", "This changes the UPDATE and DELETE statement codes to be little bit smarter when they decide what columns should be part of the read map.", "Currently, as soon as these 2 nodes find that there are relevant triggers on the table, we decide to read all the columns from the table.", "I am changing code to check if all the relevant tiggers have missing REFERENCING clause.", "If yes, then do not need to read all the columns.", "Just the columns needed by the UPDATE/DELETE statement.", "This will get rid of OOM we run into when the table has LOB columns BUT only in the case when the UPDATE/DELETE statement does not reference the LOB column and all the triggers defined on them have missing REFERENCING clause.", "I have enabled the TriggerTests in lowmem suite with the missing REFERENCING clause cases enabled.", "For all the other test cases, I simply return from those test cases without actually testing it because we do not have fix for those cases yet.", "The lowmem suite does not get regularly and when it is run, as the name indicates, it runs with limited heap.", "I wanted us to be able to run these tests with default heap as well.", "To achieve that, I am including the TriggerTests in lang suite too.", "Please let me know if there are any questions.", "I will commit this patch sometime next week.", "The INSERT table with INSERT triggers work fine already without my changes as long as the INSERT statement does not reference the LOB column.", "v2 looks like a good incremental improvement.", "+1 to commit.", "(Nit: The declarations of needToIncludeAllColumns end with two semi-colons.)", "Knut, thanks for reviwing the patch.", "I committed the changes(with revision 917771) after removing the redundant ;", "Will go ahead and close this issue."], "SplitGT": [" 4)\tfinds all DELETE triggers on the table 5)\tif there are any DELETE triggers, then do one of the following a)If all of the triggers have MISSING referencing clause, then that means that the trigger actions do not have access to before and after values.", "In that case, there is no need to blanketly decide to include all the columns in the read map just because there are triggers defined on the table.", "b)Since one/more triggers have REFERENCING clause on them, get all the columns because we don't know what the user will ultimately reference."], "issueString": "If the CREATE TRIGGER does not have the REFERENCING clause, then there is no need to keep before and after values for the triggering table\nIn order for the trigger action to have access to before and after values of the triggering table, the CREATE TRIGGER should use the REFERENCING clause. Without the REFERENCING clause, old and new values of triggering table can't be accessed by the trigger action. Based on this, we can improve Derby memory utilization by not keeping old and new values if REFERENCING clause is missing. It will be good to see if the code already does this optimization and if not, then introducing this optimization will definitely be very useful when the triggering table could have LOB columns.\nI am attaching a patch (not ready for commit yet), DERBY4538_NoReferencingClause_diff_v1.txt. This patch takes care of UPDATE triggers with no REFERENCING clause defined on them. During Update, Derby tries to determine which columns need to be read from the triggering table. As soon as we find out that the update table has triggers defined on it, we decide to read all the columns. We can improve on this algorithm My patch is attempting to be more intelligant about what columns should be read. The new logic is as follows.\n\t/*\n \t** If we have any triggers, then do one of the following\n \t** 1)If all of the triggers have MISSING referencing clause, then that\n \t** means that the trigger actions do not have access to before and \n \t** after values. In that case, there is no need to blanketly decide to\n \t** include all the columns in the read map just because there are\n \t** triggers defined on the table.\n \t** 2)Since one/more triggers have REFERENCING clause on them, get all \n \t** the columns because we don't know what the user will ultimately reference.\n \t*/\n\nWould love to hear if anyone has any feedback on this approach. Similar changes need to go in for INSERT and UPDATE statements. I will post a patch which will include those changes once i have it ready.\nAttaching patch DERBY4538_NoReferencingClause_diff_v2.txt which is ready for commit. This changes the UPDATE and DELETE statement codes to be little bit smarter when they decide what columns should be part of the read map. Currently, as soon as these 2 nodes find that there are relevant triggers on the table, we decide to read all the columns from the table. I am changing code to check if all the relevant tiggers have missing REFERENCING clause. If yes, then do not need to read all the columns. Just the columns needed by the UPDATE/DELETE statement. This will get rid of OOM we run into when the table has LOB columns BUT only in the case when the UPDATE/DELETE statement does not reference the LOB column and all the triggers defined on them have missing REFERENCING clause. I have enabled the TriggerTests in lowmem suite with the missing REFERENCING clause cases enabled. For all the other test cases, I simply return from those test cases without actually testing it because we do not have fix for those cases yet. The lowmem suite does not get regularly and when it is run, as the name indicates, it runs with limited heap. I wanted us to be able to run these tests with default heap as well. To achieve that, I am including the TriggerTests in lang suite too. Please let me know if there are any questions. I will commit this patch sometime next week.\n\nThe INSERT table with INSERT triggers work fine already without my changes as long as the INSERT statement does not reference the LOB column.\nv2 looks like a good incremental improvement. +1 to commit.\n\n(Nit: The declarations of needToIncludeAllColumns end with two semi-colons.)\nKnut, thanks for reviwing the patch. I committed the changes(with revision 917771) after removing the redundant ;\n\nWill go ahead and close this issue. \n", "issueSearchSentences": ["If we have any triggers, then do one of the following", "*", "private static FormatableBitSet getDeleteReadMap\n\t(\n\t\tTableDescriptor\t\t\t\tbaseTable,\n\t\tVector\t\t\t\t\t\tconglomVector,\n\t\tGenericDescriptorList\t\trelevantTriggers,\n\t\tboolean[]\t\t\t\t\tneedsDeferredProcessing\n\t)\n\t\tthrows StandardException\n\t{\n\t\tint\t\tcolumnCount = baseTable.getMaxColumnID();\n\t\tFormatableBitSet\tcolumnMap = new FormatableBitSet(columnCount + 1);\n\n\t\t/* \n\t\t** Get a list of the indexes that need to be \n\t\t** updated.  ColumnMap contains all indexed\n\t\t** columns where 1 or more columns in the index\n\t\t** are going to be modified.\n\t\t**\n\t\t** Notice that we don't need to add constraint\n\t\t** columns.  This is because we add all key constraints\n\t\t** (e.g. foreign keys) as a side effect of adding their\n\t\t** indexes above.  And we don't need to deal with\n\t\t** check constraints on a delete.\n\t\t**\n\t\t** Adding indexes also takes care of the replication \n\t\t** requirement of having the primary key.\n\t\t*/\n\t\tDMLModStatementNode.getXAffectedIndexes(baseTable,  null, columnMap, conglomVector );\n\n\t\t/*\n\t \t** If we have any DELETE triggers, then do one of the following\n\t \t** 1)If all of the triggers have MISSING referencing clause, then that\n\t \t** means that the trigger actions do not have access to before and \n\t \t** after values. In that case, there is no need to blanketly decide to\n\t \t** include all the columns in the read map just because there are\n\t \t** triggers defined on the table.\n\t \t** 2)Since one/more triggers have REFERENCING clause on them, get all \n\t \t** the columns because we don't know what the user will ultimately reference.\n\t \t*/\n\t\tbaseTable.getAllRelevantTriggers( StatementType.DELETE, (int[])null, relevantTriggers );\n\n\t\tif (relevantTriggers.size() > 0)\n\t\t{\n\t\t\tneedsDeferredProcessing[0] = true;\n\t\t\t\n\t\t\tboolean needToIncludeAllColumns = false;\n\t\t\tEnumeration descs = relevantTriggers.elements();\n\t\t\twhile (descs.hasMoreElements())\n\t\t\t{\n\t\t\t\tTriggerDescriptor trd = (TriggerDescriptor) descs.nextElement();\n\t\t\t\t//Does this trigger have REFERENCING clause defined on it\n\t\t\t\tif (!trd.getReferencingNew() && !trd.getReferencingOld())\n\t\t\t\t\tcontinue;\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tneedToIncludeAllColumns = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (needToIncludeAllColumns) {\n\t\t\t\tfor (int i = 1; i <= columnCount; i++)\n\t\t\t\t{\n\t\t\t\t\tcolumnMap.set(i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn\tcolumnMap;\n\t}", "Just the columns needed by the UPDATE/DELETE statement.", "I am changing code to check if all the relevant tiggers have missing REFERENCING clause."], "issueSearchIndexes": [13, 12, 0, 30, 28]}
{"aId": 134, "code": "public boolean isValid(int timeout) throws SQLException {\n        // Validate that the timeout has a legal value\n        if (timeout < 0) {\n            throw Util.generateCsSQLException(SQLState.INVALID_API_PARAMETER,\n                                              new Integer(timeout), \"timeout\",\n                                              \"java.sql.Connection.isValid\");\n        }\n\n        // Check if the connection is closed\n        if (isClosed()) {\n            return false;\n        }\n\n        // Do a simple query against the database\n        synchronized(this) {\n            try {\n                // Save the current network timeout value\n                int oldTimeout = netAgent_.getTimeout();\n\n                // Set the required timeout value on the network connection\n                netAgent_.setTimeout(timeout);\n\n                // If this is the first time this method is called on this \n                // connection we prepare the query \n                if (isValidStmt == null) {\n                    isValidStmt = prepareStatement(\"VALUES (1)\");\n                }\n\n                // Set the query timeout\n                isValidStmt.setQueryTimeout(timeout);\n\n                // Run the query against the database\n                ResultSet rs = isValidStmt.executeQuery();\n                rs.close();\n\n                // Restore the previous timeout value\n                netAgent_.setTimeout(oldTimeout);\n            } catch(SQLException e) {\n                // If an SQL exception is thrown the connection is not valid,\n                // we ignore the exception and return false.\n                return false;\n            }\n\t }\n\n        return true;  // The connection is valid\n    }", "comment": " Checks if the connection has not been closed and is still valid. The validity is checked by running a simple query against the database.", "issueId": "DERBY-1090", "issueStringList": ["Implement Connection.isValid as defined by JDBC4", "The Javadoc for JDBC4 says this about Connection.isValid:", "boolean isValid(int timeout) throws SQLException", "Returns true if the connection has not been closed and is still valid.", "The driver shall submit a query on the connection or use some other mechanism that positively verifies the connection is still valid when this method is called.", "The query submitted by the driver to validate the connection shall be executed in the context of the current transaction.", "Parameters: timeout - - The time in seconds to wait for the database operation used to validate the connection to complete.", "If the timeout period expires before the operation completes, this method returns false.", "A value of 0 indicates a timeout is not applied to the database operation.", "Returns: true if the connection is valid, false otherwise", "In case someone else have suggestions or ideas on how to best implement this functionality, here are some high-level initial thoughts on how to implement it:", "to check the validity of the connection, issue a simple query like", "e.g., \"VALUES (1)\"", "to implement the timeout, use the setQueryTimeout() method.", "This will hopefully be sufficient in the embedded version as I expect that for all error situations where the connection no longer is valid, an exception will be thrown when issuing the query.", "For the Derby client we probably need some timeout mechanism in the client code (in addition to setting the query timeout) in order to detect that the server has not responded within before the specified timeout has elapsed.", "I have not studied the network code in details yet to find out if it already has code or hooks for specifying a timeout on the DRDA request to the server.", "Any suggestions on how to best implement this are welcome.", "In embedded would it  be sufficient just to call the isClosed() method?", "Dan, thanks for the suggestion of only using isClosed in the embedded driver.", "I have also wondered if calling isClosed would be sufficient, and actually I have not been able to create a scenario where isClosed returns false followed by simple query that fails.", "The main reasons for including execution of a simple query also in the embedded driver are:", "I do not know the code well enough to be sure that there will not be situations where isClosed returns false and a query returns e.g., a timeout or exception due to some resource constraints, deadlock or other error situations.", "It will make the behavior and implementation more similar between what is done in the embedded and in the client driver.", "I will probably submit a patch for how isValid can be implemented for the Embedded server containing both a check for isClosed and a query.", "If you or other on the list still thinks it is unnecessary to include execution of a query I will remove it.", "The query case actually seems somewhat harder to me, and one needs to understand the code far more, than the isClosed approach.", "Maybe this knowledge needs to exist for the client implementation anyway.", "I think one has to see how many ways the query can fail and", "then see how many map to the connection being not valid.", "I don't believe the query failing, always means the connection is not valid.", "If the query failed due to out of memory error, then the connection is still valid.", "There's no requirement for the embedded and client dirver to have identical implementations, the embedded gains performance", "by having direct access to the engine, something that is clearly not possible with the client.", "This naturally leads to different implementations", "for various methods.", "Thanks for commenting on this, Dan.", "I agree that using a query is more complicated than just checking for isClosed.", "So if checking for isClosed is sufficient to verify that the connection is \"valid\" we should go for that approach in the embedded driver as it is less complex and has better performance.", "Still, I think the purpose of adding the isValid method to the JDBC standard is to positively determine that it is possible to run queries on it.", "I am not convinced that your example of a simple query on the connection failing due to out of memory should still return that the connection is \"valid\"?", "I expect this is a method that will be used together with a connection pool implementation where either the pool or the user will use this for \"ensuring\" the connection is \"valid\" before it is used for something.", "And having a connection that returns out of memory errors on every query is not something that an application would think is a \"useful\" connection to have around (on the other side, creating a new connection does probably not make the situation any better in this case).", "The JavaDoc for isValid (see the test in the Jira issue) strongly indicates that we actually should take the cost of running a query against the database.", "Anyway, I have no strong opinions on whether to just check isClosed or issue a query against the database.", "But since I now happen to have a patch that solves this using a query I will upload this patch tonight.", "Tomorrow moring I will upload a new patch that is only checking for isClosed.", "I do not expect anyone to do a review or commit any of these, but it might trigger some more comments and opinions from other on the list.", "The patch contains one alternative implementation of  Connection.isValid() for the embedded driver by verifying that the connection", "is open (by calling isClosed()) and by running a simple query (\"VALUES (1)\") against the database.", "If the connection is closed or if the query returns any SQL exception, isValid returns false.", "To support the timeout defined as a parameter to isValid, setQueryTimeout is used.", "Testing:", "The patch extends the TestConnectionMethods.java test with test for isValid in the following cases:", "wrong parameter values (negative timeout)", "isValid with no timeout", "isValid with a specified timeout", "isValid on a connection that is closed", "isValid on a \"open connection\" to a database that is shutdown", "I plan to submit an alternative patch that is checking only for isClosed as well as a more complete patch containing an implementation of isValid for the Derby client driver.", "svn status reports:", "M      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnection.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java", "I have run the JDBC4 tests using Java 1.6 and derbyall using 1.5 under Solaris 10 x86.", "Only errors seen in the regression test was reported.", "The patch is complete for the embedded driver and could be reviewed and committed, but I expect that we should wait until we have decided if using only isClosed is a better and sufficient solution.", "Hi, Olav.", "It's not clear to me what a committer needs to do with this patch.", "You have checked the box saying you intend it for inclusion to the project, but you also say other, alternate patches are on  the way.", "Do you want a committer to commit this, or is it just for review?", "Hi, David.", "The main purpose of sending in the patch was to get opinions from more people on what would be the best alternative solution to check if a connection is valid in the embedded driver.", "The current alternatives are:", "a) check if connection is not closed followed by a simple query against the database (this is implemented by the patch I submitted yesterday)", "b) just check that the connection is not closed (I plan to submit an alternative patch for this soon)", "Dan has suggested that checking for isClosed could be sufficient in the embedded version.", "It would be good to hear if other have opinions about this.", "If I do not get other suggestions I will probably propose that the next patch (checking only for isClosed) being reviewed and commited.", "This patch (embedded1090-isclosed.diff)  implementations Connection.isValid() for the embedded driver by verifying that the connection", "is not closed (by calling isClosed()).", "If the connection is closed, isValid returns false, otherwise it returns true.", "The timeout defined as a parameter to isValid is not used.", "Compared to the previous patch I sent a few days ago (embedded1090-query.diff), this patch does not run any query against Derby to validate the", "connection.", "My proposal (also based on suggestions from Dan) is that we only check for isClosed() in the embedded driver.", "I have not experienced any situation where isClosed returned false and the query failed.", "If we later discover situations where the connection is not \"valid\" even if isValid returns true, we can add a query as done in my first patch to isValid.", "Testing:", "The patch extends the TestConnectionMethods.java test with test for isValid in the following cases:", "wrong parameter values (negative timeout)", "isValid with no timeout", "isValid with a specified timeout", "isValid on a connection that is closed", "isValid on a \"open connection\" to a database that is shutdown", "svn status reports:", "M      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java", "I have run the JDBC4 tests using Java 1.6 and derbyall using Java 1.5 under Solaris 10 x86.", "Only errors seen in the regression test was reported (runtimeinfo failed in derbynetmats).", "The patch is complete for the embedded driver and can be reviewed and committed.", "Looks good to me.", "The jdbc4 tests run cleanly.", "Derbyall only has errors which I see in a clean client: wisconsin, sysinfo, sysinfo_withproperties, xaSimplePositive, and a new failure in SURTest caused by:", "> java.lang.NoSuchMethodError: main", "> Exception in thread \"main\"", "Test Failed.", "I have committed embedded1090_isClosed.diff at subversion revision 388771.", "This patch (client1090_patch1.diff) implements the Connection.isValid for the network client.", "The connection is valid if (a) it is not closed (checked isClosed()) and (b) a simple query (\"VALUES (1)\") is executed successfully.", "Any exception thrown by the query execution is treated as if the connection is not valid.", "If a timeout is specified this is handled by setting a query timeout for executing the query (queryTimeout() is used).", "The implementation handles most failure situations, with the exception of a hanging server that is not returning any reply to the client.", "I plan to submit a fix for this in a separte patch.", "The isValid() call is tested for the following scenarios:", "illegal parameter values (negative timeout)", "no timeout value", "with a timeout specified", "on a connection to a database that has been shutdown", "on a connection to a network server that has been stopped", "svn status reports:", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java", "M      java/client/org/apache/derby/client/net/NetConnection40.java", "I have run the JDBC4 tests and derbyall with the patch.", "Only failure was in tools/derbyrunjartest.java.", "The patch can be reviewed and committed.", "I have looked at the patch, and I think it looks good, and can be committed.", "I concur, looks good.", "JDBC4 tests run cleanly.", "Derbyall runs cleanly modulo wisconsin noise.", "Committed at subversion revision 396028.", "Dyre and Rick, thanks for reviewing and committing the patch.", "The first implementation of Connection.isValid() for the client driver handles most failuire situations.", "One situation that is not handled is if the server \"hangs\" and the client does not receive a reply.", "The application will be hanging \"forever\" in the isValid() call due to the blocking read on the socket even if a timeout value has been specified.", "I plan to submit a fix to this problem by setting a timeout on the socket before the read is called on the socket (using java.net.socket.setSoTimeout).", "One potential problem with using socket.setSoTimeout is that its implementation is platform dependent.", "Some operating systems might not support the timeout value and block forever on socket operations even if a timeout is set.", "I would appreciate to hear if anybody has better or alternative solutions on how to handle the problem with blocking socket read and hanging server.", "This patch (client1090_patch2.diff) addresses the problem of Connection.isValid() hanging infinite if the server is either \"hanging\" or not sending a reply.", "The reason for the client to hang in these situations is that blocking read (and write) is used for receiving replies from the Derby network server.", "To avoid the client hanging infinite in the blocking read when the caller has specified a timeout to isValid() we set a maximum timeout value on the socket (by using java.net.socket.setSoTimeout()) before the query is sent to the server.", "Thus, if the server does not respond within the specified timeout period the blocking read will return with an exception.", "If this exception is thrown, isValid will return false for this connection.", "The timeout on the socket is reset to whatever value it had before the call to isValid.", "Thus, this socket timeout should only influence on the query issued by the isValid code.", "The implementation has been tested by setting a very low timeout value and introducing a delay in the network server.", "svn status reports:", "M      java/client/org/apache/derby/client/net/NetAgent.java", "M      java/client/org/apache/derby/client/net/NetConnection40.java", "I have run the JDBC4 tests and derbyall with the patch.", "Only failure was in tools/derbyrunjartest.java.", "The patch can be reviewed and committed.", "Looks solid.", "JDBC4 tests run cleanly.", "So does derbyall modulo the wisconsin noise.", "Committed at subversion revision 397899."], "SplitGT": [" Checks if the connection has not been closed and is still valid.", "The validity is checked by running a simple query against the database."], "issueString": "Implement Connection.isValid as defined by JDBC4\nThe Javadoc for JDBC4 says this about Connection.isValid:\n\nboolean isValid(int timeout) throws SQLException\n\nReturns true if the connection has not been closed and is still valid. The driver shall submit a query on the connection or use some other mechanism that positively verifies the connection is still valid when this method is called. \n\nThe query submitted by the driver to validate the connection shall be executed in the context of the current transaction. \n\nParameters: timeout - - The time in seconds to wait for the database operation used to validate the connection to complete. If the timeout period expires before the operation completes, this method returns false. A value of 0 indicates a timeout is not applied to the database operation. \n\nReturns: true if the connection is valid, false otherwise \nIn case someone else have suggestions or ideas on how to best implement this functionality, here are some high-level initial thoughts on how to implement it:\n\n  -to check the validity of the connection, issue a simple query like\n   e.g., \"VALUES (1)\"\n\n  -to implement the timeout, use the setQueryTimeout() method. \n\nThis will hopefully be sufficient in the embedded version as I expect that for all error situations where the connection no longer is valid, an exception will be thrown when issuing the query.\n\nFor the Derby client we probably need some timeout mechanism in the client code (in addition to setting the query timeout) in order to detect that the server has not responded within before the specified timeout has elapsed. I have not studied the network code in details yet to find out if it already has code or hooks for specifying a timeout on the DRDA request to the server. Any suggestions on how to best implement this are welcome.\n\nIn embedded would it  be sufficient just to call the isClosed() method?\n\nDan, thanks for the suggestion of only using isClosed in the embedded driver. I have also wondered if calling isClosed would be sufficient, and actually I have not been able to create a scenario where isClosed returns false followed by simple query that fails.\n\nThe main reasons for including execution of a simple query also in the embedded driver are:\n\n * I do not know the code well enough to be sure that there will not be situations where isClosed returns false and a query returns e.g., a timeout or exception due to some resource constraints, deadlock or other error situations.\n\n * It will make the behavior and implementation more similar between what is done in the embedded and in the client driver.\n\nI will probably submit a patch for how isValid can be implemented for the Embedded server containing both a check for isClosed and a query. If you or other on the list still thinks it is unnecessary to include execution of a query I will remove it.\n\n\nThe query case actually seems somewhat harder to me, and one needs to understand the code far more, than the isClosed approach.\nMaybe this knowledge needs to exist for the client implementation anyway. I think one has to see how many ways the query can fail and\nthen see how many map to the connection being not valid. I don't believe the query failing, always means the connection is not valid.\nIf the query failed due to out of memory error, then the connection is still valid.\n\nThere's no requirement for the embedded and client dirver to have identical implementations, the embedded gains performance\nby having direct access to the engine, something that is clearly not possible with the client. This naturally leads to different implementations\nfor various methods.\nThanks for commenting on this, Dan. I agree that using a query is more complicated than just checking for isClosed. So if checking for isClosed is sufficient to verify that the connection is \"valid\" we should go for that approach in the embedded driver as it is less complex and has better performance. \n\nStill, I think the purpose of adding the isValid method to the JDBC standard is to positively determine that it is possible to run queries on it. I am not convinced that your example of a simple query on the connection failing due to out of memory should still return that the connection is \"valid\"? I expect this is a method that will be used together with a connection pool implementation where either the pool or the user will use this for \"ensuring\" the connection is \"valid\" before it is used for something. And having a connection that returns out of memory errors on every query is not something that an application would think is a \"useful\" connection to have around (on the other side, creating a new connection does probably not make the situation any better in this case). The JavaDoc for isValid (see the test in the Jira issue) strongly indicates that we actually should take the cost of running a query against the database.\n\nAnyway, I have no strong opinions on whether to just check isClosed or issue a query against the database. But since I now happen to have a patch that solves this using a query I will upload this patch tonight. Tomorrow moring I will upload a new patch that is only checking for isClosed. I do not expect anyone to do a review or commit any of these, but it might trigger some more comments and opinions from other on the list. \nThe patch contains one alternative implementation of  Connection.isValid() for the embedded driver by verifying that the connection\nis open (by calling isClosed()) and by running a simple query (\"VALUES (1)\") against the database. If the connection is closed or if the query returns any SQL exception, isValid returns false. To support the timeout defined as a parameter to isValid, setQueryTimeout is used.\n\nTesting:\n\nThe patch extends the TestConnectionMethods.java test with test for isValid in the following cases:\n\n  -wrong parameter values (negative timeout)\n  -isValid with no timeout\n  -isValid with a specified timeout\n  -isValid on a connection that is closed\n  -isValid on a \"open connection\" to a database that is shutdown\n\nI plan to submit an alternative patch that is checking only for isClosed as well as a more complete patch containing an implementation of isValid for the Derby client driver.\n\nsvn status reports:\n\nM      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnection.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java\n\nI have run the JDBC4 tests using Java 1.6 and derbyall using 1.5 under Solaris 10 x86. Only errors seen in the regression test was reported.\n\nThe patch is complete for the embedded driver and could be reviewed and committed, but I expect that we should wait until we have decided if using only isClosed is a better and sufficient solution.\n\n\nHi, Olav.  It's not clear to me what a committer needs to do with this patch.  You have checked the box saying you intend it for inclusion to the project, but you also say other, alternate patches are on  the way.  Do you want a committer to commit this, or is it just for review?\nHi, David. The main purpose of sending in the patch was to get opinions from more people on what would be the best alternative solution to check if a connection is valid in the embedded driver. The current alternatives are:\n\n  a) check if connection is not closed followed by a simple query against the database (this is implemented by the patch I submitted yesterday)\n  b) just check that the connection is not closed (I plan to submit an alternative patch for this soon)\n\nDan has suggested that checking for isClosed could be sufficient in the embedded version. It would be good to hear if other have opinions about this. If I do not get other suggestions I will probably propose that the next patch (checking only for isClosed) being reviewed and commited.\nThis patch (embedded1090-isclosed.diff)  implementations Connection.isValid() for the embedded driver by verifying that the connection \nis not closed (by calling isClosed()). If the connection is closed, isValid returns false, otherwise it returns true. The timeout defined as a parameter to isValid is not used.\n\nCompared to the previous patch I sent a few days ago (embedded1090-query.diff), this patch does not run any query against Derby to validate the\nconnection. My proposal (also based on suggestions from Dan) is that we only check for isClosed() in the embedded driver. I have not experienced any situation where isClosed returned false and the query failed. If we later discover situations where the connection is not \"valid\" even if isValid returns true, we can add a query as done in my first patch to isValid.\n\nTesting: \n\nThe patch extends the TestConnectionMethods.java test with test for isValid in the following cases: \n\n  -wrong parameter values (negative timeout) \n  -isValid with no timeout \n  -isValid with a specified timeout \n  -isValid on a connection that is closed \n  -isValid on a \"open connection\" to a database that is shutdown \n\nsvn status reports: \n\nM      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java\n\nI have run the JDBC4 tests using Java 1.6 and derbyall using Java 1.5 under Solaris 10 x86. Only errors seen in the regression test was reported (runtimeinfo failed in derbynetmats).\n\nThe patch is complete for the embedded driver and can be reviewed and committed.\nLooks good to me. The jdbc4 tests run cleanly. Derbyall only has errors which I see in a clean client: wisconsin, sysinfo, sysinfo_withproperties, xaSimplePositive, and a new failure in SURTest caused by:\n\n> java.lang.NoSuchMethodError: main\n> Exception in thread \"main\"\nTest Failed.\n\nI have committed embedded1090_isClosed.diff at subversion revision 388771.\nThis patch (client1090_patch1.diff) implements the Connection.isValid for the network client. The connection is valid if (a) it is not closed (checked isClosed()) and (b) a simple query (\"VALUES (1)\") is executed successfully. Any exception thrown by the query execution is treated as if the connection is not valid.\n\nIf a timeout is specified this is handled by setting a query timeout for executing the query (queryTimeout() is used). \n\nThe implementation handles most failure situations, with the exception of a hanging server that is not returning any reply to the client. I plan to submit a fix for this in a separte patch. \n\nThe isValid() call is tested for the following scenarios:\n\n  -illegal parameter values (negative timeout)\n  -no timeout value\n  -with a timeout specified\n  -on a connection to a database that has been shutdown\n  -on a connection to a network server that has been stopped\n\nsvn status reports:\n\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java\nM      java/client/org/apache/derby/client/net/NetConnection40.java\n\nI have run the JDBC4 tests and derbyall with the patch. Only failure was in tools/derbyrunjartest.java.\n\nThe patch can be reviewed and committed.\nI have looked at the patch, and I think it looks good, and can be committed.\n\nI concur, looks good. JDBC4 tests run cleanly. Derbyall runs cleanly modulo wisconsin noise. Committed at subversion revision 396028.\nDyre and Rick, thanks for reviewing and committing the patch.\nThe first implementation of Connection.isValid() for the client driver handles most failuire situations. One situation that is not handled is if the server \"hangs\" and the client does not receive a reply. The application will be hanging \"forever\" in the isValid() call due to the blocking read on the socket even if a timeout value has been specified. I plan to submit a fix to this problem by setting a timeout on the socket before the read is called on the socket (using java.net.socket.setSoTimeout). One potential problem with using socket.setSoTimeout is that its implementation is platform dependent. Some operating systems might not support the timeout value and block forever on socket operations even if a timeout is set.\n\nI would appreciate to hear if anybody has better or alternative solutions on how to handle the problem with blocking socket read and hanging server. \n\n\nThis patch (client1090_patch2.diff) addresses the problem of Connection.isValid() hanging infinite if the server is either \"hanging\" or not sending a reply. \n\nThe reason for the client to hang in these situations is that blocking read (and write) is used for receiving replies from the Derby network server. To avoid the client hanging infinite in the blocking read when the caller has specified a timeout to isValid() we set a maximum timeout value on the socket (by using java.net.socket.setSoTimeout()) before the query is sent to the server. Thus, if the server does not respond within the specified timeout period the blocking read will return with an exception.\nIf this exception is thrown, isValid will return false for this connection. The timeout on the socket is reset to whatever value it had before the call to isValid. Thus, this socket timeout should only influence on the query issued by the isValid code.\n\nThe implementation has been tested by setting a very low timeout value and introducing a delay in the network server.\n\nsvn status reports:\n\nM      java/client/org/apache/derby/client/net/NetAgent.java\nM      java/client/org/apache/derby/client/net/NetConnection40.java\n\nI have run the JDBC4 tests and derbyall with the patch. Only failure was in tools/derbyrunjartest.java.\n\nThe patch can be reviewed and committed.\nLooks solid. JDBC4 tests run cleanly. So does derbyall modulo the wisconsin noise. Committed at subversion revision 397899.\n", "issueSearchSentences": ["Thus, if the server does not respond within the specified timeout period the blocking read will return with an exception.", "is open (by calling isClosed()) and by running a simple query (\"VALUES (1)\") against the database.", "Any exception thrown by the query execution is treated as if the connection is not valid.", "The reason for the client to hang in these situations is that blocking read (and write) is used for receiving replies from the Derby network server.", "The Javadoc for JDBC4 says this about Connection.isValid:"], "issueSearchIndexes": [143, 50, 111, 141, 2]}
{"aId": 136, "code": "boolean supportsEUSRIDPWD()\n    {\n        return SUPPORTS_EUSRIDPWD;\n    }", "comment": " EUSRIDPWD support depends on the availability of the algorithm in the JCE implementation in the classpath of the server. At runtime, information about this capability is figured out.", "issueId": "DERBY-1675", "issueStringList": ["Network Server should not send to client that it supports EUSRIDPWD when running against Sun JVM", "As part of ACCSECRD, if the server does not accept the security mechanism sent by the client,  the server will send a list of security mechanism that it supports.", "Currently even when the server is running with sun jvm,  it will still send EUSRIDPWD as a sec mec that it supports, which is incorrect.", "The server should test if it can support EUSRIDPWD dynamically  and if it does, only then send EURRIDPWD as an option that it supports.", "see DRDAConnThread.writeACCSECRD(int)", "EUSRIDPWD support depends on the JCE available in the classpath of the server", "This patch(derby1675.diff.txt) does the following", "1.", "Add code to check if server jvm can support EUSRIDPWD.", "2.", "Throw an error if the derby.drda.securityMechanism is set to ENCRYPTED_USER_AND_PASSWORD_SECURITY", "and if the server jvm cannot support EUSRIDPWD.", "3.", "Server sends the client the list of supported security mechanisms as part of ACCSECRD.", "Now, the server will correctly only send EUSRIDPWD as an option if the running server can support this security mechanism.", "Test related changes:", "Changes were made to testProtocol.java and a new method readSecMecAndSECCHKCD is added to TestProto to read the SECMEC and SECCHKCD values.", "Note, that with ibm142 and ibm15 jvms that support eusridpwd, the SECMEC value 9 (eusridpwd) will be sent as part of the ACCSECRD response.", "But for the jvms that dont support the eusridpwd, the SECMEC value of 9 wont be sent.", "The new method readSecMecAndSECCHKCD takes", "care of printing out the SECMEC values that are sent by the server - this results in the need for a new master file for the jvm that support eusridpwd and the jvm that cannot support it.", "A new master file has been added for ibm14.", "Tests for codepath that covers #2 is already present in testSecMec.java.", "This results in themaster updates for the jvms that do not support eusridpwd for the case where server is started with", "derby..drda.securityMechanism=ENCRYPTED_USER_AND_PASSWORD_SECURITY.", "derbyall ran ok on ibm142/linux with two known intermittent failures(NSInSameJVM and DerbyNetAutoStart)", "I ran testSecMec on win2k/t40laptop/ on ibm jvm 131,142,15 as well as sun jvm 131,142,15.", "Also have updated masters for jcc versions 2.4,2.6,2.8.", "Can someone please review this change.", "Thanks.", "Am reviewing the changes - I have changes in similar code areas (DERBY-1517)", "I ran full set of tests against this patch on XP, sun jdk 1.42 and passed except for 2 known intermittent errors in", "testProperties and DerbyNetNewServer", "francois do you have any initial comments on the change?", "tests passed for me and they look reasonable but would prefer to get review of someone experienced in this code.", "I can work on committing this today or tommorow, but after that I will be away for a week.", "This seems like something that would be nice to get into 10.2.", "Here are my comments.", "Very good changes indeed Sunitha.", "My comments are ONLY minor ones.", "Mostly recommendations with some of the comments, etc.", "1) java/drda/org/apache/derby/impl/drda/NetworkServerControlImpl.java", "A) Static block:", "+    // Sun JCE does not have support for EUSRIDPWD, whereas", "+    // most versions of IBM JCE have support for this.", "Hence", "+    // find out if the server can support EUSRIDPWD.", "Minor nit but EUSRIDPWD is not part of the JVM - It is just that some JCE provider(s) may not have DH support with a Prime of 32-bytes.", "I", "would have phrased this differently, such as:", "DRDA Specification for the EUSRIDPWD security mechanism", "requires DH algorithm support with a 32-byte prime to be", "used.", "Not all JCE implementations have support for this.", "Hence here we need to find out if EUSRIDPWD can be used", "with the current JVM.", "Again, this is just my recommendation to phrase this differently - Take it or leave it :)", "+    /**", "+     * EUSRIDPWD support depends on the availability of the", "+     * algorithm in the JCE implementation in the classpath", "+     * of the server.", "At runtime, information about this", "+     * capability is figured out.", "+     * @return whether EUSRIDPWD is supported or not", "+     */", "B) supportsEUSRIDPWD():", "Here I would have just put the following comments:", "This method returns whether EUSRIDPWD security mechanism", "is supported or not.", "See class static block for more", "info.", "@return true if EUSRIDPWD is supported, falso otherwise", "I think you need 1 more CR (line space before the next getIntPropVal())", "2) +++ java/testing/org/apache/derbyTesting/functionTests/tests/derbynet/protocol.tests", "readScalar2Bytes SECMEC 3// SECMEC", "readScalar2Bytes SECMEC 9// SECMEC", "readScalar2Bytes SECMEC 4// SECMEC", "readScalar2Bytes SECMEC 8// SECMEC", "readScalar1Byte SECCHKCD 1// SECMEC", "+readSecMecAndSECCHKCD // read secmec values and secchkcd", "We're loosing the returned list to check here but I guess it is not obvious to have this protocol test driver behave conditionally based on the JVM being run, etc...since there is no canon's for this test if am not mistaken...Anyway, too much of a big deal I'd say.", "I have also tested the patch with Solaris / jdk 1.5 ...", "Cheers.", "Thanks Francois  for your comments.", "> \"We're loosing the returned list to check here\"", "Wrt to #2,  We are not losing the returned list to check since the readSecMecAndSECCHKCD method prints the secmec that it receives.", "Actually that was the reason, I had to print the values in readSecMecAndSECCHKCD.", "Thus we have two different cannons, which is why the testProtocol.out was added for ibm14.", "So if you look at the diff for testProtocol.out ,  for e.g.,  you will see this.", "......", "Test trying security mechanism we don't support", "+SECMEC=3 SECMEC=4 SECMEC=8 SECCHKCD=1", "In case for ibm142 (new masterfile that got added), you would see", "+Test trying security mechanism we don't support", "+SECMEC=3 SECMEC=9 SECMEC=4 SECMEC=8 SECCHKCD=1", "Do you agree ?", "or am I missing something in your comment.", "I like your suggestion for  the comments in the code.", "I'll make that change.", "Thanks.", "Oops - Yes this is right - I actually checked the canon's - nevermind Sunitha :)", "Thanks.", "I committed the submitted patch (derby1675.diff.txt) to the trunk as requested by Sunitha and given the minor", "nature of the reviewers comments  -thanks Francois for the quick review.", "Go ahead and post", "the follow up comment change patch to this issue.", "This 2 step process actually works better for", "me as I can easily scan the second patch and if it is only comments won't need to run any other tests to", "feel ok to commit.", "m1_142:6>svn commit", "Sending        java\\drda\\org\\apache\\derby\\impl\\drda\\DRDAConnThread.java", "Sending        java\\drda\\org\\apache\\derby\\impl\\drda\\NetworkServerControlImpl.java", "Sending        java\\drda\\org\\apache\\derby\\impl\\drda\\TestProto.java", "Sending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\DerbyNet\\jdk14\\ver2.8\\testSecMec.out", "Sending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\DerbyNet\\testSecMec.out", "Sending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\DerbyNet\\ver2.6\\testSecMec.out", "Sending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\DerbyNet\\ver2.8\\testSecMec.out", "Sending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\DerbyNetClient\\jdk14\\testSecMec.out", "Sending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\DerbyNetClient\\testSecMec.out", "Adding         java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\ibm14", "Adding         java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\ibm14\\testProtocol.out", "Sending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\testProtocol.out", "Sending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\tests\\derbynet\\protocol.tests", "Sending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\tests\\derbynet\\testSecMec.java", "Transmitting file data .............", "Committed revision 441722.", "Thanks Mike for the commit for derby1675.diff.txt.", "I am attaching a followup  patch  derby1675.comments.diff.txt .", "This patch only has change in comments.", "svn stat", "M      java\\drda\\org\\apache\\derby\\impl\\drda\\NetworkServerControlImpl.java", "Can someone please commit this patch.", "Thanks."], "SplitGT": [" EUSRIDPWD support depends on the availability of the algorithm in the JCE implementation in the classpath of the server.", "At runtime, information about this capability is figured out."], "issueString": "Network Server should not send to client that it supports EUSRIDPWD when running against Sun JVM\nAs part of ACCSECRD, if the server does not accept the security mechanism sent by the client,  the server will send a list of security mechanism that it supports. Currently even when the server is running with sun jvm,  it will still send EUSRIDPWD as a sec mec that it supports, which is incorrect. The server should test if it can support EUSRIDPWD dynamically  and if it does, only then send EURRIDPWD as an option that it supports.\n\nsee DRDAConnThread.writeACCSECRD(int)\nEUSRIDPWD support depends on the JCE available in the classpath of the server\n\nThis patch(derby1675.diff.txt) does the following\n1. Add code to check if server jvm can support EUSRIDPWD.  \n2. Throw an error if the derby.drda.securityMechanism is set to ENCRYPTED_USER_AND_PASSWORD_SECURITY \nand if the server jvm cannot support EUSRIDPWD.\n3. Server sends the client the list of supported security mechanisms as part of ACCSECRD. Now, the server will correctly only send EUSRIDPWD as an option if the running server can support this security mechanism.\n\nTest related changes:\nChanges were made to testProtocol.java and a new method readSecMecAndSECCHKCD is added to TestProto to read the SECMEC and SECCHKCD values.  Note, that with ibm142 and ibm15 jvms that support eusridpwd, the SECMEC value 9 (eusridpwd) will be sent as part of the ACCSECRD response. But for the jvms that dont support the eusridpwd, the SECMEC value of 9 wont be sent. The new method readSecMecAndSECCHKCD takes \ncare of printing out the SECMEC values that are sent by the server - this results in the need for a new master file for the jvm that support eusridpwd and the jvm that cannot support it.  A new master file has been added for ibm14.\n\nTests for codepath that covers #2 is already present in testSecMec.java. This results in themaster updates for the jvms that do not support eusridpwd for the case where server is started with\nderby..drda.securityMechanism=ENCRYPTED_USER_AND_PASSWORD_SECURITY.\n\n\nderbyall ran ok on ibm142/linux with two known intermittent failures(NSInSameJVM and DerbyNetAutoStart)\n\nI ran testSecMec on win2k/t40laptop/ on ibm jvm 131,142,15 as well as sun jvm 131,142,15. Also have updated masters for jcc versions 2.4,2.6,2.8.\n\nCan someone please review this change. \n\nThanks.\n\n\nAm reviewing the changes - I have changes in similar code areas (DERBY-1517)\nI ran full set of tests against this patch on XP, sun jdk 1.42 and passed except for 2 known intermittent errors in \ntestProperties and DerbyNetNewServer\nfrancois do you have any initial comments on the change?  tests passed for me and they look reasonable but would prefer to get review of someone experienced in this code.  I can work on committing this today or tommorow, but after that I will be away for a week.  This seems like something that would be nice to get into 10.2.\nHere are my comments.\n\nVery good changes indeed Sunitha. My comments are ONLY minor ones. Mostly recommendations with some of the comments, etc.\n\n1) java/drda/org/apache/derby/impl/drda/NetworkServerControlImpl.java\n\nA) Static block:\n\n+    // Sun JCE does not have support for EUSRIDPWD, whereas\n+    // most versions of IBM JCE have support for this.  Hence\n+    // find out if the server can support EUSRIDPWD.\n\nMinor nit but EUSRIDPWD is not part of the JVM - It is just that some JCE provider(s) may not have DH support with a Prime of 32-bytes. I \n\nwould have phrased this differently, such as:\n\n    // DRDA Specification for the EUSRIDPWD security mechanism\n    // requires DH algorithm support with a 32-byte prime to be\n    // used. Not all JCE implementations have support for this.\n    // Hence here we need to find out if EUSRIDPWD can be used\n    // with the current JVM.\n\nAgain, this is just my recommendation to phrase this differently - Take it or leave it :)\n\n+    /**\n+     * EUSRIDPWD support depends on the availability of the\n+     * algorithm in the JCE implementation in the classpath \n+     * of the server. At runtime, information about this \n+     * capability is figured out.  \n+     * @return whether EUSRIDPWD is supported or not\n+     */\n\nB) supportsEUSRIDPWD():\n\nHere I would have just put the following comments:\n\n    /**\n     * This method returns whether EUSRIDPWD security mechanism\n     * is supported or not. See class static block for more\n     * info.\n     * @return true if EUSRIDPWD is supported, falso otherwise\n     */\n\nI think you need 1 more CR (line space before the next getIntPropVal())\n\n2) +++ java/testing/org/apache/derbyTesting/functionTests/tests/derbynet/protocol.tests\n\n-readScalar2Bytes SECMEC 3// SECMEC\n-readScalar2Bytes SECMEC 9// SECMEC\n-readScalar2Bytes SECMEC 4// SECMEC\n-readScalar2Bytes SECMEC 8// SECMEC\n-readScalar1Byte SECCHKCD 1// SECMEC\n+readSecMecAndSECCHKCD // read secmec values and secchkcd\n\nWe're loosing the returned list to check here but I guess it is not obvious to have this protocol test driver behave conditionally based on the JVM being run, etc...since there is no canon's for this test if am not mistaken...Anyway, too much of a big deal I'd say.\n\nI have also tested the patch with Solaris / jdk 1.5 ...\n\nCheers.\nThanks Francois  for your comments.   \n\n> \"We're loosing the returned list to check here\"\n\nWrt to #2,  We are not losing the returned list to check since the readSecMecAndSECCHKCD method prints the secmec that it receives.  Actually that was the reason, I had to print the values in readSecMecAndSECCHKCD. \n\nThus we have two different cannons, which is why the testProtocol.out was added for ibm14.\n\nSo if you look at the diff for testProtocol.out ,  for e.g.,  you will see this. \n......\nTest trying security mechanism we don't support\n+SECMEC=3 SECMEC=4 SECMEC=8 SECCHKCD=1\n\nIn case for ibm142 (new masterfile that got added), you would see \n+Test trying security mechanism we don't support\n+SECMEC=3 SECMEC=9 SECMEC=4 SECMEC=8 SECCHKCD=1\n\nDo you agree ? or am I missing something in your comment. \n\nI like your suggestion for  the comments in the code. I'll make that change.\n\nThanks. \nOops - Yes this is right - I actually checked the canon's - nevermind Sunitha :)\n\nThanks.\nI committed the submitted patch (derby1675.diff.txt) to the trunk as requested by Sunitha and given the minor\nnature of the reviewers comments  -thanks Francois for the quick review.\nGo ahead and post\nthe follow up comment change patch to this issue.  This 2 step process actually works better for\nme as I can easily scan the second patch and if it is only comments won't need to run any other tests to \nfeel ok to commit.\n\nm1_142:6>svn commit\n\nSending        java\\drda\\org\\apache\\derby\\impl\\drda\\DRDAConnThread.java\nSending        java\\drda\\org\\apache\\derby\\impl\\drda\\NetworkServerControlImpl.java\nSending        java\\drda\\org\\apache\\derby\\impl\\drda\\TestProto.java\nSending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\DerbyNet\\jdk14\\ver2.8\\testSecMec.out\nSending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\DerbyNet\\testSecMec.out\nSending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\DerbyNet\\ver2.6\\testSecMec.out\nSending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\DerbyNet\\ver2.8\\testSecMec.out\nSending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\DerbyNetClient\\jdk14\\testSecMec.out\nSending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\DerbyNetClient\\testSecMec.out\nAdding         java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\ibm14\nAdding         java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\ibm14\\testProtocol.out\nSending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\master\\testProtocol.out\nSending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\tests\\derbynet\\protocol.tests\nSending        java\\testing\\org\\apache\\derbyTesting\\functionTests\\tests\\derbynet\\testSecMec.java\nTransmitting file data .............\nCommitted revision 441722.\nThanks Mike for the commit for derby1675.diff.txt. \n\nI am attaching a followup  patch  derby1675.comments.diff.txt . \nThis patch only has change in comments. \n\nsvn stat\nM      java\\drda\\org\\apache\\derby\\impl\\drda\\NetworkServerControlImpl.java\n\nCan someone please commit this patch.  Thanks. \n", "issueSearchSentences": ["+     */", "+     * capability is figured out.", "info.", "boolean supportsEUSRIDPWD()\n    {\n        return SUPPORTS_EUSRIDPWD;\n    }", "Network Server should not send to client that it supports EUSRIDPWD when running against Sun JVM"], "issueSearchIndexes": [65, 63, 71, 0, 1]}
{"aId": 137, "code": "private Boolean isSoftUpgraded()\n            throws StandardException {\n        // Determine if we are accessing a soft upgraded database or not.\n        // This is required to write the correct stream header format for Clobs.\n        if (inSoftUpgradeMode == null) {\n            inSoftUpgradeMode = Boolean.valueOf(\n                lcc.getDataDictionary().checkVersion(\n                    DataDictionary.DD_VERSION_CURRENT, null));\n        }\n        return inSoftUpgradeMode;\n    }", "comment": " Tells if the database being accessed is soft upgraded or not.", "issueId": "DERBY-4278", "issueStringList": ["Batch inserts with Clobs fails with the embedded driver", "Batch inserts with Clobs fail because Derby is unable to determine if it should write the Clob stream header formats using the old 10.4 style format or the new 10.5 format.", "More specifically, the access mode (soft upgrade or not) hasn't been set specifically by Derby before the stream header has to be generated, and there isn't enough context to determine the mode at generation time.", "Bug was reported on derby-user: http://www.nabble.com/Hibernate-%2B-Derby---Unable-to-determine-stream-header-for-hibernate-type-%27text%27-td24099674.html", "The bug was reported for Derby used with Hibernate.", "Possible workarounds are to use the client driver or to avoid using batched inserts with Clobs (i.e.", "don't use batched inserts, which may degrade performance, or use a different data type).", "Attached regression tests for the bug as patch 1a.", "The patch must be committed together with the fix.", "Attaching fix for the bug as patch 2a.", "The problem is solved by explicitly telling the SQLCLob data object whether the database being accessed is accessed in soft upgrade mode or not.", "This information is readily available in EmbedPreparedStatement.", "I chose to determine the mode lazily, so the method (isSoftUpgraded) should be used instead of referencing the variable directly.", "Running regression tests.", "Patch ready for review.", "Regression tests passed.", "I'm marking this issue as Urgent as it seems to be triggered with default configuration using Derby with Hibernate (and Clobs in the table of course).", "It is also a regression, introduced through the new Clob header format code.", "Finally, the bug was reported by a user.", "User reported that his application ran successfully with the fix applied (see the thread from the issue description).", "Committed patches 1a and 2a to trunk with revision 790135.", "Awaiting test results before back-porting to 10.5."], "SplitGT": [" Tells if the database being accessed is soft upgraded or not."], "issueString": "Batch inserts with Clobs fails with the embedded driver\nBatch inserts with Clobs fail because Derby is unable to determine if it should write the Clob stream header formats using the old 10.4 style format or the new 10.5 format.\nMore specifically, the access mode (soft upgrade or not) hasn't been set specifically by Derby before the stream header has to be generated, and there isn't enough context to determine the mode at generation time.\n\nBug was reported on derby-user: http://www.nabble.com/Hibernate-%2B-Derby---Unable-to-determine-stream-header-for-hibernate-type-%27text%27-td24099674.html\n\nThe bug was reported for Derby used with Hibernate. Possible workarounds are to use the client driver or to avoid using batched inserts with Clobs (i.e. don't use batched inserts, which may degrade performance, or use a different data type).\nAttached regression tests for the bug as patch 1a.\nThe patch must be committed together with the fix.\nAttaching fix for the bug as patch 2a.\nThe problem is solved by explicitly telling the SQLCLob data object whether the database being accessed is accessed in soft upgrade mode or not. This information is readily available in EmbedPreparedStatement. I chose to determine the mode lazily, so the method (isSoftUpgraded) should be used instead of referencing the variable directly.\n\nRunning regression tests.\nPatch ready for review.\nRegression tests passed.\nI'm marking this issue as Urgent as it seems to be triggered with default configuration using Derby with Hibernate (and Clobs in the table of course). It is also a regression, introduced through the new Clob header format code.\nFinally, the bug was reported by a user.\nUser reported that his application ran successfully with the fix applied (see the thread from the issue description).\n\nCommitted patches 1a and 2a to trunk with revision 790135.\nAwaiting test results before back-porting to 10.5.\n", "issueSearchSentences": ["Batch inserts with Clobs fails with the embedded driver", "Attaching fix for the bug as patch 2a.", "Batch inserts with Clobs fail because Derby is unable to determine if it should write the Clob stream header formats using the old 10.4 style format or the new 10.5 format.", "The bug was reported for Derby used with Hibernate.", "I'm marking this issue as Urgent as it seems to be triggered with default configuration using Derby with Hibernate (and Clobs in the table of course)."], "issueSearchIndexes": [1, 10, 2, 5, 17]}
{"aId": 139, "code": "public boolean supportsRefCursors()\n    {\n\t\treturn false;\n\t}", "comment": " Added in JDBC 4.2. Derby does not support the Types.REF_CURSOR type.", "issueId": "DERBY-6000", "issueStringList": ["Implement support for JDBC 4.2", "Open JDK 8 will include maintenance rev 4.2 of JDBC.", "The public discussion of JDBC 4.2 will take place here: http://openjdk.java.net/jeps/170.", "We will want to build Derby support for JDBC 4.2 after a public spec appears.", "At this time, it is unclear what Derby release will carry this support.", "Attaching JDBC_4.2_Changes.html, the first rev of a functional spec for this work.", "The changes are defined by the javadoc specdiffs published by JDBC spec lead Lance Andersen.", "The latest specdiffs can be found here: http://cr.openjdk.java.net/~lancea/8005080/specdiffs.01/", "I have built Open JDK 8 on my mac by following the instructions here:", "https://wikis.oracle.com/display/OpenJDK/Mac+OS+X+Port", "However, the mercurial source indicated on that page does not contain the recent Open JDK checkin of JDBC 4.2.", "To get that more complete source, I issued the following command:", "hg clone http://hg.openjdk.java.net/jdk8/tl", "Probably a similar sequence of steps on the platform of your choice will help you build an Open JDK 8 which contains the JDBC 4.2 changes.", "Attaching derby-6000-01-aa-executeLargeUpdateEmbedded.diff.", "This patch adds the new Statement.executeLargeUpdate() methods introduced by JDBC 4.2.", "I am running tests now.", "This patch adds the following new methods to Derby's embedded JDBC 3.0 implementation of java.sql.Statement:", "public  long executeLargeUpdate( String sql ) throws SQLException;", "public  long executeLargeUpdate( String sql, int autoGeneratedKeys) throws SQLException;", "public  long executeLargeUpdate( String sql, int[] columnIndexes ) throws SQLException;", "public  long executeLargeUpdate( String sql, String[] columnNames ) throws SQLException;", "This involved three changes:", "1) Changing the type of the update counter from int to long.", "2) Adding the new methods.", "3) Forwarding the executeUpdate() overloads to the corresponding newly added executeLargeUpdate() overloads.", "I have put off adding regression tests until I have added parallel methods to the client JDBC implementation.", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/sql/ResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/TemporaryRowHolderResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/BasicNoPutResultSetImpl.java", "M       java/engine/org/apache/derby/impl/sql/execute/RealResultSetStatisticsFactory.java", "M       java/engine/org/apache/derby/impl/sql/execute/DMLWriteResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/DeleteResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/NoRowsResultSetImpl.java", "M       java/engine/org/apache/derby/impl/sql/execute/UpdateResultSet.java", "Step (1).", "M       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedPreparedStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java", "Steps (2) and (3).", "Tests passed cleanly for me on derby-6000-01-aa-executeLargeUpdateEmbedded.diff.", "Committed at subversion revision 1438600.", "Attaching derby-6000-02-ad-executeLargeUpdateClient.diff.", "This adds large update support to Statements in the client JDBC driver.", "I am running tests now.", "This adds the following method to the embedded driver:", "Statement.getLargeUpdateCount()", "...and the following methods to the client driver:", "Statement.executeLargeUpdate( String )", "Statement.executeLargeUpdate( String, int )", "Statement.executeLargeUpdate( String, int[] )", "Statement.executeLargeUpdate( String, String[] )", "Statement.getLargeUpdateCount()", "The following changes are made:", "1) The update count on the client side is expanded from an int to a long.", "2) The update count is passed from the server to the client in the SQLCard descriptor.", "Previously, only an int sized update count was passed.", "Now a long sized update count is passed.", "This is done by leaving the low order 32 bits of the update count in the slot of the SQLCard which was previously used for the update count.", "Then the upper 32 bits are put in a previously unused slot of the SQLCard.", "This should mean that when clients and servers are at different revs, the client will still get the correct update count except in cases when the update count is greater than Integer.MAX_VALUE.", "In those oddball cases, the client used to receive garbage from the server.", "In these mixed rev situations, the client will continue to receive garbage for the update count if the number of updated rows exceeds Integer.MAX_VALUE.", "3) Magic numbers were eliminated when processing the SQLCard.", "Hopefully, this will make this code easier to study and debug.", "4) Factory methods were added for client-side BatchUpdateExceptions.", "These will be expanded when we add support for the new BatchUpdateException constructor added by JDBC 4.2.", "5) The new methods were added.", "6) The engine ResultSet code was tweaked to let tests force the engine to return absurdly large update counts.", "Otherwise, it is practically impossible to test the large update methods since this involves generating more than 2 billion rows for each test case.", "7) Tests were added for large updates for both the embedded and client drivers.", "Touches the following files:", "M       java/drda/org/apache/derby/impl/drda/DRDAConnThread.java", "M       java/client/org/apache/derby/client/am/PreparedStatement.java", "M       java/client/org/apache/derby/client/am/Agent.java", "Changes for (1) and (2).", "M       java/client/org/apache/derby/client/net/NetConnectionReply.java", "M       java/client/org/apache/derby/client/net/NetCursor.java", "M       java/client/org/apache/derby/client/am/Sqlca.java", "Changes for (3).", "M       java/client/org/apache/derby/client/am/Utils.java", "M       java/client/org/apache/derby/client/am/BatchUpdateException.java", "Changes for (4).", "M       java/engine/org/apache/derby/iapi/jdbc/EnginePreparedStatement.java", "M       java/client/org/apache/derby/client/am/Statement.java", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java", "M       java/drda/org/apache/derby/impl/drda/DRDAStatement.java", "M       java/client/org/apache/derby/client/am/LogicalStatementEntity.java", "Changes for (5).", "M       java/engine/org/apache/derby/impl/sql/execute/DMLWriteResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/RowUtil.java", "Changes for (6).", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/XA40Test.java", "Changes for (7).", "Tests passed cleanly for me on derby-6000-02-ad-executeLargeUpdateClient.diff.", "Committed derby-6000-02-ad-executeLargeUpdateClient.diff at subversion revision 1439883.", "Attaching derby-6000-03-aa-executeLargeBatch.diff.", "This patch adds large batch support.", "I am running tests now.", "Adds the following method to the embedded and client drivers:", "Statement.executeLargeBatch()", "Most of the machinery needed for this was added as part of implementing large updates.", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/Util.java", "Embedded changes.", "M       java/client/org/apache/derby/client/am/Statement.java", "M       java/client/org/apache/derby/client/am/LogicalStatementEntity.java", "Client changes.", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java", "M       java/testing/org/apache/derbyTesting/junit/BaseTestCase.java", "New tests.", "Tests passed cleanly for me on derby-6000-03-aa-executeLargeBatch.diff.", "Committed at subversion revision 1440035.", "Attaching derby-6000-04-aa-setLargeMaxRows.diff.", "This patch adds support for setting/getting large limits on returned row counts.", "I will run regression tests.", "This patch adds the following JDBC 4.2 methods to the embedded and client drivers:", "Statement.setLargeMaxRows( long )", "Statement.getLargeMaxRows()", "Mostly this involved changing the datatype of some variables from int to long and then adding the new methods.", "As with the previous patch, some debug entry points were added so that we can test the new methods without actually generating more than 2 billion rows.", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/sql/Activation.java", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java", "M       java/engine/org/apache/derby/impl/sql/execute/ScrollInsensitiveResultSet.java", "M       java/engine/org/apache/derby/impl/sql/execute/BaseActivation.java", "M       java/engine/org/apache/derby/impl/sql/GenericActivationHolder.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedResultSet.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java", "Embedded changes.", "M       java/client/org/apache/derby/client/am/Statement.java", "M       java/client/org/apache/derby/client/am/Cursor.java", "M       java/client/org/apache/derby/client/am/LogicalStatementEntity.java", "M       java/client/org/apache/derby/client/am/ResultSet.java", "Client changes.", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java", "New tests.", "Tests passed cleanly for me on derby-6000-04-aa-setLargeMaxRows.diff.", "Committed at subversion revision 1440656.", "Attaching derby-6000-05-aa-executeLargeUpdatePS.diff.", "This patch adds JDBC 4.2 large update support to PreparedStatements.", "I am running tests now.", "This patch adds the following method to the embedded and client implementations of PreparedStatement:", "public long executeLargeUpdate()", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/jdbc/BrokeredPreparedStatement.java", "M       java/engine/org/apache/derby/iapi/jdbc/EnginePreparedStatement.java", "M       java/engine/org/apache/derby/impl/jdbc/EmbedPreparedStatement.java", "Embedded changes.", "M       java/client/org/apache/derby/client/am/PreparedStatement.java", "M       java/client/org/apache/derby/client/am/LogicalPreparedStatement.java", "Client changes.", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/PreparedStatementTest.java", "New tests.", "Tests passed cleanly for me on derby-6000-05-aa-executeLargeUpdatePS.diff.", "Committed at subversion revision 1441088.", "Attaching derby-6000-06-aa-DatabaseMetaData.diff.", "This patch makes the JDBC 4.2 changes to DatabaseMetaData.", "I will run regression tests.", "This patch makes the following changes to the embedded and client drivers:", "1) Changes the datatype of the CARDINALITY and PAGES columns returned by getIndexInfo().", "The column types are changed from INT to BIGINT.", "2) Adds a getMaxLogicalLOBSize() method.", "This method is supposed to return the maximum size of a LOB in bytes.", "For Derby that is the maximum size of a CLOB.", "A CLOB can have Integer.MAX_VALUE chars, which works out to Integer.MAX_VALUE * 2 bytes.", "3) Adds a supportsRefCursors() method.", "This returns false because Derby does not support the Types.REF_CURSOR type.", "Touches the following files:", "M       java/engine/org/apache/derby/iapi/reference/Limits.java", "M       java/engine/org/apache/derby/impl/jdbc/metadata.properties", "M       java/engine/org/apache/derby/impl/jdbc/EmbedDatabaseMetaData.java", "Embedded changes.", "M       java/client/org/apache/derby/client/am/LogicalDatabaseMetaData40.java", "M       java/client/org/apache/derby/client/am/DatabaseMetaData.java", "Client changes.", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/Wrapper41DBMD.java", "M       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/DatabaseMetaDataTest.java", "A       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/Wrapper42DBMD.java", "Tests.", "Tests passed cleanly for me on derby-6000-06-aa-DatabaseMetaData.diff except for the heisenbug in NetworkServerControlClientCommandTest.", "testPingWithWrongHost.", "Committed derby-6000-06-aa-DatabaseMetaData.diff at subversion revision 1441436."], "SplitGT": [" Added in JDBC 4.2.", "Derby does not support the Types.REF_CURSOR type."], "issueString": "Implement support for JDBC 4.2\nOpen JDK 8 will include maintenance rev 4.2 of JDBC. The public discussion of JDBC 4.2 will take place here: http://openjdk.java.net/jeps/170. We will want to build Derby support for JDBC 4.2 after a public spec appears. At this time, it is unclear what Derby release will carry this support.\nAttaching JDBC_4.2_Changes.html, the first rev of a functional spec for this work. The changes are defined by the javadoc specdiffs published by JDBC spec lead Lance Andersen. The latest specdiffs can be found here: http://cr.openjdk.java.net/~lancea/8005080/specdiffs.01/\nI have built Open JDK 8 on my mac by following the instructions here:\n\nhttps://wikis.oracle.com/display/OpenJDK/Mac+OS+X+Port\n\nHowever, the mercurial source indicated on that page does not contain the recent Open JDK checkin of JDBC 4.2. To get that more complete source, I issued the following command:\n\nhg clone http://hg.openjdk.java.net/jdk8/tl\n\nProbably a similar sequence of steps on the platform of your choice will help you build an Open JDK 8 which contains the JDBC 4.2 changes.\n\n\nAttaching derby-6000-01-aa-executeLargeUpdateEmbedded.diff. This patch adds the new Statement.executeLargeUpdate() methods introduced by JDBC 4.2. I am running tests now.\n\nThis patch adds the following new methods to Derby's embedded JDBC 3.0 implementation of java.sql.Statement:\n\n    public  long executeLargeUpdate( String sql ) throws SQLException;\n    public  long executeLargeUpdate( String sql, int autoGeneratedKeys) throws SQLException;\n    public  long executeLargeUpdate( String sql, int[] columnIndexes ) throws SQLException;\n    public  long executeLargeUpdate( String sql, String[] columnNames ) throws SQLException;\n\nThis involved three changes:\n\n1) Changing the type of the update counter from int to long.\n\n2) Adding the new methods.\n\n3) Forwarding the executeUpdate() overloads to the corresponding newly added executeLargeUpdate() overloads.\n\nI have put off adding regression tests until I have added parallel methods to the client JDBC implementation.\n\n\nTouches the following files:\n\n-----------------------\n\nM       java/engine/org/apache/derby/iapi/sql/ResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/TemporaryRowHolderResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/BasicNoPutResultSetImpl.java\nM       java/engine/org/apache/derby/impl/sql/execute/RealResultSetStatisticsFactory.java\nM       java/engine/org/apache/derby/impl/sql/execute/DMLWriteResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/DeleteResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/NoRowsResultSetImpl.java\nM       java/engine/org/apache/derby/impl/sql/execute/UpdateResultSet.java\n\nStep (1).\n\n-----------------------\n\nM       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedPreparedStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java\n\nSteps (2) and (3).\n\nTests passed cleanly for me on derby-6000-01-aa-executeLargeUpdateEmbedded.diff. Committed at subversion revision 1438600.\nAttaching derby-6000-02-ad-executeLargeUpdateClient.diff. This adds large update support to Statements in the client JDBC driver. I am running tests now.\n\nThis adds the following method to the embedded driver:\n\n  Statement.getLargeUpdateCount()\n\n...and the following methods to the client driver:\n\n  Statement.executeLargeUpdate( String )\n  Statement.executeLargeUpdate( String, int )\n  Statement.executeLargeUpdate( String, int[] )\n  Statement.executeLargeUpdate( String, String[] )\n  Statement.getLargeUpdateCount()\n\nThe following changes are made:\n\n1) The update count on the client side is expanded from an int to a long.\n\n2) The update count is passed from the server to the client in the SQLCard descriptor. Previously, only an int sized update count was passed. Now a long sized update count is passed. This is done by leaving the low order 32 bits of the update count in the slot of the SQLCard which was previously used for the update count. Then the upper 32 bits are put in a previously unused slot of the SQLCard. This should mean that when clients and servers are at different revs, the client will still get the correct update count except in cases when the update count is greater than Integer.MAX_VALUE. In those oddball cases, the client used to receive garbage from the server. In these mixed rev situations, the client will continue to receive garbage for the update count if the number of updated rows exceeds Integer.MAX_VALUE.\n\n3) Magic numbers were eliminated when processing the SQLCard. Hopefully, this will make this code easier to study and debug.\n\n4) Factory methods were added for client-side BatchUpdateExceptions. These will be expanded when we add support for the new BatchUpdateException constructor added by JDBC 4.2.\n\n5) The new methods were added.\n\n6) The engine ResultSet code was tweaked to let tests force the engine to return absurdly large update counts. Otherwise, it is practically impossible to test the large update methods since this involves generating more than 2 billion rows for each test case.\n\n7) Tests were added for large updates for both the embedded and client drivers.\n\n\nTouches the following files:\n\n-----------------------\n\nM       java/drda/org/apache/derby/impl/drda/DRDAConnThread.java\nM       java/client/org/apache/derby/client/am/PreparedStatement.java\nM       java/client/org/apache/derby/client/am/Agent.java\n\nChanges for (1) and (2).\n\n-----------------------\n\nM       java/client/org/apache/derby/client/net/NetConnectionReply.java\nM       java/client/org/apache/derby/client/net/NetCursor.java\nM       java/client/org/apache/derby/client/am/Sqlca.java\n\nChanges for (3).\n\n-----------------------\n\nM       java/client/org/apache/derby/client/am/Utils.java\nM       java/client/org/apache/derby/client/am/BatchUpdateException.java\n\nChanges for (4).\n\n-----------------------\n\nM       java/engine/org/apache/derby/iapi/jdbc/EnginePreparedStatement.java\nM       java/client/org/apache/derby/client/am/Statement.java\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java\nM       java/drda/org/apache/derby/impl/drda/DRDAStatement.java\nM       java/client/org/apache/derby/client/am/LogicalStatementEntity.java\n\nChanges for (5).\n\n-----------------------\n\nM       java/engine/org/apache/derby/impl/sql/execute/DMLWriteResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/RowUtil.java\n\nChanges for (6).\n\n-----------------------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/XA40Test.java\n\nChanges for (7).\n\nTests passed cleanly for me on derby-6000-02-ad-executeLargeUpdateClient.diff.\nCommitted derby-6000-02-ad-executeLargeUpdateClient.diff at subversion revision 1439883.\nAttaching derby-6000-03-aa-executeLargeBatch.diff. This patch adds large batch support. I am running tests now.\n\nAdds the following method to the embedded and client drivers:\n\n  Statement.executeLargeBatch()\n\nMost of the machinery needed for this was added as part of implementing large updates.\n\n\nTouches the following files:\n\n----------\n\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/Util.java\n\nEmbedded changes.\n\n----------\n\nM       java/client/org/apache/derby/client/am/Statement.java\nM       java/client/org/apache/derby/client/am/LogicalStatementEntity.java\n\nClient changes.\n\n----------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java\nM       java/testing/org/apache/derbyTesting/junit/BaseTestCase.java\n\nNew tests.\n\nTests passed cleanly for me on derby-6000-03-aa-executeLargeBatch.diff. Committed at subversion revision 1440035.\nAttaching derby-6000-04-aa-setLargeMaxRows.diff. This patch adds support for setting/getting large limits on returned row counts. I will run regression tests.\n\nThis patch adds the following JDBC 4.2 methods to the embedded and client drivers:\n\n  Statement.setLargeMaxRows( long )\n  Statement.getLargeMaxRows()\n\nMostly this involved changing the datatype of some variables from int to long and then adding the new methods. As with the previous patch, some debug entry points were added so that we can test the new methods without actually generating more than 2 billion rows.\n\nTouches the following files:\n\n----------\n\nM       java/engine/org/apache/derby/iapi/sql/Activation.java\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EngineStatement.java\nM       java/engine/org/apache/derby/impl/sql/execute/ScrollInsensitiveResultSet.java\nM       java/engine/org/apache/derby/impl/sql/execute/BaseActivation.java\nM       java/engine/org/apache/derby/impl/sql/GenericActivationHolder.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedResultSet.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedStatement.java\n\nEmbedded changes.\n\n----------\n\nM       java/client/org/apache/derby/client/am/Statement.java\nM       java/client/org/apache/derby/client/am/Cursor.java\nM       java/client/org/apache/derby/client/am/LogicalStatementEntity.java\nM       java/client/org/apache/derby/client/am/ResultSet.java\n\nClient changes.\n\n----------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java\n\nNew tests.\n\nTests passed cleanly for me on derby-6000-04-aa-setLargeMaxRows.diff. Committed at subversion revision 1440656.\nAttaching derby-6000-05-aa-executeLargeUpdatePS.diff. This patch adds JDBC 4.2 large update support to PreparedStatements. I am running tests now.\n\nThis patch adds the following method to the embedded and client implementations of PreparedStatement:\n\n  public long executeLargeUpdate()\n\n\n\nTouches the following files:\n\n--------------\n\nM       java/engine/org/apache/derby/iapi/jdbc/BrokeredPreparedStatement.java\nM       java/engine/org/apache/derby/iapi/jdbc/EnginePreparedStatement.java\nM       java/engine/org/apache/derby/impl/jdbc/EmbedPreparedStatement.java\n\nEmbedded changes.\n\n--------------\n\nM       java/client/org/apache/derby/client/am/PreparedStatement.java\nM       java/client/org/apache/derby/client/am/LogicalPreparedStatement.java\n\nClient changes.\n\n--------------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/StatementTest.java\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/PreparedStatementTest.java\n\nNew tests.\n\nTests passed cleanly for me on derby-6000-05-aa-executeLargeUpdatePS.diff. Committed at subversion revision 1441088.\nAttaching derby-6000-06-aa-DatabaseMetaData.diff. This patch makes the JDBC 4.2 changes to DatabaseMetaData. I will run regression tests.\n\nThis patch makes the following changes to the embedded and client drivers:\n\n1) Changes the datatype of the CARDINALITY and PAGES columns returned by getIndexInfo(). The column types are changed from INT to BIGINT.\n\n2) Adds a getMaxLogicalLOBSize() method. This method is supposed to return the maximum size of a LOB in bytes. For Derby that is the maximum size of a CLOB. A CLOB can have Integer.MAX_VALUE chars, which works out to Integer.MAX_VALUE * 2 bytes.\n\n3) Adds a supportsRefCursors() method. This returns false because Derby does not support the Types.REF_CURSOR type.\n\n\nTouches the following files:\n\n--------------\n\nM       java/engine/org/apache/derby/iapi/reference/Limits.java\nM       java/engine/org/apache/derby/impl/jdbc/metadata.properties\nM       java/engine/org/apache/derby/impl/jdbc/EmbedDatabaseMetaData.java\n\nEmbedded changes.\n\n--------------\n\nM       java/client/org/apache/derby/client/am/LogicalDatabaseMetaData40.java\nM       java/client/org/apache/derby/client/am/DatabaseMetaData.java\n\nClient changes.\n\n--------------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/Wrapper41DBMD.java\nM       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/DatabaseMetaDataTest.java\nA       java/testing/org/apache/derbyTesting/functionTests/tests/jdbcapi/Wrapper42DBMD.java\n\nTests.\n\nTests passed cleanly for me on derby-6000-06-aa-DatabaseMetaData.diff except for the heisenbug in NetworkServerControlClientCommandTest. testPingWithWrongHost.\nCommitted derby-6000-06-aa-DatabaseMetaData.diff at subversion revision 1441436.\n", "issueSearchSentences": ["A CLOB can have Integer.MAX_VALUE chars, which works out to Integer.MAX_VALUE * 2 bytes.", "This patch adds the following method to the embedded and client implementations of PreparedStatement:", "3) Adds a supportsRefCursors() method.", "This patch adds the following new methods to Derby's embedded JDBC 3.0 implementation of java.sql.Statement:", "2) Adds a getMaxLogicalLOBSize() method."], "issueSearchIndexes": [177, 153, 178, 18, 174]}
{"aId": 141, "code": "public boolean isValid(int timeout) throws SQLException {\n        // Validate that the timeout has a legal value\n        if (timeout < 0) {\n            throw Util.generateCsSQLException(SQLState.INVALID_API_PARAMETER,\n                                              new Integer(timeout), \"timeout\",\n                                              \"java.sql.Connection.isValid\");\n        }\n\n        // Use the closed status for the connection to determine if the\n        // connection is valid or not\n        return !isClosed();\n    }", "comment": " Checks if the connection has not been closed and is still valid. The validity is checked by checking that the connection is not closed.", "issueId": "DERBY-1090", "issueStringList": ["Implement Connection.isValid as defined by JDBC4", "The Javadoc for JDBC4 says this about Connection.isValid:", "boolean isValid(int timeout) throws SQLException", "Returns true if the connection has not been closed and is still valid.", "The driver shall submit a query on the connection or use some other mechanism that positively verifies the connection is still valid when this method is called.", "The query submitted by the driver to validate the connection shall be executed in the context of the current transaction.", "Parameters: timeout - - The time in seconds to wait for the database operation used to validate the connection to complete.", "If the timeout period expires before the operation completes, this method returns false.", "A value of 0 indicates a timeout is not applied to the database operation.", "Returns: true if the connection is valid, false otherwise", "In case someone else have suggestions or ideas on how to best implement this functionality, here are some high-level initial thoughts on how to implement it:", "to check the validity of the connection, issue a simple query like", "e.g., \"VALUES (1)\"", "to implement the timeout, use the setQueryTimeout() method.", "This will hopefully be sufficient in the embedded version as I expect that for all error situations where the connection no longer is valid, an exception will be thrown when issuing the query.", "For the Derby client we probably need some timeout mechanism in the client code (in addition to setting the query timeout) in order to detect that the server has not responded within before the specified timeout has elapsed.", "I have not studied the network code in details yet to find out if it already has code or hooks for specifying a timeout on the DRDA request to the server.", "Any suggestions on how to best implement this are welcome.", "In embedded would it  be sufficient just to call the isClosed() method?", "Dan, thanks for the suggestion of only using isClosed in the embedded driver.", "I have also wondered if calling isClosed would be sufficient, and actually I have not been able to create a scenario where isClosed returns false followed by simple query that fails.", "The main reasons for including execution of a simple query also in the embedded driver are:", "I do not know the code well enough to be sure that there will not be situations where isClosed returns false and a query returns e.g., a timeout or exception due to some resource constraints, deadlock or other error situations.", "It will make the behavior and implementation more similar between what is done in the embedded and in the client driver.", "I will probably submit a patch for how isValid can be implemented for the Embedded server containing both a check for isClosed and a query.", "If you or other on the list still thinks it is unnecessary to include execution of a query I will remove it.", "The query case actually seems somewhat harder to me, and one needs to understand the code far more, than the isClosed approach.", "Maybe this knowledge needs to exist for the client implementation anyway.", "I think one has to see how many ways the query can fail and", "then see how many map to the connection being not valid.", "I don't believe the query failing, always means the connection is not valid.", "If the query failed due to out of memory error, then the connection is still valid.", "There's no requirement for the embedded and client dirver to have identical implementations, the embedded gains performance", "by having direct access to the engine, something that is clearly not possible with the client.", "This naturally leads to different implementations", "for various methods.", "Thanks for commenting on this, Dan.", "I agree that using a query is more complicated than just checking for isClosed.", "So if checking for isClosed is sufficient to verify that the connection is \"valid\" we should go for that approach in the embedded driver as it is less complex and has better performance.", "Still, I think the purpose of adding the isValid method to the JDBC standard is to positively determine that it is possible to run queries on it.", "I am not convinced that your example of a simple query on the connection failing due to out of memory should still return that the connection is \"valid\"?", "I expect this is a method that will be used together with a connection pool implementation where either the pool or the user will use this for \"ensuring\" the connection is \"valid\" before it is used for something.", "And having a connection that returns out of memory errors on every query is not something that an application would think is a \"useful\" connection to have around (on the other side, creating a new connection does probably not make the situation any better in this case).", "The JavaDoc for isValid (see the test in the Jira issue) strongly indicates that we actually should take the cost of running a query against the database.", "Anyway, I have no strong opinions on whether to just check isClosed or issue a query against the database.", "But since I now happen to have a patch that solves this using a query I will upload this patch tonight.", "Tomorrow moring I will upload a new patch that is only checking for isClosed.", "I do not expect anyone to do a review or commit any of these, but it might trigger some more comments and opinions from other on the list.", "The patch contains one alternative implementation of  Connection.isValid() for the embedded driver by verifying that the connection", "is open (by calling isClosed()) and by running a simple query (\"VALUES (1)\") against the database.", "If the connection is closed or if the query returns any SQL exception, isValid returns false.", "To support the timeout defined as a parameter to isValid, setQueryTimeout is used.", "Testing:", "The patch extends the TestConnectionMethods.java test with test for isValid in the following cases:", "wrong parameter values (negative timeout)", "isValid with no timeout", "isValid with a specified timeout", "isValid on a connection that is closed", "isValid on a \"open connection\" to a database that is shutdown", "I plan to submit an alternative patch that is checking only for isClosed as well as a more complete patch containing an implementation of isValid for the Derby client driver.", "svn status reports:", "M      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnection.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java", "I have run the JDBC4 tests using Java 1.6 and derbyall using 1.5 under Solaris 10 x86.", "Only errors seen in the regression test was reported.", "The patch is complete for the embedded driver and could be reviewed and committed, but I expect that we should wait until we have decided if using only isClosed is a better and sufficient solution.", "Hi, Olav.", "It's not clear to me what a committer needs to do with this patch.", "You have checked the box saying you intend it for inclusion to the project, but you also say other, alternate patches are on  the way.", "Do you want a committer to commit this, or is it just for review?", "Hi, David.", "The main purpose of sending in the patch was to get opinions from more people on what would be the best alternative solution to check if a connection is valid in the embedded driver.", "The current alternatives are:", "a) check if connection is not closed followed by a simple query against the database (this is implemented by the patch I submitted yesterday)", "b) just check that the connection is not closed (I plan to submit an alternative patch for this soon)", "Dan has suggested that checking for isClosed could be sufficient in the embedded version.", "It would be good to hear if other have opinions about this.", "If I do not get other suggestions I will probably propose that the next patch (checking only for isClosed) being reviewed and commited.", "This patch (embedded1090-isclosed.diff)  implementations Connection.isValid() for the embedded driver by verifying that the connection", "is not closed (by calling isClosed()).", "If the connection is closed, isValid returns false, otherwise it returns true.", "The timeout defined as a parameter to isValid is not used.", "Compared to the previous patch I sent a few days ago (embedded1090-query.diff), this patch does not run any query against Derby to validate the", "connection.", "My proposal (also based on suggestions from Dan) is that we only check for isClosed() in the embedded driver.", "I have not experienced any situation where isClosed returned false and the query failed.", "If we later discover situations where the connection is not \"valid\" even if isValid returns true, we can add a query as done in my first patch to isValid.", "Testing:", "The patch extends the TestConnectionMethods.java test with test for isValid in the following cases:", "wrong parameter values (negative timeout)", "isValid with no timeout", "isValid with a specified timeout", "isValid on a connection that is closed", "isValid on a \"open connection\" to a database that is shutdown", "svn status reports:", "M      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java", "I have run the JDBC4 tests using Java 1.6 and derbyall using Java 1.5 under Solaris 10 x86.", "Only errors seen in the regression test was reported (runtimeinfo failed in derbynetmats).", "The patch is complete for the embedded driver and can be reviewed and committed."], "SplitGT": [" Checks if the connection has not been closed and is still valid.", "The validity is checked by checking that the connection is not closed."], "issueString": "Implement Connection.isValid as defined by JDBC4\nThe Javadoc for JDBC4 says this about Connection.isValid:\n\nboolean isValid(int timeout) throws SQLException\n\nReturns true if the connection has not been closed and is still valid. The driver shall submit a query on the connection or use some other mechanism that positively verifies the connection is still valid when this method is called. \n\nThe query submitted by the driver to validate the connection shall be executed in the context of the current transaction. \n\nParameters: timeout - - The time in seconds to wait for the database operation used to validate the connection to complete. If the timeout period expires before the operation completes, this method returns false. A value of 0 indicates a timeout is not applied to the database operation. \n\nReturns: true if the connection is valid, false otherwise \nIn case someone else have suggestions or ideas on how to best implement this functionality, here are some high-level initial thoughts on how to implement it:\n\n  -to check the validity of the connection, issue a simple query like\n   e.g., \"VALUES (1)\"\n\n  -to implement the timeout, use the setQueryTimeout() method. \n\nThis will hopefully be sufficient in the embedded version as I expect that for all error situations where the connection no longer is valid, an exception will be thrown when issuing the query.\n\nFor the Derby client we probably need some timeout mechanism in the client code (in addition to setting the query timeout) in order to detect that the server has not responded within before the specified timeout has elapsed. I have not studied the network code in details yet to find out if it already has code or hooks for specifying a timeout on the DRDA request to the server. Any suggestions on how to best implement this are welcome.\n\nIn embedded would it  be sufficient just to call the isClosed() method?\n\nDan, thanks for the suggestion of only using isClosed in the embedded driver. I have also wondered if calling isClosed would be sufficient, and actually I have not been able to create a scenario where isClosed returns false followed by simple query that fails.\n\nThe main reasons for including execution of a simple query also in the embedded driver are:\n\n * I do not know the code well enough to be sure that there will not be situations where isClosed returns false and a query returns e.g., a timeout or exception due to some resource constraints, deadlock or other error situations.\n\n * It will make the behavior and implementation more similar between what is done in the embedded and in the client driver.\n\nI will probably submit a patch for how isValid can be implemented for the Embedded server containing both a check for isClosed and a query. If you or other on the list still thinks it is unnecessary to include execution of a query I will remove it.\n\n\nThe query case actually seems somewhat harder to me, and one needs to understand the code far more, than the isClosed approach.\nMaybe this knowledge needs to exist for the client implementation anyway. I think one has to see how many ways the query can fail and\nthen see how many map to the connection being not valid. I don't believe the query failing, always means the connection is not valid.\nIf the query failed due to out of memory error, then the connection is still valid.\n\nThere's no requirement for the embedded and client dirver to have identical implementations, the embedded gains performance\nby having direct access to the engine, something that is clearly not possible with the client. This naturally leads to different implementations\nfor various methods.\nThanks for commenting on this, Dan. I agree that using a query is more complicated than just checking for isClosed. So if checking for isClosed is sufficient to verify that the connection is \"valid\" we should go for that approach in the embedded driver as it is less complex and has better performance. \n\nStill, I think the purpose of adding the isValid method to the JDBC standard is to positively determine that it is possible to run queries on it. I am not convinced that your example of a simple query on the connection failing due to out of memory should still return that the connection is \"valid\"? I expect this is a method that will be used together with a connection pool implementation where either the pool or the user will use this for \"ensuring\" the connection is \"valid\" before it is used for something. And having a connection that returns out of memory errors on every query is not something that an application would think is a \"useful\" connection to have around (on the other side, creating a new connection does probably not make the situation any better in this case). The JavaDoc for isValid (see the test in the Jira issue) strongly indicates that we actually should take the cost of running a query against the database.\n\nAnyway, I have no strong opinions on whether to just check isClosed or issue a query against the database. But since I now happen to have a patch that solves this using a query I will upload this patch tonight. Tomorrow moring I will upload a new patch that is only checking for isClosed. I do not expect anyone to do a review or commit any of these, but it might trigger some more comments and opinions from other on the list. \nThe patch contains one alternative implementation of  Connection.isValid() for the embedded driver by verifying that the connection\nis open (by calling isClosed()) and by running a simple query (\"VALUES (1)\") against the database. If the connection is closed or if the query returns any SQL exception, isValid returns false. To support the timeout defined as a parameter to isValid, setQueryTimeout is used.\n\nTesting:\n\nThe patch extends the TestConnectionMethods.java test with test for isValid in the following cases:\n\n  -wrong parameter values (negative timeout)\n  -isValid with no timeout\n  -isValid with a specified timeout\n  -isValid on a connection that is closed\n  -isValid on a \"open connection\" to a database that is shutdown\n\nI plan to submit an alternative patch that is checking only for isClosed as well as a more complete patch containing an implementation of isValid for the Derby client driver.\n\nsvn status reports:\n\nM      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnection.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java\n\nI have run the JDBC4 tests using Java 1.6 and derbyall using 1.5 under Solaris 10 x86. Only errors seen in the regression test was reported.\n\nThe patch is complete for the embedded driver and could be reviewed and committed, but I expect that we should wait until we have decided if using only isClosed is a better and sufficient solution.\n\n\nHi, Olav.  It's not clear to me what a committer needs to do with this patch.  You have checked the box saying you intend it for inclusion to the project, but you also say other, alternate patches are on  the way.  Do you want a committer to commit this, or is it just for review?\nHi, David. The main purpose of sending in the patch was to get opinions from more people on what would be the best alternative solution to check if a connection is valid in the embedded driver. The current alternatives are:\n\n  a) check if connection is not closed followed by a simple query against the database (this is implemented by the patch I submitted yesterday)\n  b) just check that the connection is not closed (I plan to submit an alternative patch for this soon)\n\nDan has suggested that checking for isClosed could be sufficient in the embedded version. It would be good to hear if other have opinions about this. If I do not get other suggestions I will probably propose that the next patch (checking only for isClosed) being reviewed and commited.\nThis patch (embedded1090-isclosed.diff)  implementations Connection.isValid() for the embedded driver by verifying that the connection \nis not closed (by calling isClosed()). If the connection is closed, isValid returns false, otherwise it returns true. The timeout defined as a parameter to isValid is not used.\n\nCompared to the previous patch I sent a few days ago (embedded1090-query.diff), this patch does not run any query against Derby to validate the\nconnection. My proposal (also based on suggestions from Dan) is that we only check for isClosed() in the embedded driver. I have not experienced any situation where isClosed returned false and the query failed. If we later discover situations where the connection is not \"valid\" even if isValid returns true, we can add a query as done in my first patch to isValid.\n\nTesting: \n\nThe patch extends the TestConnectionMethods.java test with test for isValid in the following cases: \n\n  -wrong parameter values (negative timeout) \n  -isValid with no timeout \n  -isValid with a specified timeout \n  -isValid on a connection that is closed \n  -isValid on a \"open connection\" to a database that is shutdown \n\nsvn status reports: \n\nM      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java\n\nI have run the JDBC4 tests using Java 1.6 and derbyall using Java 1.5 under Solaris 10 x86. Only errors seen in the regression test was reported (runtimeinfo failed in derbynetmats).\n\nThe patch is complete for the embedded driver and can be reviewed and committed.\n", "issueSearchSentences": ["The Javadoc for JDBC4 says this about Connection.isValid:", "is open (by calling isClosed()) and by running a simple query (\"VALUES (1)\") against the database.", "e.g., \"VALUES (1)\"", "This will hopefully be sufficient in the embedded version as I expect that for all error situations where the connection no longer is valid, an exception will be thrown when issuing the query.", "wrong parameter values (negative timeout)"], "issueSearchIndexes": [2, 50, 13, 15, 55]}
{"aId": 146, "code": "public  static  void    dropConnection( String connectionURL )\n    {\n        _connections.remove( connectionURL );\n    }", "comment": " Remove the cached connection to the foreign database.", "issueId": "DERBY-6440", "issueStringList": ["Connections opened by ForeignTableVTI never get released", "I noticed during a run of suites.All that one database instance never got garbage collected, even after it had been shut down.", "It turned out it could not get garbage collected because it was still referenced from the static HashMap _connections in ForeignTableVTI.", "Looking closer at ForeignTableVTI, it looks as if it only calls put() and get() on the HashMap, never remove(), so its memory footprint will keep increasing as it is used.", "It would be good to have some way (preferably automatic) of releasing the resources held by ForeignTableVTI when they are no longer needed.", "(The reason why I looked for memory leaks in the first place, was the OutOfMemoryErrors that we've seen every now and then in the nightly testing on JDK 8 lately (for example [here|http://download.java.net/javadesktop/derby/request_5585930/javadb-task-3780475.html]).", "I don't know if this bug is what's causing those OOMEs, though.)", "Thanks for logging this issue, Knut.", "Probably we can add a static method to remove the connection from the HashMap in ForeignTableVTI and call that method from ForeignDBViews.unloadTool().", "Thanks.", "Attaching derby-6440-01-aa-dropConnectionOnUnload.diff.", "This patch causes ForeignDBViews.unloadTool() to remove the connection to the foreign database from the HashMap managed by ForeignTableVTI.", "I am running tests now.", "Now when you call...", "{noformat}", "call syscs_util.syscs_register_tool", "(", "'foreignViews', false,", "...", ");", "{noformat}", "...the foreign connection managed by ForeignTableVTI is dropped.", "Touches the following files:", "M       java/engine/org/apache/derby/vti/ForeignTableVTI.java", "Adds two new static methods to this class:", "public static void dropConnection( String connectionURL ) - This method drops the connection associated with the connection url.", "public static int countConnections() - This method is useful for verifying how many connections are still being managed by ForeignTableVTI.", "M       java/tools/org/apache/derby/impl/tools/optional/ForeignDBViews.java", "Now unloadTool() calls ForeignTableVTI.dropConnection() on its way out.", "M       java/testing/org/apache/derbyTesting/functionTests/tests/lang/OptionalToolsTest.java", "Adds some test cases to verify that syscs_util.syscs_register_tool() drops the connection on its way out.", "On exiting, the test_02_foreignDBViews() test verifies that the ForeignTableVTI._connections HashMap is empty.", "Tests passed cleanly for me on derby-6440-01-aa-dropConnectionOnUnload.diff."], "SplitGT": [" Remove the cached connection to the foreign database."], "issueString": "Connections opened by ForeignTableVTI never get released\nI noticed during a run of suites.All that one database instance never got garbage collected, even after it had been shut down. It turned out it could not get garbage collected because it was still referenced from the static HashMap _connections in ForeignTableVTI. Looking closer at ForeignTableVTI, it looks as if it only calls put() and get() on the HashMap, never remove(), so its memory footprint will keep increasing as it is used.\n\nIt would be good to have some way (preferably automatic) of releasing the resources held by ForeignTableVTI when they are no longer needed.\n(The reason why I looked for memory leaks in the first place, was the OutOfMemoryErrors that we've seen every now and then in the nightly testing on JDK 8 lately (for example [here|http://download.java.net/javadesktop/derby/request_5585930/javadb-task-3780475.html]). I don't know if this bug is what's causing those OOMEs, though.)\nThanks for logging this issue, Knut. Probably we can add a static method to remove the connection from the HashMap in ForeignTableVTI and call that method from ForeignDBViews.unloadTool(). Thanks.\nAttaching derby-6440-01-aa-dropConnectionOnUnload.diff. This patch causes ForeignDBViews.unloadTool() to remove the connection to the foreign database from the HashMap managed by ForeignTableVTI. I am running tests now.\n\nNow when you call...\n\n{noformat}\ncall syscs_util.syscs_register_tool\n(\n    'foreignViews', false,\n    ...\n);\n{noformat}\n\n...the foreign connection managed by ForeignTableVTI is dropped.\n\n\nTouches the following files:\n\n--------------\n\nM       java/engine/org/apache/derby/vti/ForeignTableVTI.java\n\nAdds two new static methods to this class:\n\npublic static void dropConnection( String connectionURL ) - This method drops the connection associated with the connection url.\n\npublic static int countConnections() - This method is useful for verifying how many connections are still being managed by ForeignTableVTI.\n\n--------------\n\nM       java/tools/org/apache/derby/impl/tools/optional/ForeignDBViews.java\n\nNow unloadTool() calls ForeignTableVTI.dropConnection() on its way out.\n\n--------------\n\nM       java/testing/org/apache/derbyTesting/functionTests/tests/lang/OptionalToolsTest.java\n\nAdds some test cases to verify that syscs_util.syscs_register_tool() drops the connection on its way out. On exiting, the test_02_foreignDBViews() test verifies that the ForeignTableVTI._connections HashMap is empty.\n\nTests passed cleanly for me on derby-6440-01-aa-dropConnectionOnUnload.diff.\n", "issueSearchSentences": ["Adds two new static methods to this class:", "public static void dropConnection( String connectionURL ) - This method drops the connection associated with the connection url.", "M       java/tools/org/apache/derby/impl/tools/optional/ForeignDBViews.java", "I noticed during a run of suites.All that one database instance never got garbage collected, even after it had been shut down.", "Thanks for logging this issue, Knut."], "issueSearchIndexes": [25, 26, 28, 2, 8]}
{"aId": 149, "code": "synchronized public boolean isValid(int timeout) throws SQLException {\n        // Check if we have a underlying physical connection\n        if (physicalConnection_ == null) {\n            return false;\n        }\n        return physicalConnection_.isValid(timeout);\n    }", "comment": " Checks if the connection has not been closed and is still valid. The validity is checked by running a simple query against the database.", "issueId": "DERBY-1090", "issueStringList": ["Implement Connection.isValid as defined by JDBC4", "The Javadoc for JDBC4 says this about Connection.isValid:", "boolean isValid(int timeout) throws SQLException", "Returns true if the connection has not been closed and is still valid.", "The driver shall submit a query on the connection or use some other mechanism that positively verifies the connection is still valid when this method is called.", "The query submitted by the driver to validate the connection shall be executed in the context of the current transaction.", "Parameters: timeout - - The time in seconds to wait for the database operation used to validate the connection to complete.", "If the timeout period expires before the operation completes, this method returns false.", "A value of 0 indicates a timeout is not applied to the database operation.", "Returns: true if the connection is valid, false otherwise", "In case someone else have suggestions or ideas on how to best implement this functionality, here are some high-level initial thoughts on how to implement it:", "to check the validity of the connection, issue a simple query like", "e.g., \"VALUES (1)\"", "to implement the timeout, use the setQueryTimeout() method.", "This will hopefully be sufficient in the embedded version as I expect that for all error situations where the connection no longer is valid, an exception will be thrown when issuing the query.", "For the Derby client we probably need some timeout mechanism in the client code (in addition to setting the query timeout) in order to detect that the server has not responded within before the specified timeout has elapsed.", "I have not studied the network code in details yet to find out if it already has code or hooks for specifying a timeout on the DRDA request to the server.", "Any suggestions on how to best implement this are welcome.", "In embedded would it  be sufficient just to call the isClosed() method?", "Dan, thanks for the suggestion of only using isClosed in the embedded driver.", "I have also wondered if calling isClosed would be sufficient, and actually I have not been able to create a scenario where isClosed returns false followed by simple query that fails.", "The main reasons for including execution of a simple query also in the embedded driver are:", "I do not know the code well enough to be sure that there will not be situations where isClosed returns false and a query returns e.g., a timeout or exception due to some resource constraints, deadlock or other error situations.", "It will make the behavior and implementation more similar between what is done in the embedded and in the client driver.", "I will probably submit a patch for how isValid can be implemented for the Embedded server containing both a check for isClosed and a query.", "If you or other on the list still thinks it is unnecessary to include execution of a query I will remove it.", "The query case actually seems somewhat harder to me, and one needs to understand the code far more, than the isClosed approach.", "Maybe this knowledge needs to exist for the client implementation anyway.", "I think one has to see how many ways the query can fail and", "then see how many map to the connection being not valid.", "I don't believe the query failing, always means the connection is not valid.", "If the query failed due to out of memory error, then the connection is still valid.", "There's no requirement for the embedded and client dirver to have identical implementations, the embedded gains performance", "by having direct access to the engine, something that is clearly not possible with the client.", "This naturally leads to different implementations", "for various methods.", "Thanks for commenting on this, Dan.", "I agree that using a query is more complicated than just checking for isClosed.", "So if checking for isClosed is sufficient to verify that the connection is \"valid\" we should go for that approach in the embedded driver as it is less complex and has better performance.", "Still, I think the purpose of adding the isValid method to the JDBC standard is to positively determine that it is possible to run queries on it.", "I am not convinced that your example of a simple query on the connection failing due to out of memory should still return that the connection is \"valid\"?", "I expect this is a method that will be used together with a connection pool implementation where either the pool or the user will use this for \"ensuring\" the connection is \"valid\" before it is used for something.", "And having a connection that returns out of memory errors on every query is not something that an application would think is a \"useful\" connection to have around (on the other side, creating a new connection does probably not make the situation any better in this case).", "The JavaDoc for isValid (see the test in the Jira issue) strongly indicates that we actually should take the cost of running a query against the database.", "Anyway, I have no strong opinions on whether to just check isClosed or issue a query against the database.", "But since I now happen to have a patch that solves this using a query I will upload this patch tonight.", "Tomorrow moring I will upload a new patch that is only checking for isClosed.", "I do not expect anyone to do a review or commit any of these, but it might trigger some more comments and opinions from other on the list.", "The patch contains one alternative implementation of  Connection.isValid() for the embedded driver by verifying that the connection", "is open (by calling isClosed()) and by running a simple query (\"VALUES (1)\") against the database.", "If the connection is closed or if the query returns any SQL exception, isValid returns false.", "To support the timeout defined as a parameter to isValid, setQueryTimeout is used.", "Testing:", "The patch extends the TestConnectionMethods.java test with test for isValid in the following cases:", "wrong parameter values (negative timeout)", "isValid with no timeout", "isValid with a specified timeout", "isValid on a connection that is closed", "isValid on a \"open connection\" to a database that is shutdown", "I plan to submit an alternative patch that is checking only for isClosed as well as a more complete patch containing an implementation of isValid for the Derby client driver.", "svn status reports:", "M      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnection.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java", "I have run the JDBC4 tests using Java 1.6 and derbyall using 1.5 under Solaris 10 x86.", "Only errors seen in the regression test was reported.", "The patch is complete for the embedded driver and could be reviewed and committed, but I expect that we should wait until we have decided if using only isClosed is a better and sufficient solution.", "Hi, Olav.", "It's not clear to me what a committer needs to do with this patch.", "You have checked the box saying you intend it for inclusion to the project, but you also say other, alternate patches are on  the way.", "Do you want a committer to commit this, or is it just for review?", "Hi, David.", "The main purpose of sending in the patch was to get opinions from more people on what would be the best alternative solution to check if a connection is valid in the embedded driver.", "The current alternatives are:", "a) check if connection is not closed followed by a simple query against the database (this is implemented by the patch I submitted yesterday)", "b) just check that the connection is not closed (I plan to submit an alternative patch for this soon)", "Dan has suggested that checking for isClosed could be sufficient in the embedded version.", "It would be good to hear if other have opinions about this.", "If I do not get other suggestions I will probably propose that the next patch (checking only for isClosed) being reviewed and commited.", "This patch (embedded1090-isclosed.diff)  implementations Connection.isValid() for the embedded driver by verifying that the connection", "is not closed (by calling isClosed()).", "If the connection is closed, isValid returns false, otherwise it returns true.", "The timeout defined as a parameter to isValid is not used.", "Compared to the previous patch I sent a few days ago (embedded1090-query.diff), this patch does not run any query against Derby to validate the", "connection.", "My proposal (also based on suggestions from Dan) is that we only check for isClosed() in the embedded driver.", "I have not experienced any situation where isClosed returned false and the query failed.", "If we later discover situations where the connection is not \"valid\" even if isValid returns true, we can add a query as done in my first patch to isValid.", "Testing:", "The patch extends the TestConnectionMethods.java test with test for isValid in the following cases:", "wrong parameter values (negative timeout)", "isValid with no timeout", "isValid with a specified timeout", "isValid on a connection that is closed", "isValid on a \"open connection\" to a database that is shutdown", "svn status reports:", "M      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java", "I have run the JDBC4 tests using Java 1.6 and derbyall using Java 1.5 under Solaris 10 x86.", "Only errors seen in the regression test was reported (runtimeinfo failed in derbynetmats).", "The patch is complete for the embedded driver and can be reviewed and committed.", "Looks good to me.", "The jdbc4 tests run cleanly.", "Derbyall only has errors which I see in a clean client: wisconsin, sysinfo, sysinfo_withproperties, xaSimplePositive, and a new failure in SURTest caused by:", "> java.lang.NoSuchMethodError: main", "> Exception in thread \"main\"", "Test Failed.", "I have committed embedded1090_isClosed.diff at subversion revision 388771.", "This patch (client1090_patch1.diff) implements the Connection.isValid for the network client.", "The connection is valid if (a) it is not closed (checked isClosed()) and (b) a simple query (\"VALUES (1)\") is executed successfully.", "Any exception thrown by the query execution is treated as if the connection is not valid.", "If a timeout is specified this is handled by setting a query timeout for executing the query (queryTimeout() is used).", "The implementation handles most failure situations, with the exception of a hanging server that is not returning any reply to the client.", "I plan to submit a fix for this in a separte patch.", "The isValid() call is tested for the following scenarios:", "illegal parameter values (negative timeout)", "no timeout value", "with a timeout specified", "on a connection to a database that has been shutdown", "on a connection to a network server that has been stopped", "svn status reports:", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java", "M      java/client/org/apache/derby/client/net/NetConnection40.java", "I have run the JDBC4 tests and derbyall with the patch.", "Only failure was in tools/derbyrunjartest.java.", "The patch can be reviewed and committed.", "I have looked at the patch, and I think it looks good, and can be committed.", "I concur, looks good.", "JDBC4 tests run cleanly.", "Derbyall runs cleanly modulo wisconsin noise.", "Committed at subversion revision 396028.", "Dyre and Rick, thanks for reviewing and committing the patch.", "The first implementation of Connection.isValid() for the client driver handles most failuire situations.", "One situation that is not handled is if the server \"hangs\" and the client does not receive a reply.", "The application will be hanging \"forever\" in the isValid() call due to the blocking read on the socket even if a timeout value has been specified.", "I plan to submit a fix to this problem by setting a timeout on the socket before the read is called on the socket (using java.net.socket.setSoTimeout).", "One potential problem with using socket.setSoTimeout is that its implementation is platform dependent.", "Some operating systems might not support the timeout value and block forever on socket operations even if a timeout is set.", "I would appreciate to hear if anybody has better or alternative solutions on how to handle the problem with blocking socket read and hanging server.", "This patch (client1090_patch2.diff) addresses the problem of Connection.isValid() hanging infinite if the server is either \"hanging\" or not sending a reply.", "The reason for the client to hang in these situations is that blocking read (and write) is used for receiving replies from the Derby network server.", "To avoid the client hanging infinite in the blocking read when the caller has specified a timeout to isValid() we set a maximum timeout value on the socket (by using java.net.socket.setSoTimeout()) before the query is sent to the server.", "Thus, if the server does not respond within the specified timeout period the blocking read will return with an exception.", "If this exception is thrown, isValid will return false for this connection.", "The timeout on the socket is reset to whatever value it had before the call to isValid.", "Thus, this socket timeout should only influence on the query issued by the isValid code.", "The implementation has been tested by setting a very low timeout value and introducing a delay in the network server.", "svn status reports:", "M      java/client/org/apache/derby/client/net/NetAgent.java", "M      java/client/org/apache/derby/client/net/NetConnection40.java", "I have run the JDBC4 tests and derbyall with the patch.", "Only failure was in tools/derbyrunjartest.java.", "The patch can be reviewed and committed.", "Looks solid.", "JDBC4 tests run cleanly.", "So does derbyall modulo the wisconsin noise.", "Committed at subversion revision 397899.", "This patch (brokeredlogical1090.diff) implemets support for Connection.isValid for pooled and XA connections.", "Testing of isValid for pooled and XA connections is implemented in the jdbc4/ConnectionTest.junit.", "This test is currently not part of either the jdbc4 suite or derbyall.", "svn status reports:", "M      java/engine/org/apache/derby/iapi/jdbc/BrokeredConnection40.java", "M      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/ConnectionTest.java", "M      java/client/org/apache/derby/client/am/LogicalConnection40.java", "I have run the jdbc4/ConnectionTest.junig, the JDBC4 test suite and derbyall with the patch.", "Only failure was in tools/derbyrunjartest.java.", "The patch can be reviewed and committed.", "The brokeredlogical1090.diff patch looks solid.", "JDBC4 tests pass.", "Derbyall passes modulo expected diffs in wisconsin and SuicideOfStreaming.", "Committed at subversion revision 406101."], "SplitGT": [" Checks if the connection has not been closed and is still valid.", "The validity is checked by running a simple query against the database."], "issueString": "Implement Connection.isValid as defined by JDBC4\nThe Javadoc for JDBC4 says this about Connection.isValid:\n\nboolean isValid(int timeout) throws SQLException\n\nReturns true if the connection has not been closed and is still valid. The driver shall submit a query on the connection or use some other mechanism that positively verifies the connection is still valid when this method is called. \n\nThe query submitted by the driver to validate the connection shall be executed in the context of the current transaction. \n\nParameters: timeout - - The time in seconds to wait for the database operation used to validate the connection to complete. If the timeout period expires before the operation completes, this method returns false. A value of 0 indicates a timeout is not applied to the database operation. \n\nReturns: true if the connection is valid, false otherwise \nIn case someone else have suggestions or ideas on how to best implement this functionality, here are some high-level initial thoughts on how to implement it:\n\n  -to check the validity of the connection, issue a simple query like\n   e.g., \"VALUES (1)\"\n\n  -to implement the timeout, use the setQueryTimeout() method. \n\nThis will hopefully be sufficient in the embedded version as I expect that for all error situations where the connection no longer is valid, an exception will be thrown when issuing the query.\n\nFor the Derby client we probably need some timeout mechanism in the client code (in addition to setting the query timeout) in order to detect that the server has not responded within before the specified timeout has elapsed. I have not studied the network code in details yet to find out if it already has code or hooks for specifying a timeout on the DRDA request to the server. Any suggestions on how to best implement this are welcome.\n\nIn embedded would it  be sufficient just to call the isClosed() method?\n\nDan, thanks for the suggestion of only using isClosed in the embedded driver. I have also wondered if calling isClosed would be sufficient, and actually I have not been able to create a scenario where isClosed returns false followed by simple query that fails.\n\nThe main reasons for including execution of a simple query also in the embedded driver are:\n\n * I do not know the code well enough to be sure that there will not be situations where isClosed returns false and a query returns e.g., a timeout or exception due to some resource constraints, deadlock or other error situations.\n\n * It will make the behavior and implementation more similar between what is done in the embedded and in the client driver.\n\nI will probably submit a patch for how isValid can be implemented for the Embedded server containing both a check for isClosed and a query. If you or other on the list still thinks it is unnecessary to include execution of a query I will remove it.\n\n\nThe query case actually seems somewhat harder to me, and one needs to understand the code far more, than the isClosed approach.\nMaybe this knowledge needs to exist for the client implementation anyway. I think one has to see how many ways the query can fail and\nthen see how many map to the connection being not valid. I don't believe the query failing, always means the connection is not valid.\nIf the query failed due to out of memory error, then the connection is still valid.\n\nThere's no requirement for the embedded and client dirver to have identical implementations, the embedded gains performance\nby having direct access to the engine, something that is clearly not possible with the client. This naturally leads to different implementations\nfor various methods.\nThanks for commenting on this, Dan. I agree that using a query is more complicated than just checking for isClosed. So if checking for isClosed is sufficient to verify that the connection is \"valid\" we should go for that approach in the embedded driver as it is less complex and has better performance. \n\nStill, I think the purpose of adding the isValid method to the JDBC standard is to positively determine that it is possible to run queries on it. I am not convinced that your example of a simple query on the connection failing due to out of memory should still return that the connection is \"valid\"? I expect this is a method that will be used together with a connection pool implementation where either the pool or the user will use this for \"ensuring\" the connection is \"valid\" before it is used for something. And having a connection that returns out of memory errors on every query is not something that an application would think is a \"useful\" connection to have around (on the other side, creating a new connection does probably not make the situation any better in this case). The JavaDoc for isValid (see the test in the Jira issue) strongly indicates that we actually should take the cost of running a query against the database.\n\nAnyway, I have no strong opinions on whether to just check isClosed or issue a query against the database. But since I now happen to have a patch that solves this using a query I will upload this patch tonight. Tomorrow moring I will upload a new patch that is only checking for isClosed. I do not expect anyone to do a review or commit any of these, but it might trigger some more comments and opinions from other on the list. \nThe patch contains one alternative implementation of  Connection.isValid() for the embedded driver by verifying that the connection\nis open (by calling isClosed()) and by running a simple query (\"VALUES (1)\") against the database. If the connection is closed or if the query returns any SQL exception, isValid returns false. To support the timeout defined as a parameter to isValid, setQueryTimeout is used.\n\nTesting:\n\nThe patch extends the TestConnectionMethods.java test with test for isValid in the following cases:\n\n  -wrong parameter values (negative timeout)\n  -isValid with no timeout\n  -isValid with a specified timeout\n  -isValid on a connection that is closed\n  -isValid on a \"open connection\" to a database that is shutdown\n\nI plan to submit an alternative patch that is checking only for isClosed as well as a more complete patch containing an implementation of isValid for the Derby client driver.\n\nsvn status reports:\n\nM      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnection.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java\n\nI have run the JDBC4 tests using Java 1.6 and derbyall using 1.5 under Solaris 10 x86. Only errors seen in the regression test was reported.\n\nThe patch is complete for the embedded driver and could be reviewed and committed, but I expect that we should wait until we have decided if using only isClosed is a better and sufficient solution.\n\n\nHi, Olav.  It's not clear to me what a committer needs to do with this patch.  You have checked the box saying you intend it for inclusion to the project, but you also say other, alternate patches are on  the way.  Do you want a committer to commit this, or is it just for review?\nHi, David. The main purpose of sending in the patch was to get opinions from more people on what would be the best alternative solution to check if a connection is valid in the embedded driver. The current alternatives are:\n\n  a) check if connection is not closed followed by a simple query against the database (this is implemented by the patch I submitted yesterday)\n  b) just check that the connection is not closed (I plan to submit an alternative patch for this soon)\n\nDan has suggested that checking for isClosed could be sufficient in the embedded version. It would be good to hear if other have opinions about this. If I do not get other suggestions I will probably propose that the next patch (checking only for isClosed) being reviewed and commited.\nThis patch (embedded1090-isclosed.diff)  implementations Connection.isValid() for the embedded driver by verifying that the connection \nis not closed (by calling isClosed()). If the connection is closed, isValid returns false, otherwise it returns true. The timeout defined as a parameter to isValid is not used.\n\nCompared to the previous patch I sent a few days ago (embedded1090-query.diff), this patch does not run any query against Derby to validate the\nconnection. My proposal (also based on suggestions from Dan) is that we only check for isClosed() in the embedded driver. I have not experienced any situation where isClosed returned false and the query failed. If we later discover situations where the connection is not \"valid\" even if isValid returns true, we can add a query as done in my first patch to isValid.\n\nTesting: \n\nThe patch extends the TestConnectionMethods.java test with test for isValid in the following cases: \n\n  -wrong parameter values (negative timeout) \n  -isValid with no timeout \n  -isValid with a specified timeout \n  -isValid on a connection that is closed \n  -isValid on a \"open connection\" to a database that is shutdown \n\nsvn status reports: \n\nM      java/engine/org/apache/derby/impl/jdbc/EmbedConnection40.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java\n\nI have run the JDBC4 tests using Java 1.6 and derbyall using Java 1.5 under Solaris 10 x86. Only errors seen in the regression test was reported (runtimeinfo failed in derbynetmats).\n\nThe patch is complete for the embedded driver and can be reviewed and committed.\nLooks good to me. The jdbc4 tests run cleanly. Derbyall only has errors which I see in a clean client: wisconsin, sysinfo, sysinfo_withproperties, xaSimplePositive, and a new failure in SURTest caused by:\n\n> java.lang.NoSuchMethodError: main\n> Exception in thread \"main\"\nTest Failed.\n\nI have committed embedded1090_isClosed.diff at subversion revision 388771.\nThis patch (client1090_patch1.diff) implements the Connection.isValid for the network client. The connection is valid if (a) it is not closed (checked isClosed()) and (b) a simple query (\"VALUES (1)\") is executed successfully. Any exception thrown by the query execution is treated as if the connection is not valid.\n\nIf a timeout is specified this is handled by setting a query timeout for executing the query (queryTimeout() is used). \n\nThe implementation handles most failure situations, with the exception of a hanging server that is not returning any reply to the client. I plan to submit a fix for this in a separte patch. \n\nThe isValid() call is tested for the following scenarios:\n\n  -illegal parameter values (negative timeout)\n  -no timeout value\n  -with a timeout specified\n  -on a connection to a database that has been shutdown\n  -on a connection to a network server that has been stopped\n\nsvn status reports:\n\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/TestConnectionMethods.java\nM      java/client/org/apache/derby/client/net/NetConnection40.java\n\nI have run the JDBC4 tests and derbyall with the patch. Only failure was in tools/derbyrunjartest.java.\n\nThe patch can be reviewed and committed.\nI have looked at the patch, and I think it looks good, and can be committed.\n\nI concur, looks good. JDBC4 tests run cleanly. Derbyall runs cleanly modulo wisconsin noise. Committed at subversion revision 396028.\nDyre and Rick, thanks for reviewing and committing the patch.\nThe first implementation of Connection.isValid() for the client driver handles most failuire situations. One situation that is not handled is if the server \"hangs\" and the client does not receive a reply. The application will be hanging \"forever\" in the isValid() call due to the blocking read on the socket even if a timeout value has been specified. I plan to submit a fix to this problem by setting a timeout on the socket before the read is called on the socket (using java.net.socket.setSoTimeout). One potential problem with using socket.setSoTimeout is that its implementation is platform dependent. Some operating systems might not support the timeout value and block forever on socket operations even if a timeout is set.\n\nI would appreciate to hear if anybody has better or alternative solutions on how to handle the problem with blocking socket read and hanging server. \n\n\nThis patch (client1090_patch2.diff) addresses the problem of Connection.isValid() hanging infinite if the server is either \"hanging\" or not sending a reply. \n\nThe reason for the client to hang in these situations is that blocking read (and write) is used for receiving replies from the Derby network server. To avoid the client hanging infinite in the blocking read when the caller has specified a timeout to isValid() we set a maximum timeout value on the socket (by using java.net.socket.setSoTimeout()) before the query is sent to the server. Thus, if the server does not respond within the specified timeout period the blocking read will return with an exception.\nIf this exception is thrown, isValid will return false for this connection. The timeout on the socket is reset to whatever value it had before the call to isValid. Thus, this socket timeout should only influence on the query issued by the isValid code.\n\nThe implementation has been tested by setting a very low timeout value and introducing a delay in the network server.\n\nsvn status reports:\n\nM      java/client/org/apache/derby/client/net/NetAgent.java\nM      java/client/org/apache/derby/client/net/NetConnection40.java\n\nI have run the JDBC4 tests and derbyall with the patch. Only failure was in tools/derbyrunjartest.java.\n\nThe patch can be reviewed and committed.\nLooks solid. JDBC4 tests run cleanly. So does derbyall modulo the wisconsin noise. Committed at subversion revision 397899.\nThis patch (brokeredlogical1090.diff) implemets support for Connection.isValid for pooled and XA connections. \n\nTesting of isValid for pooled and XA connections is implemented in the jdbc4/ConnectionTest.junit. This test is currently not part of either the jdbc4 suite or derbyall. \n\nsvn status reports:\n\nM      java/engine/org/apache/derby/iapi/jdbc/BrokeredConnection40.java\nM      java/testing/org/apache/derbyTesting/functionTests/tests/jdbc4/ConnectionTest.java\nM      java/client/org/apache/derby/client/am/LogicalConnection40.java\n\nI have run the jdbc4/ConnectionTest.junig, the JDBC4 test suite and derbyall with the patch. Only failure was in tools/derbyrunjartest.java. \n\nThe patch can be reviewed and committed.\nThe brokeredlogical1090.diff patch looks solid. JDBC4 tests pass. Derbyall passes modulo expected diffs in wisconsin and SuicideOfStreaming. Committed at subversion revision 406101.\n", "issueSearchSentences": ["The Javadoc for JDBC4 says this about Connection.isValid:", "Thus, if the server does not respond within the specified timeout period the blocking read will return with an exception.", "isValid with no timeout", "isValid with no timeout", "I have not experienced any situation where isClosed returned false and the query failed."], "issueSearchIndexes": [2, 143, 56, 92, 87]}
{"aId": 151, "code": "public int getJDBCMajorVersion() {\n        return 4;\n    }", "comment": " Retrieves the major JDBC version number for this driver.", "issueId": "DERBY-1546", "issueStringList": ["Derby JDBC 4.0 driver returns 3 for JDBC driver major version", "For 10.2 the DatabaseMetaData.getJDBCMajorVersion() is returning \"3\" for", "the Derby JDBC 4.0 driver.", "It should return 4.", "This is easily", "reproduced by running a simple test to obtain a connection and", "output the value,", "Database product: Apache Derby", "Database version: 10.2.0.4 alpha", "Driver name:      Apache Derby Embedded JDBC Driver", "Driver version:   10.2.0.4 alpha", "JDBC driver major version: 3", "JDBC driver minor version: 0", "Test code:", "org.apache.derby.jdbc.EmbeddedConnectionPoolDataSource40 ds =", "new", "org.apache.derby.jdbc.EmbeddedConnectionPoolDataSource40();", "ds.setDatabaseName(\"C:\\\\drivers\\\\derby\\\\databases\\\\JDBC40DB\");", "ds.setUser(\"dbuser1\");", "ds.setPassword(\"dbpwd1\");", "PooledConnection pooledConn =", "ds.getPooledConnection();", "Connection conn = pooledConn.getConnection();", "System.out.println(\"Database product: \" +", "conn.getMetaData().getDatabaseProductName());", "System.out.println(\"Database version: \" +", "conn.getMetaData().getDatabaseProductVersion());", "System.out.println(\"Driver name:      \" +", "conn.getMetaData().getDriverName());", "System.out.println(\"Driver version:   \" +", "conn.getMetaData().getDriverVersion());", "System.out.println(\"JDBC driver major version: \" +", "conn.getMetaData().getJDBCMajorVersion());", "System.out.println(\"JDBC driver minor version: \" +", "conn.getMetaData().getJDBCMinorVersion());", "Relevant Derby Embedded code in EmbedDatabaseMetaData is:", "JDBC 3.0", "Retrieves the major JDBC version number for this driver.", "@return JDBC version major number", "public int getJDBCMajorVersion()", "{", "return 3;", "}", "and client code in org.apache.derby.client.am.DatabaseMetaData:", "public int getJDBCMajorVersion() throws SQLException {", "checkForClosedConnection();", "return 3;", "}", "I am not sure if this should be JVM dependent or if it should always return 4  regardless of the JVM version.", "This is the correct behavior if you are running on jvm 1.4 or 1.5.", "If you are running on 1.6, the major version should be 4.", "It isn't, so this is a bug.", "derby-1546-v1.diff makes getJDBCMajorVersion() return 4 when using the", "JDBC 4.0 driver and 3 otherwise (the method was not present in JDBC", "2.0, so there is no need to return 2 for the 2.0 driver).", "Description of the changes:", "EmbedDatabaseMetaData40 and NetDatabaseMetaData40 override", "getJDBCMajorVersion() and getJDBCMinorVersion().", "jdbcapi/dbMetaDataJdbc30.java was modified to print \"AS EXPECTED\"", "instead of the returned value from the JDBC version methods (of", "course, it prints something else if the version is not as", "expected).", "This was done in order to avoid the need for separate", "jdk16 canons.", "TestUtil.getJDBCMajorVersion() was updated to recognize JDBC major", "version > 3.", "Fixed a bug in build.xml in functionTests/util.", "TestUtil.java is", "incorrectly compiled with source and target level 1.4.", "It works", "correctly after an 'ant clobber' because some other 1.3 class", "depends on it and causes it to be compiled as part of another ant", "target, but if TestUtil.java is the only file that needs", "recompilation, jdk 1.4 is used.", "Derbyall runs cleanly (with the exception of the DERBY-1578 failures)", "on Sun JVM 1.5 and 1.6.", "Reviews would be greatly appreciated!", "Thanks.", "Hi Knut Anders.", "Thanks for the ample explanation of the changes.", "They look good to me.", "Thank you for looking at the patch, Rick.", "Committed revision 425987."], "SplitGT": [" Retrieves the major JDBC version number for this driver."], "issueString": "Derby JDBC 4.0 driver returns 3 for JDBC driver major version\nFor 10.2 the DatabaseMetaData.getJDBCMajorVersion() is returning \"3\" for \nthe Derby JDBC 4.0 driver.  It should return 4.  This is easily \nreproduced by running a simple test to obtain a connection and \noutput the value,\n\nDatabase product: Apache Derby\nDatabase version: 10.2.0.4 alpha\nDriver name:      Apache Derby Embedded JDBC Driver\nDriver version:   10.2.0.4 alpha\nJDBC driver major version: 3\nJDBC driver minor version: 0\n\nTest code:\n\n        \norg.apache.derby.jdbc.EmbeddedConnectionPoolDataSource40 ds =\n            new \norg.apache.derby.jdbc.EmbeddedConnectionPoolDataSource40();\n\n        \nds.setDatabaseName(\"C:\\\\drivers\\\\derby\\\\databases\\\\JDBC40DB\");\n\n        ds.setUser(\"dbuser1\");\n        ds.setPassword(\"dbpwd1\");\n\n        PooledConnection pooledConn = \nds.getPooledConnection();\n        Connection conn = pooledConn.getConnection();\n\n        System.out.println(\"Database product: \" + \nconn.getMetaData().getDatabaseProductName());\n        System.out.println(\"Database version: \" + \nconn.getMetaData().getDatabaseProductVersion());\n        System.out.println(\"Driver name:      \" + \nconn.getMetaData().getDriverName());\n        System.out.println(\"Driver version:   \" + \nconn.getMetaData().getDriverVersion());\n        System.out.println(\"JDBC driver major version: \" + \nconn.getMetaData().getJDBCMajorVersion());\n        System.out.println(\"JDBC driver minor version: \" + \nconn.getMetaData().getJDBCMinorVersion());\n\n\nRelevant Derby Embedded code in EmbedDatabaseMetaData is:\n * JDBC 3.0\n    *\n    * Retrieves the major JDBC version number for this driver.\n    *\n    * @return JDBC version major number\n\t*/\n\tpublic int getJDBCMajorVersion()\n\t{\n\t\treturn 3;\n\t}\n\nand client code in org.apache.derby.client.am.DatabaseMetaData:\npublic int getJDBCMajorVersion() throws SQLException {\n        checkForClosedConnection();\n        return 3;\n    }\n\nI am not sure if this should be JVM dependent or if it should always return 4  regardless of the JVM version.\n\n\nThis is the correct behavior if you are running on jvm 1.4 or 1.5.\n\nIf you are running on 1.6, the major version should be 4. It isn't, so this is a bug.\nderby-1546-v1.diff makes getJDBCMajorVersion() return 4 when using the\nJDBC 4.0 driver and 3 otherwise (the method was not present in JDBC\n2.0, so there is no need to return 2 for the 2.0 driver).\n\nDescription of the changes:\n\n  * EmbedDatabaseMetaData40 and NetDatabaseMetaData40 override\n    getJDBCMajorVersion() and getJDBCMinorVersion().\n\n  * jdbcapi/dbMetaDataJdbc30.java was modified to print \"AS EXPECTED\"\n    instead of the returned value from the JDBC version methods (of\n    course, it prints something else if the version is not as\n    expected). This was done in order to avoid the need for separate\n    jdk16 canons.\n\n  * TestUtil.getJDBCMajorVersion() was updated to recognize JDBC major\n    version > 3.\n\n  * Fixed a bug in build.xml in functionTests/util. TestUtil.java is\n    incorrectly compiled with source and target level 1.4. It works\n    correctly after an 'ant clobber' because some other 1.3 class\n    depends on it and causes it to be compiled as part of another ant\n    target, but if TestUtil.java is the only file that needs\n    recompilation, jdk 1.4 is used.\n\nDerbyall runs cleanly (with the exception of the DERBY-1578 failures)\non Sun JVM 1.5 and 1.6. Reviews would be greatly appreciated! Thanks.\nHi Knut Anders. Thanks for the ample explanation of the changes. They look good to me.\nThank you for looking at the patch, Rick. Committed revision 425987.\n", "issueSearchSentences": ["@return JDBC version major number", "and client code in org.apache.derby.client.am.DatabaseMetaData:", "{", "checkForClosedConnection();", "System.out.println(\"JDBC driver major version: \" +"], "issueSearchIndexes": [39, 44, 41, 46, 32]}
{"aId": 155, "code": "public static int runScript(\n\t\t  Connection conn,\n\t\t  InputStream sqlIn,\n\t\t  String inputEncoding,\n\t\t  PrintStream sqlOut,\n\t\t  String outputEncoding)\n\t\t  throws UnsupportedEncodingException\n  {\n\t  LocalizedOutput lo = \n\t\t  outputEncoding == null ?\n\t\t\t\t  LocalizedResource.getInstance().\n\t\t            getNewOutput(sqlOut)\n\t             :  \n\t\t          LocalizedResource.getInstance().\n                    getNewEncodedOutput(sqlOut, outputEncoding);\n\n\t  Main ijE;\n\t  if (JVMInfo.JDK_ID == JVMInfo.J2SE_13)\n\t  {\n\t\t  ijE = new Main(lo);\n\t  }\n\t  else\n\t  {\n\t\t  ijE = new org.apache.derby.impl.tools.ij.Main14(lo);\n\t  }\t  \n\t  \n\t  LocalizedInput li = LocalizedResource.getInstance().\n\t            getNewEncodedInput(sqlIn, inputEncoding);\n\t  \n\t  \n\t  ijE.goScript(conn, li);\n\t  \n\t  return -1;\n  }", "comment": " Run a SQL script from an InputStream and write the resulting output to the provided PrintStream.", "issueId": "DERBY-1609", "issueStringList": ["Add a runScript method to ij that takes a script as an InputStream and returns the output to a stream.", "Useful for running ij SQL scripts as part of JUnit tests and for applications to use instead of the awkward way to use ij from a program today.", "Run a SQL script from an input stream and write", "the resulting output to the provided OutputStream.", "@param conn Connection to be used as the script's default connection.", "@param sqlIn InputStream for the script.", "@param inputEncoding Encoding of the script.", "@param sqlOut OutputStream for the script's output", "@param outputEncoding Output encoding to use.", "@return Number of SQLExceptions thrown during the execution, -1 if not known.", "@throws UnsupportedEncodingException", "public static int runScript(", "Connection conn,", "InputStream sqlIn,", "String inputEncoding,", "PrintStream sqlOut,", "String outputEncoding)", "throws UnsupportedEncodingException"], "SplitGT": [" Run a SQL script from an InputStream and write the resulting output to the provided PrintStream."], "issueString": "Add a runScript method to ij that takes a script as an InputStream and returns the output to a stream.\nUseful for running ij SQL scripts as part of JUnit tests and for applications to use instead of the awkward way to use ij from a program today.\n\n  /**\n   * Run a SQL script from an input stream and write\n   * the resulting output to the provided OutputStream.\n   * \n   * @param conn Connection to be used as the script's default connection. \n   * @param sqlIn InputStream for the script.\n   * @param inputEncoding Encoding of the script.\n   * @param sqlOut OutputStream for the script's output\n   * @param outputEncoding Output encoding to use.\n   * @return Number of SQLExceptions thrown during the execution, -1 if not known.\n   * @throws UnsupportedEncodingException\n   */\n  public static int runScript(\n\t\t  Connection conn,\n\t\t  InputStream sqlIn,\n\t\t  String inputEncoding,\n\t\t  PrintStream sqlOut,\n\t\t  String outputEncoding)\n\t\t  throws UnsupportedEncodingException\n", "issueSearchSentences": ["PrintStream sqlOut,", "String inputEncoding,", "InputStream sqlIn,", "@throws UnsupportedEncodingException", "public static int runScript("], "issueSearchIndexes": [16, 15, 14, 11, 12]}
{"aId": 157, "code": "public boolean isClosed()\n        throws SQLException {\n        if (agent_.loggingEnabled()) {\n            agent_.logWriter_.traceEntry(this, \"isClosed\", !openOnClient_);\n        }\n        if (agent_.loggingEnabled()) {\n            agent_.logWriter_.traceExit(this, \"isClosed\", !openOnClient_);\n        }\n        return !openOnClient_;\n    }", "comment": " Tell whether the statement has been closed or not.", "issueId": "DERBY-953", "issueStringList": ["Add miscellaneous Statement methods introduced by JDBC 4", "As described in the JDBC 4 spec, sections 13.1 and 3.1.", "This adds support for new Statement methods added by JDBC4 and not addressed by other JIRAs: isClosed() and getResultSetHoldability().", "Uploaded patch 'DERBY-953-1a.diff' for implementing Statement.isClosed() on both client and embedded side.", "There seems to be a bug in Derby, where Statements are not closed when the parent connection is.", "The problem is not seem when testing the client side, but it might still be the case that the problem do occur \"under the hood\" on the server/embedded side.", "Created issue DERBY-1095 for the bug.", "No tests are uploaded yet, as they are dependent on some JUnit changes.", "Will be handled as a separate Jira issue.", "Derbyall has not been run for this patch, as it is only created two new methods that return variables.", "All tests will be run as part of the testing issue.", "The new tests will basically test the existing implementation.", "I leave it up to a committer if the patch is delayed until the testing is in place or not, as the patch is rather simple.", "As a side note, it is possible to implement isClosed() to return the intended values despite the bug described.", "However, in my opinion, this will only mask the bug, thus it is better to implement it as it is done in the current patch and wait for the bug to be fixed.", "If we want to have correct results despite the bug, we only need to have isClosed() check the status of the parent connection before checking it's own state, but the Statement would actually not be closed even though isClosed() says it is...", "BTW: getResultSetHoldability() is already implemented (JDBC3?", ").", "Statement.isClosed() will not return correct values on the embedded side when parent connection is closed until the blocking issue DERBY-1095 is resolved.", "'DERBY-953-2a.diff' implements EmbedStatement.isClosed() in different way.", "If the statement is marked as active, it goes to the parent connection to verify this.", "Tests have been run locally, but they are not yet submitted for commit.", "See DERBY-1097 for testing code.", "Derbyall has not been run, the patch only adds new code that is not used anywhere yet.", "Implementation is in line with the comment for the initial submission, and with the comments on DERBY-1095.", "Nothing have been changed for the client side since the previous patch.", "See 'DERBY-953-1a.stat' for svn status (unchanged).", "Please review, and when acceptable, commit.", "I don't like the approach of using an exception to determine if the statement is closed.", "I see your motivation -- you want to reuse the code that sets active to false.", "I think the better way to do this is to refactor out the code inside checkExecStatus() that sets the active field, thusly:", "protected final boolean checkActive() throws SQLException {", "if (!getConnection().isClosed())", "return true;", "active = false;", "return false;", "}", "protected final void checkExecStatus() throws SQLException {", "if ( !", "checkActive() ) {", "throw Util.noCurrentConnection();", "}", "}", "public boolean isClosed() throws SQLException {", "if ( active )", "checkActive();", "return !active;", "}", "The code snippet posted in the previous comment still has the same problem as the original code, which was the reason why I returned true in the catch block.", "A NoCurrentConnection exception can be thrown in getConnection().", "active would then still not be set to false, and isClosed would throw this exception.", "I do not like that isClosed can throw an exception in this case, and in this situation I would dare say a NoCurrentConnection is the same as the statement being closed and we could simply return true.", "So I don't quite see how the new proposal would solve the issue.", "It would also introduce yet another method for checking the state, taking the number up to three; checkStatus, checkExecStatus and checkActive.", "If you still want this to happen, give me a little more pushback, I'm not yet convinced I want to do this.", "I do however see that I could have checked that the exception thrown actually is a NoCurrentConnection exception, and then re-throw the exception if it is not.", "Would that ease your concerns?", "Sorry, I missed that about getConnection().", "But my point still stands, we shouldn't use exceptions for making decisions mainline execution.", "We can refactor getConnection() using the same approach:", "Try to get the connection.", "Returns null if it's not valid", "protected final Connection getConnectionInternal() {", "java.sql.Connection appConn = getEmbedConnection().getApplicationConnection();", "if (appConn != applicationConnection) {", "appCon = null;", "return appConn;", "}", "Check the status without throwing an exception.", "Returns true if the statement", "is active and has a valid, open connection, false otherwise", "protected final boolean checkExecNoException() {", "Connection conn = getConnectionInternal();", "if ( conn == null  || conn.isClosed() )", "active = false;", "return active;", "}", "protected final void checkExecStatus() throws SQLException {", "checkStatus();", "if ( !", "checkExecStatusNoException() )", "throw Util.noCurrentConnection()", "}", "public final java.sql.Connection getConnection() throws SQLException {", "checkStatus();", "java.sql.Connection appConn = getConnectionInternal();", "if ( appConn == null )", "throw Util.noCurrentConnection();", "}", "public final boolean isClosed() throws SQLException {", "return (  !", "active ||  checkExecStatusNoException() );", "}", "'DERBY-953-3a.diff' is a patch implementing pretty much what David suggested.", "I made some corrections, and I also had to add a try-catch block to the 'checkExecStatusNoException'-method, because we are using the Connection-interface there, not the EmbedConnection implementation.", "It is not quite clear to me if we can get another Connection-implementation there, but I have assumed so.", "If the connection is *always* an EmbedConnection, we could cast.", "Other comments:", "1) The patch has some white-space changes.", "The file contains a mix of tabs and spaces, and I chose to use spaces for the patch.", "2) The patch also has some Javadoc fixes.", "3) My StatementTest passes (embedded and DerbyNetClient, JCC excluded due to missing JDBC4 support).", "4) I ran derbyall, but made some minor changes afterwards.", "The first one passed, the second run is ongoing.", "I will report if errors occur.", "Patch can be reviewed and committed.", "I was expecting the patch to be very similar to the one for ResultSet.isClosed(), but it seems to have gained in complexity for little value.", "Not sure I understand David's comment about \"using exception for mainline decisions\", I don't see that happening in the simpler version", "of the patch (ie.", "one similar to the changes made for ResultSet.isClosed()).", "An execption is only used when the Statement is closed, that's", "not the mainline execution, it's the exception case.", "Sorry, I wasn't able to comment earlier, I've been busy,.", "I could be stubborn about my point of view, but I think that's not worthwhile.", "Dan has a good point, and Kristian has also pointed out to me that there are exceptions all the way down so there's no way to avoid catching an exception.", "So I must humbly apologize to Kristian and say I think I have to agree with Dan that the first patch is simpler and is more in line with ResultSet.isClosed().", "I would like it to check for a *specific* SQL State (e.g.", "SQLState.NO_CURRENT_CONNECTION) rather than swallow any old exception.", "I'll make that change and commit.", "David", "Why do you need to check for a specific state, the field active tells you everything you need to know?", "A ResultSet can still be open and the check methods throw no current connection, this is the case when the ResultSet is open", "in a global transaction but the transaction is detached from the connection.", "Statement may fall along the same lines.", "I think this is the correct fix, a slightly modified version of the second patch, removing the assumption that if", "checkExecStatus throws an exception that the statement is closed.", "This them matches the ResultSet.isClosed() approach.", "+     * Tell whether this statment has been closed or not.", "+     *", "+     * @return <code>true</code> is closed, <code>false</code> otherwise.", "+     * @exception SQLException if a database access error occurs.", "+     */", "+    public boolean isClosed()", "+        throws SQLException {", "+        // If active, verify state by consulting parent connection.", "+        if (active) {", "+            try {", "+                checkExecStatus();", "+            } catch (SQLException sqle) {", "+            }", "+        }", "+        return !active;", "+    }", "Thanks for your tips on this, Dan.", "Your version looks just right.", "I'll wait to hear from Kristian, but if he's OK, I can make the change you suggest and commit.", "One question on this: your example swallows *any* SqlException.", "I think this assumes that the only possible exception is going to be NO_CURRENT_CONNECTION.", "Is that a fair assumption?", "I can't say I fully understand the code.", "Shouldn't we be throwing other exceptions besides NO_CURRENT_CONNECTION?", "No, that's not the assumption I made.", "The assumption is that after a call to checkExecStatus() the active field will correctly represent the closed/open state of the Statement.", "I can add comments to three methods that are involved in this code stating what exceptions they throw if you think that will help.", "I guess I just feel uncomfortable with swallowing *all* exceptions.", "Can you explain it to me like I were a novice why that's OK in this case?", "Why wouldn't it be better to check for the specific exception?", "Not really sure what explanations you are looking for David, I just clarified the javadoc comments for EmbedStatement.checkStatus and checkExecStatus based upon a few minutes of code inspection.", "Modifying the javadoc firms up the contract this method is exposing and thus the code in isClosed() is allowed to make assumptions", "based upon that contract.", "The  checkExecStatus method only throws execeptions in two cases, one the statement is closed and two the statement is part of a non-active global transaction.", "In either of those two cases and the no exception case after the execution the active field correctly represents the open state of the Statement.", "One exception thrown is the NO_CURRENT_CONNECTION sql state, means either :", "the Statement is open but in a suspended transaction (isClosed needs to return false)", "the Statement has been closed implicitly due to its connection being closed and this is the first", "call against the Statement that has noticed the connection has been closed.", "(isClosed needs to return true)", "The other is ALREADY_CLOSED, means either :", "the Statement has been explictly closed  (isClosed needs to return true)", "the Statement has been closed implicitly and a previous checkExecStatus threw a  NO_CURRENT_CONNECTION (isClosed needs to return true)", "Thus only catching NO_CURRENT_CONNECTION would be wrong as ALREADY_CLOSED is a valid exception that could occur", "here and require isClosed() to return true.", "Thus we are left with needing to catch the two exceptions that this method can throw, which seems,", "to me, to be the same as catching everything.", "Thanks, Dan, this was what I'm looking for.", "I'm working on committing this patch."], "SplitGT": [" Tell whether the statement has been closed or not."], "issueString": "Add miscellaneous Statement methods introduced by JDBC 4\nAs described in the JDBC 4 spec, sections 13.1 and 3.1.\n\nThis adds support for new Statement methods added by JDBC4 and not addressed by other JIRAs: isClosed() and getResultSetHoldability().\nUploaded patch 'DERBY-953-1a.diff' for implementing Statement.isClosed() on both client and embedded side.\nThere seems to be a bug in Derby, where Statements are not closed when the parent connection is. The problem is not seem when testing the client side, but it might still be the case that the problem do occur \"under the hood\" on the server/embedded side. Created issue DERBY-1095 for the bug.\n\nNo tests are uploaded yet, as they are dependent on some JUnit changes. Will be handled as a separate Jira issue.\nDerbyall has not been run for this patch, as it is only created two new methods that return variables.\nAll tests will be run as part of the testing issue. The new tests will basically test the existing implementation.\n\nI leave it up to a committer if the patch is delayed until the testing is in place or not, as the patch is rather simple.\n\nAs a side note, it is possible to implement isClosed() to return the intended values despite the bug described. However, in my opinion, this will only mask the bug, thus it is better to implement it as it is done in the current patch and wait for the bug to be fixed.\nIf we want to have correct results despite the bug, we only need to have isClosed() check the status of the parent connection before checking it's own state, but the Statement would actually not be closed even though isClosed() says it is...\n\nBTW: getResultSetHoldability() is already implemented (JDBC3?).\nStatement.isClosed() will not return correct values on the embedded side when parent connection is closed until the blocking issue DERBY-1095 is resolved.\n'DERBY-953-2a.diff' implements EmbedStatement.isClosed() in different way. If the statement is marked as active, it goes to the parent connection to verify this. Tests have been run locally, but they are not yet submitted for commit. See DERBY-1097 for testing code.\nDerbyall has not been run, the patch only adds new code that is not used anywhere yet.\nImplementation is in line with the comment for the initial submission, and with the comments on DERBY-1095.\nNothing have been changed for the client side since the previous patch. See 'DERBY-953-1a.stat' for svn status (unchanged).\n\nPlease review, and when acceptable, commit.\nI don't like the approach of using an exception to determine if the statement is closed.  I see your motivation -- you want to reuse the code that sets active to false.  I think the better way to do this is to refactor out the code inside checkExecStatus() that sets the active field, thusly:\n\nprotected final boolean checkActive() throws SQLException {\n  if (!getConnection().isClosed())\n    return true;\n\n  active = false;\n  return false;\n}\n\nprotected final void checkExecStatus() throws SQLException {\n  if ( ! checkActive() ) {\n    throw Util.noCurrentConnection();\n  }\n}\n\npublic boolean isClosed() throws SQLException {\n  if ( active )\n    checkActive();\n\n  return !active;\n}\nThe code snippet posted in the previous comment still has the same problem as the original code, which was the reason why I returned true in the catch block.\nA NoCurrentConnection exception can be thrown in getConnection(). active would then still not be set to false, and isClosed would throw this exception. I do not like that isClosed can throw an exception in this case, and in this situation I would dare say a NoCurrentConnection is the same as the statement being closed and we could simply return true.\n\nSo I don't quite see how the new proposal would solve the issue. It would also introduce yet another method for checking the state, taking the number up to three; checkStatus, checkExecStatus and checkActive.\n\nIf you still want this to happen, give me a little more pushback, I'm not yet convinced I want to do this.\nI do however see that I could have checked that the exception thrown actually is a NoCurrentConnection exception, and then re-throw the exception if it is not.\nWould that ease your concerns?\n\n\n\nSorry, I missed that about getConnection().  But my point still stands, we shouldn't use exceptions for making decisions mainline execution.\n\nWe can refactor getConnection() using the same approach:\n\n/**\n * Try to get the connection.  Returns null if it's not valid\n */\nprotected final Connection getConnectionInternal() {\n    java.sql.Connection appConn = getEmbedConnection().getApplicationConnection();\n    if (appConn != applicationConnection) {\n        appCon = null;\n\n    return appConn;\n}\n\n/**\n* Check the status without throwing an exception.  Returns true if the statement\n* is active and has a valid, open connection, false otherwise\n*/\nprotected final boolean checkExecNoException() {\n    Connection conn = getConnectionInternal();\n    if ( conn == null  || conn.isClosed() )\n      active = false;\n\n    return active;\n}\n\nprotected final void checkExecStatus() throws SQLException {\n   checkStatus();\n\n   if ( ! checkExecStatusNoException() )\n       throw Util.noCurrentConnection()\n}\n\npublic final java.sql.Connection getConnection() throws SQLException {\n    checkStatus();\n\n    java.sql.Connection appConn = getConnectionInternal();\n\n    if ( appConn == null ) \n        throw Util.noCurrentConnection();\n}\n\npublic final boolean isClosed() throws SQLException {\n    return (  ! active ||  checkExecStatusNoException() );\n}\n\n  \n'DERBY-953-3a.diff' is a patch implementing pretty much what David suggested. I made some corrections, and I also had to add a try-catch block to the 'checkExecStatusNoException'-method, because we are using the Connection-interface there, not the EmbedConnection implementation. It is not quite clear to me if we can get another Connection-implementation there, but I have assumed so. If the connection is *always* an EmbedConnection, we could cast.\n\nOther comments:\n1) The patch has some white-space changes. The file contains a mix of tabs and spaces, and I chose to use spaces for the patch.\n2) The patch also has some Javadoc fixes.\n3) My StatementTest passes (embedded and DerbyNetClient, JCC excluded due to missing JDBC4 support).\n4) I ran derbyall, but made some minor changes afterwards. The first one passed, the second run is ongoing. I will report if errors occur.\n\nPatch can be reviewed and committed.\nI was expecting the patch to be very similar to the one for ResultSet.isClosed(), but it seems to have gained in complexity for little value.\n\nNot sure I understand David's comment about \"using exception for mainline decisions\", I don't see that happening in the simpler version\nof the patch (ie. one similar to the changes made for ResultSet.isClosed()). An execption is only used when the Statement is closed, that's\nnot the mainline execution, it's the exception case.\n\nSorry, I wasn't able to comment earlier, I've been busy,.\nI could be stubborn about my point of view, but I think that's not worthwhile.  Dan has a good point, and Kristian has also pointed out to me that there are exceptions all the way down so there's no way to avoid catching an exception.\n\nSo I must humbly apologize to Kristian and say I think I have to agree with Dan that the first patch is simpler and is more in line with ResultSet.isClosed().\n\nI would like it to check for a *specific* SQL State (e.g. SQLState.NO_CURRENT_CONNECTION) rather than swallow any old exception.   I'll make that change and commit.\n\nDavid\nWhy do you need to check for a specific state, the field active tells you everything you need to know?\n\nA ResultSet can still be open and the check methods throw no current connection, this is the case when the ResultSet is open\nin a global transaction but the transaction is detached from the connection.\n\nStatement may fall along the same lines.\n\n\nI think this is the correct fix, a slightly modified version of the second patch, removing the assumption that if\ncheckExecStatus throws an exception that the statement is closed. This them matches the ResultSet.isClosed() approach.\n\n     /**\n+     * Tell whether this statment has been closed or not.\n+     *\n+     * @return <code>true</code> is closed, <code>false</code> otherwise.\n+     * @exception SQLException if a database access error occurs.\n+     */\n+    public boolean isClosed() \n+        throws SQLException {\n+        // If active, verify state by consulting parent connection.\n+        if (active) {\n+            try {\n+                checkExecStatus();\n+            } catch (SQLException sqle) {\n+            }\n+        }\n+        return !active;\n+    }\nThanks for your tips on this, Dan.  Your version looks just right.  I'll wait to hear from Kristian, but if he's OK, I can make the change you suggest and commit.\nOne question on this: your example swallows *any* SqlException.  I think this assumes that the only possible exception is going to be NO_CURRENT_CONNECTION.  Is that a fair assumption?  I can't say I fully understand the code.  Shouldn't we be throwing other exceptions besides NO_CURRENT_CONNECTION?\nNo, that's not the assumption I made. The assumption is that after a call to checkExecStatus() the active field will correctly represent the closed/open state of the Statement. I can add comments to three methods that are involved in this code stating what exceptions they throw if you think that will help.\nI guess I just feel uncomfortable with swallowing *all* exceptions.  Can you explain it to me like I were a novice why that's OK in this case?  Why wouldn't it be better to check for the specific exception?\nNot really sure what explanations you are looking for David, I just clarified the javadoc comments for EmbedStatement.checkStatus and checkExecStatus based upon a few minutes of code inspection. Modifying the javadoc firms up the contract this method is exposing and thus the code in isClosed() is allowed to make assumptions\nbased upon that contract.\n\nThe  checkExecStatus method only throws execeptions in two cases, one the statement is closed and two the statement is part of a non-active global transaction.\nIn either of those two cases and the no exception case after the execution the active field correctly represents the open state of the Statement.\n\nOne exception thrown is the NO_CURRENT_CONNECTION sql state, means either :\n                    the Statement is open but in a suspended transaction (isClosed needs to return false)\n                    the Statement has been closed implicitly due to its connection being closed and this is the first\n                    call against the Statement that has noticed the connection has been closed. (isClosed needs to return true)\n\nThe other is ALREADY_CLOSED, means either :\n                     the Statement has been explictly closed  (isClosed needs to return true)\n                     the Statement has been closed implicitly and a previous checkExecStatus threw a  NO_CURRENT_CONNECTION (isClosed needs to return true)\n\n\nThus only catching NO_CURRENT_CONNECTION would be wrong as ALREADY_CLOSED is a valid exception that could occur\nhere and require isClosed() to return true. Thus we are left with needing to catch the two exceptions that this method can throw, which seems,\nto me, to be the same as catching everything.\n\n\n\nThanks, Dan, this was what I'm looking for.  I'm working on committing this patch.\n", "issueSearchSentences": ["}", "}", "+     */", "protected final boolean checkActive() throws SQLException {", "protected final void checkExecStatus() throws SQLException {"], "issueSearchIndexes": [43, 89, 132, 32, 38]}
{"aId": 159, "code": "public StringDataValue getValue(RuleBasedCollator collatorForComparison)\n\t{\n\t\tif (collatorForComparison != null)\n\t\t{\n\t\t\t//non-null collatorForComparison means use this collator sensitive\n\t\t\t//implementation of SQLChar\n\t\t    setCollator(collatorForComparison);\n\t\t    return this;\t\t\t\n\t\t} else {\n\t\t\t//null collatorForComparison means use UCS_BASIC for collation.\n\t\t\t//For that, we need to use the base class SQLChar\n\t\t\tSQLChar s = new SQLChar();\n\t\t\ts.copyState(this);\n\t\t\treturn s;\n\t\t}\n\t}", "comment": " We do not anticipate this method on collation sensitive DVD to be ever called in Derby 10.3 In future, when Derby will start supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs.", "issueId": "DERBY-2534", "issueStringList": ["Add new api \"public StringDataValue getValue(RuleBasedCollator)\" on StringDataValue.", "This method will return either the base DVDs for char datatypes or it will return collation sensitive DVD for char datatypes.", "In Derby 10.3, the collation of char datatypes can be different depending on what kind of collation is requested by the user at the database create time through the optional JDBC url attribute COLLATION.", "The collation type associated with the DTD will determine which kind of DVD needs to be generated.", "(Note that, irrespective of what collation is used, the format id of the char datatypes remain same.)", "In order to support this behavior of generating the base DVD or the collation sensitive DVD for character datatypes, we need to add a new api to StringDataValue which will look as follows", "Gets either SQLChar/SQLVarchar/SQLLongvarchar/SQLClob(base classes) or", "CollatorSQLChar/CollatorSQLVarchar/CollatorSQLLongvarch/CollatorSQLClob", "(subclasses).", "Whether this method returns the base class or the subclass", "depends on the value of the RuleBasedCollator.", "If RuleBasedCollator is", "null, then the object returned would be baseclass otherwise it would be", "subcalss.", "public StringDataValue getValue(RuleBasedCollator collatorForComparison);", "I am attaching a patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt to this Jira entry which I plan to commit soon.", "The patch adds a new api to StringDataValue interface and the new api looks as follows", "public StringDataValue getValue(RuleBasedCollator collatorForComparison);", "The new api will be needed in quite a few different places.", "2 distinct uses that I can see at this point are", "1)Store will have a format id and collation type when it is trying to construct a DVD template.", "Using the formatid, we will first always get the base class DVD for char datatypes namely SQLChar, SQLVarchar, SQLLongvarchar or SQLClob.", "Next, if the collation type is not 0  ie it is not UCS_BASIC, then we want to use Collation sensitive DVDs of base char DVDs because we want to use the passed Collator for collation rather than the default UCS_BASIC Collator.", "The collation sensitive DVDs of char datatypes are CollatorSQLChar, CollatorSQLVarchar, CollatorSQLLongvarchar and CollatorSQLClob.", "In order to derive these collation sensitive DVDs of character datatypes, we will use this new api called getValue on base character DVDs.", "The getValue method will have the Collator object as parameter to it.", "If the Collator object is null, then we can continue to use the base DVD.", "But if the Collator object is not null, then we want to construct collation sensitive DVD.", "The new api on StringDataValue will help achieve this behavior.", "2)Another place which I can envision using this new api is in DataTypeDescriptor.getNull() method which returns a DVD.", "Currently, the implementation of this method looks as follows", "public DataValueDescriptor getNull() {", "return typeId.getNull();", "}", "So, if the typeid of DTD is character data type, this method will always return base char DVD, no matter what is the collation type of the DTD.", "But, if the DTD has a territory based collation set for it, then this method should return collation sensitive char DVD.", "This functionality can be achieved by using the new api on StringDataValue.", "I do not anticipate this new method ever getting called on collation sensitive DVDs in Derby 10.3 In future, when Derby will start  supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs but for Derby 10.3, the new api in collation sensitive DVDs is just a place holder.", "Another change to note is I changed all the collation sensitive subclasses to have their method setCollator changed from private to protected.", "This is so that the getValue method from their correspoding base classes can call the setCollator method on subclasses.", "The files changed by this patch are", "svn stat -q", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLLongvarchar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\StringDataValue.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLChar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLClob.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLVarchar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLChar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLClob.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLVarchar.java", "M      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLLongvarchar.java", "The code compiles ok with my changes.", "None of the tests should get impacted because currently, this new api on StringDataValue is  not called by any other code in Derby.", "Just commited the patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt with revision 526668.", "If anyone has any feedback, please share them.", "I will address them in subsequent patches."], "SplitGT": [" We do not anticipate this method on collation sensitive DVD to be ever called in Derby 10.3 In future, when Derby will start supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs."], "issueString": "Add new api \"public StringDataValue getValue(RuleBasedCollator)\" on StringDataValue. This method will return either the base DVDs for char datatypes or it will return collation sensitive DVD for char datatypes.\nIn Derby 10.3, the collation of char datatypes can be different depending on what kind of collation is requested by the user at the database create time through the optional JDBC url attribute COLLATION. The collation type associated with the DTD will determine which kind of DVD needs to be generated. (Note that, irrespective of what collation is used, the format id of the char datatypes remain same.) In order to support this behavior of generating the base DVD or the collation sensitive DVD for character datatypes, we need to add a new api to StringDataValue which will look as follows\n\n\t/**\n\t * Gets either SQLChar/SQLVarchar/SQLLongvarchar/SQLClob(base classes) or \n\t * CollatorSQLChar/CollatorSQLVarchar/CollatorSQLLongvarch/CollatorSQLClob\n\t * (subclasses). Whether this method returns the base class or the subclass \n\t * depends on the value of the RuleBasedCollator. If RuleBasedCollator is \n\t * null, then the object returned would be baseclass otherwise it would be \n\t * subcalss.\n\t */\n\tpublic StringDataValue getValue(RuleBasedCollator collatorForComparison);\n\nI am attaching a patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt to this Jira entry which I plan to commit soon. The patch adds a new api to StringDataValue interface and the new api looks as follows\npublic StringDataValue getValue(RuleBasedCollator collatorForComparison);\n\nThe new api will be needed in quite a few different places. 2 distinct uses that I can see at this point are\n1)Store will have a format id and collation type when it is trying to construct a DVD template. Using the formatid, we will first always get the base class DVD for char datatypes namely SQLChar, SQLVarchar, SQLLongvarchar or SQLClob. Next, if the collation type is not 0  ie it is not UCS_BASIC, then we want to use Collation sensitive DVDs of base char DVDs because we want to use the passed Collator for collation rather than the default UCS_BASIC Collator. The collation sensitive DVDs of char datatypes are CollatorSQLChar, CollatorSQLVarchar, CollatorSQLLongvarchar and CollatorSQLClob. In order to derive these collation sensitive DVDs of character datatypes, we will use this new api called getValue on base character DVDs. The getValue method will have the Collator object as parameter to it. If the Collator object is null, then we can continue to use the base DVD. But if the Collator object is not null, then we want to construct collation sensitive DVD. The new api on StringDataValue will help achieve this behavior.\n2)Another place which I can envision using this new api is in DataTypeDescriptor.getNull() method which returns a DVD. Currently, the implementation of this method looks as follows\n\tpublic DataValueDescriptor getNull() {\n\t\treturn typeId.getNull();\n\t}\nSo, if the typeid of DTD is character data type, this method will always return base char DVD, no matter what is the collation type of the DTD. But, if the DTD has a territory based collation set for it, then this method should return collation sensitive char DVD. This functionality can be achieved by using the new api on StringDataValue.\n\nI do not anticipate this new method ever getting called on collation sensitive DVDs in Derby 10.3 In future, when Derby will start  supporting SQL standard COLLATE clause, this method might get called on the collation sensitive DVDs but for Derby 10.3, the new api in collation sensitive DVDs is just a place holder.\n\nAnother change to note is I changed all the collation sensitive subclasses to have their method setCollator changed from private to protected. This is so that the getValue method from their correspoding base classes can call the setCollator method on subclasses.\n\nThe files changed by this patch are\nsvn stat -q\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLLongvarchar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\StringDataValue.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLChar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLClob.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLVarchar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLChar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLClob.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\SQLVarchar.java\nM      java\\engine\\org\\apache\\derby\\iapi\\types\\CollatorSQLLongvarchar.java\n\nThe code compiles ok with my changes. None of the tests should get impacted because currently, this new api on StringDataValue is  not called by any other code in Derby.\n\nJust commited the patch DERBY2534_getValue_On_StringDataValue_v1_diff.txt with revision 526668. If anyone has any feedback, please share them. I will address them in subsequent patches.\n", "issueSearchSentences": ["subcalss.", "The patch adds a new api to StringDataValue interface and the new api looks as follows", "The getValue method will have the Collator object as parameter to it.", "Using the formatid, we will first always get the base class DVD for char datatypes namely SQLChar, SQLVarchar, SQLLongvarchar or SQLClob.", "Add new api \"public StringDataValue getValue(RuleBasedCollator)\" on StringDataValue."], "issueSearchIndexes": [14, 17, 26, 22, 1]}
{"aId": 160, "code": "public  String  vtiTable()  { return _vtiTable; }", "comment": " Return the unqualified table function name", "issueId": "DERBY-6117", "issueStringList": ["Extend the Table Functions java interface to pass more query context information from Derby", "General requirement is to extend the Table Functions java interface (through RestrictedVTI or another interface) and pass more context information from Derby to Table Functions - esp in query execution phase.", "Greater urgency is required for the first 2 items below, especially the ability to access the original SQL which was available with VTIs.", "This is critical to the GaianDB project - we extract HINTs from the query (where we pass meta data like user credentials), and also extract full original complex predicate expressions (involving functions etc - which cannot be expressed with a Restriction) - to push on in our query prorogation...", "In order of importance + simplicity:", "1 - Original SQL (this used to be available with VTIs through VTIEnvironment for both compilation and execution phases)", "2 - Name of function that was called", "3 - User Info (ID, etc) - (this can currently be passed in the SQL hint)", "4 - Richer predicate expressions (incl functions, etc)", "5 - Context within Join query (e.g.", "inner or outer table, join type)", "6 - Other Query Plan information", "7 - Anything else...?", "Original forum discussion:", "http://apache-database.10148.n7.nabble.com/Limitations-of-Table-Functions-vs-old-VTIs-td127988.html#a127995", "i agree with all above, especially the name of the function called.", "adding information from", "https://issues.apache.org/jira/browse/DERBY-6115", "1) derby should support passing IN to initScan", "2) derby should transform IN to an OR clause as a work around to not passing down IN scan", "3) function should have access to information about the function's return type, i.e.", "the if the result type is a table definition, function should have access to that definition.", "this is necessary when a function is declared with multiple names and return types.", "for example, with foreign table loads, we want to pre-transform data from remote result set in 1 thread, then hand to derby thread.", "we need to know what the main derby thread reading resultset wants in sqltype for each column.", "4) derby should introspect resultset to see which column names are searchable, and thus, fast for querying,  perhaps isSearchable on ResultSetMetaData is the right / wrong thing to do.", "maybe can do this with VTIConsting ?", "5) derby should do multi-probe on vti function if vti function indicates on a metaData that isSearchable is true, or that it implements perfectly the initscan restriction.", "6) vti function should be able to tell derby that it correctly implements the vti restriction, either for a given one, or for any, and derby should not request the column in initscan columnNames, and derby  should not check again the restriction.", "( for example, assume foreign table with username and picture as BLOB) , a query for select username where picture is not null, currently, derby will pass select username and picture as columnnames, and function will have to pull all the username and blob data and hand to derby, just to allow derby to check again is not null, even though function already did this .", "This is a HUGE performance issue we are experiencing.", "i'm sure i'll have more issues to add :)", "Note that part of item (3) can be obtained by calling DriverManager.getConnection( \"jdbc:default:connection\" ) in order to get the connection and then executing a \"values current_user\" statement.", "\ufeff\ufeffAttaching derby-6117-01-aa-AwareVTI.diff.", "This patch introduces the AwareVTI interface.", "This is a first step toward giving table functions more context about their execution environments.", "I am running tests now.", "Introduces two new classes/interfaces:", "o VTIContext - This is a simple class which contains the following information:", "The name of the schema holding the table function.", "The non-schema-qualified name of the table function.", "The text of the statement invoking the table function.", "o AwareVTI - Table functions which implement this interface are handed the VTIContext describing their execution environment.", "VTITemplate now implements AwareVTI so most table functions will get this functionality for free.", "VTIContext exposes the following methods:", "{noformat}", "public  String  vtiSchema() { return _vtiSchema; }", "public  String  vtiTable()  { return _vtiTable; }", "public  String  statementText() { return _statementText; }", "{noformat}", "AwareVTI contains these method:", "{noformat}", "public  VTIContext  getContext();", "public  void    setContext( VTIContext context );", "{noformat}", "Touches the following files:", "A       java/engine/org/apache/derby/vti/VTIContext.java", "A       java/engine/org/apache/derby/vti/AwareVTI.java", "M       java/engine/org/apache/derby/vti/VTITemplate.java", "Introduces the new classes and wires them into most existing table functions.", "M       java/engine/org/apache/derby/iapi/sql/execute/ResultSetFactory.java", "M       java/engine/org/apache/derby/impl/sql/compile/MethodCallNode.java", "M       java/engine/org/apache/derby/impl/sql/compile/FromVTI.java", "M       java/engine/org/apache/derby/impl/sql/compile/StaticMethodCallNode.java", "M       java/engine/org/apache/derby/impl/sql/execute/GenericResultSetFactory.java", "M       java/engine/org/apache/derby/impl/sql/execute/VTIResultSet.java", "Compile-time and execution-time machinery to support VTIContext.", "A       java/testing/org/apache/derbyTesting/functionTests/tests/lang/AwareVTITest.java", "A       java/testing/org/apache/derbyTesting/functionTests/tests/lang/DummyAwareVTI.java", "M       java/testing/org/apache/derbyTesting/functionTests/tests/lang/_Suite.java", "Basic tests for this new feature.", "M       tools/javadoc/publishedapi.ant", "Adds AwareVTI and VTIContext to the public api.", "Attaching derby-6117-01-ab-AwareVTI.diff.", "This fixes an NPE during compilation of old-style VTIs, introduced by the previous rev of the patch.", "Re-starting the tests.", "Touches the same files as the previous rev.", "Tests passed cleanly for me on derby-6117-01-ab-AwareVTI.diff except for the query plan instability recently introduced into org.apache.derbyTesting.functionTests.tests.lang.SelectivityTest by other work."], "SplitGT": [" Return the unqualified table function name"], "issueString": "Extend the Table Functions java interface to pass more query context information from Derby\nGeneral requirement is to extend the Table Functions java interface (through RestrictedVTI or another interface) and pass more context information from Derby to Table Functions - esp in query execution phase.\n\nGreater urgency is required for the first 2 items below, especially the ability to access the original SQL which was available with VTIs. This is critical to the GaianDB project - we extract HINTs from the query (where we pass meta data like user credentials), and also extract full original complex predicate expressions (involving functions etc - which cannot be expressed with a Restriction) - to push on in our query prorogation...\n\nIn order of importance + simplicity:\n--------------------------------------------------\n1 - Original SQL (this used to be available with VTIs through VTIEnvironment for both compilation and execution phases)\n2 - Name of function that was called\n\n3 - User Info (ID, etc) - (this can currently be passed in the SQL hint)\n4 - Richer predicate expressions (incl functions, etc)\n5 - Context within Join query (e.g. inner or outer table, join type)\n6 - Other Query Plan information\n7 - Anything else...?\n\nOriginal forum discussion:\nhttp://apache-database.10148.n7.nabble.com/Limitations-of-Table-Functions-vs-old-VTIs-td127988.html#a127995\ni agree with all above, especially the name of the function called.\n\nadding information from\n\nhttps://issues.apache.org/jira/browse/DERBY-6115\n\n1) derby should support passing IN to initScan\n2) derby should transform IN to an OR clause as a work around to not passing down IN scan\n3) function should have access to information about the function's return type, i.e. the if the result type is a table definition, function should have access to that definition.  this is necessary when a function is declared with multiple names and return types.  for example, with foreign table loads, we want to pre-transform data from remote result set in 1 thread, then hand to derby thread.  we need to know what the main derby thread reading resultset wants in sqltype for each column. \n4) derby should introspect resultset to see which column names are searchable, and thus, fast for querying,  perhaps isSearchable on ResultSetMetaData is the right / wrong thing to do.  maybe can do this with VTIConsting ?\n5) derby should do multi-probe on vti function if vti function indicates on a metaData that isSearchable is true, or that it implements perfectly the initscan restriction.\n6) vti function should be able to tell derby that it correctly implements the vti restriction, either for a given one, or for any, and derby should not request the column in initscan columnNames, and derby  should not check again the restriction. ( for example, assume foreign table with username and picture as BLOB) , a query for select username where picture is not null, currently, derby will pass select username and picture as columnnames, and function will have to pull all the username and blob data and hand to derby, just to allow derby to check again is not null, even though function already did this .  This is a HUGE performance issue we are experiencing.  \n\ni'm sure i'll have more issues to add :)\nNote that part of item (3) can be obtained by calling DriverManager.getConnection( \"jdbc:default:connection\" ) in order to get the connection and then executing a \"values current_user\" statement.\n\ufeff\ufeffAttaching derby-6117-01-aa-AwareVTI.diff. This patch introduces the AwareVTI interface. This is a first step toward giving table functions more context about their execution environments. I am running tests now.\n\nIntroduces two new classes/interfaces:\n\no VTIContext - This is a simple class which contains the following information:\n\n  - The name of the schema holding the table function.\n  - The non-schema-qualified name of the table function.\n  - The text of the statement invoking the table function.\n\no AwareVTI - Table functions which implement this interface are handed the VTIContext describing their execution environment.\n\nVTITemplate now implements AwareVTI so most table functions will get this functionality for free.\n\nVTIContext exposes the following methods:\n\n{noformat}\n    /** Return the name of the schema holding the table function */\n    public  String  vtiSchema() { return _vtiSchema; }\n\n    /** Return the unqualified table function name */\n    public  String  vtiTable()  { return _vtiTable; }\n\n    /** Return the text of the statement which invoked the table function */\n    public  String  statementText() { return _statementText; }\n{noformat}\n\nAwareVTI contains these method:\n\n{noformat}\n    /** Get the table function context */\n    public  VTIContext  getContext();\n\n    /** Set the table function context */\n    public  void    setContext( VTIContext context );\n{noformat}\n\n\n\nTouches the following files:\n\n----------------\n\nA       java/engine/org/apache/derby/vti/VTIContext.java\nA       java/engine/org/apache/derby/vti/AwareVTI.java\nM       java/engine/org/apache/derby/vti/VTITemplate.java\n\nIntroduces the new classes and wires them into most existing table functions.\n\n----------------\n\nM       java/engine/org/apache/derby/iapi/sql/execute/ResultSetFactory.java\nM       java/engine/org/apache/derby/impl/sql/compile/MethodCallNode.java\nM       java/engine/org/apache/derby/impl/sql/compile/FromVTI.java\nM       java/engine/org/apache/derby/impl/sql/compile/StaticMethodCallNode.java\nM       java/engine/org/apache/derby/impl/sql/execute/GenericResultSetFactory.java\nM       java/engine/org/apache/derby/impl/sql/execute/VTIResultSet.java\n\nCompile-time and execution-time machinery to support VTIContext.\n\n----------------\n\nA       java/testing/org/apache/derbyTesting/functionTests/tests/lang/AwareVTITest.java\nA       java/testing/org/apache/derbyTesting/functionTests/tests/lang/DummyAwareVTI.java\nM       java/testing/org/apache/derbyTesting/functionTests/tests/lang/_Suite.java\n\nBasic tests for this new feature.\n\n----------------\n\nM       tools/javadoc/publishedapi.ant\n\nAdds AwareVTI and VTIContext to the public api.\n\nAttaching derby-6117-01-ab-AwareVTI.diff. This fixes an NPE during compilation of old-style VTIs, introduced by the previous rev of the patch. Re-starting the tests.\n\nTouches the same files as the previous rev.\n\nTests passed cleanly for me on derby-6117-01-ab-AwareVTI.diff except for the query plan instability recently introduced into org.apache.derbyTesting.functionTests.tests.lang.SelectivityTest by other work.\n", "issueSearchSentences": ["public  String  vtiSchema() { return _vtiSchema; }", "{noformat}", "public  String  vtiTable()  { return _vtiTable; }", "{noformat}", "public  VTIContext  getContext();"], "issueSearchIndexes": [47, 46, 48, 52, 53]}
